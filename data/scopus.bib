Scopus
EXPORT DATE: 21 May 2025

@ARTICLE{Lu2025231,
	author = {Lu, Alvin Liang Hao and Iwaihara, Mizuho},
	title = {Using Annotator Labels Instead of Golden Labels for Fine Emotion Detection},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15493 LNCS},
	pages = {231 – 245},
	doi = {10.1007/978-981-96-0865-2_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213066855&doi=10.1007%2f978-981-96-0865-2_19&partnerID=40&md5=aa57dc21fc7e22f5e3bf8e5f4e34436e},
	affiliations = {Graduate School of Information, Production and Systems, Waseda University, Kitakyushu, Japan},
	abstract = {Textual fine-emotion detection is a challenging task that has yet to achieve powerful performance in both Language model (LM) and Large Language models (LLM). In this paper, we analyze a fine-emotion dataset and current approaches to provide insight of existing issues. We propose the idea of treating fine-emotion detection as having multiple appropriate answers, and to consider annotator-level labels instead of the golden label. We then evaluated treating neutral label separately and using LLM as aid for mistake filtering and augmentation. We show that using annotator labels instead of golden label allows BERT model to predict different interpretations without being penalized despite the weaker performance. Large potential has yet to be explored on annotator-level label fine-emotion detection and we provide several ideas through the approaches evaluated and the analysis of these approaches. We hope to encourage a change in how fine-emotion detection is detected, allowing multiple accurate answers instead of one. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {BERT; ChatGPT; Fine Emotion Detection; Large Language Model; Llama3},
	keywords = {Speech recognition; 'current; BERT; ChatGPT; Emotion detection; Fine emotion detection; Language model; Large language model; Llama3; Performance; Emotion Recognition},
	correspondence_address = {A.L.H. Lu; Graduate School of Information, Production and Systems, Waseda University, Kitakyushu, Japan; email: alvinlhlu@moegi.waseda.jp},
	editor = {Oliver G. and Frings-Hessami V. and Du J.T. and Tezuka T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981960864-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shrestha2025,
	author = {Shrestha, Rabin and Ko, Taewoo and Lee, Jeehee},
	title = {Quantifying Project Uncertainties: Leveraging Historical Bid and Change Order Data for Automated Detection of Cost and Schedule Impacts in New Projects},
	year = {2025},
	journal = {Journal of Construction Engineering and Management},
	volume = {151},
	number = {4},
	doi = {10.1061/JCEMD4.COENG-15689},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217615395&doi=10.1061%2fJCEMD4.COENG-15689&partnerID=40&md5=afa161ca7a28cbcb610a43bf1233b458},
	affiliations = {Civil and Environmental Engineering and Construction, Howard R. Hughes College of Engineering, Univ. of Nevada, Las Vegas, 89154, NV, United States; College of Architecture, Kookmin Univ., Seoul, 02707, South Korea; School of Architecture and Building Science, Chung-Ang Univ., Seoul, 06974, South Korea},
	abstract = {Unexpected uncertainties often arise during construction project execution, impacting performance measures such as time, budget, scope, and quality. This study addresses these cost and schedule challenges by creating an automated risk management model that utilizes natural language processing (NLP) techniques. NLP techniques are powerful tools that can process and analyze natural language data, allowing us to uncover valuable insights from textual data. This method enables the extraction of meaningful information from bid, contract, and change order documentation. The bidirectional encoder representations from transformers (BERT) model, a widely recognized transformer-based model, transforms words and phrases into numerical representations. After that, cosine similarity is used to assess the similarity between new and old projects. All these techniques allow us to predict potential costs and schedule changes for upcoming projects based on data from past similar projects. The research question of this study is: How can historical bidding and change order documents be utilized to forecast uncertainties in project cost and schedule for new projects? To address this question, the authors proposed an approach using NLP, BERT, and cosine similarity to extract the relevant data from past similar projects to forecast the cost and schedule changes for upcoming new projects, thus providing proactive insights for project management. Using a case study of 113 projects, out of which 20% were set aside for testing, the model achieved an accuracy of 78.30% in forecasting cost changes and 75.0% in forecasting schedule changes, with an overall accuracy of more than 75% in predicting changes. This finding demonstrates the model's efficacy in anticipating project uncertainties, thus significantly contributing to improved project management. This data-driven approach to managing uncertainties ultimately enhances overall project success and performance by allowing construction professionals to anticipate and address potential risks and variations proactively. © 2025 American Society of Civil Engineers.},
	author_keywords = {Change order; Construction bid documents; Cost; Lage language model (LLM); Natural language processing (NLP); Project uncertainties; Schedule},
	keywords = {Cosine transforms; Costs; Data accuracy; Electric transformer testing; Information management; Natural language processing systems; Project management; Risk assessment; Risk management; Change order; Construction bid document; Cost and schedule; Lage language model; Language model; Language processing; Natural language processing; Natural languages; Project uncertainty; Schedule; Budget control},
	correspondence_address = {J. Lee; School of Architecture and Building Science, Chung-Ang Univ., Seoul, 06974, South Korea; email: jhlee0404@cau.ac.kr},
	publisher = {American Society of Civil Engineers (ASCE)},
	issn = {07339364},
	coden = {JCEMD},
	language = {English},
	abbrev_source_title = {J Constr Eng Manage},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Presa2025460,
	author = {Presa, João Paulo Cavalcante and Camilo Junior, Celso Gonçalves and Oliveira, Sávio Salvarino Teles de},
	title = {Evaluating Large Language Models for Tax Law Reasoning},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15412 LNAI},
	pages = {460 – 474},
	doi = {10.1007/978-3-031-79029-4_32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219187432&doi=10.1007%2f978-3-031-79029-4_32&partnerID=40&md5=33b751f5d154a5459997d7dd5d2e2963},
	affiliations = {Federal University of Goias (UFG), Goiânia, Brazil},
	abstract = {The ability to reason over laws is essential for legal professionals, facilitating interpreting and applying legal principles to complex real-world situations. Tax laws are crucial for funding government functions and shaping economic behavior, yet their interpretation poses challenges due to their complexity, constant evolution, and susceptibility to differing viewpoints. Large Language Models (LLMs) show considerable potential in supporting this reasoning process by processing extensive legal texts and generating relevant information. This study evaluates the performance of LLMs in legal reasoning within the domain of tax law for legal entities, utilizing a dataset of real-world questions and expert answers in Brazilian Portuguese. We employed quantitative metrics (BLEU, ROUGE) and qualitative assessment using a solid LLM to ensure factual accuracy and relevance. A novel dataset was curated, comprising genuine questions from legal entities in tax law, answered by legal experts with corresponding legal texts. The evaluation includes both open-source and proprietary LLMs, providing a assessment of their effectiveness in legal reasoning tasks. The strong correlation between robust LLM evaluator metric and Bert Score F1 suggests these metrics effectively capture semantic aspects pertinent to human-perceived quality. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Large Language Models (LLMs); Legal Question Answering; Legal Reasoning; Tax Law},
	keywords = {Government data processing; Laws and legislation; Taxation; Language model; Large language model; Legal entities; Legal principles; Legal question answering; Legal questions; Legal reasoning; Legal texts; Question Answering; Tax laws; Semantics},
	correspondence_address = {J.P.C. Presa; Federal University of Goias (UFG), Goiânia, Brazil; email: joaopaulop@discente.ufg.br},
	editor = {Paes A. and Verri F.A.N.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303179028-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {37th Australasian Joint Conference on Artificial Intelligence, AJCAI 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15443 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210837397&partnerID=40&md5=8512d7bd486d356a58aa3d33ef654628},
	abstract = {The proceedings contain 62 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Highlighting Case Studies in LLM Literature Review of Interdisciplinary System Science; legal Judgment Prediction Through Argument Analysis; conditional Prototypical Optimal Transport for Enhanced Clue Identification in Multiple Choice Question Answering; REFINE on Scarce Data: Retrieval Enhancement Through Fine-Tuning via Model Fusion of Embedding Models; Leveraging LLM in Genetic Programming Hyper-heuristics for Dynamic Microservice Deployment; bidirectional Dependency Representation Disentanglement for Time Series Classification; SCODA - Framework for Software Capability Representation and Inspection; some Considerations for the Preservation of Endangered Languages Using Low-Resource Machine Translation; improving Intersectional Group Fairness Using Conditional Generative Adversarial Network and Transfer Learning; GPT-4 Attempting to Attack AI-Text Detectors; Charting a Fair Path: FaGGM Fairness-Aware Generative Graphical Models; shedding Light on Greenwashing: Explainable Machine Learning for Green Ad Detection; Beyond Factualism: A Study of LLM Calibration Through the Lens of Conversational Emotion Recognition; ensuring Fairness in Stochastic Multi-armed Bandit Problems for Effective Group Recommendations; human Decision-Making Concepts with Goal-Oriented Reasoning for Explainable Deep Reinforcement Learning; towards Explainable Deep Learning for Non-melanoma Skin Cancer Diagnosis; Localization System Enhanced with CDLPE: A Low-Cost, Resilient Map-Matching Algorithm; FocDepthFormer: Transformer with Latent LSTM for Depth Estimation from Focal Stack; TSI: A Multi-view Representation Learning Approach for Time Series Forecasting; climate Downscaling Monthly Coastal Sea Surface Temperature Using Convolutional Neural Network and Composite Loss; DBSSM: Deep BERT-Based Semantic Skill Matching from Resumes to a Public Skill Taxonomy; Designing an Adaptive AI System for Operation on Board the SpIRIT Nano-Satellite; LSTM Autoencoder-Based Deep Neural Networks for Barley Genotype-to-Phenotype Prediction; an Improved Prescriptive Tree-Based Model for Stochastic Parallel Machine Scheduling; Economic Graph Lottery Ticket: A GNN Based Economic Forecasting Model; pattern-Based Trading by Continual Learning of Price and Volume Patterns.},
	editor = {Gong M. and Song Y. and Koh Y.S. and Xiang W. and Wang D.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981960350-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hsu2025,
	author = {Hsu, Enshuo and Roberts, Kirk},
	title = {Leveraging large language models for knowledge-free weak supervision in clinical natural language processing},
	year = {2025},
	journal = {Scientific Reports},
	volume = {15},
	number = {1},
	doi = {10.1038/s41598-024-68168-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000745146&doi=10.1038%2fs41598-024-68168-2&partnerID=40&md5=ba92229e5397996270cde5ec502eb85e},
	affiliations = {McWilliams School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, TX, United States; Center for Health Data Science and Analytics, Houston Methodist, Houston, TX, United States; Enterprise Development and Integration, University of Texas MD Anderson Cancer Center, Houston, TX, United States},
	abstract = {The performance of deep learning-based natural language processing systems is based on large amounts of labeled training data which, in the clinical domain, are not easily available or affordable. Weak supervision and in-context learning offer partial solutions to this issue, particularly using large language models (LLMs), but their performance still trails traditional supervised methods with moderate amounts of gold-standard data. In particular, inferencing with LLMs is computationally heavy. We propose an approach leveraging fine-tuning LLMs and weak supervision with virtually no domain knowledge that still achieves consistently dominant performance. Using a prompt-based approach, the LLM is used to generate weakly-labeled data for training a downstream BERT model. The weakly supervised model is then further fine-tuned on small amounts of gold standard data. We evaluate this approach using Llama2 on three different i2b2/ n2c2 datasets for clinical named entity recognition. With no more than 10 gold standard notes, our final BERT models weakly supervised by fine-tuned Llama2-13B consistently outperformed out-of-the-box PubMedBERT by 4.7–47.9% in F1 scores. With only 50 gold standard notes, our models achieved close performance to fully fine-tuned systems. © The Author(s) 2024.},
	author_keywords = {Electronic health records; Large language models; Natural language processing; Weak supervision},
	keywords = {Deep Learning; Humans; Natural Language Processing; article; context learning; deep learning; electronic health record; human; large language model; natural language processing},
	correspondence_address = {K. Roberts; McWilliams School of Biomedical Informatics, University of Texas Health Science Center at Houston, Houston, United States; email: kirk.roberts@uth.tmc.edu},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {40064991},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kuang2025,
	author = {Kuang, Xianwen and Liu, Jun and Zhang, Haiyang and Schweighofer, Simon},
	title = {Towards algorithmic framing analysis: expanding the scope by using LLMs},
	year = {2025},
	journal = {Journal of Big Data},
	volume = {12},
	number = {1},
	doi = {10.1186/s40537-025-01092-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000055782&doi=10.1186%2fs40537-025-01092-y&partnerID=40&md5=59bec8ce57baa83c861517c8affa619e},
	affiliations = {Department of Media and Communication, School of Humanities and Social Sciences, Xi’an Jiaotong-Liverpool University, Suzhou, 215123, China; Center for Tracking and Society, University of Copenhagen, Copenhagen, 2300, Denmark; Department of Computing, School of Advanced Technology, Xi’an Jiaotong-Liverpool University, Suzhou, 215123, China},
	abstract = {Framing analysis, an extensively used, multi-disciplinary social science research method, requires substantial manpower and time to code and uncover human-level understanding of story contexts. However, recent advances in deep learning have led to a qualitative jump in algorithm-assisted methods, with large language models (LLMs) like BERT and GPT going beyond surface characteristics to infer the semantic properties of a text. In this study, we explore the application of the BERT for natural language inference (NLI), which leverages bidirectional context and rich embeddings to assist scholars in identifying contextual information in media texts for quantitative framing analysis. More specifically, we investigate the capability of LLMs to identify generic media frames by comparing the results from a zero-shot analysis using BERT-NLI to those from human analysis. We find that the reliability of detecting generic frames varies significantly across different datasets, indicating that even a large LLM like BERT-NLI, trained on millions of texts from diverse sources, cannot be uniformly trusted across different contexts. Nonetheless, LLMs might be employed productively in specific contexts after careful consideration of their agreement with human-generated ratings. © The Author(s) 2025.},
	author_keywords = {BERT-NLI; Big Data; Context; Framing analysis; Large language models (LLMs)},
	keywords = {Algorithmic languages; Computational linguistics; Deep learning; Economic and social effects; Natural language processing systems; Semantics; Algorithmics; BERT-natural language inference; Context; Framing analyze; Language inference; Language model; Large language model; Natural languages; Research method; Social science research},
	correspondence_address = {S. Schweighofer; Department of Media and Communication, School of Humanities and Social Sciences, Xi’an Jiaotong-Liverpool University, Suzhou, 215123, China; email: simon.schweighofer@xjtlu.edu.cn},
	publisher = {Springer Nature},
	issn = {21961115},
	language = {English},
	abbrev_source_title = {J. Big Data},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gardazi2025,
	author = {Gardazi, Nadia Mushtaq and Daud, Ali and Malik, Muhammad Kamran and Bukhari, Amal and Alsahfi, Tariq and Alshemaimri, Bader},
	title = {BERT applications in natural language processing: a review},
	year = {2025},
	journal = {Artificial Intelligence Review},
	volume = {58},
	number = {6},
	doi = {10.1007/s10462-025-11162-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000171889&doi=10.1007%2fs10462-025-11162-5&partnerID=40&md5=603f5aea2c932f88c64a7918116501fa},
	affiliations = {Department of Data Science, Faculty of Computing and Information Technology, University of the Punjab, Lahore, Pakistan; Faculty of Resilience, Rabdan Academy, Abu Dhabi, United Arab Emirates; Department of Information Systems and Technology, Collage of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia; Software Engineering Department, College of Computing and Information Sciences, King Saud University, Riyadh, Saudi Arabia},
	abstract = {BERT (Bidirectional Encoder Representations from Transformers) has revolutionized Natural Language Processing (NLP) by significantly enhancing the capabilities of language models. This review study examines the complex nature of BERT, including its structure, utilization in different NLP tasks, and the further development of its design via modifications. The study thoroughly analyses the methodological aspects, conducting a comprehensive analysis of the planning process, the implemented procedures, and the criteria used to decide which data to include or exclude in the evaluation framework. In addition, the study thoroughly examines the influence of BERT on several NLP tasks, such as Sentence Boundary Detection, Tokenization, Grammatical Error Detection and Correction, Dependency Parsing, Named Entity Recognition, Part of Speech Tagging, Question Answering Systems, Machine Translation, Sentiment analysis, fake review detection and Cross-lingual transfer learning. The review study adds to the current literature by integrating ideas from multiple sources, explicitly emphasizing the problems and prospects in BERT-based models. The objective is to comprehensively comprehend BERT and its implementations, targeting both experienced researchers and novices in the domain of NLP. Consequently, the present study is expected to inspire more research endeavors, promote innovative adaptations of BERT, and deepen comprehension of its extensive capabilities in various NLP applications. The results presented in this research are anticipated to influence the advancement of future language models and add to the ongoing discourse on enhancing technology for understanding natural language. © The Author(s) 2025.},
	author_keywords = {BERT applications; Bidirectional encoder representation for Transformers (BERT); Deep learning (DL); Large Language models (LLM); Natural Language processing (NLP)},
	keywords = {Computational linguistics; Computer aided language translation; Distribution transformers; Machine translation; Natural language processing systems; Transfer learning; Bidirectional encoder representation for transformer; Bidirectional encoder representation for transformer application; Complex nature; Deep learning; Language model; Language processing; Large language model; Natural language processing; Natural languages; Transformer applications; Deep learning},
	correspondence_address = {A. Daud; Faculty of Resilience, Rabdan Academy, Abu Dhabi, United Arab Emirates; email: alimsdb@gmail.com},
	publisher = {Springer Nature},
	issn = {02692821},
	coden = {AIRVE},
	language = {English},
	abbrev_source_title = {Artif Intell Rev},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Bhattarai2025577,
	author = {Bhattarai, Omkar and Chaudhary, Raj and Kumar, Rahul and Abidi, Ali Imam},
	title = {A Systematic Analysis of Diverse Large Language Models and Their Operational Paradigm},
	year = {2025},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1039 LNNS},
	pages = {577 – 592},
	doi = {10.1007/978-981-97-4152-6_43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207640759&doi=10.1007%2f978-981-97-4152-6_43&partnerID=40&md5=8afd5d932a455cf44ae419a5850e3dba},
	affiliations = {Department of the Computer Science and Engineering, Sharda University, Greater Noida, India},
	abstract = {LLMs (Large Language Models) generated texts (e.g. Texts generated by Chat GPT) and its use has been growing rapidly where any language-related problems can be solved or any queries based on language translation can be answered easily. Some of the most well-known LLMs include OpenAI’s GPT models (GPT1, 2, 3.5, 4), Google’s BARD, BERT, Facebook’s RoBERTa and so on. Since natural language text is generated by such LLMs, it has the several possible issues associated with it. For example, our creativity will be faded away as all the ideas, codes and solutions are generated by these models. Therefore, accurate and efficient classifier tool is necessary to be formulated and implemented. Before developing a classifier tool, review of various LLMs will be done so that actual working of the large language models can be identified and used for further analysis of classifier model. LLM research has recently made tremendous strides in both academia and business industry, with ChatGPT’s introduction—a potent AI chatbot built on LLMs being a noteworthy milestone received a great deal of public interest. LLMs’ technical development has had a significant impact on AI community, which have fundamentally altered how we create and employ AI systems. Given this rapid advancement in technology, we evaluate current developments in LLMs in this survey by explaining the backdrop, major findings, and mainstream techniques. Pre-training, adaptation adjustment, use, and capacity evaluation—the four core LLM components—are the ones we focus on. We also discuss the difficulties that still need to be overcome in order to advance future advances, as well as the resources that are available for developing LLMs. For both academics and engineers, this study provides a current review of the LLM literature. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {AI systems; BARD; BERT; Chat bot; ChatGPT; LLMs; Pre-training; RoBERTa},
	keywords = {Classification (of information); Computer aided language translation; Linguistics; Natural language processing systems; Problem oriented languages; 'current; AI systems; BARD; BERT; Chat bots; ChatGPT; Language model; Large language model; Pre-training; RoBERTa; Industrial research},
	correspondence_address = {O. Bhattarai; Department of the Computer Science and Engineering, Sharda University, Greater Noida, India; email: omkarbhattarai71@gmail.com},
	editor = {Hassanien A.E. and Anand S. and Jaiswal A. and Kumar P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-981974151-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2025683,
	author = {Li, Chengzhang and Zhou, Jun and Li, Ta},
	title = {CSCLORA: AN EFFICIENT FINE-TUNING METHOD FOR OPEN-SOURCE LARGE LANGUAGE MODELS IN CHINESE SPELLING CORRECTION},
	year = {2025},
	journal = {International Journal of Innovative Computing, Information and Control},
	volume = {21},
	number = {3},
	pages = {683 – 699},
	doi = {10.24507/ijicic.21.03.683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003393044&doi=10.24507%2fijicic.21.03.683&partnerID=40&md5=b1a6013eda19acd69cd873066fa8c864},
	affiliations = {School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences No, 19(A), Yuquan Road, Shijingshan District, Beijing, 100049, China; Key Laboratory of Speech Acoustics and Content Understanding Institute of Acoustics, Chinese Academy of Sciences, No. 21, North 4th Ring Road, Haidian District, Beijing, 100190, China},
	abstract = {Chinese Spelling Correction (CSC) is used to detect and correct spelling errors in Chinese sentences automatically. It not only improves the readability and fluency of Chinese text but also avoids the interference of misspelled text on downstream tasks of Natural Language Processing (NLP). Many recent works have achieved significant results with the help of pre-trained language models represented by BERT and using data augmentation, external knowledge components, and other methods. However, for recently emerged open-source Large Language Models (LLMs), the training cost required for these advanced methods is not acceptable for individuals and small-scale laboratories. How to effectively train CSC tasks on an open-source LLM remains to be explored, which is becoming increasingly important as LLMs flourish. In this study, we offer a new universal training framework for CSC, called CSCLoRA, which allows low-cost training on publicly available LLMs. We improved the lightweight fine-tuning method Low-Rank Adaptation of LLMs (LoRA) to learn richer semantic knowledge from multiple low-dimensional representations, and only generated teacher representations required by each layer of the LLM from target texts of parallel corpus. These are automated methods that avoid data augmentation and external knowledge components relying on expert knowledge. Experiments show that our method requires comparable training costs to the original LoRA, but achieves state-of-the-art performance in open-domain and medical verticals. © 2025, ICIC International. All rights reserved.},
	author_keywords = {Chinese spelling correction; Contrastive learning; CSCLoRA; Lightweight fine-tuning; LoRA; Natural language processing},
	keywords = {C (programming language); Contrastive Learning; Learning to rank; Metadata; Modeling languages; Natural language processing systems; Personnel training; Problem oriented languages; Teaching; Chinese spelling correction; CSCLoRA; Fine tuning; Language model; Language processing; Lightweight fine-tuning; Low-rank adaptation of LLM; Natural language processing; Natural languages; Spelling correction; Semantics},
	correspondence_address = {T. Li; Key Laboratory of Speech Acoustics and Content Understanding Institute of Acoustics, Chinese Academy of Sciences, Beijing, No. 21, North 4th Ring Road, Haidian District, 100190, China; email: lita@hccl.ioa.ac.cn},
	publisher = {ICIC International},
	issn = {13494198},
	language = {English},
	abbrev_source_title = {Int. J. Innov. Comput. Inf. Control},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Garcés2025,
	author = {Garcés, Diego and Santos, Matilde and Fernández-Llorca, David},
	title = {Leveraging language models for automated distribution of review notes in animated productions},
	year = {2025},
	journal = {Neurocomputing},
	volume = {626},
	doi = {10.1016/j.neucom.2025.129620},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217279188&doi=10.1016%2fj.neucom.2025.129620&partnerID=40&md5=db3dbf4feb79761793d1c764029516e5},
	affiliations = {Computer Science Faculty, Complutense University of Madrid, Madrid, Spain; Skydance Animation Madrid, Madrid, Spain; Institute of Knowledge Technology, Complutense University of Madrid, Madrid, Spain; European Commission, Joint Research Centre, Seville, Spain; Computer Engineering Department, University of Alcalá, Madrid, Spain},
	abstract = {During the production of an animated film, professionals at the animation studio prepare thousands of notes. These notes describe improvements and corrections identified by supervisors and directors during daily meetings where the film's progress is reviewed. After each meeting, these notes are manually distributed to the appropriate departments that need to address them. Due to the manual nature of this process, many notes are not assigned correctly, and the identified issues are not addressed, reducing the final quality of the film. This article describes and compares several approaches to automatically distribute notes using multi-label text classification with different language models (LM). Implemented methods include logistic regression models, encoder-only models such as the BERT family, and decoder-only models such as Llama 2 including fine-tuning and QLoRA techniques. Training and inference were conducted on a local RTX-3090. The results of the different techniques have been compared, achieving a maximum average accuracy of 0.83 and an f1-score of 0.89 with the fine-tuned Multilingual BERT model. This demonstrates the validity of these models for multi-label text classification, as well as their usefulness in a hitherto unexplored area such as animation studios. © 2025},
	author_keywords = {Large Language Models (LLM); Movie production; Natural Language Processing; Review notes; Text Classification},
	keywords = {Animation; Film preparation; Logistic regression; Natural language processing systems; Animation studios; Language model; Language processing; Large language model; Movie production; Multi-label text classification; Natural language processing; Natural languages; Review note; Text classification; animated production; Article; automated distribution; bidirectional encoder representations from transformer; decomposition; language model; large language model; logistic regression analysis; natural language processing; training; transfer of learning; validity; Motion picture studios},
	correspondence_address = {D. Garcés; Computer Science Faculty, Complutense University of Madrid, Madrid, Spain; email: digarces@ucm.es; D. Fernández-Llorca; European Commission, Joint Research Centre, Seville, Spain; email: david.fernandez-llorca@ec.europa.eu},
	publisher = {Elsevier B.V.},
	issn = {09252312},
	coden = {NRCGE},
	language = {English},
	abbrev_source_title = {Neurocomputing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Nowak2025,
	author = {Nowak, Sebastian and Wulff, Benjamin and Layer, Yannik C. and Theis, Maike and Isaak, Alexander and Salam, Babak and Block, Wolfgang and Kuetting, Daniel and Pieper, Claus C. and Luetkens, Julian A. and Attenberger, Ulrike and Sprinkart, Alois M.},
	title = {Privacy-ensuring Open-weights Large Language Models Are Competitive with Closed-weights GPT-4o in Extracting Chest Radiography Findings from Free-Text Reports},
	year = {2025},
	journal = {Radiology},
	volume = {314},
	number = {1},
	doi = {10.1148/radiol.240895},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215624115&doi=10.1148%2fradiol.240895&partnerID=40&md5=01339531356f82d35c9cc7e33d3dbfcc},
	affiliations = {Department of Diagnostic and Interventional Radiology, University Hospital Bonn, Venusberg-Campus 1, Bonn, 53127, Germany},
	abstract = {Background: Large-scale secondary use of clinical databases requires automated tools for retrospective extraction of structured content from free-text radiology reports. Purpose: To share data and insights on the application of privacy-preserving open-weights large language models (LLMs) for reporting content extraction with comparison to standard rule-based systems and the closed-weights LLMs from OpenAI. Materials and Methods: In this retrospective exploratory study conducted between May 2024 and September 2024, zero-shot prompting of 17 open-weights LLMs was preformed. These LLMs with model weights released under open licenses were compared with rule-based annotation and with OpenAI’s GPT-4o, GPT-4o-mini, GPT-4-turbo, and GPT-3.5-turbo on a manually annotated public English chest radiography dataset (Indiana University, 3927 patients and reports). An annotated nonpublic German chest radiography dataset (18 500 reports, 16 844 patients [10 340 male; mean age, 62.6 years ± 21.5 {SD}]) was used to compare local fine-tuning of all open-weights LLMs via low-rank adaptation and 4-bit quantization to bidirectional encoder representations from transformers (BERT) with different subsets of reports (from 10 to 14 580). Nonoverlapping 95% CIs of macro-averaged F1 scores were defined as relevant differences. Results: For the English reports, the highest zero-shot macro-averaged F1 score was observed for GPT-4o (92.4% [95% CI: 87.9, 95.9]); GPT-4o outperformed the rule-based CheXpert [Stanford University] (73.1% [95% CI: 65.1, 79.7]) but was comparable in performance to several open-weights LLMs (top three: Mistral-Large [Mistral AI], 92.6% [95% CI: 88.2, 96.0]; Llama-3.1–70b [Meta AI], 92.2% [95% CI: 87.1, 95.8]; and Llama-3.1–405b [Meta AI]: 90.3% [95% CI: 84.6, 94.5]). For the German reports, Mistral-Large (91.6% [95% CI: 90.5, 92.7]) had the highest zero-shot macro-averaged F1 score among the six other open-weights LLMs and outperformed the rule-based annotation (74.8% [95% CI: 73.3, 76.1]). Using 1000 reports for fine-tuning, all LLMs (top three: Mistral-Large, 94.3% [95% CI: 93.5, 95.2]; OpenBioLLM-70b [Saama]: 93.9% [95% CI: 92.9, 94.8]; and Mixtral-8×22b [Mistral AI]: 93.8% [95% CI: 92.8, 94.7]) achieved significantly higher macro-averaged F1 score than did BERT (86.7% [95% CI: 85.0, 88.3]); however, the differences were not relevant when 2000 or more reports were used for fine-tuning. Conclusion: LLMs have the potential to outperform rule-based systems for zero-shot “out-of-the-box” structuring of report databases, with privacy-ensuring open-weights LLMs being competitive with closed-weights GPT-4o. Additionally, the open-weights LLM outperformed BERT when moderate numbers of reports were used for fine-tuning. © 2025 Radiological Society of North America Inc.. All rights reserved.},
	keywords = {Aged; Female; Humans; Male; Middle Aged; Natural Language Processing; Privacy; Radiography, Thoracic; Radiology Information Systems; Retrospective Studies; algorithm; Article; artificial intelligence; bidirectional encoder representations from transformer; ChatGPT; human; imagery; intensive care unit; large language model; learning algorithm; lung congestion; machine learning; natural language processing; pleura effusion; pneumothorax; privacy; retrospective study; support vector machine; thorax radiography; aged; female; male; middle aged; privacy; procedures; radiology information system},
	correspondence_address = {S. Nowak; Department of Diagnostic and Interventional Radiology, University Hospital Bonn, Bonn, Venusberg-Campus 1, 53127, Germany; email: Sebastian.Nowak@ukbonn.de},
	publisher = {Radiological Society of North America Inc.},
	issn = {00338419},
	coden = {RADLA},
	pmid = {39807977},
	language = {English},
	abbrev_source_title = {Radiology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Taghavi Far2025,
	author = {Taghavi Far, Seyed Mohammad and Feyzi, Farid},
	title = {Large language models for software vulnerability detection: a guide for researchers on models, methods, techniques, datasets, and metrics},
	year = {2025},
	journal = {International Journal of Information Security},
	volume = {24},
	number = {2},
	doi = {10.1007/s10207-025-00992-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219755516&doi=10.1007%2fs10207-025-00992-7&partnerID=40&md5=6e99b11b23a864d914eb555b1086b6fe},
	affiliations = {Computer Engineering, University of Guilan, Rasht, Iran},
	abstract = {Large language models (LLMs) have emerged as transformative tools in the domain of software vulnerability detection and management, offering sophisticated capabilities in identifying, analyzing, and mitigating security risks. This article delves into the utilization of LLMs, examining their role in revolutionizing traditional approaches to software vulnerability detection. We explore the various categories of LLMs, such as bidirectional encoder representations from transformers (BERT) and generative pre-trained transformer (GPT), and how these models are being leveraged to improve the accuracy and efficiency of vulnerability detection. This article reviews how LLMs are being integrated into existing software security frameworks, synthesizing research findings on their performance in various contexts. It includes insights into how LLM-based methods complement traditional techniques like static analysis and fuzz testing, without engaging in a direct comparative analysis of these approaches. The comparison highlights the strengths of LLMs, such as their ability to generalize across diverse codebases and programming languages, while also addressing their limitations, such as susceptibility to biases from training data and the hallucination. The article synthesizes findings from recent research, showcasing how LLMs have been successfully employed to detect a range of vulnerabilities, from buffer overflows to SQL injections, and outlines how these models enhance productivity by automating the detection and reporting of security flaws. Additionally, we discuss the inherent challenges in applying LLMs to software vulnerability detection, such as the need for high-quality datasets, and the ethical implications related to the deployment of LLM-based systems in security-critical applications. Addressing these challenges is crucial for the future advancement of LLM technologies in the cybersecurity domain. A comprehensive introduction to foundational and specialized datasets is provided, including datasets such as CVEfixes, Big-Vul, and LineVul, which are tailored for software vulnerability detection. These datasets serve as crucial resources for training and benchmarking LLMs. Moreover, we introduce evaluation metrics such as F1-score, precision, recall, and AUC-ROC that are used to assess the performance of models in detecting and mitigating vulnerabilities, offering a structured way to gauge the success and limitations of LLMs. In addition, the article explores fine-tuning techniques such as full fine-tuning, feature extraction, adapter-based fine-tuning, and LoRA (low-rank adaptation), highlighting how each method can enhance LLM performance in vulnerability detection. By focusing on parameter-efficient fine-tuning approaches, such as adapter layers and prefix-tuning, and LoRa, we outline ways to optimize model performance while reducing computational overhead. By providing a comprehensive review of the literature and practical insights into LLM integration, this article aims to fill the gap in existing research and serve as a foundational guide for future investigations. Researchers and practitioners in the field of software security will benefit from the comparative analyses, detailed case studies, and strategic recommendations provided herein, which collectively highlight the potential of LLMs to complement and enhance traditional software vulnerability detection techniques. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2025.},
	author_keywords = {Computing methodologies; Fine-tuning techniques; Large language models (LLMs); Machine learning; Machine learning approaches; Security and privacy; Software and application security; Software security engineering; Software vulnerabilities; Software vulnerability datasets; Software vulnerability detection; Vulnerability detection metrics},
	keywords = {Ability testing; Benchmarking; Computer software selection and evaluation; Data privacy; Electric transformer testing; Ethical technology; Problem oriented languages; Software testing; Application security; Computing methodologies; Fine tuning; Fine-tuning technique; Language model; Large language model; Machine learning approaches; Machine-learning; Security and privacy; Security engineering; Software security; Software security engineering; Software vulnerabilities; Software vulnerability dataset; Software vulnerability detection; Vulnerability detection; Vulnerability detection metric; Application programs},
	correspondence_address = {F. Feyzi; Computer Engineering, University of Guilan, Rasht, Iran; email: feizi@guilan.ac.ir},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {16155262},
	language = {English},
	abbrev_source_title = {Int. J. Inf. Secur.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pendyala2025,
	author = {Pendyala, Vishnu S. and Kamdar, Karnavee and Mulchandani, Kapil},
	title = {Automated Research Review Support Using Machine Learning, Large Language Models, and Natural Language Processing},
	year = {2025},
	journal = {Electronics (Switzerland)},
	volume = {14},
	number = {2},
	doi = {10.3390/electronics14020256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215959010&doi=10.3390%2felectronics14020256&partnerID=40&md5=46ee64657bfb58b9abe2ffac0da87d8a},
	affiliations = {Department of Applied Data Science, San Jose State University, San Jose, 95192, CA, United States; Oracle, Austin, 78741, TX, United States; Amazon, Seattle, 98170, WA, United States},
	abstract = {Research expands the boundaries of a subject, economy, and civilization. Peerreview is at the heart of research and is understandably an expensive process. This work,with human-in-the-loop, aims to support the research community in multiple ways. Itpredicts quality, and acceptance, and recommends reviewers. It helps the authors andeditors to evaluate research work using machine learning models developed based on adataset comprising 18,000+ research papers, some of which are from highly acclaimed,top conferences in Artificial Intelligence such as NeurIPS and ICLR, their reviews, aspectscores, and accept/reject decisions. Using machine learning algorithms such as SupportVector Machines, Deep Learning Recurrent Neural Network architectures such as LSTM, awide variety of pre-trained word vectors using Word2Vec, GloVe, FastText, transformerarchitecture-based BERT, DistilBERT, Google’s Large Language Model (LLM), PaLM 2, andTF-IDF vectorizer, a comprehensive system is built. For the system to be readily usable andto facilitate future enhancements, a frontend, a Flask server in the cloud, and a NOSQLdatabase at the backend are implemented, making it a complete system. The work is novelin using a unique blend of tools and techniques to address most aspects of building asystem to support the peer review process. The experiments result in a 86% test accuracyon acceptance prediction using DistilBERT. Results from other models are comparable, withPaLM-based LLM embeddings achieving 84% accuracy. © 2025 by the authors.},
	author_keywords = {large language models; long short-term memory; machine learning; natural language processing; peer review; support vector machines},
	correspondence_address = {V.S. Pendyala; Department of Applied Data Science, San Jose State University, San Jose, 95192, United States; email: vishnu.pendyala@sjsu.edu},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Raza20253267,
	author = {Raza, Shaina and Paulen-Patterson, Drai and Ding, Chen},
	title = {Fake news detection: comparative evaluation of BERT-like models and large language models with generative AI-annotated data},
	year = {2025},
	journal = {Knowledge and Information Systems},
	volume = {67},
	number = {4},
	pages = {3267 – 3292},
	doi = {10.1007/s10115-024-02321-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214083205&doi=10.1007%2fs10115-024-02321-1&partnerID=40&md5=6307e7b539c8b19fecd9f0293896c3ac},
	affiliations = {AI Engineering, Vector Institute, College Street, Toronto, M5G 0C6, ON, Canada; Department of Computer Science, Toronto Metropolitan University, 350 Victoria St., Toronto, M5B 2K3, ON, Canada},
	abstract = {Fake news poses a significant threat to public opinion and social stability in modern society. This study presents a comparative evaluation of BERT-like encoder-only models and autoregressive decoder-only large language models (LLMs) for fake news detection. We introduce a dataset of news articles labeled with GPT-4 assistance (an AI-labeling method) and verified by human experts to ensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned on this dataset. Additionally, we developed an instruction-tuned LLM approach with majority voting during inference for label generation. Our analysis reveals that BERT-like models generally outperform LLMs in classification tasks, while LLMs demonstrate superior robustness against text perturbations. Compared to weak labels (distant supervision) data, the results show that AI labels with human supervision achieve better classification results. This study highlights the effectiveness of combining AI-based annotation with human oversight and demonstrates the performance of different families of machine learning models for fake news detection. © Crown 2025.},
	author_keywords = {Annotations; BERT models; Fake news; Large language models},
	keywords = {Supervised learning; Annotation; Auto-regressive; BERT model; Comparative evaluations; Fake news; Language model; Large language model; News articles; Public opinions; Social stability; Contrastive Learning},
	correspondence_address = {S. Raza; AI Engineering, Vector Institute, Toronto, College Street, M5G 0C6, Canada; email: shaina.raza@torontomu.ca},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {02191377},
	language = {English},
	abbrev_source_title = {Knowl. Inf. Systems. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Rong2025153,
	author = {Rong, Dunlei and Yao, Lina and Zheng, Yinting and Yu, Shuang and Xu, Xiaofei and Liu, Mingyi and Wang, Zhongjie},
	title = {LLM Enhanced Representation for Cold Start Service Recommendation},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15404 LNCS},
	pages = {153 – 167},
	doi = {10.1007/978-981-96-0805-8_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212940761&doi=10.1007%2f978-981-96-0805-8_12&partnerID=40&md5=3daa006d8df0ba84b19775ada130d240},
	affiliations = {Faculty of Computing, Harbin Institute of Technology, Harbin, China; Csiro’s Data61, Sydney, Australia; University of New South Wales, Sydney, Australia; School of Economics and Finance, South China University of Technology, Guangzhou, China},
	abstract = {With the rise of service globalization and the advent of LLMs, users are becoming increasingly active on the internet to discover services and engage in social interaction. Instead of browsing through vast amounts of information, users prefer to interact directly with smart devices for decision-making and recommendations. However, there are two main challenges in this process: firstly, user needs are often ambiguous, with different functionalities potentially being described in similar terms. Secondly, the internet hosts a large number of services and requirements, complicating the process of service composition. To address the first challenge, this paper proposes the Graph Self-Attention Transformer (GSAT) model, which enhances representation from both semantic and topological perspective. From topological perspective, it integrates local features by walking through the historical records of mashups, uses graph self-attention module on this records, and employs an attention mechanism on all mashups to capture global features. From semantic perspective, it enhances mashup and API descriptions with the help of LLMs. To verify the effectiveness in solving the second challenge, This paper partitions the ProgrammableWeb dataset under and evaluates the GSAT performance under the cold-start setting. This paper compares GSAT with traditional methods and several LLMs, including BERT, T5, LLaMA and ChatGPT. The experiments show that GSAT effectively distinguishes between mashups and achieves state-of-the-art (SOTA) performance. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {LLM; Service Recommendation; Service Representation},
	keywords = {Amount of information; Cold-start; Information users; LLM; Mash up; Mashups; Service globalization; Service recommendations; Service representation; Social interactions; Decision making},
	correspondence_address = {Z. Wang; Faculty of Computing, Harbin Institute of Technology, Harbin, China; email: rainy@hit.edu.cn},
	editor = {Gaaloul W. and Sheng M. and Yu Q. and Yangui S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981960804-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {26th International Conference on Information Integration and Web Intelligence, iiWAS 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15342 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212253172&partnerID=40&md5=5f4500486ebf9c039d0e8b8e9d3f35af},
	abstract = {The proceedings contain 52 papers. The special focus in this conference is on Information Integration and Web Intelligence. The topics include: Financial News Classification Using Language Learning Models and Reinforcement Learning; ExtractGPT: Exploring the Potential of Large Language Models for Product Attribute Value Extraction; Feature Extraction for Claim Check-Worthiness Prediction Tasks Using LLM; training Data for Dialogue Generation Considering Philosophies; Finding Adequate Additional Layer of Auxiliary Task in BERT-Based Multi-task Learning; ponzi Scheme Detection and Prevention in Blockchain Platforms Using Machine Learning: A Systematic Literature Review; Cross-Chain Personal Data Exchange on EVM Platforms: Enhancing Transparency, and Equity; Incentivize Peer Review Without Rewarding: Using OSS-Like Citation Pull Request; towards Website X-Ray for Europe’s Municipalities: Unveiling Digital Transformation with Multimodal Embeddings; evolving Applications of Conversational Agents in Healthcare: A Literature Review; hybrid Edge-Cloud Federated Learning: The Case of Lightweight Smoking Detection; anonymization of Unstructured Health Data in Spanish; when Good Enough is the Best Option: Use of Digital Sufficiency to Fight Climate Change; multi-target Feature Selection Method for Predicting User-Level Psychological Status from Text; FIEAP: A Machine Learning Approach for Fair and Interpretable Employee Attrition Prediction; HOCON34k: A Corpus of Hate Speech in Online Comments from German Newspapers; SISIS: Sequence Indexing for SImilarity Search; top-k on Sequences: A New Approach to Enhanced Similarity Search; exploratory Data Analysis of Time Series Using Pre-segmented Clustering; a Data Science Approach for Predicting Soccer Passes Using Positional Data; a Method for Integrating Heterogeneous Data into a Knowledge Graph; predicting Knowledge Graph Updates from Edit Histories; Automatic Extraction of RML-star Mappings from Property Graphs; Exploring the Role of UML in Data Modelling for NoSQL Databases: Position Paper; railway Systems’ Ontologies: A Literature Review and an Alignment Proposal; Combining GraphSAGE and Label Propagation for Node Classification in Graphs.},
	editor = {Delir Haghighi P. and Greguš M. and Kotsis G. and Khalil I.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303178089-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2025,
	author = {Zhang, Zhang and Mao, Xinjun and Wang, Shangwen and Yang, Kang and Zhang, Tanghaoran and Lu, Yao},
	title = {CARLDA: An Approach for Stack Overflow API Mention Recognition Driven by Context and LLM-Based Data Augmentation},
	year = {2025},
	journal = {Journal of Software: Evolution and Process},
	volume = {37},
	number = {4},
	doi = {10.1002/smr.70015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002444234&doi=10.1002%2fsmr.70015&partnerID=40&md5=133d69d26ebeec4edb364e478ecf2a35},
	affiliations = {College of Computer Science and Technology, National University of Defense Technology, Hunan, China},
	abstract = {The recognition of Application Programming Interface (API) mentions in software-related texts is vital for extracting API-related knowledge, providing deep insights into API usage and enhancing productivity efficiency. Previous research identifies two primary technical challenges in this task: (1) differentiating APIs from common words and (2) identifying morphological variants of standard APIs. While deep learning-based methods have demonstrated advancements in addressing these challenges, they rely heavily on high-quality labeled data, leading to another significant data-related challenge: (3) the lack of such high-quality data due to the substantial effort required for labeling. To overcome these challenges, this paper proposes a context-aware API recognition method named CARLDA. This approach utilizes two key components, namely, Bidirectional Encoder Representations from Transformers (BERT) and Bidirectional Long Short-Term Memory (BiLSTM), to extract context at both the word and sequence levels, capturing syntactic and semantic information to address the first challenge. For the second challenge, it incorporates a character-level BiLSTM with an attention mechanism to grasp global character-level context, enhancing the recognition of morphological features of APIs. To address the third challenge, we developed specialized data augmentation techniques using large language models (LLMs) to tackle both in-library and cross-library data shortages. These techniques generate a variety of labeled samples through targeted transformations (e.g., replacing tokens and restructuring sentences) and hybrid augmentation strategies (e.g., combining real-world and generated data while applying style rules to replicate authentic programming contexts). Given the uncertainty about the quality of LLM-generated samples, we also developed sample selection algorithms to filter out low-quality samples (i.e., incomplete or incorrectly labeled samples). Moreover, specific datasets have been constructed to evaluate CARLDA's ability to address the aforementioned challenges. Experimental results demonstrate that (1) CARLDA significantly enhances F1 by 11.0% and the Matthews correlation coefficient (MCC) by 10.0% compared to state-of-the-art methods, showing superior overall performance and effectively tackling the first two challenges, and (2) LLM-based data augmentation techniques successfully yield high-quality labeled data and effectively alleviate the third challenge. © 2025 John Wiley & Sons Ltd.},
	author_keywords = {API mention; API recognition; context-aware; data augmentation; LLMs},
	keywords = {Data quality; Deep learning; High level languages; Labeled data; Syntactics; Application programming interface mention; Application programming interface recognition; Applications programming interfaces; Context-Aware; Data augmentation; High quality; Language model; Large language model; Model-based OPC; Semantics},
	correspondence_address = {X. Mao; College of Computer Science and Technology, National University of Defense Technology, Hunan, China; email: xjmao@nudt.edu.cn},
	publisher = {John Wiley and Sons Ltd},
	issn = {20477481},
	language = {English},
	abbrev_source_title = {J. Softw. Evol. Process},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mirtaheri2025,
	author = {Mirtaheri, Seyedeh Leili and Pugliese, Andrea and Movahed, Narges and Shahbazian, Reza},
	title = {A comparative analysis on using GPT and BERT for automated vulnerability scoring},
	year = {2025},
	journal = {Intelligent Systems with Applications},
	volume = {26},
	doi = {10.1016/j.iswa.2025.200515},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002907901&doi=10.1016%2fj.iswa.2025.200515&partnerID=40&md5=cdfa74110a442b201fdb7d39416a57d6},
	affiliations = {Department of Informatics, Modeling, Electronics and System Engineering (DIMES), University of Calabria, CS, Rende, 87036, Italy; Mechanical, Energy, and Management Engineering Department, University of Calabria, CS, Rende, 87036, Italy},
	abstract = {Large language models and transformers such as GPT and BERT have shown great improvements in many domains including cybersecurity. A constantly increasing number of vulnerabilities necessitate automated vulnerability scoring systems. Therefore, a deeper understanding of GPT and BERT compatibility with the requirements of the cybersecurity domain seems inevitable for system designers. The BERT model's family is known to be optimized in understanding the contextual relationships with a bidirectional approach, while the GPT models perform unidirectional processing with generative capabilities. Automated vulnerability scoring systems require both the features to analyze the vulnerability and to augment the vulnerability descriptions. On the other hand, powerful GPT models are often more “resource-intensive in comparison with the BERT family. This paper presents a comprehensive comparison analysis of GPT and BERT in terms of their text classification performance, utilizing the vulnerability description classification task. We outline a thorough theoretical and experimental comparison of the models, regarding their architectures, training objectives, and fine-tuning, as well as their text classification performance. We evaluate these models on the vulnerability description classification task and employ rigorous evaluation metrics to shed light on their relative strengths and shortcomings. We also evaluate the hybrid architectures that benefit from combining GPT and BERT at the same time. Our experiment results show that they can effectively leverage the complementary strengths of both GPT and BERT, namely generative and comprehension, leading to further improvements in classification performance. © 2025 The Authors},
	author_keywords = {Large language model (LLM); Machine learning; Transformers; Vulnerability scoring},
	keywords = {Classification (of information); Distribution transformers; Classification performance; Cyber security; Language model; Large language model; Machine-learning; Scoring systems; Text classification; Transformer; Vulnerability description; Vulnerability scoring},
	correspondence_address = {S.L. Mirtaheri; Department of Informatics, Modeling, Electronics and System Engineering (DIMES), University of Calabria, Rende, CS, 87036, Italy; email: leili.mirtaheri@dimes.unical.it},
	publisher = {Elsevier B.V.},
	issn = {26673053},
	language = {English},
	abbrev_source_title = {Intell. Syst. Applications.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chai20251,
	author = {Chai, Seok Hyeon and Chen, Ivan and Huang, Jason and Yacoub, Thamer},
	title = {Large Language Model for Geotechnical Engineering Applications Using Retrieval Augmented Generation},
	year = {2025},
	journal = {Geotechnical Special Publication},
	volume = {2025-March},
	number = {GSP 365},
	pages = {1 – 10},
	doi = {10.1061/9780784485989.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000510156&doi=10.1061%2f9780784485989.001&partnerID=40&md5=7a825b0d09bc7a90e5a7b1f41384eb36},
	affiliations = {Rocscience, Inc., Toronto, ON, Canada},
	abstract = {The application of Natural Language Processing (NLP) in the field of Civil and geotechnical engineering presents unique challenges with the complexity of the calculations and the necessity for engineering judgment. Large Language Models (LLM) have been successfully presented to be one of the most effective solutions in many specific fields such as arts and literature, finance, and even software development. However, the use of LLM in the field of Civil Engineering and specifically in Geotechnical Engineering has not been widely discussed often compared to the other fields. This paper aims to cover the details with the framework and breakdown of how LLMs can be used to retrieve information from domain-specific data set specifically related to geotechnical engineering. The paper covers topics ranging from settlement analysis, ground improvements, to scripting features with the Rocscience platform. Data sources include research papers, technical documents from geotechnical engineers, and documentation for online help from the relevant geotechnical software. The paper is structured into three main sections: an introduction to LLM models with a focus on pre-trained models and model selection; a discussion of the data retrieval process using domain-specific database using Retrieval Augmented Generation (RAG); and an evaluation of the model’s performance. Performance benchmarks are established with vector embedding to trace context retrieval, and validation is performed using methods such as Recall-Oriented Understudy for Gisting Evaluation (ROGUE), Bidirectional Encoder Representations From Transformer (BERT), and Bilingual Evaluation Understudy (BLEU) score to compare the result with prompt-completion pairs. The study demonstrates that an LLM with sufficient geotechnical domain-specific data source produces superior responses compared to LLM trained on a generic public data set. The paper concludes with a discussion on the comparative results and the future potential of the LLM in geotechnical engineering. © ASCE.},
	author_keywords = {APIs with OpenAI; ChatGPT; Civil Engineering; fine-tuned models; Large Language Models (LLM); Retrieval Augmented Generation (RAG); RS2; Settle3; settlement analysis},
	keywords = {API with openai; ChatGPT; Fine-tuned model; Geotechnical; Language model; Large language model; Retrieval augmented generation; RS2; Settle3; Settlement analysis},
	correspondence_address = {S.H. Chai; Rocscience, Inc., Toronto, Canada; email: steve.chai@rocscience.com},
	editor = {Beauregard M.S. and Budge A.S.},
	publisher = {American Society of Civil Engineers (ASCE)},
	issn = {08950563},
	coden = {GSPUE},
	language = {English},
	abbrev_source_title = {Geotech Spec Publ},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Xu202588,
	author = {Xu, Xiaowei and Jiang, Ruixuan and Zheng, Si and Wang, Min and Ju, Yi and Li, Jiao},
	title = {Classification of Chronic Dizziness Using Large Language Models},
	year = {2025},
	journal = {Journal of Healthcare Informatics Research},
	volume = {9},
	number = {1},
	pages = {88 – 102},
	doi = {10.1007/s41666-024-00178-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209905020&doi=10.1007%2fs41666-024-00178-1&partnerID=40&md5=c4a6694c22c7cb153c80f59adb8cad50},
	affiliations = {Institute of Medical Information, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100020, China; Department of Neurology, Beijing Tiantan Hospital, Capital Medical University, No.119, South 4Th Ring West Road, Fengtai District, Beijing, 100070, China; China National Clinical Research Center for Neurological Diseases, Beijing Tiantan Hospital, Capital Medical University, Beijing, China; Clinical Center for Vertigo and Balance Disturbance, Beijing Tiantan Hospital, Capital Medical University, Beijing, China; Institute for Artificial Intelligence, Department of Computer Science and Technology, BNRist, Tsinghua University, Beijing, 100084, China; College of Biomedical Engineering & Instrument Science, Zhejiang University, Hangzhou, 310058, China},
	abstract = {Efficiently classifying chronic dizziness disorders, including persistent postural-perceptual dizziness (PPPD), anxiety, and depressive disorders, is crucial, particularly in primary healthcare settings. This study introduces DizzyInsight, an innovative etiological classification model, designed to enhance the accuracy and reliability of large language model (LLM) and machine learning approaches for etiological classification of chronic dizziness. Eight physicians specializing in chronic dizziness diagnosis, affiliated with the Clinical Center for Vertigo and Balance Disturbance at Beijing Tiantan Hospital, Capital Medical University, furnished comprehensive definitions and evaluations of chronic dizziness characteristics. The study included 260 patients, consisting of 105 males and 155 females, with a mean age of 59.52 ± 13 years. These patients were recruited from the same center between July 2021 and October 2023. For comparative analysis, we utilized the general models bidirectional encoder representations from transformers (BERT) and LLM to assess different outcomes. Seven major categories and 33 subcategory evidence have been defined for etiological classification of chronic dizziness. With DizzyInsight, we constructed the feature dataset regarding chronic dizziness. The DizzyInsight based on the identified evidence of LLM method yielded a positive predictive value of 0.69, a sensitivity of 0.86 for persistent postural-perceptual dizziness (PPPD), a positive predictive value of 0.81, and a sensitivity of 0.66 for anxiety and depressive disorders. These findings highlight the potential of DizzyInsight leveraging LLM to improve the efficacy and interpretability of machine learning models in etiological classification of chronic dizziness disorders. Further research and model development are necessary to improve the accuracy of evidence identification and assess the applicability of DizzyInsight in primary care settings, as well as to evaluate its external validity. © The Author(s) 2024.},
	author_keywords = {Anxiety and depressive disorders; Chronic dizziness; Decision support; Etiological classification; Persistent postural-perceptual dizziness (PPPD)},
	keywords = {Anxiety and depressive disorder; Chronic dizziness; Classification models; Decision supports; Etiological classification; Language model; Model learning; Persistent postural-perceptual dizziness; Positive predictive values; Primary healthcare; Diagnosis},
	correspondence_address = {J. Li; Institute of Medical Information, Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, 100020, China; email: li.jiao@imicams.ac.cn; Y. Ju; Department of Neurology, Beijing Tiantan Hospital, Capital Medical University, Beijing, No.119, South 4Th Ring West Road, Fengtai District, 100070, China; email: juyi1226@vip.163.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {2509498X},
	language = {English},
	abbrev_source_title = {J. Healthc. Informatics Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Chillara202594,
	author = {Chillara, Anil Kumar and Saxena, Paresh and Maiti, Rajib Ranjan},
	title = {Transformer-based GAN-augmented Defender for Adversarial USB Keystroke Injection Attacks},
	year = {2025},
	journal = {ICDCN 2025 - Proceedings of the 26th International Conference on Distributed Computing and Networking},
	pages = {94 – 103},
	doi = {10.1145/3700838.3700871},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218348890&doi=10.1145%2f3700838.3700871&partnerID=40&md5=e376c39ffaec04177f5d65740254ed85},
	affiliations = {Birla Institute of Technology and Sciences, Telangana, Hyderabad, India},
	abstract = {Existing defenses against adversarial Universal Serial Bus (USB) keystroke injection attacks are often insufficient, as adversaries can exploit data poisoning techniques during model training to undermine performance. This paper introduces a novel approach using a transformer-based Large Language Model (LLM) with the Bidirectional Encoder Representations from Transformers (BERT) as a defender against such attacks. Unlike traditional methods, our approach leverages the BERT model's advanced capabilities in understanding complex data patterns, combined with data augmentation using the Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP) method. We present the system design for both the BERT LLM based defender model, as well as USB data augmentation via GANs. We perform systematic evaluation and utilize methods including train on synthetic, test on real (TSTR) for evaluation of augmented data, and performance metrics including precision, recall and accuracy to evaluate the performance of the proposed defender model. Our results show that the proposed BERT-based model achieves a 90.02% detection accuracy, significantly outperforming other state-of-the-art models, establishing it as a better and novel defense mechanism against adversarial USB keystroke injection attacks. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {Adversarial attacks; BERT; GANs; LLMs; Transformer models; USB keystroke injection attacks},
	keywords = {Modeling languages; Network security; Problem oriented languages; Program debugging; Bidirectional encoder representation from transformer; Data augmentation; GAN; Language model; LLM; Model training; Performance; Transformer modeling; Universal serial bus; Universal serial bus keystroke injection attack; System buses},
	correspondence_address = {A.K. Chillara; Birla Institute of Technology and Sciences, Hyderabad, Telangana, India; email: p20190422@hyderabad.bits-pilani.ac.in},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840071062-9},
	language = {English},
	abbrev_source_title = {ICDCN - Proc. Int. Conf. Distrib. Comput. Netw.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Xiong2025,
	author = {Xiong, Shufeng and Tian, Wenjie and Wang, Bingkun and Zhang, Yiming and Zhang, Xu and Che, Yinchao and Shi, Lei and Si, Haiping},
	title = {Enhancing food safety review classification with large language models and label embedding},
	year = {2025},
	journal = {Expert Systems with Applications},
	volume = {283},
	doi = {10.1016/j.eswa.2025.127550},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003810735&doi=10.1016%2fj.eswa.2025.127550&partnerID=40&md5=203a92973292acb60053f5975e494361},
	affiliations = {College of Information and Management Science, Henan Agricultural University, Zhengzhou, 450002, China; School of Information Engineering, Zhengzhou College of Finance and Economics, Zhengzhou, 450002, China},
	abstract = {In the digital age, internet users actively contribute to food safety supervision by providing feedback on platforms like social media. This user-generated content has become a critical resource for food regulation. However, traditional text classification methods often fail to capture the complex semantic structures of such fragmented and large-scale comments. To address this challenge, we propose a novel LLM-enhanced classification framework featuring three key innovations: (1) keyword-enhanced label representation using domain-specific terminology extraction, (2) LLM-powered semantic summarization for generating category descriptions, and (3) a hybrid deep learning architecture combining BiLSTM(Bidirectional Long Short-Term Memory), BERT(Bidirectional Encoder Representations for Transformers), and self-attention mechanisms. The framework first reduces information noise through keyword extraction, then leverages large language models to generate enriched semantic summaries from keyword-related statements. Finally, it integrates label embeddings by fusing BiLSTM-derived vectors with self-attention mechanisms and BERT-based text representations. Experimental results demonstrate that our model significantly outperforms existing methods in food safety comment classification, achieving a 2% improvement in F1 score compared to baseline models. The proposed framework offers a new paradigm for domain-specific text classification by effectively combining LLM capabilities with deep learning architectures. It excels in handling specialized vocabulary and enhancing label semantic understanding, providing a robust solution for real-world applications in food safety regulation. © 2025},
	author_keywords = {Deep learning; Food safety review; Label-embedding; Large language models},
	keywords = {Deep learning; Embeddings; Food safety review; Food-safety; Label-embedding; Language model; Large language model; Learning architectures; Safety reviews; Short term memory; Deep learning},
	correspondence_address = {B. Wang; School of Information Engineering, Zhengzhou College of Finance and Economics, Zhengzhou, 450002, China; email: wangbingkun@zzife.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {09574174},
	coden = {ESAPE},
	language = {English},
	abbrev_source_title = {Expert Sys Appl},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ettaleb2025175,
	author = {Ettaleb, Mohamed and Moriceau, Véronique and Kamel, Mouna and Aussenac-Gilles, Nathalie},
	title = {The contribution of LLMs to relation extraction in the economic field},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	pages = {175 – 183},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217771157&partnerID=40&md5=0ed30b85381a2dab839db2d4feeed2fc},
	affiliations = {IRIT, Université de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; Espace-Dev, Université de Perpignan, France},
	abstract = {Relation Extraction (RE) is a fundamental task in natural language processing, aimed at deducing semantic relationships between entities in a text. Traditional supervised extraction methods relation extraction methods involve training models to annotate tokens representing entity mentions, followed by predicting the relationship between these entities. However, recent advancements have transformed this task into a sequence-to-sequence problem. This involves converting relationships between entities into target string, which are then generated from the input text. Thus, language models now appear as a solution to this task and have already been used in numerous studies, with various levels of refinement, across different domains. The objective of the present study is to evaluate the contribution of large language models (LLM) to the task of relation extraction in a specific domain (in this case, the economic domain), compared to smaller language models. To do this, we considered as a baseline a model based on the BERT architecture, trained in this domain, and four LLM, namely FinGPT specific to the financial domain, XLNet, ChatGLM, and Llama3, which are generalists. All these models were evaluated on the same extraction task, with zero-shot for the general-purpose LLM, as well as refinements through few-shot learning and fine-tuning. The experiments showedthat the best performance in terms of F-score was achieved with fine-tuned LLM, with Llama3 achieving the highest performance. © 2025 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Digital elevation model; Economic and social effects; Natural language processing systems; Problem oriented languages; Zero-shot learning; Economic fields; Extraction method; Language model; Language processing; Natural languages; Performance; Relation extraction; Relationships between entities; Semantic relationships; Training model; Semantics},
	editor = {Chen C.-C. and Moreno-Sandoval A. and Huang J. and Xie Q. and Ananiadou S. and Chen H.-H.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176209-1},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2025,
	author = {Yang, Chibok and Kim, Yangsok},
	title = {Enhancing topic coherence and diversity in document embeddings using LLMs: A focus on BERTopic},
	year = {2025},
	journal = {Expert Systems with Applications},
	volume = {281},
	doi = {10.1016/j.eswa.2025.127517},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002752132&doi=10.1016%2fj.eswa.2025.127517&partnerID=40&md5=cc4d9b94f94b35ec4d5bd558127caebe},
	affiliations = {Department of Management Information Systems, Keimyung University, Daegu, 42601, South Korea},
	abstract = {With the rapid growth of digital textual data, the need for systematic organization of large datasets has become critical. Topic modeling stands out as an effective approach for analyzing large volumes of text datasets. Neural Topic Models (NTMs) have been developed to overcome the limitations of traditional methods by using contextual embeddings, such as Bidirectional Encoder Representations from Transformers (BERT), to improve topic coherence. Recent advancements in Natural Language Processing (NLP) have further enhanced document processing capabilities through large language models (LLMs) such as LLaMA and the Generative Pre-trained Transformer (GPT). This research explores whether LLM embeddings within NTMs offer better performance compared to conventional models like Sentence-BERT (S-BERT) and DistilBERT. In particular, we examine the impact of text preprocessing on topic modeling. A comparative analysis is conducted using datasets from three domains, evaluating six topic models, including LLMs such as Falcon and LLaMA3, using three evaluation metrics. Results show that while no single model consistently excelled across all metrics, LLaMA3 demonstrated the best performance in coherence among the LLMs. In addition, overall topic modeling performance improved with the application of all six preprocessing techniques. LLaMA3 showed progressively better performance with additional preprocessing, confirming its stability and effectiveness in topic modeling. These findings suggest that LLMs can be reliable tools for topic identification across diverse datasets. © 2025},
	author_keywords = {BERTopic; Embedding; Large language models (LLMs); Topic modeling},
	keywords = {Natural language processing systems; Spatio-temporal data; Bertopic; Effective approaches; Embeddings; Language model; Large datasets; Large language model; Performance; Rapid growth; Textual data; Topic Modeling; Modeling languages},
	correspondence_address = {Y. Kim; Department of Management Information Systems, Keimyung University, Daegu, 42601, South Korea; email: yangsok.kim@kmu.ac.kr},
	publisher = {Elsevier Ltd},
	issn = {09574174},
	coden = {ESAPE},
	language = {English},
	abbrev_source_title = {Expert Sys Appl},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Devyatkin20256,
	author = {Devyatkin, Dmitry A. and Salimovsky, Vladimir A. and Chudova, Natalia V. and Ryzhova, Anastasia A. and Grigoriev, Oleg G.},
	title = {Large language models and speech genre systematicity; [Большие языковые модели и жанрово-речевая системность]},
	year = {2025},
	journal = {Zanry Reci},
	volume = {20},
	number = {1},
	pages = {6 – 23},
	doi = {10.18500/2311-0740-2025-20-1-45-6-23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000313989&doi=10.18500%2f2311-0740-2025-20-1-45-6-23&partnerID=40&md5=31afc2ebcf2d919bcec27cabcd32d967},
	affiliations = {Russian Artificial Intelligence Research Institute in Federal Research Center “Computer Science and Control” RAS, Moscow, 117312, Russian Federation; Perm State National Research University, 15 Bukireva St., Perm, 614068, Russian Federation},
	abstract = {The paper examines a large language model (LLM) to recognize speech genres. Although artificial neural networks are effectively utilized in many important fields, they, however, have a serious drawback. The mechanism of their functioning is hidden from researchers; therefore, the results of their use do not get explanation. The purpose of the study is to reveal the basic mechanisms of functioning of the linguistic model LLM (Transformer) and thereby ensure the interpretability of the data it provides. The research is based on two genres of academic text: “Description of a new scientific phenomenon” and “Explication of a scientific concept.” We verified a hypothesis according to which the LLM feature set is based on the speech systematicity of the recognized genres. It is also shown that since genre-speech systematicity is determined by extralinguistic factors, primarily the characteristics of human consciousness, its manifestations, reflected in the hidden state of the LLM, can be used to model cognitive processes embodied in speech. We also analyze existing approaches to the interpretation of LLMs and describe the applied method to do it. The paper provides the following linguistic interpretation of LLM training and fine-tuning: preliminary training on large text corpora allows a model to display language resources (a system of linguistic units and general principles of their use) relatively completely, while fine-tuning on samples of a certain genre-speech organization restructures the linguistic systematicity into speech systematicity. During the experiments we decoded the hidden state of the LLM and accurately reproduced the composition and frequency of lexis from the training dataset. The classification score for each of the considered genres by the LLM is F1 0.99, we believe this is because of their speech consistency. © Девяткин Д. А., Салимовский В. А., Чудова Н. В., Рыжова А. А., Григорьев О. Г., 2025.},
	author_keywords = {academic text; artificial neural network; BERT; cognitive-speech action; large language model; speech genre; speech systematicity; Transformer},
	correspondence_address = {V.A. Salimovsky; Perm State National Research University, Perm, 15 Bukireva St., 614068, Russian Federation; email: salimovsky@rambler.ru},
	publisher = {Saratov State University},
	issn = {23110740},
	language = {Russian},
	abbrev_source_title = {Zanry. Reci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Krishna2025,
	author = {Krishna, Dasari Siva and Srikanth, Panigrahi and Rao, Routhu Srinivasa and Holla M, Raviraja},
	title = {Data2Summ: review on enhancing summarization with transformers and attention models for speech and text compression},
	year = {2025},
	journal = {Physica Scripta},
	volume = {100},
	number = {3},
	doi = {10.1088/1402-4896/adb24c},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217955114&doi=10.1088%2f1402-4896%2fadb24c&partnerID=40&md5=8f86ccfd5eadde900881e9b4839042c2},
	affiliations = {Department of Computer Science and Engineering, Gandhi Institute of Technology and Management, Andhra Pradesh, Visakhapatnam, 530045, India; Department of Artificial Intelligence and Machine Learning, Chaitanya Bharathi Institute of Technology, Kokapet, Gandipet Telangana, Hyderabad, 500075, India; Department of Information and Communication Technology, Manipal Institute of Technology, Manipal Academy of Higher Education (MAHE), Karnataka, Manipal, 576104, India},
	abstract = {Today, nearly 120 zettabytes of data are generated daily, with a significant portion coming from speech and text. Digesting such vast amounts of data is a daunting task for the average person. To simplify this challenge, various speech and text summarization techniques are being developed. Summarization is a crucial task that aims to condense key information from text while preserving its overall meaning. This work focuses on developing Data2Summ, an efficient approach for summarizing speech and text by leveraging transformers and advanced attention models. These models capture intricate contextual relationships between words, enabling a nuanced understanding of the input data. The methodology incorporates various models, such as BERT, Pegasus, Llama-2, RoBert2Robert, T5, and DistilBERT, which harness the power of transformers that have demonstrated exceptional performance in various natural language processing tasks. Additionally, we experiment with a modified version of DistilBERT, which shows improved performance compared to other transformers. Evaluation includes benchmarking against existing summarization techniques and assessing the quality, coherence, and informativeness of the generated summaries using ROUGE score. © 2025 The Author(s). Published by IOP Publishing Ltd.},
	author_keywords = {attention models; deep learning; large language models (LLM); natural language processing; speech and text compression; transformers},
	keywords = {Data assimilation; Data compression; Natural language processing systems; Spatio-temporal data; Speech enhancement; Attention model; Deep learning; Language model; Language processing; Large language model; Natural language processing; Natural languages; Speech compression; Text compressions; Transformer; Distribution transformers},
	correspondence_address = {D.S. Krishna; Department of Computer Science and Engineering, Gandhi Institute of Technology and Management, Visakhapatnam, Andhra Pradesh, 530045, India; email: sivadasari120891@gmail.com; P. Srikanth; Department of Artificial Intelligence and Machine Learning, Chaitanya Bharathi Institute of Technology, Hyderabad, Kokapet, Gandipet Telangana, 500075, India; email: srikanth.panigrahi@gmail.com; R.S. Rao; Department of Computer Science and Engineering, Gandhi Institute of Technology and Management, Visakhapatnam, Andhra Pradesh, 530045, India; email: srouthu@gitam.edu; R. Holla M; Department of Information and Communication Technology, Manipal Institute of Technology, Manipal Academy of Higher Education (MAHE), Manipal, Karnataka, 576104, India; email: raviraj.holla@manipal.edu},
	publisher = {Institute of Physics},
	issn = {00318949},
	coden = {PHSTB},
	language = {English},
	abbrev_source_title = {Phys Scr},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Maiti2025314,
	author = {Maiti, Pratyusha and Goel, Ashok},
	title = {Can an AI Partner Empower Learners to Ask Critical Questions?},
	year = {2025},
	journal = {International Conference on Intelligent User Interfaces, Proceedings IUI},
	pages = {314 – 324},
	doi = {10.1145/3708359.3712134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001923759&doi=10.1145%2f3708359.3712134&partnerID=40&md5=1dbb2b15abb130357ffe4db08e1ea1cc},
	affiliations = {Design Intelligence Lab, Georgia Institute of Technology, Atlanta, GA, United States},
	abstract = {Jill Watson is an LLM-powered conversational AI partner integrated with instructor-provided courseware, offering learners contextually relevant and immediately applicable support. This study examines learner-generated questions as part of organic interactions with Jill embedded within classroom Learning Management System and investigates whether Jill empowers learners to ask higher-order questions. Leveraging Bloom's Taxonomy to assess question complexity, we collected over 5500 student questions from classroom deployments across three academic semesters and two educational settings. Student questions were classified using a fine-tuned BERT model and regression models were used to analyze the trends of complexity of the questions over time. Our results reveal a significant proportion of higher-order questions being asked in our classrooms, exceeding typical educational distributions. We also found a statistically significant increase in higher-order questioning with sustained interaction with Jill. These findings demonstrate that Jill empowers learners to engage in critical questioning, thereby enhancing their educational experience by promoting depth, relevance, and application of course concepts. Further research is recommended with larger and more diverse samples to generalize these findings.  © 2025 Copyright held by the owner/author(s).},
	author_keywords = {Conversational AI Agents; Question Answering; Virtual Teaching Assistant},
	keywords = {Adversarial machine learning; Chatbots; Curricula; E-learning; Federated learning; Regression analysis; Students; Teaching; Classroom learning; Conversational AI agent; Courseware; Critical questions; High-order; Higher-order; Learning management system; Organics; Question Answering; Virtual teaching assistants; Contrastive Learning},
	correspondence_address = {P. Maiti; Design Intelligence Lab, Georgia Institute of Technology, Atlanta, United States; email: pratyusha.maiti@gmail.com},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071306-4},
	language = {English},
	abbrev_source_title = {Int Conf Intell User Interfaces Proc IUI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {37th Australasian Joint Conference on Artificial Intelligence, AJCAI 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15442 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210864415&partnerID=40&md5=5c917edf76a2fbe8a2dc9c4a607b064f},
	abstract = {The proceedings contain 62 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Highlighting Case Studies in LLM Literature Review of Interdisciplinary System Science; legal Judgment Prediction Through Argument Analysis; conditional Prototypical Optimal Transport for Enhanced Clue Identification in Multiple Choice Question Answering; REFINE on Scarce Data: Retrieval Enhancement Through Fine-Tuning via Model Fusion of Embedding Models; Leveraging LLM in Genetic Programming Hyper-heuristics for Dynamic Microservice Deployment; bidirectional Dependency Representation Disentanglement for Time Series Classification; SCODA - Framework for Software Capability Representation and Inspection; some Considerations for the Preservation of Endangered Languages Using Low-Resource Machine Translation; improving Intersectional Group Fairness Using Conditional Generative Adversarial Network and Transfer Learning; GPT-4 Attempting to Attack AI-Text Detectors; Charting a Fair Path: FaGGM Fairness-Aware Generative Graphical Models; shedding Light on Greenwashing: Explainable Machine Learning for Green Ad Detection; Beyond Factualism: A Study of LLM Calibration Through the Lens of Conversational Emotion Recognition; ensuring Fairness in Stochastic Multi-armed Bandit Problems for Effective Group Recommendations; human Decision-Making Concepts with Goal-Oriented Reasoning for Explainable Deep Reinforcement Learning; towards Explainable Deep Learning for Non-melanoma Skin Cancer Diagnosis; Localization System Enhanced with CDLPE: A Low-Cost, Resilient Map-Matching Algorithm; FocDepthFormer: Transformer with Latent LSTM for Depth Estimation from Focal Stack; TSI: A Multi-view Representation Learning Approach for Time Series Forecasting; climate Downscaling Monthly Coastal Sea Surface Temperature Using Convolutional Neural Network and Composite Loss; DBSSM: Deep BERT-Based Semantic Skill Matching from Resumes to a Public Skill Taxonomy; Designing an Adaptive AI System for Operation on Board the SpIRIT Nano-Satellite; LSTM Autoencoder-Based Deep Neural Networks for Barley Genotype-to-Phenotype Prediction; an Improved Prescriptive Tree-Based Model for Stochastic Parallel Machine Scheduling; Economic Graph Lottery Ticket: A GNN Based Economic Forecasting Model; pattern-Based Trading by Continual Learning of Price and Volume Patterns.},
	editor = {Gong M. and Song Y. and Koh Y.S. and Xiang W. and Wang D.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981960347-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2025388,
	author = {Li, Zenglin and Cui, Yujie and Zhang, Xinyu and Wu, Wenfeng and Li, Bo},
	title = {Recommendation of Small-Sample Indicator Based on Sentence-BERT},
	year = {2025},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1350 LNEE},
	pages = {388 – 398},
	doi = {10.1007/978-981-96-2252-8_39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000484988&doi=10.1007%2f978-981-96-2252-8_39&partnerID=40&md5=0128c3f4237a9370e9dcb1488f5b09da},
	affiliations = {School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; National Defense University PLA China, Joint Warfare Academy Training Centre, Beijing, China; Open Project of Innovation Workstation of the Key Laboratory of Intelligent Gaming, Beijing, China},
	abstract = {The recommendation of system capability indicators can provide a basis for combat effectiveness evaluation and improve the efficiency of indicator data collection, but the existing traditional methods are too subjective and inefficient. The article proposes an intelligent recommendation method for system capability indicators based on semantic understanding technology: firstly, crawling open-source weakly related semantic matching training sets, publicly available military articles and other relevant textual data, applying large language models to construct model training datasets suitable for the military domain; secondly, establishing a Chinese semantic matching model based on Sentence-BERT to achieve similarity scoring and ranking of input indicators and other texts; finally, designing simulation experiments to verify the feasibility and accuracy of this method, which can provide reliable support and reference for relevant decision-making. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Indicator Recommendation; LLM; semantic matching; Sentence-BERT},
	keywords = {Data accuracy; Combat effectiveness; Data collection; Effectiveness evaluation; Indicator recommendation; LLM; Recommendation methods; Semantic matching; Sentence-BERT; Small samples; System capabilities; Semantics},
	correspondence_address = {Z. Li; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; email: libo803@nwpu.edu.cn},
	editor = {Yan L. and Duan H. and Deng Y.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18761100},
	isbn = {978-981962251-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Electr. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Parveen2025386,
	author = {Parveen, Risha and Mehraj, Ali and Zhang, Zheying and Systä, Kari and Kilamo, Terhi},
	title = {Towards Automated Recovery of Links Between Code Commits and Requirements–Initial Results},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15452 LNCS},
	pages = {386 – 394},
	doi = {10.1007/978-3-031-78386-9_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211918231&doi=10.1007%2f978-3-031-78386-9_29&partnerID=40&md5=6b06f96b59ef059abb22a43f7d70671e},
	affiliations = {Tampere University, Tampere, Finland},
	abstract = {The paper reports work-on-progress on discovering undocumented links between source code updates and textual descriptions of desired features. The technical work is based on an existing trained model, T-BERT, that is shown to be effective for an example project by comparing the documented links to those automatically discovered. Prior work has concentrated on the development and evaluation of the ML model. Our aim is to take the next steps towards a practical tool. In this paper, we test the algorithm with a few example projects and analyze the discovered links. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {issue-commit link; link recovery; LLM; requirements traceability; T-BERT},
	keywords = {Issue-commit link; Link recoveries; LLM; Model T; Requirements traceability; Source codes; T-BERT; Technical work; Textual description},
	correspondence_address = {R. Parveen; Tampere University, Tampere, Finland; email: risha.parveen@tuni.fi},
	editor = {Pfahl D. and Anwar H. and Gonzalez Huerta J. and Klünder J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303178385-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Colombo2025,
	author = {Colombo, Andrea and Bernasconi, Anna and Ceri, Stefano},
	title = {An LLM-assisted ETL pipeline to build a high-quality knowledge graph of the Italian legislation},
	year = {2025},
	journal = {Information Processing and Management},
	volume = {62},
	number = {4},
	doi = {10.1016/j.ipm.2025.104082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217076368&doi=10.1016%2fj.ipm.2025.104082&partnerID=40&md5=d1bbb8d660dc7af4ca8ed0789c7bf7ba},
	affiliations = {Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Via Giuseppe Ponzio, 34, Milan, 20133, Italy},
	abstract = {The increasing complexity of legislative systems, characterized by an ever-growing number of laws and their interdependencies, has highlighted the utility of Knowledge Graphs (KGs) as an effective data model for organizing such information, compared to traditional methods, often based on relational models, which struggle to efficiently represent interlinked data, such as references within laws, hindering efficient knowledge discovery. A paradigm shift in modeling legislative data is already ongoing with the adoption of common international standards, predominantly XML-based, such as Akoma Ntoso (AKN) and the Legal Knowledge Interchange Format, which aim to capture fundamental aspects of laws shared across different legislations and simplify the task of creating Knowledge Graphs through the use of XML tags and identifiers. However, to enable advanced analysis and data discovery within these KGs, it is necessary to carefully check, complement, and enrich KG nodes and edges with properties, either metadata or additional derived knowledge, that enhance the quality and utility of the model, for instance, by leveraging the capabilities of state-of-the-art Large Language Models. In this paper, we present an ETL pipeline for modeling and querying the Italian legislation in a Knowledge Graph, by adopting the property graph model and the AKN standard implemented in the Italian system. The property graph model offers a good compromise between knowledge representation and the possibility of performing graph analytics, which we consider essential for enabling advanced pattern detection. Then, we enhance the KG with valuable properties by employing carefully fine-tuned open-source LLMs, i.e., BERT and Mistral-7B models, which enrich and augment the quality of the KG, allowing in-depth analysis of legislative data. © 2025 The Authors},
	author_keywords = {Data quality; Knowledge graph; Large language models; Law; Property graph},
	keywords = {XML; Data quality; Graph model; High quality; Knowledge graphs; Language model; Large language model; Law; Property; Property graph; Quality knowledge; Knowledge graph},
	correspondence_address = {A. Colombo; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Via Giuseppe Ponzio, 34, 20133, Italy; email: andrea1.colombo@polimi.it},
	publisher = {Elsevier Ltd},
	issn = {03064573},
	coden = {IPMAD},
	language = {English},
	abbrev_source_title = {Inf. Process. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Qiu2025,
	author = {Qiu, Min and Wang, Tao},
	title = {Large Language Model-Aided Production-Level Intelligent Economic Forecasting Method},
	year = {2025},
	journal = {Journal of Circuits, Systems and Computers},
	volume = {34},
	number = {07},
	doi = {10.1142/S0218126625501889},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000744044&doi=10.1142%2fS0218126625501889&partnerID=40&md5=d72058353aad00878cba184a7b20f83b},
	affiliations = {Hebi Institute of Engineering and Technology, Henan Polytechnic University, Hebi, 458000, China; Zhengzhou University of Science and Technology, Zhengzhou, 450064, China},
	abstract = {In a rapidly changing industrial environment, the accuracy of economic forecasting is increasingly critical. With the rise of the Large language Model (LLM), a new path for economic forecasting has been opened up. Therefore, the purpose of this study is to use LLM to improve the accuracy and flexibility of industrial economic forecasting. By analyzing the shortcomings of existing forecasting methods, the Bidirectional Encoder Representations from Transformers (BERT) model is used to process economic data, and the text is transformed into high-dimensional vectors to accurately capture economic characteristics. Subsequently, it is combined with the Generative Pre-trained Transformer (GPT) large language model to deepen the data analysis, and assists the Bidirectional Long Short-Term Memory (BiLSTM) model for industrial economic prediction. In addition, the optimized Dung Beetle Optimization (DBO) algorithm is introduced to fine-tune BiLSTM parameters, and a new framework of economic intelligent prediction assisted by the large language model is constructed. The results show that this method significantly improves the accuracy, timeliness and comprehensiveness of the forecast. And it can be flexibly applied to multi-industry and multi-time scale forecasting. © 2025 World Scientific Publishing Company.},
	author_keywords = {BERT; deep learning; intelligent forecasting; Large language model},
	keywords = {Bidirectional encoder representation from transformer; Deep learning; Economic forecasting; Forecasting methods; Industrial environments; Intelligent forecasting; Language model; Large language model; Production level; Short term memory; Prediction models},
	correspondence_address = {M. Qiu; Hebi Institute of Engineering and Technology, Henan Polytechnic University, Hebi, 458000, China; email: qiumin0607@163.com},
	publisher = {World Scientific},
	issn = {02181266},
	coden = {JCSME},
	language = {English},
	abbrev_source_title = {J. Circuits Syst. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2025,
	author = {Chen, Qingyu and Hu, Yan and Peng, Xueqing and Xie, Qianqian and Jin, Qiao and Gilson, Aidan and Singer, Maxwell B. and Ai, Xuguang and Lai, Po-Ting and Wang, Zhizheng and Keloth, Vipina K. and Raja, Kalpana and Huang, Jimin and He, Huan and Lin, Fongci and Du, Jingcheng and Zhang, Rui and Zheng, W. Jim and Adelman, Ron A. and Lu, Zhiyong and Xu, Hua},
	title = {Benchmarking large language models for biomedical natural language processing applications and recommendations},
	year = {2025},
	journal = {Nature Communications },
	volume = {16},
	number = {1},
	doi = {10.1038/s41467-025-56989-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002971344&doi=10.1038%2fs41467-025-56989-2&partnerID=40&md5=45e7bf5792e8588c32798f3663bfd079},
	affiliations = {Department of Biomedical Informatics and Data Science, Yale School of Medicine, Yale University, New Haven, CT, United States; National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; McWilliams School of Biomedical Informatics, University of Texas Health Science at Houston, Houston, TX, United States; Department of Ophthalmology and Visual Science, Yale School of Medicine, Yale University, New Haven, CT, United States; Division of Computational Health Sciences, Department of Surgery, Medical School, University of Minnesota, Minneapolis, MN, United States; Center for Learning Health System Sciences, University of Minnesota, Minneapolis, 55455, MN, United States},
	abstract = {The rapid growth of biomedical literature poses challenges for manual knowledge curation and synthesis. Biomedical Natural Language Processing (BioNLP) automates the process. While Large Language Models (LLMs) have shown promise in general domains, their effectiveness in BioNLP tasks remains unclear due to limited benchmarks and practical guidelines. We perform a systematic evaluation of four LLMs—GPT and LLaMA representatives—on 12 BioNLP benchmarks across six applications. We compare their zero-shot, few-shot, and fine-tuning performance with the traditional fine-tuning of BERT or BART models. We examine inconsistencies, missing information, hallucinations, and perform cost analysis. Here, we show that traditional fine-tuning outperforms zero- or few-shot LLMs in most tasks. However, closed-source LLMs like GPT-4 excel in reasoning-related tasks such as medical question answering. Open-source LLMs still require fine-tuning to close performance gaps. We find issues like missing information and hallucinations in LLM outputs. These results offer practical insights for applying LLMs in BioNLP. © This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply 2025.},
	keywords = {Benchmarking; Humans; Large Language Models; Natural Language Processing; benchmarking; cost analysis; data processing; knowledge; literature review; Article; automation; benchmarking; comparative study; evaluation study; large language model; natural language processing; practice guideline; quantitative analysis; task performance; human; large language model},
	correspondence_address = {H. Xu; Department of Biomedical Informatics and Data Science, Yale School of Medicine, Yale University, New Haven, United States; email: hua.xu@yale.edu; Z. Lu; National Library of Medicine, National Institutes of Health, Bethesda, United States; email: zhiyong.lu@nih.gov},
	publisher = {Nature Research},
	issn = {20411723},
	pmid = {40188094},
	language = {English},
	abbrev_source_title = {Nat. Commun.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wu2025725,
	author = {Wu, Pengcheng and Mou, Xun and Gong, Leihao and Tu, Haobei and Qiu, Linqiong and Yang, Bo},
	title = {An automatic machine fault identification method using the knowledge graph–embedded large language model},
	year = {2025},
	journal = {International Journal of Advanced Manufacturing Technology},
	volume = {138},
	number = {2},
	pages = {725 – 739},
	doi = {10.1007/s00170-025-15555-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003947839&doi=10.1007%2fs00170-025-15555-2&partnerID=40&md5=4ad6759734c7b2329c6c6d7c5d9308ae},
	affiliations = {College of Artificial Intelligence, Southwest University, Chongqing, 400715, China; National & Local Joint Engineering Research Center of Intelligent Transmission and Control Technology, Chongqing, China; Chongqing Key Laboratory of Brain-Inspired Computing and Intelligent Chips, Chongqing, China; School of Mathematical Science, Queensland University of Technology, Brisbane, QLD, Australia; State Key Laboratory of Mechanical Transmission for Advanced Equipment, Chongqing University, Chongqing, China},
	abstract = {Computer numerical control (CNC) machines are prone to various faults during long-term operation, which can compromise production safety. However, accurately identifying fault sources and obtaining rapid troubleshooting solutions remains a significant challenge. To tackle this challenge, this study proposes an automated machining process decision-making system that integrates a knowledge graph and a large language model (LLM). The system first constructs a graph-based fault knowledge representation using BERT-Transformer-CRF for machining knowledge extraction. The developed machining process knowledge graph is then enhanced and endowed with knowledge reasoning capabilities via the large language model. By combining the graph-structured machining process representing form and knowledge inference ability, the proposed system significantly improves fault diagnosis and troubleshooting efficiency. To evaluate its performance, a functional test was conducted, comparing the system with conventional approaches in terms of accuracy, knowledge inference ability, and user-friendliness. Experimental results in practical industrial scenarios demonstrate that the proposed model achieves 97.50% accuracy in fault diagnosis and troubleshooting. Additionally, subjective evaluations indicate high usability, with scores of 9.4 for user-friendliness and 9.1 for knowledge inference ability. These findings highlight the system’s potential to enhance fault troubleshooting in industrial machining processes. © The Author(s) 2025.},
	author_keywords = {Fault localization; Knowledge graph; Knowledge inference; Large language model; Machining process},
	keywords = {Grinding (machining); Inference engines; Machining centers; Automatic machines; Fault localization; Faults diagnosis; Knowledge graphs; Knowledge inference; Language model; Large language model; Machine faults; Machining Process; User friendliness; Knowledge graph},
	correspondence_address = {P. Wu; College of Artificial Intelligence, Southwest University, Chongqing, 400715, China; email: wupengcheng_mech@163.com; L. Qiu; School of Mathematical Science, Queensland University of Technology, Brisbane, Australia; email: emily.qiu345@gmail.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {02683768},
	coden = {IJATE},
	language = {English},
	abbrev_source_title = {Int J Adv Manuf Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shang2025,
	author = {Shang, Yu-Ming and Mao, Hongli and Tian, Tian and Huang, Heyan and Mao, Xian-Ling},
	title = {From local to global: Leveraging document graph for named entity recognition},
	year = {2025},
	journal = {Knowledge-Based Systems},
	volume = {312},
	doi = {10.1016/j.knosys.2025.113017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217932486&doi=10.1016%2fj.knosys.2025.113017&partnerID=40&md5=1b1cc0f73c7c294e67066c1073a9b20f},
	affiliations = {Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing Institute of Technology, Beijing, China},
	abstract = {Named Entity Recognition (NER) is a fundamental task in Natural Language Processing (NLP) that aims to identify the span and category of entities within text. Recent advancements have demonstrated significant improvements in NER performance by incorporating document-level context. However, due to input length limitations, these models only consider the context of nearby sentences, failing to capture global long-range dependencies within the entire document. To address this issue, we propose a novel span-based two-stage method that formulates the document as a span graph, enabling the capture of global long-range dependencies at both token and span levels. Specifically, (1) we first train a binary classifier without considering entity types to extract candidate spans from each sentence. (2) Then, we leverage the robust contextual understanding and structural reasoning capabilities of Large Language Models (LLMs) like GPT to incrementally integrate these spans into the document-level span graph. By utilizing this span graph as a guide, we retrieve relevant contextual sentences for each target sentence and jointly encode them using BERT to capture token-level dependencies. Furthermore, by employing a Graph Transformer with well-designed position encoding to incorporate graph structure, our model effectively exploits span-level dependencies throughout the document. Extensive experiments on resource-rich nested and flat NER datasets, as well as low-resource distantly supervised NER datasets, demonstrate that our proposed model outperforms previous state-of-the-art models, showcasing its effectiveness in capturing long-range dependencies and enhancing NER accuracy. © 2025},
	author_keywords = {Document-level; LLM; Named entity recognition; Span graph},
	keywords = {Encoding (symbols); Natural language processing systems; Document-level; Input lengths; Language model; Language processing; Large language model; Long-range dependencies; Named entity recognition; Natural languages; Performance; Span graph; Graph theory},
	correspondence_address = {H. Mao; School of Computer Science, Beijing Institute of Technology, Beijing, China; email: maohongli.bit@gmail.com},
	publisher = {Elsevier B.V.},
	issn = {09507051},
	coden = {KNSYE},
	language = {English},
	abbrev_source_title = {Knowl Based Syst},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Konev202542,
	author = {Konev, Anton A. and Payusova, Tatyana I.},
	title = {Large language models in information security and penetration testing: a systematic review of application possibilities; [Большие языковые модели в информационной безопасности и тестировании на проникновение: систематический обзор возможностей применения]},
	year = {2025},
	journal = {Scientific and Technical Journal of Information Technologies, Mechanics and Optics},
	volume = {25},
	number = {1},
	pages = {42 – 52},
	doi = {10.17586/2226-1494-2025-25-1-42-52},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000465351&doi=10.17586%2f2226-1494-2025-25-1-42-52&partnerID=40&md5=ab7334b9a40c7853b792baf609630f80},
	affiliations = {Tomsk State University of Control Systems and Radioelectronics (TUSUR), Tomsk, 634050, Russian Federation; Tyumen State University, Tyumen, 625003, Russian Federation},
	abstract = {The development of artificial intelligence technologies, in particular, large language models (LLM), has led to changes in many areas of human life and activity. Information security (IS) has also undergone significant changes. Penetration testing (pentest) allows evaluating the security system in practice in “combat” conditions. LLMs can take practical security analysis to a qualitatively new level in terms of automation and the ability to generate non-standard attack patterns. The presented systematic review is aimed at determining the already known ways of applying LLM in cybersecurity, as well as identifying “blank spots” in the development of technology. The selection of literature sources was carried out in accordance with the multi-stage PRISMA guidelines based on the analysis of abstracts and keywords of publications. The resulting sample was supplemented using the “snowball” method and manual search of articles. The total number of publications was 50 works from January 2023 to March 2024. The conducted research allowed to analyze the ways of using LLM in the field of information security (goal setting and decision-making support, pentest automation, security analysis of LLM models and program code), determine the LLM architectures (GPT-4, GPT-3.5, Bard, LLaMA, LLaMA 2, BERT, Mixtral 8×7B Instruct, FLAN, Bloom) and software solutions based on LLM used in the field of information security (GAIL-PT, AutoAttacker, NetSecGame, Cyber Sentinel, Microsoft Counterfit, GARD project, GPTFUZZER, VuRLE), to establish limitations (finite “lifetime” of data for LLM training, insufficient cognitive abilities of language models, lack of independent goal setting and difficulties in adapting LLM to new task parameters), identify potential growth points and development of technology in the context of cyber defense (elimination of “hallucinations” of models and ensuring protection of LLM from jailbreaks, implementation of integration of known disparate solutions and software automation of tasks in the field of information security using LLM). The presented results can be useful in developing theoretical and practical solutions, educational and training datasets, software packages and tools for penetration testing, new approaches to building LLM and improving their cognitive abilities, taking into account aspects of working with jailbreaks and “hallucinations”, as well as for independent further multilateral study of the issue. © Конев А.А., Паюсова Т.И., 2025.},
	author_keywords = {artificial intelligence; attack modeling; ChatGPT; computational linguistics; jailbreaking; machine learning; natural language processing; Red Teaming},
	correspondence_address = {A.A. Konev; Tomsk State University of Control Systems and Radioelectronics (TUSUR), Tomsk, 634050, Russian Federation; email: kaa@fb.tusur.ru},
	publisher = {ITMO University},
	issn = {22261494},
	language = {Russian},
	abbrev_source_title = {Sci. Tech. J. Inf. Tech. Mech. Optics},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Puts2025,
	author = {Puts, Sander and Zegers, Catharina M.L. and Dekker, Andre and Bermejo, Iñigo},
	title = {Developing an ICD-10 Coding Assistant: Pilot Study Using RoBERTa and GPT-4 for Term Extraction and Description- Based Code Selection},
	year = {2025},
	journal = {JMIR Formative Research},
	volume = {9},
	doi = {10.2196/60095},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217741389&doi=10.2196%2f60095&partnerID=40&md5=8ba11d54ad70c87c108929425c2d9989},
	affiliations = {Department of Radiation Oncology (Maastro), GROW Research Institute for Oncology and Reproduction, Maastricht University Medical Centre+, Maastricht, Netherlands; Data Science Institute (DSI), Hasselt University, Belgium},
	abstract = {Background: The International Classification of Diseases (ICD), developed by the World Health Organization, standardizes health condition coding to support health care policy, research, and billing, but artificial intelligence automation, while promising, still underperforms compared with human accuracy and lacks the explainability needed for adoption in medical settings. Objective: The potential of large language models for assisting medical coders in the ICD-10 coding was explored through the development of a computer-assisted coding system. This study aimed to augment human coding by initially identifying lead terms and using retrieval-augmented generation (RAG)-based methods for computer-assisted coding enhancement. Methods: The explainability dataset from the CodiEsp challenge (CodiEsp-X) was used, featuring 1000 Spanish clinical cases annotated with ICD-10 codes. A new dataset, CodiEsp-X-lead, was generated using GPT-4 to replace full-textual evidence annotations with lead term annotations. A Robustly Optimized BERT (Bidirectional Encoder Representations from Transformers) Pretraining Approach transformer model was fine-tuned for named entity recognition to extract lead terms. GPT-4 was subsequently employed to generate code descriptions from the extracted textual evidence. Using a RAG approach, ICD codes were assigned to the lead terms by querying a vector database of ICD code descriptions with OpenAI's text-embedding- ada-002 model. Results: The fine-tuned Robustly Optimized BERT Pretraining Approach achieved an overall F1-score of 0.80 for ICD lead term extraction on the new CodiEsp-X-lead dataset. GPT-4-generated code descriptions reduced retrieval failures in the RAG approach by approximately 5% for both diagnoses and procedures. However, the overall explainability F1-score for the CodiEsp-X task was limited to 0.305, significantly lower than the state-of-the-art F1-score of 0.633. The diminished performance was partly due to the reliance on code descriptions, as some ICD codes lacked descriptions, and the approach did not fully align with the medical coder's workflow. Conclusions: While lead term extraction showed promising results, the subsequent RAG-based code assignment using GPT-4 and code descriptions was less effective. Future research should focus on refining the approach to more closely mimic the medical coder's workflow, potentially integrating the alphabetic index and official coding guidelines, rather than relying solely on code descriptions. This alignment may enhance system accuracy and better support medical coders in practice. © 2025 JMIR Publications Inc.. All rights reserved.},
	author_keywords = {AI automation; artificial intelligence; Bidirectional Encoder Representations from Transformers; code analysis; coding; computer assisted coding; computer-assisted-coding; GPT-4; ICD-10; International Classification of Diseases; large language model; LLM; named entity recognition; NER; RAG; retrieval-augmented generation; RoBERTa; Robustly Optimized BERT Pretraining Approach; term extraction; transformer model},
	correspondence_address = {S. Puts; Department of Radiation Oncology (Maastro), GROW Research Institute for Oncology and Reproduction, Maastricht University Medical Centre+, Maastricht, P.O. Box 616, 6200 MD, Netherlands; email: putssander@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {2561326X},
	language = {English},
	abbrev_source_title = {JMIR Form.  Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Breton202586,
	author = {Breton, Julien and Billami, Mokhtar Boumedyen and Chevalier, Max and Trojahn, Cassia},
	title = {Empowering CamemBERT Legal Entity Extraction With LLM Boostrapping},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15370 LNAI},
	pages = {86 – 101},
	doi = {10.1007/978-3-031-77792-9_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210809942&doi=10.1007%2f978-3-031-77792-9_6&partnerID=40&md5=e6c7c5c644cabb5d5e30ac846d19833c},
	affiliations = {Informatics Research Institute of Toulouse (IRIT), Toulouse, France; Berger-Levrault, Toulouse, France},
	abstract = {The legal industry is characterized by the presence of large volumes and complex documents. Given the continuous evolution of these documents, there is a growing interest in automating the processing of legal texts to streamline compliance. One key step of this process is the extraction of legal entities. State-of-the-art methods for legal entity extraction, including rule-based systems, Bi-LSTM, and BERT, require substantial annotated data to be effective, a task that is time-intensive for domain experts. With the rise of Large Language Models (LLMs), research has increasingly focused on leveraging their capabilities and exploring zero-shot approaches. In this paper, we present a hybrid system that distils GPT-4 knowledge through rule-based methods into a CamemBERT model. This approach not only reduces the need for expert involvement compared to the standard CamemBERT system but also outperforms the GPT-4-only system, enhancing the F1 score for legal entities by 9–24% points. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {CamemBERT; Knowledge Distilation; Large Language Models (LLMs); Legal Entity Extraction; Limited Annotated Data},
	keywords = {Metadata; CamemBERT; Complex documents; Entity extractions; Knowledge distilation; Language model; Large language model; Large volumes; Legal entities; Legal entity extraction; Limited annotated data; Modeling languages},
	correspondence_address = {J. Breton; Informatics Research Institute of Toulouse (IRIT), Toulouse, France; email: julien.breton@irit.fr},
	editor = {Alam M. and Rospocher M. and van Erp M. and Hollink L. and Gesese G.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303177791-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pahune2025,
	author = {Pahune, Saurabh and Akhtar, Zahid},
	title = {Transitioning from MLOps to LLMOps: Navigating the Unique Challenges of Large Language Models},
	year = {2025},
	journal = {Information (Switzerland)},
	volume = {16},
	number = {2},
	doi = {10.3390/info16020087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218460051&doi=10.3390%2finfo16020087&partnerID=40&md5=d9005edf891e30705f78dc417dba5492},
	affiliations = {Cardinal Health, Dublin, 43017, OH, United States; Department of Network and Computer Security, State University of New York Polytechnic Institute, Utica, 13502, NY, United States},
	abstract = {Large Language Models (LLMs), such as the GPT series, LLaMA, and BERT, possess incredible capabilities in human-like text generation and understanding across diverse domains, which have revolutionized artificial intelligence applications. However, their operational complexity necessitates a specialized framework known as LLMOps (Large Language Model Operations), which refers to the practices and tools used to manage lifecycle processes, including model fine-tuning, deployment, and LLMs monitoring. LLMOps is a subcategory of the broader concept of MLOps (Machine Learning Operations), which is the practice of automating and managing the lifecycle of ML models. LLM landscapes are currently composed of platforms (e.g., Vertex AI) to manage end-to-end deployment solutions and frameworks (e.g., LangChain) to customize LLMs integration and application development. This paper attempts to understand the key differences between LLMOps and MLOps, highlighting their unique challenges, infrastructure requirements, and methodologies. The paper explores the distinction between traditional ML workflows and those required for LLMs to emphasize security concerns, scalability, and ethical considerations. Fundamental platforms, tools, and emerging trends in LLMOps are evaluated to offer actionable information for practitioners. Finally, the paper presents future potential trends for LLMOps by focusing on its critical role in optimizing LLMs for production use in fields such as healthcare, finance, and cybersecurity. © 2025 by the authors.},
	author_keywords = {cybersecurity; ethical AI practices; generative AI (GenAI); GPT; infrastructure scalability; LangChain; large language models (LLMs); LLMOps; MLOps; model fine-tuning; retrieval-augmented generation (RAG); security in AI operations; text generation; Vertex AI},
	keywords = {Ethical aspects; Machine learning; Problem oriented languages; Report generators; Cyber security; Ethical AI practice; Fine tuning; Generative AI; GPT; Infrastructure scalability; Langchain; Language model; Large language model; Large language model operation; Machine learning operation; Machine-learning; Model fine-tuning; Modeling operation; Retrieval-augmented generation; Security in AI operation; Text generations; Vertex AI; Scalability},
	correspondence_address = {Z. Akhtar; Department of Network and Computer Security, State University of New York Polytechnic Institute, Utica, 13502, United States; email: akhtarz@sunypoly.edu},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20782489},
	language = {English},
	abbrev_source_title = {Information},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Baro20251215,
	author = {Baro, Everton F. and Oliveira, Luiz S. and Britto, Alceu de Souza},
	title = {Predicting hospitalization with LLMs from health insurance data},
	year = {2025},
	journal = {Medical and Biological Engineering and Computing},
	volume = {63},
	number = {4},
	pages = {1215 – 1226},
	doi = {10.1007/s11517-024-03251-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001067044&doi=10.1007%2fs11517-024-03251-4&partnerID=40&md5=78d8cd9c3bbaf9feca01f2f2928c041c},
	affiliations = {Department of Informatics, Federal University of Parana, Rua Francisco H. dos Santos, 100, Parana, Curitiba, 81530-090, Brazil; Department of Informatics, Federal Institute of Parana, Rodovia PR 323, KM 310, Parana, Umuarama, 87507-014, Brazil; Postgraduate Program in Informatics, Pontifical Catholic University of Parana, Rua Imaculada Conceicao, 1155 Bloco 8, Parana, Curitiba, 80215-901, Brazil},
	abstract = {Abstract: Predictions of hospitalizations can help in the development of applications for health insurance, hospitals, and medicine. The data collected by health insurance has potential that is not always explored, and extracting features from it for use in machine learning applications requires demanding processes and specialized knowledge. With the emergence of large language models (LLM) there are possibilities to use this data for a wide range of applications requiring little specialized knowledge. To do this, it is necessary to organize and prepare this data to be used by these models. Therefore, in this work, an approach is presented for using data from health insurance in LLMs with the objective of predict hospitalizations. As a result, pre-trained models were generated in Portuguese and English with health insurance data that can be used in several applications. To prove the effectiveness of the models, tests were carried out to predict hospitalizations in general and due to stroke. For hospitalizations in general, F1-Score = 87.8 and AUC = 0.955 were achieved, and for hospitalizations due to stroke, the best model achieved F1-Score = 88.7 and AUC of 0.964. Considering the potential for use, the models were made available to the scientific community. © International Federation for Medical and Biological Engineering 2024.},
	author_keywords = {BERT; Health insurance; Hospitalization; Large language models; LLaMA; Machine learning; RoBERTa; Strokes},
	keywords = {Electronic health record; Hospital data processing; BERT; F1 scores; Hospitalization; Language model; Large language model; LLaMA; Machine-learning; RoBERTa; Specialized knowledge; Stroke; Article; cerebrovascular accident; controlled study; data integrity; data privacy; English (language); health insurance; hospitalization; human; large language model; major clinical study; Portuguese (language); predictive model; sensitivity and specificity; Health insurance},
	correspondence_address = {E.F. Baro; Department of Informatics, Federal University of Parana, Curitiba, Rua Francisco H. dos Santos, 100, Parana, 81530-090, Brazil; email: efbaro@inf.ufpr.br},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {01400118},
	coden = {MBECD},
	language = {English},
	abbrev_source_title = {Med. Biol. Eng. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Agyemang2025107,
	author = {Agyemang, Alex and Schlippe, Tim},
	title = {AI in Education: An Analysis of Large Language Models for Twi Automatic Short Answer Grading},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2326 CCIS},
	pages = {107 – 123},
	doi = {10.1007/978-3-031-78255-8_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211792381&doi=10.1007%2f978-3-031-78255-8_7&partnerID=40&md5=56a7cac33dfc155418771b0f2bfca223},
	affiliations = {IU International University of Applied Sciences, Bad Honnef, Germany},
	abstract = {Automatic short answer grading can significantly enhance the speed and fairness of grading, making it particularly valuable in areas with a shortage of teachers, such as Africa [1]. However, for most African languages it is very challenging to build automatic short answer grading systems due to the limited availability of natural language processing corpora. Furthermore, only experts can deal with the complex algorithms, required for training and fine-tuning traditional automatic short answer grading systems. Given that state-of-the-art large language models have the potential to address these problems through their growing capabilities and ease of use through prompting, particularly in zero-shot and few-shot learning, we investigated their performance for grading student answers in the African language Twi. To address the absence of a Twi corpus, we translated and validated the University of North Texas benchmark corpus [2], creating the first Twi automatic short answer grading corpus. On this corpus, we evaluated the performances of the large language models GPT-4o [3], Claude 3 Sonnet [4], and LLaMA 3 [5] as well as for comparison two more traditional approaches: a fine-tuned AfroLM and a cross-lingual M-BERT approach. Among individual models, the cross-lingual M-BERT had the best performance with a mean absolute error of 0.79 points out of 5 points, followed by fine-tuned AfroLM at 0.73 points and Claude 3 Sonnet at 1.00 points. However, combining AfroLM and M-BERT outputs achieved the lowest mean absolute error of 0.64 points, which is less than the human grader variance of 0.75 points in the original corpus [6]. Combining the outputs of the large language models GPT-4o, Claude 3 Sonnet, and LLaMA 3, obtained through few-shot learning, yielded a mean absolute error of 1.10 points. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Africa; AI in Education; Automatic Short Answer Grading; Large-Language Models; LLMs; Natural Language Processing},
	keywords = {Benchmarking; Linguistics; Modeling languages; Natural language processing systems; Personnel training; Problem oriented languages; Teaching; Translation (languages); Africa; AI in education; Automatic short answer grading; Language model; Language processing; Large-language model; LLM; Natural language processing; Natural languages; Performance; Zero-shot learning},
	correspondence_address = {T. Schlippe; IU International University of Applied Sciences, Bad Honnef, Germany; email: tim.schlippe@iu.org},
	editor = {Gerber A. and Maritz J. and Pillay A.W.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303178254-1},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2025,
	author = {Zhang, Yufeng and Kohne, Joseph G. and Webster, Katherine and Vartanian, Rebecca and Wittrup, Emily and Najarian, Kayvan},
	title = {AXpert: human expert facilitated privacy-preserving large language models for abdominal X-ray report labeling},
	year = {2025},
	journal = {JAMIA Open},
	volume = {8},
	number = {1},
	doi = {10.1093/jamiaopen/ooaf008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217951523&doi=10.1093%2fjamiaopen%2fooaf008&partnerID=40&md5=8a9af4e731eaa64cc527450cdfdc813f},
	affiliations = {Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, 48105, MI, United States; Department of Pediatrics, University of Michigan, Ann Arbor, 48105, MI, United States; Susan B. Meister Child Health Evaluation and Research Center, University of Michigan, Ann Arbor, 48105, MI, United States; Michigan Institute for Data Science, University of Michigan, Ann Arbor, 48105, MI, United States; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, 48105, MI, United States; Department of Emergency Medicine, University of Michigan, Ann Arbor, 48105, MI, United States},
	abstract = {Importance: The lack of a publicly accessible abdominal X-ray (AXR) dataset has hindered necrotizing enterocolitis (NEC) research. While significant strides have been made in applying natural language processing (NLP) to radiology reports, most efforts have focused on chest radiology. Development of an accurate NLP model to identify features of NEC on abdominal radiograph can support efforts to improve diagnostic accuracy for this and other rare pediatric conditions. Objectives: This study aims to develop privacy-preserving large language models (LLMs) and their distilled version to efficiently annotate pediatric AXR reports. Materials and Methods: Utilizing pediatric AXR reports collected from C.S. Mott Children’s Hospital, we introduced AXpert in 2 formats: one based on the instruction-fine-tuned 7-B Gemma model, and a distilled version employing a BERT-based model derived from the fine-tuned model to improve inference and fine-tuning efficiency. AXpert aims to detect NEC presence and classify its subtypes—pneumatosis, portal venous gas, and free air. Results: Extensive testing shows that LLMs, including Axpert, outperforms baseline BERT models on all metrics. Specifically, Gemma-7B (F1 score: 0.9 ± 0.015) improves upon BlueBERT by 132% in F1 score for detecting NEC positive samples. The distilled BERT model matches the performance of the LLM labelers and surpasses expert-trained baseline BERT models. Discussion: Our findings highlight the potential of using LLMs for clinical NLP tasks. With minimal expert knowledge injections, LLMs can achieve human-like performance, greatly reducing manual labor. Privacy concerns are alleviated as all models are trained and deployed locally. Conclusion: AXpert demonstrates potential to reduce human labeling efforts while maintaining high accuracy in automating NEC diagnosis with AXR, offering precise image labeling capabilities. Lay Summary In pediatric healthcare, diagnosing conditions like necrotizing enterocolitis (NEC), a serious gastrointestinal issue in infants, is challenging due to the scarcity of public X-ray data. To address this, we introduced AXpert, an innovative tool designed to enhance NEC diagnosis by analyzing abdominal X-ray reports from children. AXpert utilizes advanced artificial intelligence (AI), specifically tailored large language models (LLMs), to interpret medical texts. These models were trained using data from C.S. Mott Children’s Hospital to identify NEC and its critical features, such as pneumatosis, portal venous gas, and free air. The study shows that AXpert outperforms previous AI models, providing both accurate and efficient diagnostic assessments. Importantly, AXpert focuses on privacy, with all data and AI operations handled locally to protect patient information. This tool not only promises to reduce the workload of medical professionals but also improves the accuracy of diagnosing severe conditions in young patients, showcasing the potential of AI in enhancing pediatric healthcare. © The Author(s) 2025.},
	author_keywords = {instruction fine-tuning; large language models; model distillation; natural language processing; radiology report labeling},
	keywords = {abdominal radiography; Article; AXpert; Bidirectional Encoder Representations from Transformer; child; clinical effectiveness; comparative study; controlled study; data classification; data privacy; diagnostic accuracy; diagnostic test accuracy study; emphysema; gas; hepatic portal vein; human; knowledge; large language model; major clinical study; Michigan; necrotizing enterocolitis; open source technology; pediatric hospital; pediatric patient; pneumoperitoneum; predictive value; reporting and data system; validation study},
	correspondence_address = {Y. Zhang; Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, 2800 Plymouth Rd, 48105, United States; email: chloezh@umich.edu},
	publisher = {Oxford University Press},
	issn = {25742531},
	language = {English},
	abbrev_source_title = {JAMIA Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Hachmeier20259845,
	author = {Hachmeier, Simon and Jäschke, Robert},
	title = {A Benchmark and Robustness Study of In-Context-Learning with Large Language Models in Music Entity Detection},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {Part F206484-1},
	pages = {9845 – 9859},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218505564&partnerID=40&md5=3e830529bf2fbe4db2625528ccc9bff8},
	affiliations = {Berlin School of Library and Information Science, Humboldt-Universität zu Berlin, Germany},
	abstract = {Detecting music entities such as song titles or artist names is a useful application to help use cases like processing music search queries or analyzing music consumption on the web. Recent approaches incorporate smaller language models (SLMs) like BERT and achieve high results. However, further research indicates a high influence of entity exposure during pre-training on the performance of the models. With the advent of large language models (LLMs), these outperform SLMs in a variety of downstream tasks. However, researchers are still divided if this is applicable to tasks like entity detection in texts due to issues like hallucination. In this paper, we provide a novel dataset of user-generated metadata and conduct a benchmark and a robustness study using recent LLMs with in-context-learning (ICL). Our results indicate that LLMs in the ICL setting yield higher performance than SLMs. We further uncover the large impact of entity exposure on the best performing LLM in our study. © 2025 Association for Computational Linguistics.},
	keywords = {Benchmarking; Metadata; Structured Query Language; Benchmark study; Context learning; Down-stream; Entity detection; In contexts; Language model; Performance; Pre-training; Robustness studies; Search queries; Computational linguistics},
	editor = {Rambow O. and Wanner L. and Apidianaki M. and Al-Khalifa H. and Di Eugenio B. and Schockaert S.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176196-4},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Mettildha202541,
	author = {Mettildha, Mary I. and Preethi, M. and Prabhu, T.N. and Priyadharsini, M. and Sugantha, Mallika S. S.},
	title = {Hybrid soft computing techniques for machine learning and optimization: Financial document summarization using Lamini FLan-T15 and BERT},
	year = {2025},
	journal = {Hybrid Soft Computing Techniques for Machine Learning and Optimization},
	pages = {41 – 52},
	doi = {10.4018/979-8-3693-6864-0.ch003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004780381&doi=10.4018%2f979-8-3693-6864-0.ch003&partnerID=40&md5=d77df774a6e1f442a20dda482c5c2205},
	affiliations = {Dr. N.G.P. Institute of Technology, India; Sri Ramakrishna Engineering College, India; Vellore Institute of Technology, India},
	abstract = {This Financial document summarizer combines modern NLP models like Law Mini- Flan- T5 and BERT to construct an advanced document summarizing system specifically designed for financial documents. Users receive incredibly accurate and clear summaries from the technology, which has been fine- tuned to extract important information from complicated financial materials. The integration of LLM (Large Language Model) models, which enables users to select between LLM models according to their preferences for summarizing, is a crucial component of the project. React is used in the front- end implementation of the system, guaranteeing a smooth and intuitive user experience. With its accurate and adaptable methods for efficiently managing financial information, the proposed system marks a substantial advancement in the field of document summarization. © 2025, IGI Global Scientific Publishing. All rights reserved.},
	publisher = {IGI Global},
	isbn = {979-836936865-7; 979-836936864-0},
	language = {English},
	abbrev_source_title = {Hybrid soft comput. tech. for mach. learn. and optim.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hu2025,
	author = {Hu, Yi and Kim, Hyeonjin and Ye, Kai and Lu, Ning},
	title = {Applying fine-tuned LLMs for reducing data needs in load profile analysis},
	year = {2025},
	journal = {Applied Energy},
	volume = {377},
	doi = {10.1016/j.apenergy.2024.124666},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206014541&doi=10.1016%2fj.apenergy.2024.124666&partnerID=40&md5=7e39dd61079b9d723c4cba9e396be0a9},
	affiliations = {Electrical & Computer Engineering Department, Future Renewable Energy Delivery and Management (FREEDM) Systems Center, North Carolina State University, Raleigh, 27606, NC, United States},
	abstract = {This paper presents a novel method for utilizing fine-tuned Large Language Models (LLMs) to minimize data requirements in load profile analysis, demonstrated through the restoration of missing data in power system load profiles. A two-stage fine-tuning strategy is proposed to adapt a pre-trained LLMs, i.e., GPT-3.5, for missing data restoration tasks. Through empirical evaluation, we demonstrate the effectiveness of the fine-tuned model in accurately restoring missing data, achieving comparable performance to state-of-the-art specifically designed models such as BERT-PIN. Key findings include the importance of prompt engineering and the optimal utilization of fine-tuning samples, highlighting the efficiency of few-shot learning in transferring knowledge from general user cases to specific target users. Furthermore, the proposed approach demonstrates notable cost-effectiveness and time efficiency compared to training models from scratch, making it a practical solution for scenarios with limited data availability and computing resources. Additionally, we applied fine-tuned LLM to load forecasting and showed its significant potential for application to other power system load profile analysis tasks. Consequently, it advances the use of LLMs in power system analytics, offering promising implications for enhancing the resilience and efficiency of power distribution systems. © 2024 Elsevier Ltd},
	author_keywords = {Fine-Tuning; Large Language Models; Load Profile Analysis; Missing Data Restoration; Prompt Engineering},
	keywords = {Data restoration; Fine tuning; Language model; Large language model; Load profile analyze; Load profiles; Missing data; Missing data restoration; Profile analysis; Prompt engineering; accuracy assessment; analytical method; computer simulation; data acquisition; performance assessment},
	correspondence_address = {Y. Hu; Electrical & Computer Engineering Department, Future Renewable Energy Delivery and Management (FREEDM) Systems Center, North Carolina State University, Raleigh, 27606, United States; email: yhu28@ncsu.edu},
	publisher = {Elsevier Ltd},
	issn = {03062619},
	coden = {APEND},
	language = {English},
	abbrev_source_title = {Appl. Energy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Nunes2025127,
	author = {Nunes, Rafael Oleques and Puttlitz, Letícia Maria and Boll, Antonio Oss and Spritzer, Andre and Freitas, Carla Maria Dal Sasso and Balreira, Dennis Giovani and Tavares, Anderson Rocha},
	title = {An Ensemble of LLMs Finetuned with LoRA for NER in Portuguese Legal Documents},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15412 LNAI},
	pages = {127 – 140},
	doi = {10.1007/978-3-031-79029-4_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219176687&doi=10.1007%2f978-3-031-79029-4_9&partnerID=40&md5=121e91dc22ad33ef7ca2bbb70723400d},
	affiliations = {Federal University of Rio Grande do Sul, Porto Alegre, Brazil},
	abstract = {Given the high computational costs of traditional fine-tuning methods and the goal of improving performance,this study investigate the application of low-rank adaptation (LoRA) for fine-tuning BERT models to Portuguese Legal Named Entity Recognition (NER) and the integration of Large Language Models (LLMs) in an ensemble setup. Focusing on the underrepresented Portuguese language, we aim to examine the reliability of extractions enabled by LoRA models and glean actionable insights from the results of both LoRA and LLMs operating in ensembles. Achieving F1-scores of 88.49% for the LeNER-Br corpus and 81.00% for the UlyssesNER-Br corpus, LoRA models demonstrated competitive performance, approaching state-of-the-art standards. Our research demonstrates that incorporating class definitions and counting votes per class substantially improves LLM ensemble results. Overall, this contribution advances the frontiers of AI-powered legal text mining, proposing small models and initial prompt engineering to low-resource conditions that are scalable for broader representation. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Large Language Models; LoRA; Named Entity Recognition},
	keywords = {Error correction; Adaptation models; Computational costs; Fine tuning; Fine-tuning methods; Improving performance; Language model; Large language model; Legal documents; Low-rank adaptation; Named entity recognition; Problem oriented languages},
	correspondence_address = {R.O. Nunes; Federal University of Rio Grande do Sul, Porto Alegre, Brazil; email: ronunes@inf.ufrgs.br},
	editor = {Paes A. and Verri F.A.N.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303179028-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jeptoo2025474,
	author = {Jeptoo, Korir Nancy and Sun, Chengjie},
	title = {Enhancing Fake News Detection with Large Language Models Through Multi-agent Debates},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15360 LNAI},
	pages = {474 – 486},
	doi = {10.1007/978-981-97-9434-8_37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210095035&doi=10.1007%2f978-981-97-9434-8_37&partnerID=40&md5=2e92ce4f12c8758cf8a533bc04dcc62f},
	affiliations = {Faculty of Computing, Harbin Institute of technology, Harbin, China},
	abstract = {Large language models (LLMs) are showing dramatic progress in terms of language generation and in reasoning tasks. Existing works on fake news detection mostly focus on fine-tuning small language models such as BERT. One downside of fine-tuning is that it requires a lot of data which might not always be available. With the prevalent spread of fake news and misinformation, alternative ways are needed especially in cases where there is lack of enough training data. In this paper, we propose using multi-agent debate strategies to enhance fake news detection by leveraging the capabilities of LLMs. We introduce two approaches: a uniform prompt multi-agent debate and a diverse prompt multi-agent debate where each LLM agent adopts distinct roles such as fact-checker, journalist, or data scientist. These methods are benchmarked against single LLM evaluations to assess the impact of collaborative reasoning. Our experiments on the PolitiFact and GossipCop datasets reveal that the multi-agent debate methods outperform single LLM assessments. Notably, the diverse persona debate approach achieves the highest performance, demonstrating the value of incorporating different perspectives in reasoning. These results suggest that multi-agent debates can effectively harness the strengths of single LLMs to improve the reliability of fake news detection systems. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Fake News Detection; Large Language Models; Multi-Agent Debate},
	keywords = {Fake news detection; Fine tuning; Language generation; Language model; Large language model; Model agents; Multi agent; Multi-agent debate; Reasoning tasks; Training data; Fake detection},
	correspondence_address = {C. Sun; Faculty of Computing, Harbin Institute of technology, Harbin, China; email: sunchengjie@hit.edu.cn},
	editor = {Wong D.F. and Wei Z. and Yang M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981979433-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zuo2025,
	author = {Zuo, Jiankun and Niu, Jiaojiao},
	title = {Construction of Journal Knowledge Graph Based on Deep Learning and LLM},
	year = {2025},
	journal = {Electronics (Switzerland)},
	volume = {14},
	number = {9},
	doi = {10.3390/electronics14091728},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004826752&doi=10.3390%2felectronics14091728&partnerID=40&md5=75957ef53531eed262aa06a4e203c054},
	affiliations = {School of Computer Science, Yangtze University, Jinzhou, 434023, China},
	abstract = {Knowledge graphs are powerful tools for representing the relationships between concepts and entities in the real world through triples. Due to their superior knowledge representation and efficient reasoning abilities, knowledge graphs have gained widespread attention across various fields, leading to their development in multiple domains. However, research on the construction of journal knowledge graphs remains relatively limited, posing challenges for the integration and utilization of knowledge in the journal domain. To address this gap, this study explores effective methods for constructing journal knowledge graphs and develops a journal knowledge graph-based question answering system. Specifically, journal datasets were collected from multiple sources using the Scrapy framework, encompassing structured, semi-structured, and unstructured data. A BERT-BiLSTM-CRF framework was then employed to extract entities, attributes, and relationships from semi-structured and unstructured data. In addition, the constructed journal knowledge graph was integrated with large language models (LLMs) to build a journal-related question answering system, facilitating efficient querying and utilization. Finally, Neo4j was used for storing the constructed journal knowledge graph. © 2025 by the authors.},
	author_keywords = {deep learning; knowledge graph construction; large language model; question answering systems},
	correspondence_address = {J. Niu; School of Computer Science, Yangtze University, Jinzhou, 434023, China; email: njjiao_92@163.com},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Santos2025489,
	author = {Santos, Guto Leoni and dos Santos, Vitor Gaboardi and Kearns, Colm and Sinclair, Gary and Black, Jack and Doidge, Mark and Fletcher, Thomas and Kilvington, Dan and Liston, Katie and Endo, Patricia Takako and Lynn, Theo},
	title = {Detecting Homophobic Speech in Soccer Tweets Using Large Language Models and Explainable AI},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15211 LNCS},
	pages = {489 – 504},
	doi = {10.1007/978-3-031-78541-2_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218439620&doi=10.1007%2f978-3-031-78541-2_30&partnerID=40&md5=b8835f734f40d08e84c0ec3bee7955b1},
	affiliations = {Dublin City University, Dublin, Ireland; Sheffield Hallam University, Sheffield, United Kingdom; Loughborough University, Loughborough, United Kingdom; Leeds Beckett University, Leeds, United Kingdom; Universidade de Pernambuco, Caruaru, Brazil; Ulster University, Belfast, United Kingdom},
	abstract = {Homophobic speech is a form of hate speech. Social media enables hate speech to spread rapidly and widely through the internet, and unlike offline hate speech, can persist indefinitely, thereby prolonging its impact. Due to the adverse impact of hate speech, policymakers have called for greater action from online platforms to moderate and remove hate speech, including homophobic content. While homophobic hate speech is prevalent in online soccer discourses, there are few studies on this empirical context in general and specifically on the use of Large Language Models (LLMs) for detecting such speech. This study addresses this gap by proposing a homophobic speech text classification pipeline. We introduce H-DICT, a new general dictionary for identifying potential homophobic content in documents, and leverage this dictionary to curate and manually label an annotated dataset of homophobic and non-homophobic samples from the UEFA European Football Championships (the Euros) discourse on Twitter. We fine-tune and evaluate five large language models (LLMs) based on the BERT architecture - BERT, DistilBERT, RoBERTa, BERT Hate, and RoBERTa Offensive - and use Integrated Gradients, an explainable AI technique to explain each model’s predictions. RoBERTa Offensive, an LLM fine-tuned specifically for detecting offensive language, presented the best performance when compared to the other LLMs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Explainable AI; Hate speech classification; Homophobic speech; Large language models; Soccer},
	keywords = {Classification (of information); Explainable AI; Hate speech classification; Homophobic speech; Language model; Large language model; Offline; Online platforms; Policy makers; Social media; Speech classification; Tweets},
	correspondence_address = {G.L. Santos; Dublin City University, Dublin, Ireland; email: guto.santos@dcu.ie},
	editor = {Aiello L.M. and Chakraborty T. and Gaito S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303178540-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jeon2025,
	author = {Jeon, Kahyun and Lee, Ghang},
	title = {Hybrid large language model approach for prompt and sensitive defect management: A comparative analysis of hybrid, non-hybrid, and GraphRAG approaches},
	year = {2025},
	journal = {Advanced Engineering Informatics},
	volume = {64},
	doi = {10.1016/j.aei.2024.103076},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213887896&doi=10.1016%2fj.aei.2024.103076&partnerID=40&md5=c7091ea831e53af9a59c11e60814237b},
	affiliations = {Yonsei University, Yonsei-ro 50, Seodaemun-gu, Seoul, 03722, South Korea},
	abstract = {This study aims to propose a large language model (LLM)-enhanced defect question-answering (QA) method that can secure private and sensitive data while yielding high performance. Prompt responses to residents’ complaints are crucial for preventing recurring defects. However, traditional defect analysis and response methods rely on the expertise of a few skilled workers, making it difficult to ensure timely responses. The rapid advancement of LLMs offers a potential solution for improving defect QA tasks. However, many companies prohibit the use of closed-source LLM services, such as ChatGPT, due to concerns about potential data breaches. One possible solution is to use open-source LLMs like Llama and BERT, which can be locally installed and used. However, open-source LLMs typically perform worse than closed-source LLMs. Although the performance of open-source LLMs can be greatly improved through fine-tuning, the preparation of training datasets requires a significant amount of time and labor. To address these challenges, this study proposes a hybrid defect QA method that deploys an open-source LLM for defect management to secure sensitive information, and a closed-source LLM for generating a training dataset to reduce both the time and labor required. To validate the proposed method, we compare it to the state-of-the-art LLMs, GPT-4o and Llama 3, as well as graph retrieval-augmented generation (GraphRAG)-based QA systems, which have been extensively studied recently. Our results show that the hybrid LLM-based QA method achieved the highest ROUGE score of 81.6%. These findings demonstrate superior practical applicability, enabling cost-effective data generation and reliable domain adaptation within a secure data environment. This approach is beneficial for domain-specific tasks beyond defect management, where the accurate provision of specialized information and integration of historical knowledge are essential. © 2024 Elsevier Ltd},
	author_keywords = {Fine-tuning; Graph-retrieval augmented generation (GraphRAG); Housing defect management; Large language model (LLM); Question–answering (QA); Synthetic data generation},
	keywords = {Information management; Defect management; Fine tuning; Graph-retrieval augmented generation; Housing defect management; Language model; Large language model; Open-source; Question Answering; Question–answering; Synthetic data generations; Question answering},
	correspondence_address = {G. Lee; Yonsei University, Seoul, Yonsei-ro 50, Seodaemun-gu, 03722, South Korea; email: glee@yonsei.ac.kr},
	publisher = {Elsevier Ltd},
	issn = {14740346},
	language = {English},
	abbrev_source_title = {Adv. Eng. Inf.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Papageorgiou2025,
	author = {Papageorgiou, Eleftheria and Varlamis, Iraklis and Chronis, Christos},
	title = {Harnessing Large Language Models and Deep Neural Networks for Fake News Detection},
	year = {2025},
	journal = {Information (Switzerland)},
	volume = {16},
	number = {4},
	doi = {10.3390/info16040297},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003671222&doi=10.3390%2finfo16040297&partnerID=40&md5=a68147473f77d91bf11617ba09d7c77b},
	affiliations = {Department of Informatics and Telematics, Harokopio University of Athens, Athens, GR-17778, Greece},
	abstract = {The spread of fake news threatens trust in both traditional and digital media. Early detection methods, based on linguistic patterns and handcrafted features, struggle to identify more sophisticated misinformation. Large language models (LLMs) offer promising solutions by capturing complex text patterns, but challenges remain in ensuring their accuracy and generalizability. This study evaluates LLM-based feature extraction for fake news detection across multiple datasets. We compare BERT-based text representations, introduce a method for extracting factual segments from news articles, and create two new datasets with fact-based features. Additionally, we explore graph-based text representations using LLMs to capture relationships within news content. By integrating these approaches, we improve fake news detection, making it more accurate and interpretable. Our findings provide insights into how LLMs and graph-based techniques can enhance misinformation detection. © 2025 by the authors.},
	author_keywords = {fake news; large language models (LLMs); text classification},
	keywords = {Character recognition; Feature Selection; Modeling languages; Detection methods; Fake news; Features extraction; Language model; Large language model; Linguistic patterns; Model-based OPC; Neural-networks; Text classification; Text representation; Deep neural networks},
	correspondence_address = {I. Varlamis; Department of Informatics and Telematics, Harokopio University of Athens, Athens, GR-17778, Greece; email: varlamis@hua.gr},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20782489},
	language = {English},
	abbrev_source_title = {Information},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mukhopadhyay2025109,
	author = {Mukhopadhyay, Parthasarathi},
	title = {Designing Conversational Search for Libraries: Retrieval Augmented Generation through Open Source Large Language Models},
	year = {2025},
	journal = {DESIDOC Journal of Library and Information Technology},
	volume = {45},
	number = {2},
	pages = {109 – 115},
	doi = {10.14429/djlit.45.2.20206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002664677&doi=10.14429%2fdjlit.45.2.20206&partnerID=40&md5=b46448e38e494c6104a7c184dab83124},
	affiliations = {Department of Library and Information Science, Kalyani University, West Bengal, Kalyani, 741 235, India},
	abstract = {Large language models (LLMs) from the commercial domain like BERT and GPT have made machine learning technologies accessible to everyone. On the other hand, the open-source LLMs like Llama, Mistral, and Orca are equally effective and are now widely available. Librarians and information professionals around the world are exploring how to use these models to improve library systems, particularly in the area of searching and finding information, and in building question-answer based search systems. This research study aims to use open-source large language models to develop a conversational search system that can answer questions in natural language on the basis of a given set of documents. The system is based on a Retrieval Augmented Generation (RAG) pipeline, which helps to overcome two major issues with large language models: providing false or imaginary information (hallucination) and giving outdated or unrelated answers. Through two case studies, this research demonstrates that using a RAG-based approach can effectively address these issues and provide more accurate and relevant results. The study proves that an open-source RAG framework can be used to incorporate large language models into library search systems. This integration allows users to receive direct answers to their questions, rather than just a list of potentially relevant documents. In the coming future, the conversational search system can be designed to work in Indian languages, allowing users to ask questions and receive answers in their preferred language. © 2025, DESIDOC.},
	author_keywords = {Conversational search; Generative AI; Library retrieval; LLM (Large Language Model); RAG (Retrieval Augmented Generation)},
	correspondence_address = {P. Mukhopadhyay; Department of Library and Information Science, Kalyani University, Kalyani, West Bengal, 741 235, India; email: psm@klyuniv.ac.in},
	publisher = {Defence Scientific Information and Documentation Centre},
	issn = {09740643},
	language = {English},
	abbrev_source_title = {DESIDOC J. Libr. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sebbag2025392,
	author = {Sebbag, Thomas and Quiniou, Solen and Stucky, Nicolas and Morin, Emmanuel},
	title = {AdminSet and AdminBERT: a Dataset and a Pre-trained Language Model to Explore the Unstructured Maze of French Administrative Documents},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {Part F206484-1},
	pages = {392 – 406},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218496207&partnerID=40&md5=248127e31536c70803b77e8e6a35f3ff},
	affiliations = {Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes, F-44000, France; Explore, Carquefou, France},
	abstract = {In recent years, Pre-trained Language Models (PLMs) have been widely used to analyze various documents, playing a crucial role in Natural Language Processing (NLP). However, administrative texts have rarely been used in information extraction tasks, even though this resource is available as open data in many countries. Most of these texts contain many specific domain terms. Moreover, especially in France, they are unstructured because many administrations produce them without a standardized framework. Due to this fact, current language models do not process these documents correctly. In this paper, we propose AdminBERT, the first French pre-trained language model for the administrative domain. Since interesting information in such texts corresponds to named entities and the relations between them, we compare this PLM with general domain language models, fine-tuned on the Named Entity Recognition (NER) task applied to administrative texts, as well as to a Large Language Model (LLM) and to a language model with an architecture different from the BERT one. We show that taking advantage of a PLM for French administrative data increases the performance in the administrative and general domains, on these texts. We also release AdminBERT as well as AdminSet, the pre-training corpus of administrative texts in French and the subset AdminSet-NER, the first NER dataset consisting exclusively of administrative texts in French. © 2025 Association for Computational Linguistics.},
	keywords = {Administrative data processing; Modeling languages; Natural language processing systems; Open Data; 'current; Domain language; Interesting information; Language model; Language processing; Named entities; Named entity recognition; Natural languages; Performance; Pre-training; Computational linguistics},
	correspondence_address = {T. Sebbag; Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes, F-44000, France; email: thomas.sebbag@univ-nantes.fr; S. Quiniou; Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes, F-44000, France; email: solen.quiniou@univ-nantes.fr; N. Stucky; Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes, F-44000, France; email: nicolas.stucky@etu.univ-nantes.fr; E. Morin; Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes, F-44000, France; email: emmanuel.morin@univ-nantes.fr},
	editor = {Rambow O. and Wanner L. and Apidianaki M. and Al-Khalifa H. and Di Eugenio B. and Schockaert S.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176196-4},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Levra2025113,
	author = {Levra, Alessandro Giaj and Gatti, Mauro and Mene, Roberto and Shiffer, Dana and Costantino, Giorgio and Solbiati, Monica and Furlan, Raffaello and Dipaola, Franca},
	title = {A large language model-based clinical decision support system for syncope recognition in the emergency department: A framework for clinical workflow integration},
	year = {2025},
	journal = {European Journal of Internal Medicine},
	volume = {131},
	pages = {113 – 120},
	doi = {10.1016/j.ejim.2024.09.017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205272176&doi=10.1016%2fj.ejim.2024.09.017&partnerID=40&md5=34dd21c8b44e50e670f6f729bddee859},
	affiliations = {Department of Cardiovascular Medicine, Humanitas Research Hospital, IRCCS, Milan, Rozzano, Italy; Department of Biomedical Sciences, Humanitas University, Milan, Pieve Emanuele, Italy; IBM, Milan, Italy; Hôpital Cardiologique du Haut Lévêque, CHU Bordeaux, France & IHU LIRYC (L'Institut de Rythmologie et Modélisation Cardiaque), Université de Bordeaux, Pessac, France; Emergency Department, IRCCS Humanitas Research Hospital, Milan, Rozzano, Italy; Emergency Department, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Università degli Studi di Milano, Milan, Italy},
	abstract = {Differentiation of syncope from transient loss of consciousness can be challenging in the emergency department (ED). Natural Language Processing (NLP) enables the analysis of free text in the electronic medical records (EMR). The present paper aimed to develop a large language models (LLM) for syncope recognition in the ED and proposed a framework for model integration within the clinical workflow. Two models, based on both the Italian and Multilingual Bidirectional Encoder Representations from Transformers (BERT) language model, were developed using consecutive EMRs. The “triage” model was only based on notes contained in the “triage” section of the EMR. The “anamnesis” model added data contained in the “medical history” section. Interpretation and calibration plots were generated. The Italian and Multi BERT models were developed and tested on both 15,098 and 15,222 EMRs, respectively. The triage model had an AUC of 0·95 for the Italian BERT and 0·94 for the Multi BERT. The anamnesis model had an AUC of 0·98 for the Italian BERT and 0·97 for Multi BERT. The LLM identified syncope when not explicitly mentioned in the EMR and also recognized common prodromal symptoms preceding syncope. Both models identified syncope patients in the ED with a high discriminative capability from nurses and doctors’ notes, thus potentially acting as a tool helping physicians to differentiate syncope from others transient loss of consciousness. © 2024},
	author_keywords = {Artificial intelligence; Clinical decision support system; Machine learning; Natural language processing; Syncope},
	keywords = {Aged; Decision Support Systems, Clinical; Electronic Health Records; Emergency Service, Hospital; Female; Humans; Italy; Male; Middle Aged; Natural Language Processing; Syncope; Triage; Workflow; abdominal pain; adult; algorithm; area under the curve; Article; clinical decision support system; controlled study; correlation coefficient; decision making; emergency ward; faintness; false positive result; female; human; integration; large language model; low back pain; major clinical study; male; medical history; natural language processing; neck pain; performance indicator; prodromal symptom; thorax pain; workflow; aged; diagnosis; electronic health record; hospital emergency service; Italy; middle aged; natural language processing; patient triage; procedures; therapy},
	correspondence_address = {R. Furlan; IRCCS Humanitas Research Hospital, Rozzano, Via A. Manzoni, 56, Milan, 20089, Italy; email: raffaello.furlan@hunimed.eu},
	publisher = {Elsevier B.V.},
	issn = {09536205},
	coden = {EJIME},
	pmid = {39341748},
	language = {English},
	abbrev_source_title = {Eur. J. Intern. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Petukhova2025100,
	author = {Petukhova, Alina and Matos-Carvalho, João P. and Fachada, Nuno},
	title = {Text clustering with large language model embeddings},
	year = {2025},
	journal = {International Journal of Cognitive Computing in Engineering},
	volume = {6},
	pages = {100 – 108},
	doi = {10.1016/j.ijcce.2024.11.004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210765539&doi=10.1016%2fj.ijcce.2024.11.004&partnerID=40&md5=8a0bd66d6061462a34aa76345ca76ea9},
	affiliations = {COPELABS, Lusófona University, Campo Grande, 376, Lisbon, 1700-921, Portugal; Center of Technology and Systems (UNINOVA-CTS) and Associated Lab of Intelligent Systems (LASI), Caparica, 2829-516, Portugal},
	abstract = {Text clustering is an important method for organising the increasing volume of digital content, aiding in the structuring and discovery of hidden patterns in uncategorised data. The effectiveness of text clustering largely depends on the selection of textual embeddings and clustering algorithms. This study argues that recent advancements in large language models (LLMs) have the potential to enhance this task. The research investigates how different textual embeddings, particularly those utilised in LLMs, and various clustering algorithms influence the clustering of text datasets. A series of experiments were conducted to evaluate the impact of embeddings on clustering results, the role of dimensionality reduction through summarisation, and the adjustment of model size. The findings indicate that LLM embeddings are superior at capturing subtleties in structured language. OpenAI's GPT-3.5 Turbo model yields better results in three out of five clustering metrics across most tested datasets. Most LLM embeddings show improvements in cluster purity and provide a more informative silhouette score, reflecting a refined structural understanding of text data compared to traditional methods. Among the more lightweight models, BERT demonstrates leading performance. Additionally, it was observed that increasing model dimensionality and employing summarisation techniques do not consistently enhance clustering efficiency, suggesting that these strategies require careful consideration for practical application. These results highlight a complex balance between the need for refined text representation and computational feasibility in text clustering applications. This study extends traditional text clustering frameworks by integrating embeddings from LLMs, offering improved methodologies and suggesting new avenues for future research in various types of textual analysis. © 2024 The Authors},
	author_keywords = {Large language models; Text clustering; Text summarisation},
	keywords = {Clustering results; Clusterings; Digital contents; Embeddings; Hidden patterns; Language model; Large language model; Model embedding; Text Clustering; Text Summarisation; Embeddings},
	correspondence_address = {A. Petukhova; COPELABS, Lusófona University, Lisbon, Campo Grande, 376, 1700-921, Portugal; email: alina.petukhova@ulusofona.pt},
	publisher = {KeAi Communications Co.},
	issn = {26663074},
	language = {English},
	abbrev_source_title = {Int. J. Cogn. Comp. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Trapp20253,
	author = {Trapp, Stefan and Warschat, Joachim},
	title = {LLM-Based Extraction of Contradictions from Patents},
	year = {2025},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {735 IFIP},
	pages = {3 – 19},
	doi = {10.1007/978-3-031-75919-2_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209920906&doi=10.1007%2f978-3-031-75919-2_1&partnerID=40&md5=09c65801a60c0f371fae1666bc8d7fe6},
	affiliations = {University of Hagen, Universitätsstraße 47, Hagen, 58097, Germany},
	abstract = {Already since the 1950s TRIZ shows that patents and the technical contradictions they solve are an important source of inspiration for the development of innovative products. However, TRIZ is a heuristic based on a historic patent analysis and does not make use of the ever-increasing number of latest technological solutions in current patents. Because of the huge number of patents, their length, and, last but not least, their complexity there is a need for modern patent retrieval and patent analysis to go beyond keyword-oriented methods. Recent advances in patent retrieval and analysis mainly focus on dense vectors based on neural AI Transformer language models like Google BERT. They are, for example, used for dense retrieval, question answering or summarization and key concept extraction. A research focus within the methods for patent summarization and key concept extraction are generic inventive concepts respectively TRIZ concepts like problems, solutions, advantage of invention, parameters, and contradictions. Succeeding rule-based approaches, finetuned BERT-like language models for sentence-wise classification represent the state-of-the-art of inventive concept extraction. While they work comparatively well for basic concepts like problems or solutions, contradictions − as a more complex abstraction − remain a challenge for these models. Even PaTRIZ, the latest and complicated multi-stage approach to extract contradictions, delivers only mixed results. This paper goes one step further, as it presents a method to extract TRIZ contradictions from patent texts based on Prompt Engineering using a generative Large Language Model (LLM), namely OpenAI’s GPT-4. The existing annotated patent dataset “PaGAN” is used to demonstrate the LLM-capabilities for extracting TRIZ contradictions from the section “State-of-the-Art” of USPTO patents. Contradiction detection, sentence extraction, contradiction summarization, parameter extraction and assignment to the 39 abstract TRIZ engineering parameters are all performed in a single prompt using the LangChain framework. Our results show that “off-the-shelf” GPT-4 is a serious alternative to PaTRIZ. Comparing the text similarity of the GPT-4 extractions with the annotated sentences from PaGAN we reach a high F1-value of 0.93 using the BERTScore metric. © IFIP International Federation for Information Processing 2025.},
	author_keywords = {AI; BERT; Classification; Contradiction; Finetuning; GPT-4; Information Extraction; Information Retrieval; Inventive Concept; LangChain; Large Language Model (LLM); NLP; OpenAI; Prompt Engineering; Summarization; Transformer; TRIZ},
	keywords = {BASIC (programming language); Behavioral research; Engineering research; Inference engines; Information retrieval systems; Knowledge acquisition; Taxonomies; Technology transfer; BERT; Contradiction; Finetuning; GPT-4; Information extraction; Inventive concept; Langchain; Language model; Large language model; Openai; Prompt engineering; Summarization; Transformer; TRIZ; Patents and inventions},
	correspondence_address = {S. Trapp; University of Hagen, Hagen, Universitätsstraße 47, 58097, Germany; email: stefan.trapp@fernuni-hagen.de},
	editor = {Cavallucci D. and Brad S. and Livotov P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303175918-5},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Proebsting20255836,
	author = {Proebsting, Grace and Poliak, Adam},
	title = {Biases in Large Language Model-Elicited Text: A Case Study in Natural Language Inference},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {Part F206484-1},
	pages = {5836 – 5851},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218498610&partnerID=40&md5=843559f8a6a3de57d46efb73d8028f27},
	affiliations = {Haverford College, United States; Bryn Mawr College, United States},
	abstract = {We test whether NLP datasets created with Large Language Models (LLMs) contain annotation artifacts and social biases like NLP datasets elicited from crowd-source workers. We recreate a portion of the Stanford Natural Language Inference corpus using GPT-4, Llama-2 70b for Chat, and Mistral 7b Instruct. We train hypothesis-only classifiers to determine whether LLM-elicited NLI datasets contain annotation artifacts. Next, we use point-wise mutual information to identify the words in each dataset that are associated with gender, race, and age-related terms. On our LLM-generated NLI datasets, fine-tuned BERT hypothesis-only classifiers achieve between 86-96% accuracy. Our analyses further characterize the annotation artifacts and stereotypical biases in LLM-generated datasets. © 2025 Association for Computational Linguistics.},
	keywords = {Large datasets; Modeling languages; Natural language processing systems; Spatio-temporal data; Age-related; Case-studies; Language inference; Language model; Mutual informations; Natural languages; Point wise; Stanford; Workers'; Computational linguistics},
	editor = {Rambow O. and Wanner L. and Apidianaki M. and Al-Khalifa H. and Di Eugenio B. and Schockaert S.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176196-4},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Han2025,
	author = {Han, Yaoyao and Liu, Jiping and Luo, An and Wang, Yong and Bao, Shuai},
	title = {Fine-Tuning LLM-Assisted Chinese Disaster Geospatial Intelligence Extraction and Case Studies},
	year = {2025},
	journal = {ISPRS International Journal of Geo-Information},
	volume = {14},
	number = {2},
	doi = {10.3390/ijgi14020079},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218853736&doi=10.3390%2fijgi14020079&partnerID=40&md5=08cf5b20a5af75c9471a49efd5394180},
	affiliations = {Research Center of Geospatial Big Data Application, Chinese Academy of Surveying and Mapping, Beijing, 100830, China; School of Spatial Informatics and Geomatics Engineering, Anhui University of Science and Technology, Huainan, 232001, China},
	abstract = {The extraction of disaster geospatial intelligence (DGI) from social media data with spatiotemporal attributes plays a crucial role in real-time disaster monitoring and emergency decision-making. However, conventional machine learning approaches struggle with semantic complexity and limited Chinese disaster corpus. Recent advancements in large language models (LLMs) offer new opportunities to overcome these challenges due to their enhanced semantic comprehension and multi-task learning capabilities. This study investigates the potential application of LLMs in disaster intelligence extraction and proposes an efficient, scalable method for multi-hazard DGI extraction. Building upon a unified ontological framework encompassing core natural disaster elements, this method employs parameter-efficient low-rank adaptation (LoRA) fine-tuning to optimize open-source Chinese LLMs using a meticulously curated instruction-tuning dataset. It achieves simultaneous identification of multi-hazard intelligence cues and extraction of disaster spatial entity attributes from unstructured Chinese social media texts through unified semantic parsing and structured knowledge mapping. Compared to pre-trained models such as BERT and ERNIE, the proposed method was shown to achieve state-of-the-art evaluation results, with the highest recognition accuracy (F1-score: 0.9714) and the best performance in structured information generation (BLEU-4 score: 92.9649). Furthermore, we developed and released DGI-Corpus, a Chinese instruction-tuning dataset covering various disaster types, to support the research and application of LLMs in this field. Lastly, the proposed method was applied to analyze the spatiotemporal evolution patterns of the Zhengzhou “7.20” flood disaster. This study enhances the efficiency of natural disaster monitoring and emergency management, offering technical support for disaster response and mitigation decision-making. © 2025 by the authors.},
	author_keywords = {emergency management; geospatial intelligence; large language models; natural disasters; social media; spatiotemporal information mining},
	correspondence_address = {Y. Wang; Research Center of Geospatial Big Data Application, Chinese Academy of Surveying and Mapping, Beijing, 100830, China; email: wangyong@casm.ac.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22209964},
	language = {English},
	abbrev_source_title = {ISPRS Int. J. Geo-Inf.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Asif202520316,
	author = {Asif, Muhammad and Ahmed Khan, Talha and Song, Wang-Cheol},
	title = {Evaluating Large Language Models for Optimized Intent Translation and Contradiction Detection Using KNN in IBN},
	year = {2025},
	journal = {IEEE Access},
	volume = {13},
	pages = {20316 – 20327},
	doi = {10.1109/ACCESS.2025.3534880},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216883523&doi=10.1109%2fACCESS.2025.3534880&partnerID=40&md5=11772101bff9e7890cc3f74d08c9d437},
	affiliations = {Jeju National University, Department of Computer Engineering, Jeju-do, Jeju-si, 63243, South Korea; University of Surrey, Institute for Communication Systems, Guildford, GU2 7XH, United Kingdom},
	abstract = {Intent-Based Networking (IBN) simplifies network management by enabling users to express high-level intents in natural language, but existing approaches often fail to ensure alignment with network policies, leading to misconfigurations. Moreover, many methods lack robust validation mechanisms, reducing their reliability in dynamic environments. This research addresses these gaps by evaluating advanced Large Language Models (LLMs) such as BERT-base uncased (BERT-bu), GPT2, LLaMA3, Claude2 and small deep learning model BiLSTM with attention for translating intents and detecting contradictions. Using a curated dataset of 10,000 intent pairs, the proposed hybrid framework integrates a K-Nearest Neighbors (KNN) classifier to validate translations and recalibrate erroneous outputs. Experimental results demonstrate up to 5% higher accuracy (88%) and F1 scores compared to existing methods, ensuring precise intent translation and reliable network orchestration. This approach significantly enhances scalability and policy compliance in automated network environments. © 2013 IEEE.},
	author_keywords = {BERT; GPT; Intent-based networking; K-Nearest Neighbors; LLaMa; LLM; NLP},
	keywords = {Computer aided language translation; Contrastive Learning; Natural language processing systems; Nearest neighbor search; BERT; GPT; Intent-based networking; K-near neighbor; Language model; Large language model; LLaMa; Natural languages; Nearest-neighbour; Networks management; Deep learning},
	correspondence_address = {W.-C. Song; Jeju National University, Department of Computer Engineering, Jeju-si, Jeju-do, 63243, South Korea; email: philo@jejunu.ac.kr},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Xing2025,
	author = {Xing, Lidong and Hou, Nannan and Zhang, Zhiqing and Li, Ke and Meng, Fangxu},
	title = {Research on False Propaganda Detection Technology Based on LLM and BERT},
	year = {2025},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13447},
	doi = {10.1117/12.3054714},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216080797&doi=10.1117%2f12.3054714&partnerID=40&md5=62f0f462d80beceeb6def4600df8a999},
	affiliations = {Institute of Automation, Chinese Academy of Sciences, No.95 Zhongguancun East Road, Haidian District, Beijing, 100190, China; BeiHang University, No.37 XueYuan Road,HaiDian District, Beijing, 100190, China; Information Center of the State Administration for Market Regulation, No. 8 Sanlihe East Road, Xicheng District, Beijing, 100037, China},
	abstract = {False propaganda, as one of the unfair competition behaviors, seriously damages consumer rights and disrupts market order. This article aims to design a False propaganda detection technology based on LLM and BERT for dishonest behavior caused by False propaganda. By annotating False propaganda text data with LLM and training a False propaganda detection model based on BERT, the rapid development of the False propaganda detection model and effective cost savings in manual annotation have been achieved. The results show that this method has good performance and efficiency, and can meet practical engineering needs. It has certain application and reference value for model development in market supervision fields such as False propaganda. © 2025 SPIE.},
	author_keywords = {auto annotating; bert; false propaganda detection; LLM},
	keywords = {Behavioral research; Optical fibers; Auto annotating; Bert; Competition behavior; Consumer rights; Detection models; Detection technology; False propaganda detection; LLM; Technology-based; Text data; Competition},
	correspondence_address = {Z. Zhang; Information Center of the State Administration for Market Regulation, Beijing, No. 8 Sanlihe East Road, Xicheng District, 100037, China; email: 2564849287@qq.com},
	editor = {Zhang K. and Lorenz P.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151068683-0},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2025,
	title = {26th International Conference on Information Integration and Web Intelligence, iiWAS 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15343 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212494941&partnerID=40&md5=fa2aecd7173d4fed3f498bd4793aadb2},
	abstract = {The proceedings contain 52 papers. The special focus in this conference is on Information Integration and Web Intelligence. The topics include: Financial News Classification Using Language Learning Models and Reinforcement Learning; ExtractGPT: Exploring the Potential of Large Language Models for Product Attribute Value Extraction; Feature Extraction for Claim Check-Worthiness Prediction Tasks Using LLM; training Data for Dialogue Generation Considering Philosophies; Finding Adequate Additional Layer of Auxiliary Task in BERT-Based Multi-task Learning; ponzi Scheme Detection and Prevention in Blockchain Platforms Using Machine Learning: A Systematic Literature Review; Cross-Chain Personal Data Exchange on EVM Platforms: Enhancing Transparency, and Equity; Incentivize Peer Review Without Rewarding: Using OSS-Like Citation Pull Request; towards Website X-Ray for Europe’s Municipalities: Unveiling Digital Transformation with Multimodal Embeddings; evolving Applications of Conversational Agents in Healthcare: A Literature Review; hybrid Edge-Cloud Federated Learning: The Case of Lightweight Smoking Detection; anonymization of Unstructured Health Data in Spanish; when Good Enough is the Best Option: Use of Digital Sufficiency to Fight Climate Change; multi-target Feature Selection Method for Predicting User-Level Psychological Status from Text; FIEAP: A Machine Learning Approach for Fair and Interpretable Employee Attrition Prediction; HOCON34k: A Corpus of Hate Speech in Online Comments from German Newspapers; SISIS: Sequence Indexing for SImilarity Search; top-k on Sequences: A New Approach to Enhanced Similarity Search; exploratory Data Analysis of Time Series Using Pre-segmented Clustering; a Data Science Approach for Predicting Soccer Passes Using Positional Data; a Method for Integrating Heterogeneous Data into a Knowledge Graph; predicting Knowledge Graph Updates from Edit Histories; Automatic Extraction of RML-star Mappings from Property Graphs; Exploring the Role of UML in Data Modelling for NoSQL Databases: Position Paper; railway Systems’ Ontologies: A Literature Review and an Alignment Proposal; Combining GraphSAGE and Label Propagation for Node Classification in Graphs.},
	editor = {Delir Haghighi P. and Greguš M. and Kotsis G. and Khalil I.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303178092-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sandoval2025355,
	author = {Sandoval, Manuel and Abuhamad, Mohammed and Furman, Patrick and Nazari, Mujtaba and Hall, Deborah L. and Silva, Yasin N.},
	title = {Identifying Cyberbullying Roles in Social Media},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15213 LNCS},
	pages = {355 – 370},
	doi = {10.1007/978-3-031-78548-1_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218461682&doi=10.1007%2f978-3-031-78548-1_26&partnerID=40&md5=3d8f8daf47cf2a62f807b71a56dd07a5},
	affiliations = {Loyola Chicago University, Chicago, 60660, IL, United States; Arizona State University, Glendale, 85306, AZ, United States},
	abstract = {Social media has revolutionized communication, allowing people worldwide to connect and interact instantly. However, it has also led to increases in cyberbullying, which poses a significant threat to children and adolescents globally, affecting their mental health and well-being. It is critical to accurately detect the roles of individuals involved in cyberbullying incidents to effectively address the issue on a large scale. This study explores the use of machine learning models to detect the roles involved in cyberbullying interactions. After examining the AMiCA dataset and addressing class imbalance issues, we evaluate the performance of various models built with four underlying LLMs (i.e. BERT, RoBERTa, T5, and GPT-2) for role detection. Our analysis shows that oversampling techniques help improve model performance. The best model, a fine-tuned RoBERTa using oversampled data, achieved an overall F1 score of 83.5%, increasing to 89.3% after applying a prediction threshold. The top-2 F1 score without thresholding was 95.7%. Our method outperforms previously proposed models. After investigating the per-class model performance and confidence scores, we show that the models perform well in classes with more samples and less contextual confusion (e.g. Bystander Other), but struggle with classes with fewer samples (e.g. Bystander Assistant) and more contextual ambiguity (e.g. Harasser and Victim). This work highlights current strengths and limitations in the development of accurate models with limited data and complex scenarios. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {cyberbullying; LLM; role detection; social media},
	keywords = {Adversarial machine learning; Social networking (online); Children and adolescents; Cyber bullying; F1 scores; Large-scales; LLM; Mental health; Modeling performance; Role detection; Social media; Well being; Anonymity},
	correspondence_address = {M. Sandoval; Loyola Chicago University, Chicago, 60660, United States; email: msandovalmadrigal@luc.edu},
	editor = {Aiello L.M. and Chakraborty T. and Gaito S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303178547-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Aarab2025,
	author = {Aarab, Ilias},
	title = {LLM-based IR-system for bank supervisors},
	year = {2025},
	journal = {Knowledge-Based Systems},
	volume = {310},
	doi = {10.1016/j.knosys.2024.112914},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214285554&doi=10.1016%2fj.knosys.2024.112914&partnerID=40&md5=b33bcf7c5faaf3b4b0a082f52160ca1b},
	affiliations = {European Central Bank, SSM/DG-SIB, Sonnemannstrasse 20, Hesse, Frankfurt am Main, 60314, Germany},
	abstract = {Bank supervisors face the complex task of ensuring that new measures are consistently aligned with historical precedents. To address this challenge, we introduce a novel Information Retrieval (IR) System tailored to assist supervisors in drafting both consistent and effective measures. This system ingests findings from on-site investigations. It then retrieves the most relevant historical findings and their associated measures from a comprehensive database, providing a solid basis for supervisors to write well-informed measures for new findings. Utilizing a blend of lexical, semantic, and Capital Requirements Regulation (CRR) fuzzy set matching techniques, the IR system ensures the retrieval of findings that closely align with current cases. The performance of this system, particularly in scenarios with partially labeled data, is validated through a Monte Carlo methodology, showcasing its robustness and accuracy. Enhanced by a Transformer-based Denoising AutoEncoder for fine-tuning, the final model achieves a Mean Average Precision (MAP@100) of 0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92. These scores surpass those of both standalone lexical models such as BM25 and semantic BERT-like models. © 2024},
	author_keywords = {Information retrieval (IR); Large language models (LLMs); Machine learning; Semantic analysis},
	keywords = {Adversarial machine learning; Contrastive Learning; Fuzzy sets; Intelligent systems; Labeled data; Metadata; Complex task; Consistent measures; Information retrieval; Information-retrieval systems; Language model; Large language model; Machine-learning; Model-based OPC; Novel information; Semantic analysis; Semantics},
	publisher = {Elsevier B.V.},
	issn = {09507051},
	coden = {KNSYE},
	language = {English},
	abbrev_source_title = {Knowl Based Syst},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Naseer2025,
	author = {Naseer, Mehwish and Ullah, Farhan and Ijaz, Samia and Naeem, Hamad and Alsirhani, Amjad and Alwakid, Ghadah Naif and Alomari, Abdullah},
	title = {Obfuscated Malware Detection and Classification in Network Traffic Leveraging Hybrid Large Language Models and Synthetic Data},
	year = {2025},
	journal = {Sensors},
	volume = {25},
	number = {1},
	doi = {10.3390/s25010202},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214470591&doi=10.3390%2fs25010202&partnerID=40&md5=a4c736aaab85dc233c96810e0cb4580e},
	affiliations = {Computer and Software Engineering Department, College of Electrical and Mechanical Engineering, National University of Sciences and Technology (NUST), Islamabad, 44080, Pakistan; Cybersecurity Center, Prince Mohammad Bin Fahd University, 617, Al Jawharah, Dhahran, Khobar, 34754, Saudi Arabia; Computer Science Department, HITEC University, Taxila, 47080, Pakistan; Department of Computer Science, College of Computer Sciences and Information Technology (CCSIT), King Faisal University, P.O. Box 400, Al-Ahsa, 31982, Saudi Arabia; Department of Computer Science, College of Computer and Information Sciences, Jouf University, Al Jouf, 72388, Saudi Arabia; Department of Computer Science, College of Computer and Information Sciences, Jouf University, Sakaka, 72341, Saudi Arabia; Department of Computer Science, Al-Baha University, Al-Baha 65779, Saudi Arabia},
	abstract = {Android malware detection remains a critical issue for mobile security. Cybercriminals target Android since it is the most popular smartphone operating system (OS). Malware detection, analysis, and classification have become diverse research areas. This paper presents a smart sensing model based on large language models (LLMs) for developing and classifying network traffic-based Android malware. The network traffic that constantly connects Android apps may contain harmful components that may damage these apps. However, one of the main challenges in developing smart sensing systems for malware analysis is the scarcity of traffic data due to privacy concerns. To overcome this, a two-step smart sensing model Syn-detect is proposed. The first step involves generating synthetic TCP malware traffic data with malicious content using GPT-2. These data are then preprocessed and used in the second step, which focuses on malware classification. This phase leverages a fine-tuned LLM, Bidirectional Encoder Representations from Transformers (BERT), with classification layers. BERT is responsible for tokenization, generating word embeddings, and classifying malware. The Syn-detect model was tested on two Android malware datasets: CIC-AndMal2017 and CIC-AAGM2017. The model achieved an accuracy of 99.8% on CIC-AndMal2017 and 99.3% on CIC-AAGM2017. The Matthew’s Correlation Coefficient (MCC) values for the predictions were 99% for CIC-AndMal2017 and 98% for CIC-AAGM2017. These results demonstrate the strong performance of the Syn-detect smart sensing model. Compared to the latest research in Android malware classification, the model outperformed other approaches, delivering promising results. © 2025 by the authors.},
	author_keywords = {cybersecurity; generative AI; large language models; malware classification; smart sensing; transfer learning},
	keywords = {Cybersecurity; alanine aminotransferase; Android malware; Cyber security; Generative AI; Language model; Large language model; Malware classifications; Malware detection; Network traffic; Smart sensing; Transfer learning; article; classification; computer security; correlation coefficient; diagnosis; generative artificial intelligence; hybrid; large language model; malware; prediction; smartphone; traffic; transfer of learning; Android malware},
	correspondence_address = {A. Alsirhani; Department of Computer Science, College of Computer and Information Sciences, Jouf University, Al Jouf, 72388, Saudi Arabia; email: amjadalsirhani@ju.edu.sa},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {14248220},
	pmid = {39796992},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Rasool2025,
	author = {Rasool, Abdur and Aslam, Saba and Hussain, Naeem and Imtiaz, Sharjeel and Riaz, Waqar},
	title = {nBERT: Harnessing NLP for Emotion Recognition in Psychotherapy to Transform Mental Health Care},
	year = {2025},
	journal = {Information (Switzerland)},
	volume = {16},
	number = {4},
	doi = {10.3390/info16040301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003653528&doi=10.3390%2finfo16040301&partnerID=40&md5=a02c5d7153c1e09e3542cd4b056488c2},
	affiliations = {Department of Information and Computer Sciences, University of Hawaii at Manoa, Honolulu, 96822, HI, United States; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, 518055, China; College of Electronics and Information Engineering, Shenzhen University, Shenzhen, 518060, China; Department of Information Technology, Loadstop, Lake Forest, 92610, CA, United States; Institute of Intelligent Manufacturing Technology (IIMT), Shenzhen Polytechnic University, 4089 Shahe West Road, Shenzhen, 518055, China},
	abstract = {The rising prevalence of mental health disorders, particularly depression, highlights the need for improved approaches in therapeutic interventions. Traditional psychotherapy relies on subjective assessments, which can vary across therapists and sessions, making it challenging to track emotional progression and therapy effectiveness objectively. Leveraging the advancements in Natural Language Processing (NLP) and domain-specific Large Language Models (LLMs), this study introduces nBERT, a fine-tuned Bidirectional Encoder Representations from the Transformers (BERT) model integrated with the NRC Emotion Lexicon, to elevate emotion recognition in psychotherapy transcripts. The goal of this study is to provide a computational framework that aids in identifying emotional patterns, tracking patient-therapist emotional alignment, and assessing therapy outcomes. Addressing the challenge of emotion classification in text-based therapy sessions, where non-verbal cues are absent, nBERT demonstrates its ability to extract nuanced emotional insights from unstructured textual data, providing a data-driven approach to enhance mental health assessments. Trained on a dataset of 2021 psychotherapy transcripts, the model achieves an average precision of 91.53%, significantly outperforming baseline models. This capability not only improves diagnostic accuracy but also supports the customization of therapeutic strategies. By automating the interpretation of complex emotional dynamics in psychotherapy, nBERT exemplifies the transformative potential of NLP and LLMs in revolutionizing mental health care. Beyond psychotherapy, the framework enables broader LLM applications in the life sciences, including personalized medicine and precision healthcare. © 2025 by the authors.},
	author_keywords = {emotion recognition; mental health diagnostics; NLP in life sciences; NRC emotion lexicon; personalized mental health care; psychotherapy transcripts},
	keywords = {Assisted living; Biomedical engineering; Cryotherapy; Diagnosis; Diseases; Drug therapy; Electrotherapeutics; Medical problems; mHealth; Noninvasive medical procedures; Nursing; Nutrition; Oncology; Pathology; Radiotherapy; Respiratory therapy; Surgery; Emotion recognition; Language processing; Life-sciences; Mental health; Mental health diagnostic; Natural language processing in life science; Natural languages; NRC emotion lexicon; Personalized mental health care; Psychotherapy transcript; Personalized medicine},
	correspondence_address = {W. Riaz; Institute of Intelligent Manufacturing Technology (IIMT), Shenzhen Polytechnic University, Shenzhen, 4089 Shahe West Road, 518055, China; email: riazwaqar@szpu.edu.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20782489},
	language = {English},
	abbrev_source_title = {Information},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hassani2025,
	author = {Hassani, Shabnam and Sabetzadeh, Mehrdad and Amyot, Daniel},
	title = {An empirical study on LLM-based classification of requirements-related provisions in food-safety regulations},
	year = {2025},
	journal = {Empirical Software Engineering},
	volume = {30},
	number = {3},
	doi = {10.1007/s10664-025-10619-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218632450&doi=10.1007%2fs10664-025-10619-z&partnerID=40&md5=fb9cc044506c4fa76c0e46df090a0ec2},
	affiliations = {University of Ottawa, Ottawa, ON, Canada},
	abstract = {As Industry 4.0 transforms the food industry, the role of software in achieving compliance with food-safety regulations is becoming increasingly critical. Food-safety regulations, like those in many legal domains, have largely been articulated in a technology-independent manner to ensure their longevity and broad applicability. However, this approach leaves a gap between the regulations and the modern systems and software increasingly used to implement them. In this article, we pursue two main goals. First, we conduct a Grounded Theory study of food-safety regulations and develop a conceptual characterization of food-safety concepts that closely relate to systems and software requirements. Second, we examine the effectiveness of two families of large language models (LLMs) – BERT and GPT – in automatically classifying legal provisions based on requirements-related food-safety concepts. Our results show that: (a) when fine-tuned, the accuracy differences between the best-performing models in the BERT and GPT families are relatively small. Nevertheless, the most powerful model in our experiments, GPT-4o, still achieves the highest accuracy, with an average Precision of 89% and an average Recall of 87%; (b) few-shot learning with GPT-4o increases Recall to 97% but decreases Precision to 65%, suggesting a trade-off between fine-tuning and few-shot learning; (c) despite our training examples being drawn exclusively from Canadian regulations, LLM-based classification performs consistently well on test provisions from the US, indicating a degree of generalizability across regulatory jurisdictions; and (d) for our classification task, LLMs significantly outperform simpler baselines constructed using long short-term memory (LSTM) networks and automatic keyword extraction. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.},
	author_keywords = {Classification; Food safety; Internet of things; Large language models (LLMs); Legal requirements; Requirements engineering},
	keywords = {C (programming language); Food storage; Empirical studies; Food Safety Regulations; Food-safety; Language model; Large language model; Legal requirements; Model-based classifications; Requirement engineering; Safety concepts; Systems and software; Food safety},
	correspondence_address = {M. Sabetzadeh; University of Ottawa, Ottawa, Canada; email: m.sabetzadeh@uottawa.ca},
	publisher = {Springer},
	issn = {13823256},
	coden = {ESENF},
	language = {English},
	abbrev_source_title = {Empir Software Eng},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Setu2025351,
	author = {Setu, Jahanggir Hossain and Hossain, Md. Shazzad and Halder, Nabarun and Islam, Ashraful and Amin, M. Ashraful},
	title = {Optimizing Software Release Management with GPT-Enabled Log Anomaly Detection},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15302 LNCS},
	pages = {351 – 365},
	doi = {10.1007/978-3-031-78166-7_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211928900&doi=10.1007%2f978-3-031-78166-7_23&partnerID=40&md5=3e925645dddb3799a58d18710d5aa9a9},
	affiliations = {Center for Computational and Data Sciences, Independent University, Bangladesh, Dhaka, 1229, Bangladesh},
	abstract = {In the complex world of software systems, understanding and maintaining system stability and performance is of utmost significance. Finding anomalies in log data has become increasingly difficult due to these systems’ growing complexity. Motivated by the need to improve software release management and ensure system reliability, this study exploits Generative Pretrained Transformer (GPT)-3’s advanced word embedding and tokenizer functionalities to convert log data to adept at identifying atypical patterns and anomalies, delineated in a two-layered structure: offline and online layers. In the offline layer, historical log data undergoes processing through the GPT model, where it is divided into sentence and word embeddings. Sentence embeddings are clustered to generate labels and taggers for subsequent stages, while word embeddings directly create taggers for the online layer’s sequence labeling. The online layer involves collecting real-time data, processing it through GPT to generate embeddings, and subjecting these embeddings to a sequence labeling process. This process yields templates and variables expediting the formation of train-test data splits for a classifier that detects anomalies. Different classifiers, namely Random Forest (RF), Light Gradient Boosting Machine (LightGBM), and Categorical Boosting (CatBoost), are evaluated. Experimental analysis on four distinct real-world datasets, namely Apache, BlueGene/L (BGL), Hadoop Distributed File System (HDFS), and Thunderbird, where CatBoost achieved remarkable accuracy rates of 99.75%, 99.00%, 98.75%, and 99.33%, respectively. The study also demonstrates that GPT-based embeddings provide a more effective anomaly detection solution than Bidirectional Encoder Representations from Transformers (BERT)-based embeddings. The proposed methodology is particularly designed to be integrated into software release management processes which enables automatic anomaly detection to augment quality control measures, thereby, expediting timely intervention. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Anomaly Detection; Anomaly Detection; GPT-3; LLM; Log Data; Machine Learning; Release Management; Word Embeddings},
	keywords = {Adaptive boosting; Anomaly detection; Computer software selection and evaluation; Network security; Program compilers; Records management; Software testing; Anomaly detection; Embeddings; Generative pretrained transformer-3; LLM; Log data; Machine-learning; Release management; Software release; Word embedding; Software reliability},
	correspondence_address = {A. Islam; Center for Computational and Data Sciences, Independent University, Bangladesh, Dhaka, 1229, Bangladesh; email: ashraful@iub.edu.bd},
	editor = {Antonacopoulos A. and Chaudhuri S. and Chellappa R. and Liu C.-L. and Bhattacharya S. and Pal U.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303178165-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ouaddi2025,
	author = {Ouaddi, Charaf and Benaddi, Lamya and Bouziane, El mahi and Naimi, Lahbib and Rahouti, Mohamed and Jakimi, Abdeslam and Saadane, Rachid},
	title = {Assessing the effectiveness of large language models for intent detection in tourism chatbots: A comparative analysis and performance evaluation},
	year = {2025},
	journal = {Scientific African},
	volume = {28},
	doi = {10.1016/j.sciaf.2025.e02649},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000447121&doi=10.1016%2fj.sciaf.2025.e02649&partnerID=40&md5=ab1f991b5b52abbd8a06fd9d48d157bd},
	affiliations = {Software Engineering and Information Systems Engineering Team, Department of Computer Sciences, Faculty of Sciences and Techniques Errachidia, Moulay Ismail University, Morocco; CIS Dept. Fordham University New York, 10023, NY, United States; Electrical Engineering Department, Hassania School of Public Works, Casablanca, Morocco},
	abstract = {In recent years, the tourism industry has observed a significant transformation by integrating chatbots, which enable tourists to interact with various services using natural language. At the heart of each chatbot is a Natural Language Understanding (NLU) component, which processes natural language inputs through intent classification. This paper evaluates the performance of Large Language Models (LLMs) such as GPT, BERT, LLaMA, and RoBERTa in the intent classification task for tourism chatbots. Our study conducts a comparative analysis of various LLMs to determine their effectiveness in classifying user intents in tourism related interactions. We assess the models’ capabilities using a tourism-specific dataset labeled according to the “Six A” criteria for tourist destination analysis. The models are evaluated using performance metrics such as accuracy, precision, recall, and F1-score. The findings provide practical insights into developing efficient NLU components for tourism chatbots, enhancing their ability to understand and assist users effectively. This paper contributes to the field by offering a comprehensive performance evaluation of LLMs for NLU in tourism, guiding researchers and practitioners in building more responsive and accurate chatbots for the tourism industry. © 2025 The Authors},
	author_keywords = {Chatbot; Deep learning; Generative AI; Intent Detection; LLM; Tourism},
	correspondence_address = {C. Ouaddi; Software Engineering and Information Systems Engineering Team, Department of Computer Sciences, Faculty of Sciences and Techniques Errachidia, Moulay Ismail University, Morocco; email: c.ouaddi@edu.umi.ac.ma},
	publisher = {Elsevier B.V.},
	issn = {24682276},
	language = {English},
	abbrev_source_title = {Sci.  African},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2025,
	title = {10th International Workshop on Big Data Management and Service, BDMS 2024, 9th International Workshop on Big Data Quality Management, BDQM 2024, DASFAA 2024 Workshop on Emerging Results in Data Science and Engineering, ERDSE 2024 and 8th International Workshop on Graph Data Management and Analysis, GDMA 2024 held in conjunction with 29th International Conference on Database Systems for Advanced Applications, DASFAA 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {14667 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218707836&partnerID=40&md5=624306a40579c162be6c23850c84bce0},
	abstract = {The proceedings contain 26 papers. The special focus in this conference is on Big Data Management and Service. The topics include: FAITH: A Fast, Accurate, and Lightweight Database-Agnostic Learned Cost Model; fast Approximate Temporal Butterfly Counting on Bipartite Graphs via Edge Sampling; Financial-ICS: Identifying Peer Firms via LongBERT from 10K Reports; establishing a Decentralized Diamond Quality Management System: Advancing Towards Global Standardization; co-estimation of Data Types and Their Positional Distribution; Enhancing Load Forecasting with VAE-GAN-Based Data Cleaning for Electric Vehicle Charging Loads; audio-Guided Visual Knowledge Representation; boundary Point Detection Combining Gravity and Outlier Detection Methods; A Meta-learning Approach for Category-Aware Sequential Recommendation on POIs; automatic Post-editing of Speech Recognition System Output Using Large Language Models; comparative Analysis with Multiple Large-Scale Language Models for Automatic Generation of Funny Dialogues; effectiveness of the Programmed Visual Contents Comparison Method for Two Phase Collaborative Learning in Computer Programming Education: A Case Study; generating Achievement Relationship Graph Between Actions for Alternative Solution Recommendation; generating News Headline Containing Specific Person Name; Investigating Evidence in Sentence Similarity Using MASK in BERT; acceleration of Synopsis Construction for Bounded Approximate Query Processing; Query Expansion in Food Review Search with Synonymous Phrase Generation by LLM; Question Answer Summary Generation from Unstructured Texts by Using LLMs; Real Estate Information Exploration in VR with LoD Control by Physical Distance; voices of Asynchronous Learning Students: Revealing Learning Characteristics Through Vocabulary Analysis of Notes Tagged in Videos; review Search Interface Based on Search Result Summarization Using Large Language Model; yes-No Flowchart Generation for Interactive Exploration of Personalized Health Improvement Actions; enhancing Link Prediction Based on Simple Path Graphs; Construction of EMU Fault Knowledge Graph Based on Large Language Model.},
	editor = {Morishima A. and Li G. and Ishikawa Y. and Amer-Yahia S. and Jagadish H.V. and Lu K.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981960913-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yong2025,
	author = {Yong, Chen and Defeng, Hu and Chao, Xu and Nannan, Chen and Jianbo, Liu},
	title = {Smart contract generation model based on code annotation and AST-LSTM tuning},
	year = {2025},
	journal = {Journal of Supercomputing},
	volume = {81},
	number = {5},
	doi = {10.1007/s11227-025-07186-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002980681&doi=10.1007%2fs11227-025-07186-x&partnerID=40&md5=52ae8306eb1189e25cfac9ff8049f2a6},
	affiliations = {School of Computer Science, Nanjing Audit University, 86 Yushan West Road, Jiangpu Street, Jiangsu, Nanjing, 211815, China; Wuhan Shubo Technology, Wuhan Shubo Technology Co., Ltd., Hongshan District, Fenghuo Innovation Valley, Hubei, Wuhan, 430070, China},
	abstract = {With the wide application of smart contracts in many fields, the number, types, and complexity of smart contracts are showing a rapidly increasing trend. However, the development of smart contracts has its own unique programming language and security requirements, which are difficult for conventional software personnel to adapt quickly, and how to realize the efficient development of smart contracts according to the application requirements is an important issue that needs to be solved for its further development. The author proposes a smart contract generation method based on abstract syntax tree (AST) long short-term memory (LSTM) characterization and code annotation tuning large language model, which adopts the AST-LSTM model combining abstract syntax tree and tree-long short-term memory(Tree-LSTM) to vectorize the code as well as Sentence-BERT to vectorize the annotations and carry out a weighted analysis, and constructs a smart contract clustering analysis model to achieve accurate clustering of functionally similar smart contracts. Then, the AST-LSTM+Transformer model is used to detect defects in the clustered code and correlate the related annotation information to construct a diverse prompt feature prompt statement dataset. Finally, the Llama2-7B model is used as the basis for demand-specific smart contract generation with the help of Lora and P-Tuning v2 fine-tuning techniques. In this paper, we conducted comparative experiments with existing methods with the help of BLEU, an auxiliary tool for the quality assessment of bilingual translation, and Mythril, VaaS, and other code security detection tools. The results of the experiment show that the average value of BLEU of the code generated by this paper’s method is improved by about 25%, and the code security is improved by about 9%, which will greatly promote the rapid development and exploitation of smart contracts with high-security requirements. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.},
	author_keywords = {Annotation; AST; Fine-tuning; LLM (large language model); Smart contract generation; Tree-LSTM},
	keywords = {Cluster analysis; Problem oriented languages; Translation (languages); Abstract Syntax Trees; Annotation; Code annotation; Fine tuning; Language model; Large language model; Security requirements; Short term memory; Smart contract generation; Tree-long short-term memory; Syntactics},
	correspondence_address = {C. Yong; School of Computer Science, Nanjing Audit University, Nanjing, 86 Yushan West Road, Jiangpu Street, Jiangsu, 211815, China; email: chenyong@nau.edu.cn; H. Defeng; School of Computer Science, Nanjing Audit University, Nanjing, 86 Yushan West Road, Jiangpu Street, Jiangsu, 211815, China; email: mp2209112@stu.nau.edu.cn; X. Chao; School of Computer Science, Nanjing Audit University, Nanjing, 86 Yushan West Road, Jiangpu Street, Jiangsu, 211815, China; email: xuchao@nau.edu.cn},
	publisher = {Springer},
	issn = {09208542},
	coden = {JOSUE},
	language = {English},
	abbrev_source_title = {J Supercomput},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Jayanthakumaran2025,
	author = {Jayanthakumaran, Muhunthan and Shukla, Nagesh and Pradhan, Biswajeet and Beydoun, Ghassan},
	title = {A systematic review of sentiment analytics in banking headlines},
	year = {2025},
	journal = {Decision Analytics Journal},
	volume = {15},
	doi = {10.1016/j.dajour.2025.100584},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004674261&doi=10.1016%2fj.dajour.2025.100584&partnerID=40&md5=a65e91572f885d11b49d58809ffbe814},
	affiliations = {Centre for Advanced Modelling and Geospatial Information Systems (CAMGIS), Faculty of Engineering and IT, University of Technology Sydney, 2007, Australia; Department of Management, Griffith Business School, Griffith University, Brisbane South Campus, 4111, Australia},
	abstract = {This systematic review investigates sentiment analysis of news headlines in the banking sector, a field susceptible to public sentiment, as demonstrated by phenomena like bank runs leading to rapid deposit withdrawals. We trace the evolution of analytic methods from traditional machine learning to advanced deep learning models, notably Bidirectional Encoder Representations from Transformer (BERT) and Generative Pre-trained Transformer (GPT). Our study highlights their applications including headline generation, sentiment measurement, fake news detection, and analysis of political bias. Despite significant advancements, we uncover research gaps, such as the ineffective use of these methodologies in banking analysis, the underuse of GPT, and a focus on performance rather than practical application. Looking ahead, we note the increasing significance of Large Language Model (LLM), the untapped potential of headline analysis in banking, and the growing interest in this area spurred by rapid technological advancements. Our findings emphasise the pivotal role of sentiment analysis in deciphering market trends and improving decision making in finance, underscoring its strategic importance in the banking industry. © 2025 The Author(s)},
	author_keywords = {Banking headlines; Market trends; Predictive modelling; Sentiment analysis; Text mining},
	correspondence_address = {N. Shukla; Department of Management, Griffith Business School, Griffith University, Brisbane South Campus, 4111, Australia; email: n.shukla@griffith.edu.au},
	publisher = {Elsevier Inc.},
	issn = {27726622},
	language = {English},
	abbrev_source_title = {Decis. Anal. J.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mahmud2025,
	author = {Mahmud, Doaa and Hajmohamed, Hadeel and Almentheri, Shamma and Alqaydi, Shamma and Aldhaheri, Lameya and Khalil, Ruhul Amin and Saeed, Nasir},
	title = {Integrating LLMs With ITS: Recent Advances, Potentials, Challenges, and Future Directions},
	year = {2025},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	doi = {10.1109/TITS.2025.3528116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216263322&doi=10.1109%2fTITS.2025.3528116&partnerID=40&md5=727797c892ca1bfc9e72b7fa4f51f50f},
	affiliations = {UAE University, College of Engineering, Department of Electrical and Communication Engineering, Al Ain, United Arab Emirates; UAE University, Engineering Requirement Unit (ERU), College of Engineering, Al Ain, United Arab Emirates},
	abstract = {Intelligent Transportation Systems (ITS) are crucial for the development and operation of smart cities, addressing key challenges in efficiency, productivity, and environmental sustainability. This paper comprehensively reviews the transformative potential of Large Language Models (LLMs) in optimizing ITS. Initially, we provide an extensive overview of ITS, highlighting its components, operational principles, and overall effectiveness. We then delve into the theoretical background of various LLM techniques, such as GPT, T5, CTRL, and BERT, elucidating their relevance to ITS applications. Following this, we examine the wide-ranging applications of LLMs within ITS, including traffic flow prediction, vehicle detection and classification, autonomous driving, traffic sign recognition, and pedestrian detection. Our analysis reveals how these advanced models can significantly enhance traffic management and safety. Finally, we explore the challenges and limitations LLMs face in ITS, such as data availability, computational constraints, and ethical considerations. We also present several future research directions and potential innovations to address these challenges. This paper aims to guide researchers and practitioners through the complexities and opportunities of integrating LLMs in ITS, offering a roadmap to create more efficient, sustainable, and responsive next-generation transportation systems.  © 2000-2011 IEEE.},
	author_keywords = {autonomous driving; Intelligent transportation systems; large language models; traffic flow optimization; traffic management},
	keywords = {Advanced traffic management systems; Highway administration; Highway traffic control; Information management; Motor transportation; Pedestrian safety; Street traffic control; Vehicle detection; Autonomous driving; Development and operations; Environmental sustainability; Flow optimization; Intelligent transportation systems; Language model; Large language model; Traffic flow; Traffic flow optimization; Traffic management; Traffic signs},
	correspondence_address = {N. Saeed; UAE University, College of Engineering, Department of Electrical and Communication Engineering, Al Ain, United Arab Emirates; email: mr.nasir.saeed@ieee.org},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15249050},
	language = {English},
	abbrev_source_title = {IEEE Trans. Intell. Transp. Syst.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@CONFERENCE{Huang20258336,
	author = {Huang, Yifei and Cao, Jingxin and Luo, Hanyu and Guan, Xin and Liu, Bo},
	title = {MAGRET: Machine-generated Text Detection with Rewritten Texts},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	volume = {Part F206484-1},
	pages = {8336 – 8346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218502807&partnerID=40&md5=a7ef4d19d0ed6f4feaadffdbb0a58809},
	affiliations = {School of Cyber Science and Engineering, Southeast University, Nanjing, 211189, China; Key Laboratory of Computer Network and Information of Ministry of Education of China, Nanjing, 211189, China; School of Computer Science and Engineering, Southeast University, Nanjing, 211189, China},
	abstract = {With the quick advancement in text generation ability of Large Language Model(LLM), concerns about the misuse of machine-generated text(MGT) have grown, raising potential violations of legal and ethical standards. Some existing studies concentrate on detecting machine-generated text in open-source models using in-model features, but their performance on closed-source large models is limited. This limitation occurs because, in the closed-source model detection, the only reference that can be obtained is the texts, which may differ significantly due to random sampling. In this paper, we demonstrate that texts generated by the same model can align both semantically and statistically under similar prompts, facilitating effective detection and traceability. Specifically, we fine-tune a BERT encoder through contrastive learning to achieve semantic alignment in randomly generated texts from the same model. Then, we propose a method called Machine-Generated Text Detection with Rewritten Texts, which designed several prompt refactoring methods and used them to request rewritten text from LLMs. Semantic and statistical relationships between rewritten and original texts provide a basis for detection and traceability. Finally, we expanded the text dataset with multi-parameter random sampling and verified the performance of MAGRET on three text-generated datasets. Experimental results show that previous methods struggle with closed-source model detection, while our approach significantly outperforms baseline methods in this regard. It also shows MAGRET's stable performance in detection and tracing tasks across various randomly sampled texts. © 2025 Association for Computational Linguistics.},
	keywords = {Adversarial machine learning; Computational linguistics; Semantics; Closed source; Ethical standards; Language model; Legal standards; Machine-generated texts; Performance; Random sampling; Source models; Text detection; Text generations; Contrastive Learning},
	correspondence_address = {J. Cao; School of Cyber Science and Engineering, Southeast University, Nanjing, 211189, China; email: jx.cao@seu.edu.cn},
	editor = {Rambow O. and Wanner L. and Apidianaki M. and Al-Khalifa H. and Di Eugenio B. and Schockaert S.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176196-4},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pham202585,
	author = {Pham, Hien Thu and Nguyen, Minh Hieu and Ha, Hiep Minh and Le, Ngoc Quang Hung and Jo, Jun},
	title = {Towards Comprehensive Innovation Landscape: Technology Retrieval Meets Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15449 LNCS},
	pages = {85 – 98},
	doi = {10.1007/978-981-96-1242-0_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213295204&doi=10.1007%2f978-981-96-1242-0_7&partnerID=40&md5=4c2f719b577c1142eace10af3799232a},
	affiliations = {Commonwealth Scientific and Industrial Research Organisation (CSIRO), Canberra, Australia; Griffith University, Brisbane, Australia; Directorate for Standards, Metrology and Quality (STAMEQ), Hanoi, Viet Nam; Hanoi University of Science and Technology, Hanoi, Viet Nam},
	abstract = {In modern dynamic business environment, understanding the technologies companies employ is vital for creating business relationships, identifying market opportunities, and shaping strategic decisions. Traditional technology mapping methods, which rely on keyword-based approaches, face limitations in processing large, diverse datasets and often struggle to detect emerging technologies. To address these challenges, we introduce a novel framework called STARS (Semantic Technology and Retrieval System). STARS leverages Large Language Models (LLMs) and Sentence-BERT to extract relevant technologies from unstructured data, generate comprehensive company profiles, and rank technologies based on their relevance to each company operations. By integrating entity extraction with Chain-of-Thought prompting, and employing semantic ranking, STARS effectively maps companies’ technological portfolios. Our experimental results demonstrate that STARS significantly improves retrieval precision, offering a robust and scalable solution for mapping technologies across industries. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Entity extraction; Innovation Landscape; Large Language Models (LLM); Semantic ranking; Sentence-BERT},
	keywords = {Mapping; Entity extractions; Innovation landscape; Language model; Large language model; Retrieval systems; Semantic rankings; Semantic retrieval; Semantic technologies; Sentence-BERT; Technology system; Semantics},
	correspondence_address = {M.H. Nguyen; Griffith University, Brisbane, Australia; email: minhhieu.nguyen@griffithuni.edu.au},
	editor = {Chen T. and Cao Y. and Nguyen Q.V.H. and Nguyen T.T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981961241-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee2025209,
	author = {Lee, Yoon Noh and Yu, Yongseung and Park, Yongjun},
	title = {CUrator: An Efficient LLM Execution Engine with Optimized Integration of CUDA Libraries},
	year = {2025},
	journal = {CGO 2025 - Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
	pages = {209 – 224},
	doi = {10.1145/3696443.3708944},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001094134&doi=10.1145%2f3696443.3708944&partnerID=40&md5=5146cec2ce4da19c915163225e47a6ba},
	affiliations = {Yonsei University, Seoul, South Korea},
	abstract = {Large Language Models (LLMs) have recently emerged as a state-of-the-art learning model with a wide range of applications in diverse computing environments. Among the various computational operations that comprise the LLM, the GEneral Matrix Multiplication (GEMM) operation is the most frequently utilized operation within the LLM. GEMM libraries such as cuBLAS and CUTLASS provide a variety of optimization techniques to achieve optimal GEMM performance in GPU-enabled computing environments. In particular, the CUTLASS open-source library for GPUs within the CUDA programming environment provides users with the capability to optimize templates for high performance. Previous research has demonstrated the effectiveness of CUTLASS-based GEMMs in improving the performance of real-world deep neural networks on various deep learning platforms. However, these studies have not considered different model parameters for modern LLMs nor have they explored the impact of diverse GPU computing environments. This paper presents CUrator, an efficient LLM execution engine that can achieve optimal end-to-end LLM performance using both cuBLAS and CUTLASS libraries on different GPUs for modern LLMs such as BERT, GPT, and Llama. CUrator first generates CUTLASS-/cuBLAS-friendly graph IRs of various LLMs on the TVM framework to maximize mapping coverage. On the CUTLASS mapping path, it performs a comprehensive search for programmable tuning parameters in the CUTLASS library with the objective of deriving optimal kernels for all GEMMs within each LLM. CUrator further introduces two optimization techniques: 1) build-time reduction key initialization support for CUTLASS Split-K GEMMs, and 2) Split-K support for CUTLASS Batch GEMMs. Finally, CUrator selects the best performing mapping path between cuBLAS and CUTLASS paths. The experimental results show that CUrator achieves inference speedups of 1.50× and 4.99×, respectively, for representative LLMs on the A100 GPU in the single and half precision, compared to the baseline. We strongly believe that the CUrator framework can provide the best direction for next-generation tuning frameworks by showing the maximum end-to-end performance of various LLMs on various GPUs. © 2025 Copyright held by the owner/author(s).},
	author_keywords = {Compiler; GEMM; GPU; Large Language Model},
	keywords = {Ada (programming language); Computer graphics equipment; Graphics processing unit; Matrix algebra; Open source software; Problem oriented languages; Program compilers; Compiler; Computing environments; Execution engine; General matrix multiplication; Language model; Large language model; MAtrix multiplication; Model executions; Optimization techniques; Performance; Deep neural networks},
	correspondence_address = {Y. Park; Yonsei University, Seoul, South Korea; email: yongjunpark@yonsei.ac.kr},
	editor = {Doerfert J. and Grosser T. and Leather H. and Sadayappan P.},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840071275-3},
	language = {English},
	abbrev_source_title = {CGO - Proc. ACM/IEEE Int. Symp. Code Gener. Optim.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bourahouat202517,
	author = {Bourahouat, Ghizlane and Abourezq, Manar and Daoudi, Najima},
	title = {Enhancing Arabic Sentiment Analysis Using Arabic LLMs},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2339 CCIS},
	pages = {17 – 27},
	doi = {10.1007/978-3-031-79164-2_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219183386&doi=10.1007%2f978-3-031-79164-2_2&partnerID=40&md5=a6b02b4b198381a967351e18aa7f15fd},
	affiliations = {LyRICA Laboratory, ESI, ITQAN Team, Rabat, Morocco},
	abstract = {Considering Sentiment Analysis’s importance, the Natural Language Processing (NLP) field has seen a surge in studies dedicated to this task. However, research efforts in Arabic Natural Language Processing haven’t reached the same prominence as those in non-Latin alphabet languages. This discrepancy can be attributed to the specificity of the Arabic language and the limited availability of freely accessible lexical resources. Considering these challenges, our paper focuses on Sentiment Analysis in Modern Standard Arabic. We achieve this using pre-trained Arabic BERT models, specifically AraBERT, ALBERT, CAMeLBERT, AraELECTRA, and QARIB. Our approach was tested on the 100k reviews dataset and Arabic Moroccan Arabic corpus (MAC) dataset. Notably, with the MAC dataset, our proposed system at- attains an accuracy of 96% when using the QARIB model, 93% when using Ara- BERT and 26% with CAMeLBERT. Regarding the 100k reviews dataset, the best accuracy of 93% was achieved when using AraBERT, followed by QARIB with an accuracy of 89% and lower accuracy was when using ALBERT with 39%. We compared the research results obtained through our approach with those of other leading methods, demonstrating the effectiveness of our methodology. These findings provide valuable insights for future enhancements in this field. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {ANLP; Arabic Sentiment Analysis; LLM; Standard Arabic; Transformers},
	keywords = {Distribution transformers; ANLP; Arabic natural language processing; Arabic sentiment analyze; Language processing; LLM; Natural languages; Research efforts; Sentiment analysis; Standard arabics; Transformer; Natural language processing systems},
	correspondence_address = {G. Bourahouat; LyRICA Laboratory, ESI, ITQAN Team, Rabat, Morocco; email: ghizlane.bourahouat@esi.ac.ma},
	editor = {Hdioud B. and Aouragh S.L.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303179163-5},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ashizawa2025252,
	author = {Ashizawa, Arisa and Mibayashi, Ryota and Ohshima, Hiroaki},
	title = {Query Expansion in Food Review Search with Synonymous Phrase Generation by LLM},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {14667 LNCS},
	pages = {252 – 260},
	doi = {10.1007/978-981-96-0914-7_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218443738&doi=10.1007%2f978-981-96-0914-7_19&partnerID=40&md5=91b3f7d47fc3e9f49ce3083ab247c9a9},
	affiliations = {Graduate School of Information Science, University of Hyogo, Hyogo, Kobe, Japan},
	abstract = {In this study, we propose a method that considers the diversity of query expressions for searching food reviews. For example, if you search for reviews of udon noodles using the query “firmness”. In that case, it is easy to output reviews containing the expression “firmness”. On the other hand, we want to output reviews containing expressions like “elasticity” and “chewiness,” which do not match the exact query but have semantic similarity. Therefore, we propose two approaches using query expansion with ChatGPT, a large language model (LLM). Both approaches use the LLM to obtain several synonymous phrases for a query. The first method trains the BERT model for relevance judgment of reviews based on semantic similarity to the query. To create training data, collect candidate queries in advance and acquire their synonymous phrases. In the second approach, when a search query is input, the synonymous phrases of the query are obtained for on-demand query expansion. We implemented these approaches and compared them to methods such as BM25. The combined use of both proposal approaches showed better performance. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {BERT; LLM; query expansion; Review Search},
	keywords = {Food ingredients; Query languages; Semantics; BERT; Data collect; Language model; Large language model; Query expansion; Query expression; Relevance judgement; Review search; Semantic similarity; Training data; Structured Query Language},
	correspondence_address = {A. Ashizawa; Graduate School of Information Science, University of Hyogo, Kobe, Hyogo, Japan; email: ad23y002@guh.u-hyogo.ac.jp},
	editor = {Morishima A. and Li G. and Ishikawa Y. and Amer-Yahia S. and Jagadish H.V. and Lu K.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981960913-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nuryani2025,
	author = {Nuryani and Munir, Rinaldi and Purwarianti, Ayu and Lestari, Dessi Puji},
	title = {BERT-BASED MODEL AND LLMS-GENERATED SYNTHETIC DATA FOR CONFLICT SENTIMENT IDENTIFICATION IN ASPECT-BASED SENTIMENT ANALYSIS},
	year = {2025},
	journal = {Interdisciplinary Journal of Information, Knowledge, and Management},
	volume = {20},
	doi = {10.28945/5439},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218439882&doi=10.28945%2f5439&partnerID=40&md5=0d08efff8b805f3a1df223f7bb2ecf4e},
	affiliations = {School of Electrical and Informatics Engineering, Bandung Institute of Technology (ITB), Bandung, Indonesia; National Research and Innovation Agency (BRIN), Indonesia},
	abstract = {Most research in sentiment analysis, as well as aspect-based sentiment analysis (ABSA), classifies sentiment polarity into two classes (positive and negative) or three classes (positive, negative, and neutral), excluding conflict sentiment. A sentiment will be classified as conflict if it expresses both positive and negative sentiments. Ignoring conflict sentiment will cause the classification to be less accurate. This study investigates the four-class sentiment classification (positive, negative, neutral, and including conflict) and proposes a model utilizing a pretrained language representation model (BERT) for identifying conflict sentiment in ABSA. We also employ an open-source large language model (LLM) created by Meta, Llama 3, for generating synthetic data to support research on four-class sentiment classification in ABSA. Background Public opinions and experiences on product reviews, social events, political movements, etc., can be used for exploring customer behavior, predicting customer preferences, understanding public sentiment, etc., so it becomes an important component in the decision-making process. Providing an accurate opinion will enable an individual, business, or organization to have an informed judgement before making a decision. An aspect-based sentiment analysis, utilizing a four-class sentiment classification system - comprising positive, negative, neutral, and conflict - will produce a more precise assessment than a general sentiment analysis utilizing a two- or three-class sentiment classification system. Methodology This study utilizes a methodology that includes generating synthetic data to augment the original datasets, designing the input representation, detecting aspect categories, performing a multi-label sentiment classification, and representing sentiment in a four-class sentiment classification. Contribution This study provides an investigation of the four-class sentiment classification (positive, negative, neutral, and conflict) and proposes a BERT-based method to identify aspects with conflict sentiment in ABSA. Moreover, it also evaluates Llama 3 for generating synthetic data to address the issues related to data scarcity and imbalanced datasets in the research on four-class sentiment classification in ABSA. The validation of the proposed model on the SemEval-2014 restaurant domain dataset shows an improvement in conflict sentiment accuracy compared to baselines. Findings The investigation of the four-class sentiment classification task in ABSA demonstrates that identifying conflict sentiment is challenging for several reasons. Among them are (1) the lack of a public dataset for this research; (2) the small amount of data with conflict labels in the available dataset resulting in an imbalanced dataset; (3) conflict sentiment is a complex sentiment containing both positive and negative sentiments; and (4) conflict sentiments are usually expressed in long and complicated sentences and involve implicit aspects. Our solution to these challenges involved generating synthetic data using Llama 3 and designing a BERT-based model on multi-label aspects for identifying aspect with conflict sentiment. The experimental results demonstrate that our proposed method outperforms previous methods in identifying the fourth sentiment in four-class sentiment classification, i.e., aspects with conflict sentiment. Recommendations Most existing ABSA models with four-class sentiment classification are con-for Practitioners ducted for product reviews (mostly in the restaurant domain) and in high-resource languages (mainly in English). Therefore, users may need to make some adjustments to different domains and languages. Recommendations Due to the limited availability of datasets for research in aspect-based sentiment for Researchers analysis with four-class sentiment classification, it is important to urgently develop extra supporting datasets. Impact on Society Aspect-based sentiment analysis (ABSA), which employs a four-class sentiment classification (positive, negative, neutral, and conflict), provides a comprehensive analysis about the aspects (or target of opinion) and their sentiment. It will help us understand the sentiment analysis problem better. By providing more accurate sentiment through aspect-based sentiment analysis with four-class sentiment classification, this study can better assist individuals, organizations, or companies in gaining a view or an opinion about any product, service, or candidate in an electoral vote. Future Research Future research on aspect-based sentiment analysis could evaluate other open-source large language models (LLMs), such as Gemma, Mixtral, etc., for generating synthetic data and evaluating the model across various domains and languages. Furthermore, future research could also utilize the LLMs to perform ABSA tasks, such as aspect term extraction, aspect category detection, and sentiment polarities, through fine-tuning the LLMs. © 2025 Informing Science Institute. All rights reserved.},
	author_keywords = {aspect-based sentiment analysis; conflict sentiment; four-class sentiment classification; large language models; pre-trained language models},
	keywords = {Large datasets; Network security; Reviews; Sales; Aspect-based sentiment analyze; Conflict sentiment; Four-class sentiment classification; Language model; Large language model; Pre-trained language model; Sentiment analysis; Sentiment classification; Synthetic data; Decision making},
	publisher = {Informing Science Institute},
	issn = {15551229},
	language = {English},
	abbrev_source_title = {Interdiscip. J. Inf. Knowl. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Ranjan2025,
	author = {Ranjan, Sakshi and Singh, Sanjay Kumar},
	title = {Overcoming catastrophic forgetting in molecular property prediction using continual learning of sequential episodes},
	year = {2025},
	journal = {Expert Systems with Applications},
	volume = {267},
	doi = {10.1016/j.eswa.2024.125997},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212829330&doi=10.1016%2fj.eswa.2024.125997&partnerID=40&md5=9a5709a0e3561d16bd0cbf97036725aa},
	affiliations = {Department of Computer Science and Engineering, IIT (BHU), Uttar Pradesh, Varanasi, 221005, India},
	abstract = {Continual Learning requires Large Language Models (LLM) to adapt to new episodes and data over time without forgetting the knowledge acquired from previous episodes. This dynamic approach to learning is crucial in molecular property prediction, where data is not static but arrives in streams. LLMs are prone to Catastrophic Forgetting (CF), where learning new information leads to erosion of previously acquired knowledge. This is particularly problematic in scenarios where the chemical, genomic, and proteomic data distribution shifts or new episodes differ significantly from prior ones. In response to the above issue, this work proposes a Multi-task Learner with Online Elastic Weight Consolidation and LLMs (Bidirectional Encoder Representation of Transformer (BERT) and Bidirectional Autoregressive Transformers (BART)) called Bidirectional Multi-Task Learner Elastic Weight Consolidation (B-MTLEWC). Two molecular datasets used for sequential learning of episodes are trained for 2000 epochs, which generated acceptable results on the B-MTLEWC model (1. Blood Brain Barrier Peptides (BBBP): Accuracy 89.16% and 88.81% and 2. Bitter: Accuracy 85.82% and 87.06% on unmasked and masked sets, respectively). The B-MTLEWC model is evaluated against BERT and BART across twelve augmented test datasets spanning three distinct episodes, focusing on knowledge retention from previous episodes. The model shows a maximum performance drop of only 1% in accuracy and Area Under the Curve, and in some cases, its performance remained consistent, demonstrating effective mitigation of CF. The empirical analysis combined with various explainability techniques highlighted significant performance improvements in sequential learning of episodes compared to State-of-the-Art methods, hence addressing the stability-plasticity trade-off. © 2024 Elsevier Ltd},
	author_keywords = {(SMILES); (XAI); Catastrophic forgetting; Continual learning; Drug discovery; Explainable Artificial Intelligence; Multi-task learner; Simplified Input Line Entry System},
	keywords = {Adversarial machine learning; Contrastive Learning; Multi-task learning; (SMILES); (XAI); Catastrophic forgetting; Continual learning; Drug discovery; Entry system; Explainable artificial intelligence; Multi tasks; Multi-task learner; Simplified input line entry system; Federated learning},
	correspondence_address = {S.K. Singh; Department of Computer Science and Engineering, IIT (BHU), Varanasi, Uttar Pradesh, 221005, India; email: sks.cse@iitbhu.ac.in},
	publisher = {Elsevier Ltd},
	issn = {09574174},
	coden = {ESAPE},
	language = {English},
	abbrev_source_title = {Expert Sys Appl},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Holmes2025,
	author = {Holmes, Glenn and Tang, Biya and Gupta, Sunil and Venkatesh, Svetha and Christensen, Helen and Whitton, Alexis},
	title = {Applications of Large Language Models in the Field of Suicide Prevention: Scoping Review},
	year = {2025},
	journal = {Journal of Medical Internet Research},
	volume = {27},
	doi = {10.2196/63126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215975831&doi=10.2196%2f63126&partnerID=40&md5=d19a94ad36e33e3602a6ce0c02567a00},
	affiliations = {Black Dog Institute, University of New South Wales, Randwick, Sydney, Australia; Applied Artificial Intelligence Institute, Deakin University, Melbourne, Australia},
	abstract = {Background: Prevention of suicide is a global health priority. Approximately 800,000 individuals die by suicide yearly, and for every suicide death, there are another 20 estimated suicide attempts. Large language models (LLMs) hold the potential to enhance scalable, accessible, and affordable digital services for suicide prevention and self-harm interventions. However, their use also raises clinical and ethical questions that require careful consideration. Objective: This scoping review aims to identify emergent trends in LLM applications in the field of suicide prevention and self-harm research. In addition, it summarizes key clinical and ethical considerations relevant to this nascent area of research. Methods: Searches were conducted in 4 databases (PsycINFO, Embase, PubMed, and IEEE Xplore) in February 2024. Eligible studies described the application of LLMs for suicide or self-harm prevention, detection, or management. English-language peer-reviewed articles and conference proceedings were included, without date restrictions. Narrative synthesis was used to synthesize study characteristics, objectives, models, data sources, proposed clinical applications, and ethical considerations. This review adhered to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) standards. Results: Of the 533 studies identified, 36 (6.8%) met the inclusion criteria. An additional 7 studies were identified through citation chaining, resulting in 43 studies for review. The studies showed a bifurcation of publication fields, with varying publication norms between computer science and mental health. While most of the studies (33/43, 77%) focused on identifying suicide risk, newer applications leveraging generative functions (eg, support, education, and training) are emerging. Social media was the most common source of LLM training data. Bidirectional Encoder Representations from Transformers (BERT) was the predominant model used, although generative pretrained transformers (GPTs) featured prominently in generative applications. Clinical LLM applications were reported in 60% (26/43) of the studies, often for suicide risk detection or as clinical assistance tools. Ethical considerations were reported in 33% (14/43) of the studies, with privacy, confidentiality, and consent strongly represented. Conclusions: This evolving research area, bridging computer science and mental health, demands a multidisciplinary approach. While open access models and datasets will likely shape the field of suicide prevention, documenting their limitations and potential biases is crucial. High-quality training data are essential for refining these models and mitigating unwanted biases. Policies that address ethical concerns—particularly those related to privacy and security when using social media data—are imperative. Limitations include high variability across disciplines in how LLMs and study methodology are reported. The emergence of generative artificial intelligence signals a shift in approach, particularly in applications related to care, support, and education, such as improved crisis care and gatekeeper training methods, clinician copilot models, and improved educational practices. Ongoing human oversight—through human-in-the-loop testing or expert external validation—is essential for responsible development and use. © Glenn Holmes, Biya Tang, Sunil Gupta, Svetha Venkatesh, Helen Christensen, Alexis Whitton.},
	author_keywords = {AI; artificial intelligence; large language model; PRISMA; self-harm; suicide; suicide prevention},
	keywords = {Humans; Suicide Prevention; automutilation; education; English (language); generative pretrained transformer; human; large language model; mental health; Review; social media; suicide; suicide prevention; systematic review},
	correspondence_address = {A. Whitton; Black Dog Institute, University of New South Wales, Sydney, Hospital Road, Randwick, 2031, Australia; email: a.whitton@unsw.edu.au},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {39847414},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kuzman202535621,
	author = {Kuzman, Taja and Ljubesic, Nikola},
	title = {LLM Teacher-Student Framework for Text Classification With No Manually Annotated Data: A Case Study in IPTC News Topic Classification},
	year = {2025},
	journal = {IEEE Access},
	volume = {13},
	pages = {35621 – 35633},
	doi = {10.1109/ACCESS.2025.3544814},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219144168&doi=10.1109%2fACCESS.2025.3544814&partnerID=40&md5=7a696286f1a4563f23177a08f7f81257},
	affiliations = {Jožef Stefan Institute, Department of Knowledge Technologies, Ljubljana, 1000, Slovenia; Jožef Stefan International Postgraduate School, Ljubljana, 1000, Slovenia},
	abstract = {With the ever-increasing number of news stories available online, classifying them by topic, regardless of the language they are written in, has become crucial for enhancing readers’ access to relevant content. To address this challenge, we propose a teacher-student framework based on large language models (LLMs) for developing multilingual news topic classification models of reasonable size with no need for manual data annotation. The framework employs a Generative Pretrained Transformer (GPT) model as the teacher model to develop a news topic training dataset through automatic annotation of 20,000 news articles in Slovenian, Croatian, Greek, and Catalan. Articles are classified into 17 main categories from the Media Topic schema, developed by the International Press Telecommunications Council (IPTC). The teacher model exhibits high zero-shot performance in all four languages. Its agreement with human annotators is comparable to that between the human annotators themselves. To mitigate the computational limitations associated with the requirement of processing millions of texts daily, smaller BERT-like student models are fine-tuned on the GPT-annotated dataset. These student models achieve high performance comparable to the teacher model. Furthermore, we explore the impact of the training data size on the performance of the student models and investigate their monolingual, multilingual, and zero-shot cross-lingual capabilities. The findings indicate that student models can achieve high performance with a relatively small number of training instances, and demonstrate strong zero-shot cross-lingual abilities. Finally, we publish the best-performing news topic classifier, enabling multilingual classification with the top-level categories of the IPTC Media Topic schema. © 2025 The Authors. This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/},
	author_keywords = {data annotation; IPTC; large language models; LLMs; Multilingual text classification; news topic; topic classification; training data preparation},
	keywords = {Classification (of information); Data assimilation; Linguistics; Metadata; Network security; Personnel training; Spatio-temporal data; Teaching; Data annotation; Data preparation; International press telecommunications councils; Language model; Large language model; Multilingual text classification; Multilingual texts; News topics; Text classification; Topic Classification; Training data; Training data preparation; Students},
	correspondence_address = {T. Kuzman; Jožef Stefan Institute, Department of Knowledge Technologies, Ljubljana, 1000, Slovenia; email: taja.kuzman@ijs.si},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Li2025,
	author = {Li, Wenxiang and Ding, Longyuan and Zhang, Yuliang and Pu, Ziyuan},
	title = {Understanding multimodal travel patterns based on semantic embeddings of human mobility trajectories},
	year = {2025},
	journal = {Journal of Transport Geography},
	volume = {124},
	doi = {10.1016/j.jtrangeo.2025.104169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218887640&doi=10.1016%2fj.jtrangeo.2025.104169&partnerID=40&md5=817a2733eb1a5ac0c23d1913807cece3},
	affiliations = {Business School, University of Shanghai for Science and Technology, Shanghai, 200093, China; Smart Urban Mobility Institute, University of Shanghai for Science and Technology, Shanghai, 200093, China; Intelligent Transportation System Research Center, Hangzhou City University, Hangzhou, 310015, China; Institute of Intelligent Transportation Systems, College of Civil Engineering and Architecture, Zhejiang University, Hangzhou, 310058, China; School of Transportation, Southeast University, Nanjing, 211189, China},
	abstract = {As more people use multiple transport modes in a single trip, understanding multimodal travel patterns becomes essential for designing a more efficient and sustainable transportation system. However, the inherent spatiotemporal dependencies in multimodal travel make it challenging to recognize these patterns accurately. Therefore, this study aims to apply the large language model (LLM) to better understand the complex multimodal travel patterns of urban residents. First, we develop a change point-based method to divide human mobility trajectories into travel segments and then use the Light Gradient Boosting Machine (LightGBM) to infer the travel modes of each segment. Next, multimodal travel features are extracted and represented in textual forms, which are transformed into semantic embeddings using the Bidirectional Encoder Representations from Transformers (BERT). Finally, we apply the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm to measure semantic similarity between these embeddings and identify different multimodal travel patterns. The proposed approach is validated using 17,621 mobility trajectories from 182 volunteers in Beijing, successfully identifying 35 representative multimodal travel patterns. Additionally, some abnormal patterns indicate underlying deficiencies in transportation facilities, providing valuable insights for transportation planning and management. In summary, the scientific contribution of this study is to redefine multimodal travel pattern recognition as a semantic similarity measurement problem by embedding diverse and discrete multimodal travel features into a unified and continuous vector space. © 2024},
	author_keywords = {Human mobility trajectory; Large language model; Multimodal travel; Pattern recognition; Semantic embedding},
	keywords = {Beijing [China]; China; modeling; pattern recognition; transportation planning; transportation system; travel behavior},
	correspondence_address = {W. Li; Business School, University of Shanghai for Science and Technology, Shanghai, 200093, China; email: liwx@usst.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {09666923},
	language = {English},
	abbrev_source_title = {J. Transp. Geogr.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ye202564,
	author = {Ye, Xiucai and Shi, Tianyi and Huang, Dong and Sakurai, Tetsuya},
	title = {Multi-Omics clustering by integrating clinical features from large language model},
	year = {2025},
	journal = {Methods},
	volume = {239},
	pages = {64 – 71},
	doi = {10.1016/j.ymeth.2025.03.017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001857456&doi=10.1016%2fj.ymeth.2025.03.017&partnerID=40&md5=cb43b121f93cd98dc4ea4720410c6eec},
	affiliations = {Department of Computer Science, University of Tsukuba, Tsukuba, 3058577, Japan},
	abstract = {Multi-omics clustering has emerged as a powerful approach for understanding complex biological systems and enabling cancer subtyping by integrating diverse omics data. Existing methods primarily focus on the integration of different types of omics data, often overlooking the value of clinical context. In this study, we propose a novel framework that incorporates clinical features extracted from large language model (LLM) to enhance multi-omics clustering. Leveraging clinical data extracted from pathology reports using a BERT-based model, our framework converts unstructured medical text into structured clinical features. These features are integrated with omics data through an autoencoder, enriching the information content of each omics layer to improve feature extraction. The extracted features are then projected into a latent subspace using singular value decomposition (SVD), followed by spectral clustering to obtain the final clustering result. We evaluate the proposed framework on six cancer datasets on three omics levels, comparing it with several state-of-the-art methods. The experimental results demonstrate that the proposed framework outperforms existing methods in multi-omics clustering for cancer subtyping. Moreover, the results highlight the efficacy of integrating clinical features derived from LLM, significantly enhancing clustering performance. This work underscores the importance of clinical context in multi-omics analysis and showcases the transformative potential of LLM in advancing precision medicine. © 2025 Elsevier Inc.},
	author_keywords = {Cancer subtyping; Large language model; Multi-omics clustering; Spectral clustering},
	keywords = {Article; autoencoder; bidirectional encoder representations from transformer model; cancer classification; clinical feature; clinical study; clustering algorithm; conceptual framework; data extraction; feature extraction; large language model; measurement accuracy; multiomics},
	correspondence_address = {X. Ye; Department of Computer Science, University of Tsukuba, Tsukuba, 3058577, Japan; email: yexiucai@cs.tsukuba.ac.jp},
	publisher = {Academic Press Inc.},
	issn = {10462023},
	coden = {MTHDE},
	language = {English},
	abbrev_source_title = {Methods},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Oğul2025,
	author = {Oğul, İskender Ülgen and Soygazi, Fatih and Bostanoğlu, Belgin Ergenç},
	title = {TurkMedNLI: a Turkish medical natural language inference dataset through large language model based translation},
	year = {2025},
	journal = {PeerJ Computer Science},
	volume = {11},
	doi = {10.7717/PEERJ-CS.2662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219134639&doi=10.7717%2fPEERJ-CS.2662&partnerID=40&md5=f61ce6158ebb8468d6992db53134e674},
	affiliations = {Computer Engineering, Izmir Institute of Technology, İzmir, Turkey; Computer Engineering, Adnan Menderes University, Aydın, Turkey},
	abstract = {Natural language inference (NLI) is a subfield of natural language processing (NLP) that aims to identify the contextual relationship between premise and hypothesis sentences. While high-resource languages like English benefit from robust and rich NLI datasets, creating similar datasets for low-resource languages is challenging due to the cost and complexity of manual annotation. Although translation of existing datasets offers a practical solution, direct translation of domain-specific datasets presents unique challenges, particularly in handling abbreviations, metric conversions, and cultural alignment. This study introduces a pipeline for translating a medical NLI dataset into Turkish, which is a low-resource language. Our approach employs fine-tuning the Llama-3.1 model with selected samples from the Medical Abbreviation dataset (MeDAL) to extract and resolve medical abbreviations. Consequently, NLI pairs are refined with extracted abbreviations and subjected to metric correction. Later, the processed sentences are then translated using Facebook’s No Language Left Behind (NLLB) translation model. To ensure quality, we conducted comprehensive evaluations using both machine learning models and medical expert review. Our results show that BERTurk achieved 75.17% accuracy on TurkMedNLI test data and 76.30% on the normalized test set, while BioBERTurk demonstrated comparable performance with 75.59% accuracy on test data and 72.29% on the normalized dataset. Medical experts further validated the translations through manual assessment of sampled sentences. This work demonstrates the effectiveness of large language models in adapting domain-specific datasets for low-resource languages, establishing a foundation for future research in multilingual biomedical NLP. Copyright 2025 Oğul et al. Distributed under Creative Commons CC-BY 4.0},
	author_keywords = {BERT; Language translation; Llama; LLM; MedNLI; Natural language inference; Natural language processing; NLLB},
	keywords = {Computer aided language translation; Inference engines; Large datasets; Machine translation; Network security; BERT; Language inference; Language processing; Language translation; Llama; LLM; MedNLI; Natural language inference; Natural language processing; Natural languages; No language leave behind; Natural language processing systems},
	correspondence_address = {İ.Ü. Oğul; Computer Engineering, Izmir Institute of Technology, İzmir, Turkey; email: iskenderogul@iyte.edu.tr},
	publisher = {PeerJ Inc.},
	issn = {23765992},
	language = {English},
	abbrev_source_title = {PeerJ Comput. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Lin2025,
	author = {Lin, Ching-Sheng},
	title = {A hybrid model for the detection of multi-agent written news articles based on linguistic features and BERT},
	year = {2025},
	journal = {Journal of Supercomputing},
	volume = {81},
	number = {2},
	doi = {10.1007/s11227-024-06882-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217533837&doi=10.1007%2fs11227-024-06882-4&partnerID=40&md5=7bf37cf05541cb5b026e0c3d914bbfb8},
	affiliations = {Master Program of Digital Innovation, Tunghai University, Taichung City, 40704, Taiwan},
	abstract = {Large language models (LLMs) are central to AI systems and Excel in natural language processing tasks. They blur the line between human and machine-generated text and are widely used by professional writers across domains including news article generation. The challenge of detecting LLM-written articles introduces novel obstacles regarding misuse and the generation of fake content. In this work, we aim to recognize two kinds of LLM-written news where one type is entirely generated by LLMs and another is paraphrased based on existing news sources. We propose a neural network model that incorporates linguistic features and BERT contextual embedding features for LLM-written news article detection. In conjunction with the proposed model, we also produce a news article corpus based on the BBC dataset to generate and paraphrase news articles through multi-agent cooperation using ChatGPT. Our model obtains 96.57% accuracy and 96.44% F1macro score, respectively, outperforming other existing models and indicating the capability of helping readers to identify LLM-written news articles. To assess the model’s robustness, we also construct another corpus based on the BBC dataset using a different language model, Claude, and demonstrate that our detection model achieves strong results. Furthermore, we apply our model to text generation detection in the medical domain, where it also delivers promising performance. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.},
	author_keywords = {BERT; ChatGPT; Large language models; Linguistic features; LLM-written news; Machine-generated text; Multi-agent cooperation},
	keywords = {Chatbots; Linguistics; Natural language processing systems; Neural networks; BERT; ChatGPT; Language model; Large language model; Large language model-written news; Linguistic features; Machine-generated texts; Multi agent cooperation; News articles; Multi agent systems},
	correspondence_address = {C.-S. Lin; Master Program of Digital Innovation, Tunghai University, Taichung City, 40704, Taiwan; email: cslin612@thu.edu.tw},
	publisher = {Springer},
	issn = {09208542},
	coden = {JOSUE},
	language = {English},
	abbrev_source_title = {J Supercomput},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Feng2025e013023,
	author = {Feng, Ruibin and Brennan, Kelly A. and Azizi, Zahra and Goyal, Jatin and Deb, Brototo and Chang, Hui Ju and Ganesan, Prasanth and Clopton, Paul and Pedron, Maxime and Ruipérez-Campillo, Samuel and Desai, Yaanik B. and De Larochellière, Hugo and Baykaner, Tina and Perez, Marco V. and Rodrigo, Miguel and Rogers, Albert J. and Narayan, Sanjiv M.},
	title = {Engineering of Generative Artificial Intelligence and Natural Language Processing Models to Accurately Identify Arrhythmia Recurrence},
	year = {2025},
	journal = {Circulation: Arrhythmia and Electrophysiology},
	volume = {18},
	number = {1},
	pages = {e013023},
	doi = {10.1161/CIRCEP.124.013023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212756156&doi=10.1161%2fCIRCEP.124.013023&partnerID=40&md5=a4989f4e98865486716ec79acbca4d7a},
	affiliations = {Department of Medicine, Stanford University, CA, United States; School of Information, University of California, Berkeley, CA, United States; Department of Computer Science, ETH Zurich, Switzerland; CoMMLab, Universitat Politècnica de València, Spain},
	abstract = {BACKGROUND: Large language models (LLMs) such as Chat Generative Pre-trained Transformer (ChatGPT) excel at interpreting unstructured data from public sources, yet are limited when responding to queries on private repositories, such as electronic health records (EHRs). We hypothesized that prompt engineering could enhance the accuracy of LLMs for interpreting EHR data without requiring domain knowledge, thus expanding their utility for patients and personalized diagnostics. METHODS: We designed and systematically tested prompt engineering techniques to improve the ability of LLMs to interpret EHRs for nuanced diagnostic questions, referenced to a panel of medical experts. In 490 full-text EHR notes from 125 patients with prior life-threatening heart rhythm disorders, we asked GPT-4-turbo to identify recurrent arrhythmias distinct from prior events and tested 220 563 queries. To provide context, results were compared with rule-based natural language processing and Bidirectional Encoder Representations from Transformer-based language models. Experiments were repeated for 2 additional LLMs. RESULTS: In an independent hold-out set of 389 notes, GPT-4-turbo had a balanced accuracy of 64.3%±4.7% out-of-the-box at baseline. This increased when asking GPT-4-turbo to provide a rationale for its answers, a structured data output, and in-context exemplars, to a balanced accuracy of 91.4%±3.8% (P<0.05). This surpassed the traditional logic-based natural language processing and BERT-based models (P<0.05). Results were consistent for GPT-3.5-turbo and Jurassic-2 LLMs. CONCLUSIONS: The use of prompt engineering strategies enables LLMs to identify clinical end points from EHRs with an accuracy that surpassed natural language processing and approximated experts, yet without the need for expert knowledge. These approaches could be applied to LLM queries for other domains, to facilitate automated analysis of nuanced data sets with high accuracy by nonexperts. © 2024 American Heart Association, Inc.},
	author_keywords = {artificial intelligence; clinical decision support; electronic health records; natural language processing; ventricular tachycardia},
	keywords = {Arrhythmias, Cardiac; Artificial Intelligence; Data Mining; Electronic Health Records; Female; Humans; Male; Natural Language Processing; Predictive Value of Tests; Recurrence; Reproducibility of Results; creatinine; accuracy; adult; Article; artificial neural network; atrial fibrillation; cardiomyopathy; classification algorithm; cohort analysis; congestive heart failure; controlled study; diagnostic test accuracy study; electronic health record; female; follow up; generative artificial intelligence; heart arrhythmia; human; hyperlipidemia; hypertension; hypertrophic cardiomyopathy; intensive care unit; ischemic cardiomyopathy; language processing; learning algorithm; machine learning; major clinical study; male; measurement accuracy; middle aged; natural language processing; artificial intelligence; data mining; diagnosis; electronic health record; pathophysiology; predictive value; procedures; recurrent disease; reproducibility; therapy},
	correspondence_address = {S.M. Narayan; Department of Medicine, Stanford University, Palo Alto, 453 Quarry Rd, 94304, United States; email: sanjiv1@stanford.edu},
	publisher = {Lippincott Williams and Wilkins},
	issn = {19413149},
	pmid = {39676642},
	language = {English},
	abbrev_source_title = {Circ. Arrhythmia Electrophysiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bhatnagar202517,
	author = {Bhatnagar, Mohit},
	title = {Enhancing Career Guidance Through Intent Mining with Large Language Models},
	year = {2025},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {228},
	pages = {17 – 33},
	doi = {10.1007/978-981-97-9255-9_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215070927&doi=10.1007%2f978-981-97-9255-9_2&partnerID=40&md5=20653641e63c8ebc56d0d0b7222dc038},
	affiliations = {Jindal Global Business School, OP Jindal Global University, Sonipat, India},
	abstract = {This study uses Large Language Models (LLMs) for extracting intents within the field of career guidance. Collating discussions from a popular social media platform, BERTopic, a state-of-the-art topic modeling technique leveraging Bidirectional Encoder Representations from Transformers (BERT) embeddings is employed to extract key career-related themes. Our analysis evaluates BERTopic's proficiency, particularly its integration with LLMs, to refine topic modeling and automate the intent extraction process. A central focus lies on the application of Generative AI for automatic topic labeling, contrasting the performance of proprietary models like OpenAI's GPT-3.5 with open-source models such as Llama-2. Subsequently, the study uses these mined intents to fine-tune a BERT based LLM, scrutinizing its efficacy in intent classification against a Random Forest baseline model. The BERT model demonstrates a remarkable improvement in multi-classification accuracy of 0.92. Our results underscore the profound and emerging capabilities of LLMs to integrate in task based chatbots that can offer nuanced, tailored career guidance, heralding potentially a new era of AI-enabled educational support. To ensure the reproducibility of our results and foster further research, the dataset and code is publicly made available. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {BERTopic; Career Guidance; Intent Mining; Large Language Models; Natural Language Processing},
	keywords = {Classification (of information); Data mining; Information retrieval; Bertopic; Career guidance; Intent mining; Language model; Language processing; Large language model; Natural language processing; Natural languages; Social media platforms; Topic Modeling; Natural language processing systems},
	correspondence_address = {M. Bhatnagar; Jindal Global Business School, OP Jindal Global University, Sonipat, India; email: mohit.bhatnagar@jgu.edu.in},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23674512},
	language = {English},
	abbrev_source_title = {Lecture. Notes. Data Eng. Commun. Tech.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tsuchida2025242,
	author = {Tsuchida, Takuma and Miyata, Rikuho and Washizaki, Hironori and Sumoto, Kensuke and Yoshioka, Nobukazu and Fukazawa, Yoshiaki},
	title = {Identifying Relationships between Attack Patterns using Large Language Models},
	year = {2025},
	journal = {IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences},
	volume = {E108.A},
	number = {3},
	pages = {242 – 253},
	doi = {10.1587/transfun.2024CIP0005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000139720&doi=10.1587%2ftransfun.2024CIP0005&partnerID=40&md5=f6e1f86a82c571b7d7c593c09bd30d58},
	affiliations = {Waseda University, Tokyo, 169-8555, Japan},
	abstract = {The Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK) and Common Attack Pattern Enumeration and Classification (CAPEC) frameworks are essential knowledge bases that catalog traditional attack patterns and their interrelationships (e.g., abstract–concrete relationships). In addition, a knowledge base named Adversarial Threat Landscape for Artificial-Intelligence Systems (ATLAS) focuses on artificial intelligence (AI)/machine learning (ML)-related attack patterns. Newly discovered attack patterns are incorporated into these knowledge bases manually, potentially leading to missed relationships or delayed information updates. This study introduces a methodology that uses large language models (LLMs) to identify abstract–concrete relationships between attack patterns, aiding in rapid classification and in the rapid development of a defensive strategy. We trained BERT, GPT, and SVM models on ATT&CK, CAPEC, and their combined datasets for relation classification among attack patterns. The evaluation results show that the fine-tuned GPT-3.5 model outperformed the other investigated models, showing potential applicability even to AI/ML-related attack patterns and emphasizing the importance of using training data in the same format as test data. This study also finds that GPT-3.5 effectively focuses on critical descriptive terms, bolstering its performance. The proposed methodology is effective in discerning attack-pattern relationships, demonstrating its potential applicability in the AI security domain. Copyright © 2025 The Institute of Electronics, Information and Communication Engineers.},
	author_keywords = {attack pattern; BERT; GPT; LLM; relation classification},
	keywords = {Abstracting; Classification (of information); Modeling languages; Artificial intelligence systems; Attack patterns; BERT; Classification framework; Common knowledge; GPT; Language model; Large language model; Machine-learning; Relation classifications; Adversarial machine learning},
	publisher = {Institute of Electronics Information Communication Engineers},
	issn = {09168508},
	coden = {IFESE},
	language = {English},
	abbrev_source_title = {IEICE Trans Fund Electron Commun Comput Sci},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2025,
	title = {International Conference on Mechatronics and Intelligent Control, ICMIC 2024},
	year = {2025},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13447},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216097654&partnerID=40&md5=276376eefb35fd4f2b309d2ea0077fe0},
	abstract = {The proceedings contain 182 papers. The topics discussed include: ASTGNN: adaptive spatio-temporal graph neural network for motor imagery recognition; research on the key technology of high-precision electron probe in the detection of mineral composition; investigation of a novel approach to facial emotion detection using an attention-enhanced residual network; research on false propaganda detection technology based on LLM and BERT; threat target image detection method based on two-stage R-CNN network; low-light underwater image enhancement method based on brightness estimation; target detection method based on event-time surface feature fusion network; and a study on rapid recognition of ripe tomato fruits in complex environment based on YOLOv5s.},
	editor = {Zhang K. and Lorenz P.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151068683-0},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Aali2025470,
	author = {Aali, Asad and Van Veen, Dave and Arefeen, Yamin Ishraq and Hom, Jason and Bluethgen, Christian and Reis, Eduardo Pontes and Gatidis, Sergios and Clifford, Namuun and Daws, Joseph and Tehrani, Arash S. and Kim, Jangwon and Chaudhari, Akshay S.},
	title = {A dataset and benchmark for hospital course summarization with adapted large language models},
	year = {2025},
	journal = {Journal of the American Medical Informatics Association},
	volume = {32},
	number = {3},
	pages = {470 – 479},
	doi = {10.1093/jamia/ocae312},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218787552&doi=10.1093%2fjamia%2focae312&partnerID=40&md5=9a9726163feaa2da4da3f9a377776fe9},
	affiliations = {Department of Radiology, Stanford University, Stanford, 94304, CA, United States; Department of Electrical and Computer Engineering, The University of Texas at Austin, Austin, 78712, TX, United States; Center for Artificial Intelligence in Medicine and Imaging, Stanford University, Palo Alto, 94304, CA, United States; Department of Electrical Engineering, Stanford University, Stanford, 94304, CA, United States; Department of Medicine, Stanford University, Stanford, 94304, CA, United States; University Hospital Zurich, Zurich, 8091, Switzerland; Albert Einstein Israelite Hospital, São Paulo, 05652-900, Brazil; School of Nursing, The University of Texas at Austin, Austin, 78712, TX, United States; One Medical, San Francisco, 94111, CA, United States; Amazon, Seattle, 98109, WA, United States; Department of Biomedical Data Science, Stanford University, Stanford, 94304, CA, United States},
	abstract = {Objective: Brief hospital course (BHC) summaries are clinical documents that summarize a patient's hospital stay. While large language models (LLMs) depict remarkable capabilities in automating real-world tasks, their capabilities for healthcare applications such as synthesizing BHCs from clinical notes have not been shown. We introduce a novel preprocessed dataset, the MIMIC-IV-BHC, encapsulating clinical note and BHC pairs to adapt LLMs for BHC synthesis. Furthermore, we introduce a benchmark of the summarization performance of 2 general-purpose LLMs and 3 healthcare-adapted LLMs. Materials and Methods: Using clinical notes as input, we apply prompting-based (using in-context learning) and fine-tuning-based adaptation strategies to 3 open-source LLMs (Clinical-T5-Large, Llama2-13B, and FLAN-UL2) and 2 proprietary LLMs (Generative Pre-trained Transformer [GPT]-3.5 and GPT-4). We evaluate these LLMs across multiple context-length inputs using natural language similarity metrics. We further conduct a clinical study with 5 clinicians, comparing clinician-written and LLM-generated BHCs across 30 samples, focusing on their potential to enhance clinical decision-making through improved summary quality. We compare reader preferences for the original and LLM-generated summary using Wilcoxon signed-rank tests. We further request optional qualitative feedback from clinicians to gain deeper insights into their preferences, and we present the frequency of common themes arising from these comments. Results: The Llama2-13B fine-tuned LLM outperforms other domain-adapted models given quantitative evaluation metrics of Bilingual Evaluation Understudy (BLEU) and Bidirectional Encoder Representations from Transformers (BERT)-Score. GPT-4 with in-context learning shows more robustness to increasing context lengths of clinical note inputs than fine-tuned Llama2-13B. Despite comparable quantitative metrics, the reader study depicts a significant preference for summaries generated by GPT-4 with in-context learning compared to both Llama2-13B fine-tuned summaries and the original summaries (P<.001), highlighting the need for qualitative clinical evaluation. Discussion and Conclusion: We release a foundational clinically relevant dataset, the MIMIC-IV-BHC, and present an open-source benchmark of LLM performance in BHC synthesis from clinical notes. We observe high-quality summarization performance for both in-context proprietary and fine-tuned open-source LLMs using both quantitative metrics and a qualitative clinical reader study. Our research effectively integrates elements from the data assimilation pipeline: our methods use (1) clinical data sources to integrate, (2) data translation, and (3) knowledge creation, while our evaluation strategy paves the way for (4) deployment.  © 2024 The Author(s).},
	author_keywords = {electronic health records; information storage and retrieval; machine learning; natural language processing},
	keywords = {Benchmarking; Datasets as Topic; Electronic Health Records; Humans; Length of Stay; Natural Language Processing; Article; benchmarking; ChatGPT; clinical decision making; clinical evaluation; context learning; controlled study; electronic health record; frequency; generative pretrained transformer; hospital discharge; hospitalization; human; information retrieval; large language model; machine learning; major clinical study; medical documentation; natural language processing; patient care; patient safety; qualitative analysis; quantitative analysis; electronic health record; information processing; length of stay; natural language processing},
	correspondence_address = {A. Aali; Department of Radiology, Stanford University, Palo Alto, 1701 Page Mill Rd, 94304, United States; email: asadaali@stanford.edu},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	pmid = {39786555},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Azim2025151,
	author = {Azim, Hazem Abdel and Waheed, Mohamed Tharwat and Mohammed, Ammar},
	title = {Large language models-based metric for generative question answering systems},
	year = {2025},
	journal = {IAES International Journal of Artificial Intelligence},
	volume = {14},
	number = {1},
	pages = {151 – 158},
	doi = {10.11591/ijai.v14.i1.pp151-158},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211239652&doi=10.11591%2fijai.v14.i1.pp151-158&partnerID=40&md5=9794d7c780ad0136f66b7672bc59d62d},
	affiliations = {School of Computing and Digital Technologies, ESLSCA Univeristy, Cairo, Egypt},
	abstract = {In the evolving landscape of text generation, which has advanced rapidly in recent years, techniques for evaluating the performance and quality of the generated text lag behind relatively. Traditionally, lexical-based metrics such as bilingual evaluation understudy (BLEU), recall-oriented understudy for gisting evaluation (ROUGE), metric for evaluation of translation with explicit ordering (METEOR), consensus-based image description evaluation (CIDER), and F1 have been utilized, primarily relying on n-gram similarity for evaluation. In recent years, neural and machine-learning-based metrics, like bidirectional encoder representations from transformers (BERT) score, key phrase question answering (KPQA), and BERT supervised training of learned evaluation metric for reading comprehension (LERC) have shown superior performance over traditional metrics but suffered from a lack of generalization towards different domains and requires massive human-labeled training data. The main contribution of the current research is to investigate the use of train-free large language models (LLMs) as scoring metrics, evaluators, and judges within a question-answering context, encompassing both closed and open-QA scenarios. To validate this idea, we employ a simple zero-shot prompting of Mixtral 8x7 B, a popular and widely used open-source LLM, to score a variety of datasets and domains. The experimental results on ten different benchmark datasets are compared against human judgments, revealing that, on average, simple LLM-based metrics outperformed sophisticated state-of-the-art statistical and neural machine-learning-based metrics by 2-8 points on answer-pairs scoring tasks and up to 15 points on contrastive preferential tasks. © 2025, Institute of Advanced Engineering and Science. All rights reserved.},
	author_keywords = {Evaluation metrics; Generative question answering; Large language models; Likert-scale scoring; Zero-shot prompting},
	correspondence_address = {H.A. Azim; School of Computing and Digital Technologies, ESLSCA Univeristy, Cairo, Egypt; email: hazem.abdelazim@eslsca.edu.eg},
	publisher = {Institute of Advanced Engineering and Science},
	issn = {20894872},
	language = {English},
	abbrev_source_title = {IAES Int. J. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Rodella2025247,
	author = {Rodella, Ilaria and Sciandra, Andrea and Tuzzi, Arjuna},
	title = {Textual Analysis of the Marie Skłodowska-Curie Actions Evaluation Summary Reports. Assessing Strengths and Weaknesses of Funded and Non-Funded Proposals},
	year = {2025},
	journal = {Italian Journal of Sociology of Education},
	volume = {17},
	number = {1},
	pages = {247 – 266},
	doi = {10.25430/pupj-IJSE-2025-1-12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004702141&doi=10.25430%2fpupj-IJSE-2025-1-12&partnerID=40&md5=e4bc528a7f7c0f88f16395048e8ec7d3},
	affiliations = {IInternational Research Office, University of Padova, Italy; Department of Philosophy, Sociology, Education and Applied Psychology & Department of Statistical Sciences, University of Padova, Italy; Department of Philosophy, Sociology, Education and Applied Psychology, University of Padova, Italy},
	abstract = {This study analyses Evaluation Summary Reports (ESRs) of Marie Skłodowska-Curie Actions (MSCA) Individual and Postdoctoral Fellowships proposals at the University of Padua (Unipd), spanning Horizon 2020 and Horizon Europe from 2015 to 2022. The aim is to identify recurring strengths and weaknesses in the evaluation process, recognizing the most important and recurrent features of successful proposals. The use of artificial intelligence is also discussed in the paper. Nearly 400 ESRs were analysed by employing keyword extraction and correspondence analysis (CA) to map relationships between words and variables such as project success. While CA did not clearly distinguish between successful and unsuccessful proposals, machine learning was applied. The coordinates from CA were used to predict project outcomes. Comparisons were made with models using only textual features and those employing transformers, specifically, BERT contextualised embeddings. Results showed that using a Large Language Model (LLM) for text representation improved prediction accuracy compared to other methods. However, it highlighted challenges in interpretability and emphasised the need for explicable methods in the absence of words. Overall, the study provides valuable insights for refining support services and training at Unipd, highlighting the effectiveness of LLMs in prediction while acknowledging the interpretive challenges associated with their use. © 2025, Padova University Press. All rights reserved.},
	author_keywords = {evaluation; large language models; Marie Skłodowska-Curie Actions; text classification},
	publisher = {Padova University Press},
	issn = {20354983},
	language = {English},
	abbrev_source_title = {Ital. J. Sociol. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Loevenich2025,
	author = {Loevenich, Johannes and Adler, Erik and Hürten, Tobias and Lopes, Roberto Rigolin F.},
	title = {Design and evaluation of an Autonomous Cyber Defence agent using DRL and an augmented LLM},
	year = {2025},
	journal = {Computer Networks},
	volume = {262},
	doi = {10.1016/j.comnet.2025.111162},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000141585&doi=10.1016%2fj.comnet.2025.111162&partnerID=40&md5=4458aa65c961a6dde15490b6f9f98474},
	affiliations = {Secure Communications & Information (SIX), Thales Deutschland GmbH, Thalesplatz 1, BW, Ditzingen, 71254, Germany; Department of Mathematics/Computer Science, University of Osnabrück, Neuer Graben 29, NI, Osnabrück, 49074, Germany; Department of Informatics, Karlsruhe Institute of Technology (KIT), Kaiserstraße 12, BW, Karlsruhe, 76131, Germany; Department of Computer Science IV, University of Bonn, Regina-Pacis-Weg 3, NW, Bonn, 53113, Germany},
	abstract = {In this paper, we design and evaluate an Autonomous Cyber Defence (ACD) agent to monitor and act within critical network segments connected to untrusted infrastructure hosting active adversaries. We assume that modern network segments use software-defined controllers with the means to host ACD agents and other cybersecurity tools that implement hybrid AI models. Our agent uses a hybrid AI architecture that integrates deep reinforcement learning (DRL), augmented Large Language Models (LLMs), and rule-based systems. This architecture can be implemented in software-defined network controllers, enabling automated defensive actions such as monitoring, analysis, decoy deployment, service removal, and recovery. A core contribution of our work is the construction of three cybersecurity knowledge graphs that organise and map data from network logs, open source Cyber Threat Intelligence (CTI) reports, and vulnerability frameworks. These graphs enable automatic mapping of Common Vulnerabilities and Exposures (CVEs) to offensive tactics and techniques defined in the MITRE ATT&CK framework using Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformer (GPT) models. Our experimental evaluation of the knowledge graphs shows that BERT-based models perform better, with precision (83.02%), recall (75.92%), and macro F1 scores (58.70%) significantly outperforming GPT models. The ACD agent was evaluated in a Cyber Operations Research (ACO) gym against eleven DRL models, including Proximal Policy Optimisation (PPO), Hierarchical PPO, and ensembles under two different attacker strategies. The results show that our ACD agent outperformed baseline implementations, with its DRL models effectively mitigating attacks and recovering compromised systems. In addition, we implemented and evaluated a chatbot using Retrieval-Augmented Generation (RAG) and a prompting agent augmented with the CTI reports represented in the cybersecurity knowledge graphs. The chatbot achieved high scores on generation metrics such as relevance (0.85), faithfulness (0.83), and semantic similarity (0.88), as well as retrieval metrics such as contextual precision (0.91). The experimental results suggest that the integration of hybrid AI systems with knowledge graphs can enable the automation and improve the precision of cyber defence operations, and also provide a robust interface for cybersecurity experts to interpret and respond to advanced cybersecurity threats. © 2025},
	author_keywords = {Autonomous Cyber Defence; Autonomous Cyber Operation Gym; Cybersecurity Knowledge Graph; Deep Reinforcement Learning; Hybrid AI Approach; Large Language Model; Performance Comparison; Proximal Policy Optimization; Retrieval-Augmented Generation},
	keywords = {Autonomous agents; Chatbots; Conformal mapping; Critical infrastructures; Cyber attacks; Decision trees; Deep learning; Deep reinforcement learning; Emotional intelligence; Fuzzy logic; Hierarchical systems; Open source software; Photomapping; Problem oriented languages; Reinforcement learning; Resource allocation; Autonomous cybe defense; Autonomous cybe operation gym; Cyber operations; Cyber security; Cyber-defense; Cybersecurity knowledge graph; Hybrid AI approach; Knowledge graphs; Language model; Large language model; Performance comparison; Policy optimization; Proximal policy optimization; Reinforcement learnings; Retrieval-augmented generation; Knowledge graph},
	correspondence_address = {J. Loevenich; Secure Communications & Information (SIX), Thales Deutschland GmbH, Ditzingen, Thalesplatz 1, BW, 71254, Germany; email: johannes.loevenich@thalesgroup.com},
	publisher = {Elsevier B.V.},
	issn = {13891286},
	coden = {CNETD},
	language = {English},
	abbrev_source_title = {Comput. Networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Roumeliotis20252769,
	author = {Roumeliotis, Konstantinos I. and Tselikas, Nikolaos D. and Nasiopoulos, Dimitrios K.},
	title = {Optimizing Airline Review Sentiment Analysis: A Comparative Analysis of LLaMA and BERT Models through Fine-Tuning and Few-Shot Learning},
	year = {2025},
	journal = {Computers, Materials and Continua},
	volume = {82},
	number = {2},
	pages = {2769 – 2792},
	doi = {10.32604/cmc.2025.059567},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218234340&doi=10.32604%2fcmc.2025.059567&partnerID=40&md5=462717dfc78e58393594ca42fb720d92},
	affiliations = {Department of Digital Systems, University of Peloponnese, Sparta, 23100, Greece; Department of Informatics and Telecommunications, University of Peloponnese, Tripoli, 22131, Greece; Department of Agribusiness and Supply Chain Management, School of Applied Economics and Social Sciences, Agricultural University of Athens, Athens, 11855, Greece},
	abstract = {In the rapidly evolving landscape of natural language processing (NLP) and sentiment analysis, improving the accuracy and efficiency of sentiment classification models is crucial. This paper investigates the performance of two advanced models, the Large Language Model (LLM) LLaMA model and NLP BERT model, in the context of airline review sentiment analysis. Through fine-tuning, domain adaptation, and the application of few-shot learning, the study addresses the subtleties of sentiment expressions in airline-related text data. Employing predictive modeling and comparative analysis, the research evaluates the effectiveness of Large Language Model Meta AI (LLaMA) and Bidirectional Encoder Representations from Transformers (BERT) in capturing sentiment intricacies. Fine-tuning, including domain adaptation, enhances the models’ performance in sentiment classification tasks. Additionally, the study explores the potential of few-shot learning to improve model generalization using minimal annotated data for targeted sentiment analysis. By conducting experiments on a diverse airline review dataset, the research quantifies the impact of fine-tuning, domain adaptation, and few-shot learning on model performance, providing valuable insights for industries aiming to predict recommendations and enhance customer satisfaction through a deeper understanding of sentiment in user-generated content (UGC). This research contributes to refining sentiment analysis models, ultimately fostering improved customer satisfaction in the airline industry. Copyright © 2025 The Authors.},
	author_keywords = {airline reviews; BERT model; customer satisfaction; domain adaptation; fine-tuning; LLaMA model; LLM classification; review sentiment analysis; Sentiment classification; user-generated content},
	keywords = {Air transportation; Contrastive Learning; Control towers; Customer satisfaction; Natural language processing systems; Reviews; Zero-shot learning; Airline review; Bidirectional encoder representation from transformer model; Customers' satisfaction; Domain adaptation; Fine tuning; Language model; Large language model classification; Large language model meta AI model; Model classification; Review sentiment analyze; Sentiment analysis; Sentiment classification; Transformer modeling; User-generated; User-generated content; Sales},
	correspondence_address = {K.I. Roumeliotis; Department of Digital Systems, University of Peloponnese, Sparta, 23100, Greece; email: k.roumeliotis@uop.gr},
	publisher = {Tech Science Press},
	issn = {15462218},
	language = {English},
	abbrev_source_title = {Comput. Mater. Continua},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Alhijawi202591,
	author = {Alhijawi, Bushra and Jarrar, Rawan and AbuAlRub, Aseel and Bader, Arwa},
	title = {Deep learning detection method for large language models-generated scientific content},
	year = {2025},
	journal = {Neural Computing and Applications},
	volume = {37},
	number = {1},
	pages = {91 – 104},
	doi = {10.1007/s00521-024-10538-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195023926&doi=10.1007%2fs00521-024-10538-y&partnerID=40&md5=55be3423e17d3927a5bb4281586a73c9},
	affiliations = {Princess Sumaya University for Technology, Amman, Jordan},
	abstract = {Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual content is written and communicated. These models can generate indistinguishable scientific content from human-authored work, raising concerns within the scientific community. Mitigating the risk of LLM-facilitated research fabrication and disseminating falsified data and results requires robust safeguards to maintain the integrity of scientific publications. This research paper presents a novel ChatGPT-generated scientific text detection method, AI-Catcher. AI-Catcher integrates two deep learning models, multilayer perceptron (MLP) and convolutional neural networks (CNN). The MLP learns the feature representations of the linguistic and statistical features. The CNN extracts high-level representations of the sequential patterns from the textual content. The proposed model fuses hidden patterns derived from MLP and CNN. AI-Catcher is a multimodal model trained using linguistic and statistical features and textual content. In addition, a new ChatGPT-Generated scientific text dataset, AIGTxt, has been collected to enhance AI-generated text detection tools. AIGTxt contains 3000 records collected from published academic articles across ten domains and divided into three classes: Human-written, ChatGPT-generated, and Mixed text. Several experiments are conducted to evaluate the performance of AI-Catcher. The comparative results demonstrate the capability of AI-Catcher to distinguish between human-written and ChatGPT-generated scientific text more accurately than alternative methods. On average, AI-Catcher improved accuracy by 37.4%. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.},
	author_keywords = {Academic plagiarism detection; ChatGPT; Deep learning; Large language models; Research fabrication},
	keywords = {Deep learning; Multilayer neural networks; Academic plagiarism detection; ChatGPT; Deep learning; Language model; Large language model; Multilayers perceptrons; Plagiarism detection; Research fabrication; Scientific texts; Textual content; Convolutional neural networks},
	correspondence_address = {B. Alhijawi; Princess Sumaya University for Technology, Amman, Jordan; email: b.alhijawi@psut.edu.jo},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09410643},
	language = {English},
	abbrev_source_title = {Neural Comput. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Cheng2025,
	author = {Cheng, Haitao and Gong, Zibin and Wang, Chang},
	title = {LLM-TFP: Integrating large language models with spatio-temporal features for urban traffic flow prediction},
	year = {2025},
	journal = {Applied Soft Computing},
	volume = {177},
	doi = {10.1016/j.asoc.2025.113174},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004040651&doi=10.1016%2fj.asoc.2025.113174&partnerID=40&md5=bbda5cf0c3133c7a04f93a81afac0fe6},
	affiliations = {School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China},
	abstract = {Accurate urban traffic flow prediction is essential for intelligent transportation systems, playing a significant role in urban traffic management, congestion mitigation, and public transit optimization. While deep learning techniques have shown considerable success in capturing the spatio-temporal dynamics of traffic flow data, their heavy reliance on large volumes of labeled data limits their effectiveness in scenarios with limited data availability. Large language models (LLMs), however, have demonstrated a remarkable ability to capture intricate spatio-temporal patterns in time series analysis, offering a promising alternative for urban traffic flow prediction. Therefore, we propose an urban traffic flow prediction framework that integrates large language models with spatio-temporal features (LLM-TFP). Our approach includes a spatio-temporal tokenizer that converts raw traffic flow data into LLM-compatible tokens by utilizing timestep, time-of-day, and spatial embeddings, capturing the essential spatio-temporal features of the data. Furthermore, we develop a spatio-temporal adapter that links these tokens with a pre-trained BERT model, selectively freezing and fine-tuning certain parameters to retain the model's language processing strengths. Experiments on the two real-world datasets have demonstrated that LLM-TFP surpasses 13 benchmark models in prediction accuracy and exhibits strong generalization capabilities in few-shot and zero-shot tasks. © 2025 Elsevier B.V.},
	author_keywords = {Large language models; Spatio-temporal features; Urban traffic flow prediction; Zero-shot learning},
	keywords = {Air traffic control; Deep learning; Highway traffic control; Mass transportation; Street traffic control; Traffic congestion; Flow data; Intelligent transportation systems; Language model; Large language model; Spatio-temporal; Spatiotemporal feature; Traffic flow; Traffic flow prediction; Urban traffic flow; Urban traffic flow prediction; Urban transportation},
	correspondence_address = {H. Cheng; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; email: chenghaitao@njupt.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {15684946},
	language = {English},
	abbrev_source_title = {Appl. Soft Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2025,
	author = {Chen, Weisi and Liu, Wulong and Zheng, Jiaxin and Zhang, Xu},
	title = {Leveraging large language model as news sentiment predictor in stock markets: a knowledge-enhanced strategy},
	year = {2025},
	journal = {Discover Computing},
	volume = {28},
	number = {1},
	doi = {10.1007/s10791-025-09573-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005003252&doi=10.1007%2fs10791-025-09573-7&partnerID=40&md5=fc2b4f1276f88ae5f172862216819cdc},
	affiliations = {School of Software Engineering, Xiamen University of Technology, 600 Ligong Road, Houxi County, Jimei District, Fujian, Xiamen, China; School of Computer and Information Engineering, Xiamen University of Technology, 600 Ligong Road, Houxi County, Jimei District, Fujian, Xiamen, China},
	abstract = {In the fast-evolving artificial intelligence era, the intersection of natural language processing and financial analysis has attracted significant attention, primarily due to its potential to provide valuable insights into financial market behavior. Sentiment analysis of financial news articles is a crucial aspect of this intersection, providing cues about market sentiment that may affect stock price dynamics. Traditional sentiment analysis methods often rely on rules or machine learning algorithms trained on labeled datasets, but these methods face challenges in capturing the context within the text. This paper proposes a framework that incorporates prompt engineering strategies, including a novel Domain Knowledge Chain-of-Thought (DK-CoT) strategy, integrating domain-specific financial knowledge with chain-of-thought reasoning, designed to leverage and enhance the performance of large language models (LLMs) in financial news sentiment analysis. DK-CoT has been compared with various prompt engineering techniques, including zero-shot, few-shot, and chain-of-thought, as well as other benchmark models like BERT and RoBERTa. Through comprehensive experiments and evaluations, we introduce the weighted F1 score as a more practical metric, emphasizing the disproportionate impact of negative news on financial markets, which better reflects real-world financial dynamics, as negative sentiments often lead to more significant market reactions than positive or neutral sentiments. Experimental results have shown that DK-CoT adopted in an LLM called GLM is effective in improving the performance and reliability of financial news sentiment analysis. Our findings provide insights into optimal prompt designs and highlight the importance of incorporating financial knowledge to uplift LLM performance while reducing the need for extensive computational resources and fine-tuning. © The Author(s) 2025.},
	author_keywords = {Accessible machine learning; Financial news; Large language model; Natural language processing; Prompt engineering; Sentiment analysis},
	correspondence_address = {W. Chen; School of Software Engineering, Xiamen University of Technology, Xiamen, 600 Ligong Road, Houxi County, Jimei District, Fujian, China; email: chenweisi@xmut.edu.cn},
	publisher = {Springer Science and Business Media B.V.},
	issn = {29482992},
	language = {English},
	abbrev_source_title = {Discov. Comput},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zou2025143,
	author = {Zou, Xinhao and Markov, Konstantin},
	title = {Combining Graph NN and LLM for Improved Text-Based Emotion Recognition},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15462 LNAI},
	pages = {143 – 154},
	doi = {10.1007/978-3-031-81542-3_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218487383&doi=10.1007%2f978-3-031-81542-3_12&partnerID=40&md5=c4457d8a36f5c31d79769e0faaeacda3},
	affiliations = {The University of Aizu, Fukushima, 965-8580, Japan},
	abstract = {Text-based emotion analysis, an important task in Natural Language Processing (NLP), aims to identify and understand emotional tendencies in text. Recently, given their strong performance in text classification, Graph Neural Networks (GNNs) have been utilized in various emotion recognition studies. They have excellent structural modeling abilities but lack context encoding strength. On the other hand, Large Language Models (LLMs) such as BERT and GPT are specially designed to model the text context. Aiming to utilize both their advantages, we investigated several ways to combine GNNs with LLMs for the emotion recognition task. First, we used BERT to generate embeddings for the graph document nodes. Next, we extended the system to include a description of the input data’s emotional content obtained from GPT as an additional node embedding. For experiments and system evaluation, we used the GoEmotions dataset. The results clearly show that combining GNN and LLM improves the emotion classification performance by 20% to 30% compared to when either GNN or LLM is used alone. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Emotion analysis and recognition; Graph Neural Network; Large Language Model},
	keywords = {Emotion Recognition; Graph embeddings; Neural network models; Embeddings; Emotion analysis; Emotion recognition; Graph neural networks; Language model; Language processing; Large language model; Natural languages; Performance; Text classification; Graph neural networks},
	correspondence_address = {K. Markov; The University of Aizu, Fukushima, 965-8580, Japan; email: markov@u-aizu.ac.jp},
	editor = {Koprinkova-Hristova P. and Kasabov N. and Kasabov N.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303181541-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sanz-Guerrero2025220,
	author = {Sanz-Guerrero, Mario and Arroyo, Javier},
	title = {Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending},
	year = {2025},
	journal = {Inteligencia Artificial},
	volume = {28},
	number = {75},
	pages = {220 – 248},
	doi = {10.4114/intartif.vol28iss75pp220-248},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000754535&doi=10.4114%2fintartif.vol28iss75pp220-248&partnerID=40&md5=337fbd6781eb7f9aae986261efaa7905},
	affiliations = {Facultad de Informática, Universidad Complutense de Madrid, Spain; Johannes Gutenberg University Mainz, Germany; Instituto de Tecnología del Conocimiento, Universidad Complutense de Madrid, Spain; Departamento de Ciencias de la Computación, Universidad de Alcalá de Henares, Spain},
	abstract = {Peer-to-peer (P2P) lending connects borrowers and lenders through online platforms but suffers from significant information asymmetry, as lenders often lack sufficient data to assess borrowers’ creditworthiness. This paper addresses this challenge by leveraging BERT, a Large Language Model (LLM) known for its ability to capture contextual nuances in text, to generate a risk score based on borrowers’ loan descriptions using a dataset from the Lending Club platform. We fine-tune BERT to distinguish between defaulted and non-defaulted loans using the loan descriptions provided by the borrowers. The resulting BERT-generated risk score is then integrated as an additional feature into an XGBoost classifier used at the loan granting stage, where decision-makers have limited information available to guide their decisions. This integration enhances predictive performance, with improvements in balanced accuracy and AUC, highlighting the value of textual features in complementing traditional inputs. Moreover, we find that the incorporation of the BERT score alters how classification models utilize traditional input variables, with these changes varying by loan purpose. These findings suggest that BERT discerns meaningful patterns in loan descriptions, encompassing borrower-specific features, specific purposes, and linguistic characteristics. However, the inherent opacity of LLMs and their potential biases underscore the need for transparent frameworks to ensure regulatory compliance and foster trust. Overall, this study demonstrates how LLM-derived insights interact with traditional features in credit risk modeling, opening new avenues to enhance the explainability and fairness of these models. © IBERAMIA and the authors.},
	author_keywords = {BERT; Credit Risk; Explainable AI; Natural Language Processing; Peer-to-Peer Lending; Transfer Learning},
	keywords = {Finance; Natural language processing systems; BERT; Credit risks; Explainable AI; Language model; Language processing; Natural language processing; Natural languages; Peer-to-peer lending; Risk score; Transfer learning; Decision making},
	publisher = {Asociacion Espanola de Inteligencia Artificial},
	issn = {11373601},
	language = {English},
	abbrev_source_title = {Inteligencia Artif.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Wu2025182,
	author = {Wu, Hao and Yang, Danping and Liu, Peng and Li, Xianxian},
	title = {Chain of Thought Guided Few-Shot Fine-Tuning of LLMs for Multimodal Aspect-Based Sentiment Classification},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15520 LNCS},
	pages = {182 – 194},
	doi = {10.1007/978-981-96-2054-8_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216125571&doi=10.1007%2f978-981-96-2054-8_14&partnerID=40&md5=cfd5b182e9dece8e16f0e1b8ed17745c},
	affiliations = {Key Lab of Education Blockchain and Intelligent Technology, Ministry of Education, Guangxi Normal University, Guilin, 541004, China; School of Computer Science and Engineering, Guangxi Normal University, Guilin, 541004, China},
	abstract = {With the proliferation of multimodal information on social media, the task of multimodal aspect-based sentiment classification (MA-BSC) gained significant attention. However, existing methods for this task heavily relies on the large-scale supervised data, which is costly and time-consuming to obtain. Recent efforts have shifted towards few-shot MABSC, where small-scale pretained models (e.g. BERT, BART) are fine-tuned using a limited samples (1% of the training set). While large language models (LLMs) have shown strong zero-shot and few-shot capabilities across various NLP tasks, their exploration in few-shot MABSC remains insufficient. To address this gap, we propose a novel fine-tuning framework for LLMs in few-shot MABSC, incorporating three key modules: few-shot sampling, label-introduced Chain-of-Though (CoT) Generation and CoT enhanced fine-tuning. Specifically, we first construct a few-shot training set via selecting informative samples based on the LLM’s zero-shot capabilities. Moreover, we generate CoT reasoning through the LLM’s zero-shot reasoning to guide fine-tuning, enhancing both performance and interpretability. Extensive experiments on two benchmark datasets (Twitter-2015 and Twitter-2017) demonstrate the superiority of our approach. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Chain of Thought; Few-shot MABSC; Large Language Model},
	keywords = {Social networking (online); Zero-shot learning; Chain of thought; Few-shot MABSC; Fine tuning; Language model; Large language model; Multi-modal; Multi-modal information; Sentiment classification; Social media; Training sets; Tweets},
	correspondence_address = {P. Liu; Key Lab of Education Blockchain and Intelligent Technology, Ministry of Education, Guangxi Normal University, Guilin, 541004, China; email: liupeng@gxnu.edu.cn},
	editor = {Ide I. and Kompatsiaris I. and Xu C. and Yanai K. and Chu W.-T. and Nitta N. and Riegler M. and Yamasaki T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981962053-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@ARTICLE{Catak2024,
	author = {Catak, Ferhat Ozgur and Kuzlu, Murat},
	title = {Uncertainty quantification in large language models through convex hull analysis},
	year = {2024},
	journal = {Discover Artificial Intelligence},
	volume = {4},
	number = {1},
	doi = {10.1007/s44163-024-00200-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210184332&doi=10.1007%2fs44163-024-00200-w&partnerID=40&md5=3b15fc1150036942ae68d6fa7facf68b},
	affiliations = {Department of Electrical Engineering and Computer Science, University of Stavanger, Rogaland, Norway; Department of Engineering Technology, Old Dominion University, Norfolk, VA, United States},
	abstract = {Uncertainty quantification approaches have been more critical in large language models (LLMs), particularly high-risk applications requiring reliable outputs. However, traditional methods for uncertainty quantification, such as probabilistic models and ensemble techniques, face challenges when applied to the complex and high-dimensional nature of LLM-generated outputs. This study proposes a novel geometric approach to uncertainty quantification using convex hull analysis. The proposed method leverages the spatial properties of response embeddings to measure the dispersion and variability of model outputs. The prompts are categorized into three types, i.e., ’easy’, ’moderate’, and ’confusing’, to generate multiple responses using different LLMs at varying temperature settings. The responses are transformed into high-dimensional embeddings via a BERT model and subsequently projected into a two-dimensional space using Principal Component Analysis (PCA), Isomap, Multidimensional Scaling (MDS). The Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm is utilized to cluster the embeddings and compute the convex hull for each selected cluster. The experimental results indicate that the uncertainty of the model for LLMs depends on the prompt complexity, the model, and the temperature setting. © The Author(s) 2024.},
	keywords = {Digital elevation model; Convex hull; Embeddings; High-dimensional; Higher-dimensional; Language model; Modelling techniques; Probabilistic ensemble; Probabilistic models; Temperature setting; Uncertainty quantifications; Embeddings},
	correspondence_address = {F.O. Catak; Department of Electrical Engineering and Computer Science, University of Stavanger, Rogaland, Norway; email: f.ozgur.catak@uis.no},
	publisher = {Springer Nature},
	issn = {27310809},
	language = {English},
	abbrev_source_title = {Discov. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Akinseloyin20241939,
	author = {Akinseloyin, Opeoluwa and Jiang, Xiaorui and Palade, Vasile},
	title = {A question-answering framework for automated abstract screening using large language models},
	year = {2024},
	journal = {Journal of the American Medical Informatics Association},
	volume = {31},
	number = {9},
	pages = {1939 – 1952},
	doi = {10.1093/jamia/ocae166},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201757646&doi=10.1093%2fjamia%2focae166&partnerID=40&md5=6caa9703ee34ec0cad7ffbfc196a68a1},
	affiliations = {Centre for Computational Science and Mathematical Modelling, Coventry University, Coventry, CV1 2TT, United Kingdom; Information School, The University of Sheffield, Sheffield, S10 2AH, United Kingdom},
	abstract = {Objective: This paper aims to address the challenges in abstract screening within systematic reviews (SR) by leveraging the zero-shot capabilities of large language models (LLMs). Methods: We employ LLM to prioritize candidate studies by aligning abstracts with the selection criteria outlined in an SR protocol. Abstract screening was transformed into a novel question-answering (QA) framework, treating each selection criterion as a question addressed by LLM. The framework involves breaking down the selection criteria into multiple questions, properly prompting LLM to answer each question, scoring and re-ranking each answer, and combining the responses to make nuanced inclusion or exclusion decisions. Results and Discussion: Large-scale validation was performed on the benchmark of CLEF eHealth 2019 Task 2: Technology-Assisted Reviews in Empirical Medicine. Focusing on GPT-3.5 as a case study, the proposed QA framework consistently exhibited a clear advantage over traditional information retrieval approaches and bespoke BERT-family models that were fine-tuned for prioritizing candidate studies (ie, from the BERT to PubMedBERT) across 31 datasets of 4 categories of SRs, underscoring their high potential in facilitating abstract screening. The experiments also showcased the viability of using selection criteria as a query for reference prioritization. The experiments also showcased the viability of the framework using different LLMs. Conclusion: Investigation justified the indispensable value of leveraging selection criteria to improve the performance of automated abstract screening. LLMs demonstrated proficiency in prioritizing candidate studies for abstract screening using the proposed QA framework. Significant performance improvements were obtained by re-ranking answers using the semantic alignment between abstracts and selection criteria. This further highlighted the pertinence of utilizing selection criteria to enhance abstract screening. © The Author(s) 2024.},
	author_keywords = {abstract screening; automated systematic review; large language model; question answering; zero-shot re-ranking},
	keywords = {abstract screening; Article; case study; clinical effectiveness; comparative study; controlled study; experiment; large language model; methodology; question answering framework; screening; systematic review (topic); technology; telehealth},
	correspondence_address = {X. Jiang; Information School, The University of Sheffield, Sheffield, The Wave,, 2 Whitham Rd, S10 2AH, United Kingdom; email: xiaorui.jiang@sheffield.ac.uk},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ohse2024,
	author = {Ohse, Julia and Hadžić, Bakir and Mohammed, Parvez and Peperkorn, Nicolina and Danner, Michael and Yorita, Akihiro and Kubota, Naoyuki and Rätsch, Matthias and Shiban, Youssef},
	title = {Zero-Shot Strike: Testing the generalisation capabilities of out-of-the-box LLM models for depression detection},
	year = {2024},
	journal = {Computer Speech and Language},
	volume = {88},
	doi = {10.1016/j.csl.2024.101663},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193683499&doi=10.1016%2fj.csl.2024.101663&partnerID=40&md5=b76980d1542621224eded770f4e9d7a7},
	affiliations = {Private University of Applied Sciences, Göttingen, Germany; Reutlingen University, Reutlingen, Germany; University of Surrey, Guilford, United Kingdom; Daiichi Institute of Technology, Kagoshima, Japan; Tokyo Metropolitan University, Tokyo, Japan},
	abstract = {Depression is a significant global health challenge. Still, many people suffering from depression remain undiagnosed. Furthermore, the assessment of depression can be subject to human bias. Natural Language Processing (NLP) models offer a promising solution. We investigated the potential of four NLP models (BERT, Llama2-13B, GPT-3.5, and GPT-4) for depression detection in clinical interviews. Participants (N = 82) underwent clinical interviews and completed a self-report depression questionnaire. NLP models inferred depression scores from interview transcripts. Questionnaire cut-off values for depression were used as a classifier for depression. GPT-4 showed the highest accuracy for depression classification (F1 score 0.73), while zero-shot GPT-3.5 initially performed with low accuracy (0.34), improved to 0.82 after fine-tuning, and achieved 0.68 with clustered data. GPT-4 estimates of symptom severity PHQ-8 score correlated strongly (r = 0.71) with true symptom severity. These findings demonstrate the potential of AI models for depression detection. However, further research is necessary before widespread deployment can be considered. © 2024 Elsevier Ltd},
	author_keywords = {Artificial intelligence; Depression detection; GPT-3.5; GPT-4; LLM; NLP},
	keywords = {Zero-shot learning; Clinical interview; Depression detection; Generalization capability; GPT-3.5; GPT-4; Language processing; LLM; Natural language processing; Natural languages; Processing model; Natural language processing systems},
	correspondence_address = {Y. Shiban; Private University of Applied Sciences, Göttingen, Germany; email: shiban@pfh.de},
	publisher = {Academic Press},
	issn = {08852308},
	coden = {CSPLE},
	language = {English},
	abbrev_source_title = {Comput Speech Lang},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Chajia2024,
	author = {Chajia, Meryem and Nfaoui, El Habib},
	title = {Customer Churn Prediction Approach Based on LLM Embeddings and Logistic Regression},
	year = {2024},
	journal = {Future Internet},
	volume = {16},
	number = {12},
	doi = {10.3390/fi16120453},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213083591&doi=10.3390%2ffi16120453&partnerID=40&md5=0a5ceab6fa772fceafd129feb835a3ac},
	affiliations = {LISAC Laboratory, Department of Computer Science, Faculty of Sciences Dhar El Mahraz, Sidi Mohamed Ben Abdellah University, Fez, 30000, Morocco},
	abstract = {Nowadays, predicting customer churn is essential for the success of any company. Loyal customers generate continuous revenue streams, resulting in long-term success and growth. Moreover, companies are increasingly prioritizing the retention of existing customers due to the higher costs associated with attracting new ones. Consequently, there has been a growing demand for advanced methods aimed at enhancing customer loyalty and satisfaction, as well as predicting churners. In our work, we focused on building a robust churn prediction model for the telecommunications industry based on large embeddings from large language models and logistic regression to accurately identify churners. We conducted extensive experiments using a range of embedding techniques, including OpenAI Text-embedding, Google Gemini Text Embedding, bidirectional encoder representations from transformers (BERT), Sentence-Transformers, Sent2vec, and Doc2vec, to extract meaningful features. Additionally, we tested various classifiers, including logistic regression, support vector machine, random forest, K-nearest neighbors, multilayer perceptron, naive Bayes, decision tree, and zero-shot classification, to build a robust model capable of making accurate predictions. The best-performing model in our experiments is the logistic regression classifier, which we trained using the extracted feature from the OpenAI Text-embedding-ada-002 model, achieving an accuracy of 89%. The proposed model demonstrates a high discriminative ability between churning and loyal customers. © 2024 by the authors.},
	author_keywords = {customer churn; customer churn prediction; embedding; LLMs; machine learning; openAI},
	keywords = {Ada (programming language); Customer satisfaction; Decision trees; Embeddings; Forestry; Logistic regression; Nearest neighbor search; Prediction models; Support vector regression; Customer churn prediction; Customer churns; Embeddings; Growing demand; High costs; LLM; Logistics regressions; Machine-learning; Openai; Revenue streams; Telecommunication industry},
	correspondence_address = {M. Chajia; LISAC Laboratory, Department of Computer Science, Faculty of Sciences Dhar El Mahraz, Sidi Mohamed Ben Abdellah University, Fez, 30000, Morocco; email: meryem.chajia@usmba.ac.ma},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {19995903},
	language = {English},
	abbrev_source_title = {Future Internet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Basaad 2024,
	author = {Basaad , Abdullah and Basurra , Shadi and Vakaj , Edlira and Eldaly , Ahmed Karam and Abdelsamea , Mohammed M.},
	title = {A BERT-GNN Approach for Metastatic Breast Cancer Prediction Using Histopathology Reports},
	year = {2024},
	journal = {Diagnostics},
	volume = {14},
	number = {13},
	doi = {10.3390/diagnostics14131365},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198366363&doi=10.3390%2fdiagnostics14131365&partnerID=40&md5=06a42a103b15712bbefd074c424bce9d},
	affiliations = {School of Computing and Digital Technology, Birmingham City University, Birmingham, B4 7XG, United Kingdom; Department of Computer Science, University of Exeter, North Park Road, Exeter, EX4 4QF, United Kingdom},
	abstract = {Metastatic breast cancer (MBC) continues to be a leading cause of cancer-related deaths among women. This work introduces an innovative non-invasive breast cancer classification model designed to improve the identification of cancer metastases. While this study marks the initial exploration into predicting MBC, additional investigations are essential to validate the occurrence of MBC. Our approach combines the strengths of large language models (LLMs), specifically the bidirectional encoder representations from transformers (BERT) model, with the powerful capabilities of graph neural networks (GNNs) to predict MBC patients based on their histopathology reports. This paper introduces a BERT-GNN approach for metastatic breast cancer prediction (BG-MBC) that integrates graph information derived from the BERT model. In this model, nodes are constructed from patient medical records, while BERT embeddings are employed to vectorise representations of the words in histopathology reports, thereby capturing semantic information crucial for classification by employing three distinct approaches (namely univariate selection, extra trees classifier for feature importance, and Shapley values to identify the features that have the most significant impact). Identifying the most crucial 30 features out of 676 generated as embeddings during model training, our model further enhances its predictive capabilities. The BG-MBC model achieves outstanding accuracy, with a detection rate of 0.98 and an area under curve (AUC) of 0.98, in identifying MBC patients. This remarkable performance is credited to the model’s utilisation of attention scores generated by the LLM from histopathology reports, effectively capturing pertinent features for classification. © 2024 by the authors.},
	author_keywords = {BERT; extra trees classifier; GNN; LLM; MBC; node classification; random forest classifier; univariate selection; XAI},
	keywords = {adult; area under the curve; Article; breast biopsy; cancer classification; cancer patient; cohort analysis; comparative study; controlled study; convolutional neural network; decision making; deep learning; evaluation study; feature extraction; feature selection; female; gene expression profiling; histopathology; human; large language model; lymph node; machine learning; major clinical study; male; medical record; metastatic breast cancer; natural language processing; nerve cell network; random forest; sample size; treatment outcome; tumor recurrence},
	correspondence_address = {M.M. Abdelsamea ; Department of Computer Science, University of Exeter, Exeter, North Park Road, EX4 4QF, United Kingdom; email: m.abdelsamea@exeter.ac.uk},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20754418},
	language = {English},
	abbrev_source_title = {Diagn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Hussain2024239,
	author = {Hussain, Zafar and Myllyaho, Lalli and Nurminen, Jukka K.},
	title = {Learning the Structure of Commands by Retraining a Language Model},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {239 – 244},
	doi = {10.1145/3674029.3674067},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204730431&doi=10.1145%2f3674029.3674067&partnerID=40&md5=df500dda8319c02ab0983753be70fbc7},
	affiliations = {University of Helsinki, Helsinki, Finland},
	abstract = {In the field of cybersecurity, learning the command-line commands' syntax holds paramount importance in distinguishing valid and malicious commands. To learn the syntax of command-line commands, we curated an extensive dataset of Windows 10 command-line commands, developed a specialized vocabulary, and trained a custom tokenizer equipped with a masked language model head. Comparative analyses against traditional methods, including a second-order Markov Model and a Regular Expression-based system, unequivocally demonstrated the language model's superior proficiency. Employing clustering algorithms like DBSCAN, HDBSCAN, and OPTICS allowed us to categorize command-line commands based on their syntactical similarities, revealing the model's excellence in understanding sequences and detecting syntax with minimal noise. Manual analyses of command syntax, complemented by BERTScore assessments, consistently yielded metrics exceeding 0.90 for precision, recall, and F1-score. These robust results affirm the model's high accuracy and effectiveness in learning command syntax. In conclusion, our language model not only helps in enhancing protective measures against malicious activities but also showcases adaptability to the ever-evolving nature of command-line commands' syntax. © 2024 Owner/Author.},
	author_keywords = {BERT; Command Syntax; Commands; language model; LLM; Markov; Regular Expressions},
	keywords = {Syntactics; BERT; Command; Command line; Command syntax; Cyber security; Language model; Learn+; LLM; Markov; Regular expressions; Markov processes},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071637-9},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Degnan20245395,
	author = {Degnan, David J. and Strauch, Clayton W. and Obiri, Moses Y. and VonKaenel, Erik D. and Kim, Grace S. and Kershaw, James D. and Novelli, David L. and Pazdernik, Karl TL and Bramer, Lisa M.},
	title = {Protein-Protein Interaction Networks Derived from Classical and Machine Learning-Based Natural Language Processing Tools},
	year = {2024},
	journal = {Journal of Proteome Research},
	volume = {23},
	number = {12},
	pages = {5395 – 5404},
	doi = {10.1021/acs.jproteome.4c00535},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209632638&doi=10.1021%2facs.jproteome.4c00535&partnerID=40&md5=c4835ac7c7e486051397e260cbf33ead},
	affiliations = {Biological Sciences Division, Pacific Northwest National Laboratory, 902 Battelle Blvd, Richland, 99354, WA, United States; AI & Data Analytics Division, Pacific Northwest National Laboratory, 902 Battelle Blvd, Richland, 99354, WA, United States; Earth Systems Science Division, Pacific Northwest National Laboratory, 902 Battelle Blvd, Richland, 99354, WA, United States; Department of Statistics, North Carolina State University, Raleigh, 27695, NC, United States},
	abstract = {The study of protein-protein interactions (PPIs) provides insight into various biological mechanisms, including the binding of antibodies to antigens, enzymes to inhibitors or promoters, and receptors to ligands. Recent studies of PPIs have led to significant biological breakthroughs. For example, the study of PPIs involved in the human:SARS-CoV-2 viral infection mechanism aided in the development of SARS-CoV-2 vaccines. Though several databases exist for the manual curation of PPI networks, text mining methods have been routinely demonstrated as useful alternatives for newly studied or understudied species, where databases are incomplete. Here, the relationship extraction performance of several open-source classical text processing, machine learning (ML)-based natural language processing (NLP), and large language model (LLM)-based NLP tools was compared. Overall, our results indicated that networks derived from classical methods tend to have high true positive rates at the expense of having overconnected networks, ML-based NLP methods have lower true positive rates but networks with the closest structures to the target network, and LLM-based NLP methods tend to exist between the two other approaches, with variable performances. The selection of a specific NLP approach should be tied to the needs of a study and text availability, as models varied in performance due to the amount of text provided. © 2024 American Chemical Society.},
	author_keywords = {BERT; biological text mining; GPT; large language models; LLM; machine learning; natural language processing; relationship extraction},
	keywords = {COVID-19; Data Mining; Databases, Protein; Humans; Machine Learning; Natural Language Processing; Protein Interaction Mapping; Protein Interaction Maps; SARS-CoV-2; gamma interferon; interleukin 1beta; interleukin 2; tumor necrosis factor; Article; coronavirus disease 2019; Escherichia coli; false negative result; false positive result; gene product; human; large language model; machine learning; natural language processing; protein expression; protein protein interaction; word processing; data mining; metabolism; procedures; protein database; Severe acute respiratory syndrome coronavirus 2; virology},
	correspondence_address = {L.M. Bramer; Biological Sciences Division, Pacific Northwest National Laboratory, Richland, 902 Battelle Blvd, 99354, United States; email: Lisa.Bramer@pnnl.gov},
	publisher = {American Chemical Society},
	issn = {15353893},
	coden = {JPROB},
	pmid = {39526844},
	language = {English},
	abbrev_source_title = {J. Proteome Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Estevanell-Valladares2024221,
	author = {Estevanell-Valladares, Ernesto L. and Gutiérrez, Yoan and Montoyo-Guijarro, Andrés and Muñoz-Guillena, Rafael and Almeida-Cruz, Yudivián},
	title = {Balancing Efficiency and Performance in NLP: A Cross-Comparison of Shallow Machine Learning and Large Language Models via AutoML; [Equilibrando eficiencia y rendimiento en PLN: comparación cruzada de Machine Learning Tradicional y Grandes Modelos de Lenguaje mediante AutoML]},
	year = {2024},
	journal = {Procesamiento del Lenguaje Natural},
	number = {73},
	pages = {221 – 233},
	doi = {10.26342/2024-73-16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206555187&doi=10.26342%2f2024-73-16&partnerID=40&md5=74df1deedfa0f8dc6327505de563a8dc},
	affiliations = {Universidad de la Habana, Cuba; Universidad de Alicante, Spain},
	abstract = {This study critically examines the resource efficiency and performance of Shallow Machine Learning (SML) methods versus Large Language Models (LLMs) in text classification tasks by exploring the balance between accuracy and environmental sustainability. We introduce a novel optimization strategy that prioritizes computational efficiency and ecological impact alongside traditional performance metrics leveraging Automated Machine Learning (AutoML). Our analysis reveals that while the pipelines we developed did not surpass state-of-the-art (SOTA) models regarding raw performance, they offer a significantly reduced carbon footprint. We discovered SML optimal pipelines with competitive performance and up to 70 times less carbon emissions than hybrid or fully LLM pipelines, such as standard BERT and DistilBERT variants. Similarly, we obtain hybrid pipelines (using SML and LLMs) with between 20% and 50% reduced carbon emissions compared to fine-tuned alternatives and only a marginal decrease in performance. This research challenges the prevailing reliance on computationally intensive LLMs for NLP tasks and underscores the untapped potential of AutoML in sculpting the next wave of environmentally conscious AI models. © 2024 Sociedad Española para el Procesamiento del Lenguaje Natural.},
	author_keywords = {AutoML; LLM; Machine Learning; Natural Language Processing},
	publisher = {Sociedad Espanola para el Procesamiento del Lenguaje Natural},
	issn = {11355948},
	language = {English},
	abbrev_source_title = {Proces. Lenguaje Nat.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu20242940,
	author = {Liu, Xin and Gao, Huiquan and Shao, Changheng and Chen, Ziliang and Lu, Wenjuan and Yang, Huiru},
	title = {Construction and Application of Large Language Model for Public Complaints with Knowledge Reasoning and Similarity Retrieval; [融合知识推理与相似度检索的民众诉求大模型构建与应用]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {11},
	pages = {2940 – 2953},
	doi = {10.3778/j.issn.1673-9418.2406057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209718567&doi=10.3778%2fj.issn.1673-9418.2406057&partnerID=40&md5=8d0fbbd808434c71f820111610b80d99},
	affiliations = {Qingdao Institute of Software, College of Computer Science and Technology, China University of Petroleum (East China), Shandong, Qingdao, 266580, China; School of Computer Science and Technology, Qingdao University, Shandong, Qingdao, 266071, China},
	abstract = {Efficiently responding to public complaints is a necessary measure to realize intelligent management and enhance public satisfaction, and the use of intelligent question answering for public complaints can save time and human resources. However, rule-based and retrieval-based models in intelligent question answering rely on preset knowledge. Therefore, they cannot provide effective responses when complaints are out of the scope of knowledge, nor can they maintain the coherence of conversations when dealing with multiple rounds of dialogues. Existing large language models can communicate smoothly with users, but general-purpose large language models lack domain knowledge. Due to the fact that the correct answers in the training data will contain information not covered by the questions, the general large language model generates wrong responses or answers that are not the questions asked, resulting in hallucination. To address these issues, a large language model (PC-LLM) for intelligent question-and-answer in the domain of public complaints has been constructed. Firstly, an entity relationship extraction model based on BERT-BiLSTM-CRF is designed to extract entities and relationships in the complaint work order in order to construct the complaint knowledge graph. The BERT model is used to vectorize the complaint work order and construct the vector index library of the complaint work order. In the stage of reply generation, this paper extracts the entities and relationships of users’complaints, conducts knowledge reasoning through entity links in the knowledge graph of complaints, obtains potential relationship tips, and uses the knowledge graph of complaints to perform knowledge reasoning to obtain potential relationship hints. Meanwhile, this paper performs quick search of complaints within the vector index library of complaint work orders, and obtains similar complaints. Finally, a more accurate response can be generated by integrating potential relationship prompts, similar complaint prompts and complaint into a large language model. Experimental analysis shows that the performance of this large language model on the complaints dataset is significantly better than that of ChatGPT4o, ERNIE Bot, Tongyi Qianwen, and other large language models. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {knowledge graph; knowledge reasoning; large language model; public complaints; similarity retrieval},
	correspondence_address = {X. Liu; Qingdao Institute of Software, College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, Shandong, 266580, China; email: lx@upc.edu.cn},
	publisher = {Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press},
	issn = {16739418},
	language = {Chinese},
	abbrev_source_title = {J. Frontier. Comput. Sci. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2024376,
	author = {Li, Youjia and Gupta, Vishu and Kilic, Muhammed Nur Talha and Choudhary, Kamal and Wines, Daniel and Liao, Wei-Keng and Choudhary, Alok and Agrawal, Ankit},
	title = {Hybrid-LLM-GNN: integrating large language models and graph neural networks for enhanced materials property prediction},
	year = {2024},
	journal = {Digital Discovery},
	volume = {4},
	number = {2},
	pages = {376 – 383},
	doi = {10.1039/d4dd00199k},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213060752&doi=10.1039%2fd4dd00199k&partnerID=40&md5=4624610127a60b57645916d6d7a2283c},
	affiliations = {Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL, United States; Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, United States; Ludwig Institute for Cancer Research, Princeton University, Princeton, NJ, United States; Department of Computer Science, Northwestern University, Evanston, IL, United States; Material Measurement Laboratory, National Institute of Standards and Technology, 100 Bureau Dr, Gaithersburg, MD, United States; DeepMaterials LLC, Silver Spring, 20906, MD, United States},
	abstract = {Graph-centric learning has attracted significant interest in materials informatics. Accordingly, a family of graph-based machine learning models, primarily utilizing Graph Neural Networks (GNN), has been developed to provide accurate prediction of material properties. In recent years, Large Language Models (LLM) have revolutionized existing scientific workflows that process text representations, thanks to their exceptional ability to utilize extensive common knowledge for understanding semantics. With the help of automated text representation tools, fine-tuned LLMs have demonstrated competitive prediction accuracy as standalone predictors. In this paper, we propose to integrate the insights from GNNs and LLMs to enhance both prediction accuracy and model interpretability. Inspired by the feature-extraction-based transfer learning study for the GNN model, we introduce a novel framework that extracts and combines GNN and LLM embeddings to predict material properties. In this study, we employed ALIGNN as the GNN model and utilized BERT and MatBERT as the LLM model. We evaluated the proposed framework in cross-property scenarios using 7 properties. We find that the combined feature extraction approach using GNN and LLM outperforms the GNN-only approach in the majority of the cases with up to 25% improvement in accuracy. We conducted model explanation analysis through text erasure to interpret the model predictions by examining the contribution of different parts of the text representation. © 2025 RSC.},
	correspondence_address = {Y. Li; Department of Electrical and Computer Engineering, Northwestern University, Evanston, United States; email: youjia@northwestern.edu; A. Agrawal; Department of Electrical and Computer Engineering, Northwestern University, Evanston, United States; email: ankit-agrawal@northwestern.edu},
	publisher = {Royal Society of Chemistry},
	issn = {2635098X},
	language = {English},
	abbrev_source_title = {Digit. Discov.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Pang20251,
	author = {Pang, Bo and Qiao, Tingrui and Walker, Caroline and Cunningham, Chris and Koh, Yun Sing},
	title = {LIBRA: Measuring Bias of Large Language Model from a Local Context},
	year = {2025},
	journal = {Lecture Notes in Computer Science},
	volume = {15572 LNCS},
	pages = {1 – 16},
	doi = {10.1007/978-3-031-88708-6_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003134215&doi=10.1007%2f978-3-031-88708-6_1&partnerID=40&md5=d558c19f51bb626a75563040d5d4b0e8},
	affiliations = {School of Computer Science, University of Auckland, Auckland, New Zealand; The Liggins Institute, University of Auckland, Auckland, New Zealand; Research Centre for Māori Health and Development, Massey University, Wellington, New Zealand},
	abstract = {Large Language Models (LLMs) have significantly advanced natural language processing applications, yet their widespread use raises concerns regarding inherent biases that may reduce utility or harm for particular social groups. Despite the advancement in addressing LLM bias, existing research has two major limitations. First, existing LLM bias evaluation focuses on the U.S. cultural context, making it challenging to reveal stereotypical biases of LLMs toward other cultures, leading to unfair development and use of LLMs. Second, current bias evaluation often assumes models are familiar with the target social groups. When LLMs encounter words beyond their knowledge boundaries that are unfamiliar in their training data, they produce irrelevant results in the local context due to hallucinations and overconfidence, which are not necessarily indicative of inherent bias. This research addresses these limitations with a Local Integrated Bias Recognition and Assessment Framework (LIBRA) for measuring bias using datasets sourced from local corpora without crowdsourcing. Implementing this framework, we develop a dataset comprising over 360,000 test cases in the New Zealand context. Furthermore, we propose the Enhanced Idealized CAT Score (EiCAT), integrating the iCAT score with a beyond knowledge boundary score (bbs) and a distribution divergence-based bias measurement to tackle the challenge of LLMs encountering words beyond knowledge boundaries. Our results show that the BERT family, GPT-2, and Llama-3 models seldom understand local words in different contexts. While Llama-3 exhibits larger bias, it responds better to different cultural contexts. The code and dataset are available at: https://github.com/ipangbo/LIBRA. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Bias; Dataset; Large Language Model},
	keywords = {Crowdsourcing; Economic and social effects; Modeling languages; Bias; Cultural context; Dataset; Knowledge boundaries; Language model; Large language model; Local contexts; Model bias; Natural language processing applications; Social groups; Natural language processing systems},
	correspondence_address = {B. Pang; School of Computer Science, University of Auckland, Auckland, New Zealand; email: bpan882@aucklanduni.ac.nz},
	editor = {Hauff C. and Macdonald C. and Jannach D. and Kazai G. and Nardini F.M. and Pinelli F. and Silvestri F. and Tonellotto N.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303188707-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ji202438,
	author = {Ji, Huishan and Si, Qingyi and Lin, Zheng and Wang, Weiping},
	title = {Towards Flexible Evaluation for Generative Visual Question Answering},
	year = {2024},
	journal = {MM 2024 - Proceedings of the 32nd ACM International Conference on Multimedia},
	pages = {38 – 47},
	doi = {10.1145/3664647.3681400},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209793752&doi=10.1145%2f3664647.3681400&partnerID=40&md5=a74970318ccf628c0d9e16a6e1249393},
	affiliations = {Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China},
	abstract = {Throughout rapid development of multimodal large language models, a crucial ingredient is a fair and accurate evaluation of their multimodal comprehension abilities. Although Visual Question Answering (VQA) could serve as a developed test field, limitations of VQA evaluation, like the inflexible pattern of Exact Match, have hindered MLLMs from demonstrating their real capability and discourage rich responses. Therefore, this paper proposes the use of semantics-based evaluators for assessing unconstrained open-ended responses on VQA datasets. As characteristics of VQA have made such evaluation significantly different from the traditional Semantic Textual Similarity (STS) task, to systematically analyze the behaviour and compare the performance of various evaluators including LLM-based ones, we propose three key properties, i.e., Alignment, Consistency and Generalization, and a corresponding dataset Assessing VQA Evaluators (AVE) to facilitate analysis. In addition, this paper proposes a Semantically Flexible VQA Evaluator (SFVE) with meticulous design based on the unique features of VQA evaluation.Experimental results verify the feasibility of model-based VQA evaluation and effectiveness of the proposed evaluator that surpasses existing semantic evaluators by a large margin. The proposed training scheme generalizes to both the BERT-like encoders and decoder-only LLM. Relaed codes and data available at https://github.com/jihuishan/flexible-evaluation-for-vqa-mm24. © 2024 Owner/Author.},
	author_keywords = {contrastive learning; evaluation method; semantic textual similarity; visual question answering},
	keywords = {Contrastive Learning; Semantics; Evaluation methods; Language model; Multi-modal; Open-ended response; Question Answering; Question-answering evaluation; Semantic textual similarity; Test fields; Textual similarities; Visual question answering; Question answering},
	correspondence_address = {Z. Lin; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; email: linzheng@iie.ac.cn},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070686-8},
	language = {English},
	abbrev_source_title = {MM - Proc. ACM Int. Conf. Multimed.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Zheng2025689,
	author = {Zheng, Aaron and Rana, Mansi and Stolcke, Andreas},
	title = {Lightweight Safety Guardrails Using Fine-tuned BERT Embeddings},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	pages = {689 – 696},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000209392&partnerID=40&md5=fa28fbacd0115af84b2d7228e7effa31},
	affiliations = {Uniphore & UC Berkeley, United States; Uniphore},
	abstract = {With the recent proliferation of large language models (LLMs), enterprises have been able to rapidly develop proof-of-concepts and prototypes. As a result, there is a growing need to implement robust guardrails that monitor, quantize and control an LLM’s behavior, ensuring that the use is reliable, safe, accurate and also aligned with the users’ expectations. Previous approaches for filtering out inappropriate user prompts or system outputs, such as LlamaGuard and OpenAI’s MOD API, have achieved significant success by fine-tuning existing LLMs. However, using fine-tuned LLMs as guardrails introduces increased latency and higher maintenance costs, which may not be practical or scalable for cost-efficient deployments. We take a different approach, focusing on fine-tuning a lightweight architecture: Sentence-BERT. This method reduces the model size from LlamaGuard’s 7 billion parameters to approximately 67 million, while maintaining comparable performance on the AEGIS safety benchmark. ©2025 Association for Computational Linguistics.},
	keywords = {Accident prevention; Benchmarking; Guards (shields); Cost-efficient; Embeddings; Fine tuning; Language model; Lightweight architecture; Maintenance cost; Proof of concept; Safety guardrails; System output; User expectations; Guard rails},
	editor = {Rambow O. and Wanner L. and Apidianaki M. and Al-Khalifa H. and Di Eugenio B. and Schockaert S. and Darwish K. and Agarwal A.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176197-1},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Grigorov20241,
	author = {Grigorov, Dilyan},
	title = {Introduction to python and large language models: A guide to language models},
	year = {2024},
	journal = {Introduction to Python and Large Language Models: A Guide to Language Models},
	pages = {1 – 380},
	doi = {10.1007/979-8-8688-0540-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002533453&doi=10.1007%2f979-8-8688-0540-0&partnerID=40&md5=216ac733b9cf249ba49567045b11902b},
	affiliations = {Varna, Bulgaria},
	abstract = {Gain a solid foundation for Natural Language Processing (NLP) and Large Language Models (LLMs), emphasizing their significance in today's computational world. This book is an introductory guide to NLP and LLMs with Python programming. The book starts with the basics of NLP and LLMs. It covers essential NLP concepts, such as text preprocessing, feature engineering, and sentiment analysis using Python. The book offers insights into Python programming, covering syntax, data types, conditionals, loops, functions, and object-oriented programming. Next, it delves deeper into LLMs, unraveling their complex components. You'll learn about LLM elements, including embedding layers, feedforward layers, recurrent layers, and attention mechanisms. You'll also explore important topics like tokens, token distributions, zero-shot learning, LLM hallucinations, and insights into popular LLM architectures such as GPT-4, BERT, T5, PALM, and others. Additionally, it covers Python libraries like Hugging Face, OpenAI API, and Cohere. The final chapter bridges theory with practical application, offering step-by-step examples of coded applications for tasks like text generation, summarization, language translation, question-answering systems, and chatbots. In the end, this book will equip you with the knowledge and tools to navigate the dynamic landscape of NLP and LLMs. What You'll Learn Understand the basics of Python and the features of Python 3.11 Explore the essentials of NLP and how do they lay the foundations for LLMs. Review LLM components. Develop basic apps using LLMs and Python. Who This Book Is For Data analysts, AI and Machine Learning Experts, Python developers, and Software Development Professionals interested in learning the foundations of NLP, LLMs, and the processes of building modern LLM applications for various tasks. © 2024 by Dilyan Grigorov. All rights reserved.},
	author_keywords = {Applications; Computer science; Conference proceedings; Informatics; Research},
	correspondence_address = {D. Grigorov; Varna, Bulgaria; email: dido.grigorov@gmail.com},
	publisher = {Apress Media LLC},
	isbn = {979-886880540-0; 979-886880539-4},
	language = {English},
	abbrev_source_title = {Introd. to Python and Larg. Lang. Model.: A Guide to Lang. Model.},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Arshad20242739,
	author = {Arshad, Muhammad Ali and Riaz, Adnan and Fatima, Rubia and Yasin, Affan},
	title = {SevPredict: Exploring the Potential of Large Language Models in Software Maintenance},
	year = {2024},
	journal = {AI (Switzerland)},
	volume = {5},
	number = {4},
	pages = {2739 – 2760},
	doi = {10.3390/ai5040132},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213446464&doi=10.3390%2fai5040132&partnerID=40&md5=f694ac7e0dfe5959b0d8fd357dd3c738},
	affiliations = {Department of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China; Department of Computer Science and Engineering, University of Bologna, Bologna, 40126, Italy; Faculty of Computing and Emerging Technologies, Emerson University, Multan, 60000, Pakistan; School of AI and Advanced Computing, Xi’an Jiaotong-Liverpool University, Suzhou, 215123, China},
	abstract = {The prioritization of bug reports based on severity is a crucial aspect of bug triaging, enabling a focus on more critical issues. Traditional methods for assessing bug severity range from manual inspection to the application of machine and deep learning techniques. However, manual evaluation tends to be resource-intensive and inefficient, while conventional learning models often lack contextual understanding. This study explores the effectiveness of large language models (LLMs) in predicting bug report severity. We propose a novel approach called SevPredict using GPT-2, an advanced LLM, and compare it against state-of-the-art models. The comparative analysis between the proposed approach and state-of-the-art approaches suggests that the proposed approach outperforms the state-of-the-art approaches in terms of performance evaluation metrics. SevPredict shows improvements over the best-performing state-of-the-art approach (BERT-SBR) with 1.72% higher accuracy, 2.18% higher precision, and 4.94% higher MCC. The improvements are even more substantial when compared to the approach by Ramay et al., with SevPredict demonstrating 10.66% higher accuracy, 10.39% higher precision, 3.29% higher recall, 7.19% higher F1-score, and a remarkable 41.27% higher MCC. These findings not only demonstrate the superiority of our GPT-2-based approach in predicting the severity of bug reports but also highlight its potential to significantly advance automated bug triaging and software maintenance. This research introduces a severity prediction tool named SevPredict. © 2024 by the authors.},
	author_keywords = {large language models; mining software repository; severity prediction},
	correspondence_address = {A. Riaz; Department of Computer Science and Engineering, University of Bologna, Bologna, 40126, Italy; email: adnan.riaz3@unibo.it; A. Yasin; School of AI and Advanced Computing, Xi’an Jiaotong-Liverpool University, Suzhou, 215123, China; email: affan.yasin@outlook.com},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {26732688},
	language = {English},
	abbrev_source_title = {AI.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Zhang20256,
	author = {Zhang, Zhen-Xing and Wen, Yuan-Bo and Lyu, Han-Qi and Liu, Chang and Zhang, Rui and Li, Xia-Qing and Wang, Chao and Du, Zi-Dong and Guo, Qi and Li, Ling and Zhou, Xue-Hai and Chen, Yun-Ji},
	title = {AI Computing Systems for Large Language Models Training},
	year = {2025},
	journal = {Journal of Computer Science and Technology},
	volume = {40},
	number = {1},
	pages = {6 – 41},
	doi = {10.1007/s11390-024-4178-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000351259&doi=10.1007%2fs11390-024-4178-1&partnerID=40&md5=a146ca514edae4ae04ed7fb62465e6e4},
	affiliations = {School of Computer Science and Technology, University of Science and Technology of China, Hefei, 230026, China; State Key Laboratory of Processors, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Cambricon Technologies, Beijing, 100191, China; Shanghai Innovation Center for Processor Technologies, Shanghai, 201210, China; Intelligent Software Research Center, Institute of Software, Chinese Academy of Sciences, Beijing, 100190, China; University of Chinese Academy of Sciences, Beijing, 101408, China},
	abstract = {In this paper, we present a comprehensive overview of artificial intelligence (AI) computing systems for large language models (LLMs) training. The rapid advancement of LLMs in recent years, coupled with the widespread adoption of algorithms and applications such as BERT, ChatGPT, and DeepSeek, has sparked significant interest in this field. We classify LLMs into encoder-only, encoder-decoder, and decoder-only models, and briefly analyze their training and inference processes to emphasize their substantial need for computational resources. These operations depend heavily on AI-specific accelerators like GPUs (graphics processing units), TPUs (tensor processing units), and MLUs (machine learning units). However, as the gap widens between the increasing complexity of LLMs and the current capabilities of accelerators, it becomes essential to adopt heterogeneous computing systems optimized for distributed environments to manage the growing computational and memory requirements of LLMs. We delve into the execution and scheduling of LLM algorithms, underlining the critical role of distributed computing strategies, memory management enhancements, and boosting computational efficiency. This paper clarifies the complex relationship between algorithm design, hardware infrastructure, and software optimization, and provides an in-depth understanding of both the software and hardware infrastructure supporting LLMs training, offering insights into the challenges and potential avenues for future development and deployment. © Institute of Computing Technology, Chinese Academy of Sciences 2025.},
	author_keywords = {accelerator; AI computing system; artificial intelligence (AI) chip; large language model (LLM)},
	keywords = {Memory management units; Tensors; Artificial intelligence  chip; Artificial intelligence computing system; Computing system; Encoder-decoder; Inference process; Language model; Large language model; Model training; Processing units; Training process; Graphics processing unit},
	correspondence_address = {Y.-J. Chen; State Key Laboratory of Processors, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; email: cyj@ict.ac.cn},
	publisher = {Springer},
	issn = {10009000},
	coden = {JCTEE},
	language = {English},
	abbrev_source_title = {J Comput Sci Technol},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Ito2024995,
	author = {Ito, Tomoki and Nakagawa, Shun},
	title = {Tender Document Analyzer with the Combination of Supervised Learning and LLM-based Improver},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {995 – 998},
	doi = {10.1145/3589335.3651233},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194497077&doi=10.1145%2f3589335.3651233&partnerID=40&md5=e7ebcc7137127650795bdbcd0e40bb41},
	affiliations = {Mitsui & CO., LTD., Chiyoda-ku, Tokyo, Japan; Mitsui & CO., LTD, Japan},
	abstract = {Bidders often take a long time to read and understand tender documents because they require specialized knowledge, and tender documents are generally long. Bidders first overview the specific items, such as payment and warranty, in a tender document and then check the overall document. Therefore, the function that can extract specific items (i.e., item extractor) and the function that can highlight words or phrases related to specific items (i.e., word-phrase highlighter) are in great demand. To develop the above two types of functions, we need to solve two problems. The first problem is the problem related to the annotated data set. The second problem concerns the BERT NER-based prediction approach in a small training dataset setting. To solve the first problem, we created two types of sequence labeling datasets related to Item Extractor and Word-Phrase Highlighter. To solve the second problem, we propose the Information Extraction (IE) method, which combines (1) a supervised learning approach using Bidirectional Encoder Representations from Transformers (BERT) and (2) a large language model (LLM)-based improver. We then developed the web application system called Tender Document Analyzer (TDDA), which includes "Item Extractor" and "Word-Phrase Highlighter". Experimental evaluation shows that our approach is practical. Firstly, the evaluation for extraction ability shows that the performance of our proposed method is much higher than the baseline approach that uses GPT 3.5, as well as demonstrates that the proposed LLM-based improver can improve the IE ability. In addition, the usability evaluation shows that bidders can solve the task in less time using our system. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {support system; tender document; text mining},
	keywords = {Data mining; Petroleum reservoir evaluation; Supervised learning; Data set; Language model; Model-based OPC; Sequence Labeling; Small training; Specialized knowledge; Support systems; Tender documents; Text-mining; Training dataset; Function evaluation},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070172-6},
	language = {English},
	abbrev_source_title = {WWW Companion - Companion Proc. ACM Web Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Delgadillo2024,
	author = {Delgadillo, Josiel and Kinyua, Johnson and Mutigwe, Charles},
	title = {FinSoSent: Advancing Financial Market Sentiment Analysis through Pretrained Large Language Models},
	year = {2024},
	journal = {Big Data and Cognitive Computing},
	volume = {8},
	number = {8},
	doi = {10.3390/bdcc8080087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202346804&doi=10.3390%2fbdcc8080087&partnerID=40&md5=97a2a16417ab03bc1264ae01fd996790},
	affiliations = {School of Engineering and Applied Sciences, University of Pennsylvania, Philadelphia, 19104, PA, United States; College of Information Sciences and Technology, Pennsylvania State University, Philadelphia, 19104, PA, United States; College of Business, Western New England University, Springfield, 01119, MA, United States},
	abstract = {Predicting the directions of financial markets has been performed using a variety of approaches, and the large volume of unstructured data generated by traders and other stakeholders on social media microblog platforms provides unique opportunities for analyzing financial markets using additional perspectives. Pretrained large language models (LLMs) have demonstrated very good performance on a variety of sentiment analysis tasks in different domains. However, it is known that sentiment analysis is a very domain-dependent NLP task that requires knowledge of the domain ontology, and this is particularly the case with the financial domain, which uses its own unique vocabulary. Recent developments in NLP and deep learning including LLMs have made it possible to generate actionable financial sentiments using multiple sources including financial news, company fundamentals, technical indicators, as well social media microblogs posted on platforms such as StockTwits and X (formerly Twitter). We developed a financial social media sentiment analyzer (FinSoSent), which is a domain-specific large language model for the financial domain that was pretrained on financial news articles and fine-tuned and tested using several financial social media corpora. We conducted a large number of experiments using different learning rates, epochs, and batch sizes to yield the best performing model. Our model outperforms current state-of-the-art FSA models based on over 860 experiments, demonstrating the efficacy and effectiveness of FinSoSent. We also conducted experiments using ensemble models comprising FinSoSent and the other current state-of-the-art FSA models used in this research, and a slight performance improvement was obtained based on majority voting. Based on the results obtained across all models in these experiments, the significance of this study is that it highlights the fact that, despite the recent advances of LLMs, sentiment analysis even in domain-specific contexts remains a difficult research problem. © 2024 by the authors.},
	author_keywords = {BERT; financial markets; LLM; sentiment analysis; social media; StockTwits; Twitter/X},
	keywords = {Decentralized finance; Financial markets; Market Research; Problem oriented languages; Sentiment analysis; BERT; Financial domains; Language model; Large language model; Micro-blog; Performance; Sentiment analysis; Social media; Stocktwit; Twitter/X; Tweets},
	correspondence_address = {J. Delgadillo; School of Engineering and Applied Sciences, University of Pennsylvania, Philadelphia, 19104, United States; email: josield@upenn.edu},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {25042289},
	language = {English},
	abbrev_source_title = {Big Data Cogn. Computing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Fussell2025,
	author = {Fussell, Rebeckah K. and Flynn, Megan and Damle, Anil and Fox, Michael F. J. and Holmes, N.G.},
	title = {Comparing large language models for supervised analysis of students' lab notes},
	year = {2025},
	journal = {Physical Review Physics Education Research},
	volume = {21},
	number = {1},
	doi = {10.1103/PhysRevPhysEducRes.21.010128},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001703060&doi=10.1103%2fPhysRevPhysEducRes.21.010128&partnerID=40&md5=3daa1a8c1e02685a9105589f0939fee3},
	affiliations = {Laboratory of Atomic and Solid State Physics, Cornell University, Ithaca, 14853, NY, United States; Department of Computer Science, Cornell University, Ithaca, 14853, NY, United States; Department of Physics, Imperial College London, London, United Kingdom},
	abstract = {Recent advancements in large language models (LLMs) hold significant promise for improving physics education research that uses machine learning. In this study, we compare the application of various models for conducting a large-scale analysis of written text grounded in a physics education research classification problem: identifying skills in students' typed lab notes through sentence-level labeling. Specifically, we use training data to fine-tune two different LLMs, BERT and LLaMA, and compare the performance of these models to both a traditional bag-of-words approach and a few-shot LLM (without fine-tuning). We evaluate the models based on their resource use, performance metrics, and research outcomes when identifying skills in lab notes. We find that higher-resource models often, but not necessarily, perform better than lower-resource models. We also find that all models report similar trends in research outcomes, although the absolute values of the estimated measurements are not always within uncertainties of each other. We use the results to discuss relevant considerations for education researchers seeking to select a model type for use as a classifier.  © 2025 authors. Published by the American Physical Society.},
	correspondence_address = {N.G. Holmes; Laboratory of Atomic and Solid State Physics, Cornell University, Ithaca, 14853, United States; email: ngholmes@cornell.edu},
	publisher = {American Physical Society},
	issn = {24699896},
	coden = {PRPEC},
	language = {English},
	abbrev_source_title = {Phys. Rev. Phys. Educ. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Hussain2024,
	author = {Hussain, Zafar and Nurminen, Jukka K. and Ranta-aho, Perttu},
	title = {Training a language model to learn the syntax of commands},
	year = {2024},
	journal = {Array},
	volume = {23},
	doi = {10.1016/j.array.2024.100355},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198014172&doi=10.1016%2fj.array.2024.100355&partnerID=40&md5=53e4ef24aaba36f4022d3ef2716335be},
	affiliations = {University of Helsinki, Pietari Kalmin katu 5, Helsinki, 00560, Finland; WithSecure, Tammasaarenkatu 7, Helsinki, 00180, Finland},
	abstract = {To protect systems from malicious activities, it is important to differentiate between valid and harmful commands. One way to achieve this is by learning the syntax of the commands, which is a complex task because of the expansive and evolving nature of command syntax. To address this, we harnessed the power of a language model. Our methodology involved constructing a specialized vocabulary from our commands dataset, and training a custom tokenizer with a Masked Language Model head, resulting in the development of a BERT-like language model. This model exhibits proficiency in learning command syntax by predicting masked tokens. In comparative analyses, our language model outperformed the Markov Model in categorizing commands using clustering algorithms (DBSCAN, HDBSCAN, OPTICS). The language model achieved higher Silhouette scores (0.72, 0.88, 0.85) compared to the Markov Model (0.53, 0.25, 0.06) and demonstrated significantly lower noise levels (2.63%, 5.39%, 8.49%) versus the Markov Model's higher noise rates (9.31%, 29.85%, 50.35%). Further validation with manually crafted syntax and BERTScore assessments consistently produced metrics above 0.90 for precision, recall, and F1-score. Our language model excels at learning command syntax, enhancing protective measures against malicious activities. © 2024 The Author(s)},
	author_keywords = {BERT; Clustering; Command syntax; Command-line; Commands; Language model; LLM; Markov; Random tokens},
	keywords = {Computational linguistics; Learning systems; Markov processes; Syntactics; BERT; Clusterings; Command; Command line; Command syntax; Language model; LLM; Markov; Markov modeling; Random token; Clustering algorithms},
	correspondence_address = {Z. Hussain; University of Helsinki, Helsinki, Pietari Kalmin katu 5, 00560, Finland; email: zafar.hussain@helsinki.fi},
	publisher = {Elsevier B.V.},
	issn = {25900056},
	language = {English},
	abbrev_source_title = {Array.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Ferrag20251,
	author = {Ferrag, Mohamed Amine and Alwahedi, Fatima and Battah, Ammar and Cherif, Bilel and Mechri, Abdechakour and Tihanyi, Norbert and Bisztray, Tamas and Debbah, Merouane},
	title = {Generative AI in cybersecurity: A comprehensive review of LLM applications and vulnerabilities},
	year = {2025},
	journal = {Internet of Things and Cyber-Physical Systems},
	volume = {5},
	pages = {1 – 46},
	doi = {10.1016/j.iotcps.2025.01.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004989357&doi=10.1016%2fj.iotcps.2025.01.001&partnerID=40&md5=f90fcbc131946112a9b3b05f20b9ed41},
	affiliations = {Department of Computer Science, Guelma University, Guelma, Algeria; Technology Innovation Institute, United Arab Emirates; Concordia University, Canada; University of Oslo, Norway; Khalifa University of Science and Technology, United Arab Emirates},
	abstract = {This paper provides a comprehensive review of the future of cybersecurity through Generative AI and Large Language Models (LLMs). We explore LLM applications across various domains, including hardware design security, intrusion detection, software engineering, design verification, cyber threat intelligence, malware detection, and phishing detection. We present an overview of LLM evolution and its current state, focusing on advancements in models such as GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends to LLM vulnerabilities, such as prompt injection, insecure output handling, data poisoning, DDoS attacks, and adversarial instructions. We delve into mitigation strategies to protect these models, providing a comprehensive look at potential attack scenarios and prevention techniques. Furthermore, we evaluate the performance of 42 LLM models in cybersecurity knowledge and hardware security, highlighting their strengths and weaknesses. We thoroughly evaluate cybersecurity datasets for LLM training and testing, covering the lifecycle from data creation to usage and identifying gaps for future research. In addition, we review new strategies for leveraging LLMs, including techniques like Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank Adapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim to enhance real-time cybersecurity defenses and improve the sophistication of LLM applications in threat detection and response. Our paper provides a foundational understanding and strategic direction for integrating LLMs into future cybersecurity frameworks, emphasizing innovation and robust model deployment to safeguard against evolving cyber threats. © 2025 The Authors},
	author_keywords = {Cybersecurity; Generative AI; LLM; Transformer security},
	keywords = {Access control; Computer viruses; Computer worms; Data privacy; Hardware security; Intrusion detection; Learning to rank; Model checking; Network intrusion; Network security; Phishing; Quantization (signal); Reinforcement learning; Cyber security; Cyber threats; Design security; Generative AI; Hardware design; Language model; Large language model; Model application; Security intrusion; Transformer security; Cyber attacks},
	correspondence_address = {M.A. Ferrag; Department of Computer Science, Guelma University, Guelma, Algeria; email: ferrag.mohamedamine@univ-guelma.dz},
	publisher = {KeAi Communications Co.},
	issn = {26673452},
	language = {English},
	abbrev_source_title = {Internet. Thing. Cyber. Phys. Syst.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Li2024,
	author = {Li, Jie and Tang, Chang and Lei, Zhechao and Zhang, Yirui and Li, Xuan and Yu, Yanhua and Pi, Renjie and Hu, Linmei},
	title = {KRA: K-Nearest Neighbor Retrieval Augmented Model for Text Classification},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {16},
	doi = {10.3390/electronics13163237},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202678138&doi=10.3390%2felectronics13163237&partnerID=40&md5=609e907757f0a27458a76d4fc7ee355f},
	affiliations = {School of Computer Science, National Pilot Software Engineering School, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of International Chinese Language Education, Beijing Normal University, Beijing, 100875, China; School of Computer Science & Technology, Beijing Institute of Technology, Beijing, 100081, China},
	abstract = {Text classification is a fundamental task in natural language processing (NLP). Deep-learning-based text classification methods usually have two stages: training and inference. However, the training dataset is only used in the training stage. To make full use of the training dataset in the inference stage in order to improve model performance, we propose a k-nearest neighbors retrieval augmented method (KRA) for deep-learning-based text classification models. KRA works by first constructing a storage system that stores the embeddings of the training samples during the training stage. During the inference stage, the model retrieves the top k-nearest neighbors of the testing text from the storage. Then, we use text augmentation methods to expand the retrieved neighbors, including traditional augmentation methods and a large language model (LLM)-based method. Next, the method weights the augmented neighbors based on their distances from the target text and incorporates their labels into the inference of the final results accordingly. We evaluate our KRA method on six benchmark datasets using four commonly used deep learning models: CNN, LSTM, BERT, and RoBERTa. The results demonstrate that KRA significantly improves the classification performance of these models, with an average accuracy improvement of 0.3% for BERT and up to 0.4% for RoBERTa. These improvements highlight the effectiveness and generalizability of KRA across different models and datasets, making it a valuable enhancement for a wide range of text classification tasks. © 2024 by the authors.},
	author_keywords = {k-nearest neighbors; text augmentation; text classification},
	correspondence_address = {Z. Lei; School of International Chinese Language Education, Beijing Normal University, Beijing, 100875, China; email: 202438091005@mail.bnu.edu.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Ma20241524,
	author = {Ma, Chunwei and Wolfinger, Russell D.},
	title = {Toward an Explainable Large Language Model for the Automatic Identification of the Drug-Induced Liver Injury Literature},
	year = {2024},
	journal = {Chemical Research in Toxicology},
	volume = {37},
	number = {9},
	pages = {1524 – 1534},
	doi = {10.1021/acs.chemrestox.4c00134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202505565&doi=10.1021%2facs.chemrestox.4c00134&partnerID=40&md5=d9d56b0045286139e137e532021afebd},
	affiliations = {JMP Statistical Discovery, LLC, Cary, 27513, NC, United States},
	abstract = {Drug-induced liver injury (DILI) stands as a significant concern in drug safety, representing the primary cause of acute liver failure. Identifying the scientific literature related to DILI is crucial for monitoring, investigating, and conducting meta-analyses of drug safety issues. Given the intricate and often obscure nature of drug interactions, simple keyword searching can be insufficient for the exhaustive retrieval of the DILI-relevant literature. Manual curation of DILI-related publications demands pharmaceutical expertise and is susceptible to errors, severely limiting throughput. Despite numerous efforts utilizing cutting-edge natural language processing and deep learning techniques to automatically identify the DILI-related literature, their performance remains suboptimal for real-world applications in clinical research and regulatory contexts. In the past year, large language models (LLMs) such as ChatGPT and its open-source counterpart LLaMA have achieved groundbreaking progress in natural language understanding and question answering, paving the way for the automated, high-throughput identification of the DILI-related literature and subsequent analysis. Leveraging a large-scale public dataset comprising 14 203 training publications from the CAMDA 2022 literature AI challenge, we have developed what we believe to be the first LLM specialized in DILI analysis based on LLaMA-2. In comparison with other smaller language models such as BERT, GPT, and their variants, LLaMA-2 exhibits an enhanced out-of-fold accuracy of 97.19% and area under the ROC curve of 0.9947 using 3-fold cross-validation on the training set. Despite LLMs’ initial design for dialogue systems, our study illustrates their successful adaptation into accurate classifiers for automated identification of the DILI-related literature from vast collections of documents. This work is a step toward unleashing the potential of LLMs in the context of regulatory science and facilitating the regulatory review process. © 2024 American Chemical Society.},
	keywords = {Chemical and Drug Induced Liver Injury; Deep Learning; Humans; Natural Language Processing; accuracy; Article; artificial intelligence; cross validation; drug-induced liver injury; intermethod comparison; large language model; medical literature; publication; workflow; chemical and drug induced liver injury; deep learning; etiology; human; natural language processing},
	correspondence_address = {C. Ma; JMP Statistical Discovery, LLC, Cary, 27513, United States; email: chunwei.ma@jmp.com},
	publisher = {American Chemical Society},
	issn = {0893228X},
	coden = {CRTOE},
	pmid = {39190012},
	language = {English},
	abbrev_source_title = {Chem. Res. Toxicol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Agrawal2025136,
	author = {Agrawal, Sanjay and Ahemad, Faizan and Sembium, Vivek},
	title = {Rationale-Guided Distillation for E-Commerce Relevance Classification: Bridging Large Language Models and Lightweight Cross-Encoders},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	pages = {136 – 148},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000095671&partnerID=40&md5=9b55020156f896e38c4d8b22e99d3d8b},
	affiliations = {Amazon, India},
	abstract = {Accurately classifying the relevance of Query-Product pairs is critical in online retail stores such as Amazon, as displaying irrelevant products can harm user experience and reduce engagement. While Large Language Models (LLMs) excel at this task due to their broad knowledge and strong reasoning abilities. However, their high computational demands constrain their practical deployment in real-world applications. In this paper, we propose a novel distillation approach for e-commerce relevance classification that uses "rationales" generated by LLMs to guide smaller cross-encoder models. These rationales capture key decision-making insights from LLMs, enhancing training efficiency and enabling the distillation to smaller cross-encoder models deployable in production without requiring the LLM. Our method achieves average ROC-AUC improvements of 1.4% on 9 multilingual e-commerce datasets, 2.4% on 3 ESCI datasets, and 6% on GLUE datasets over vanilla cross-encoders. Our 110M parameter BERT model matches 7B parameter LLMs in performance (< 1% ROC-AUC difference) while being 50 times faster per sample. ©2025 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Decision making; Glues; Query languages; Structured Query Language; Computational demands; Decisions makings; E- commerces; Excel; Language model; Online retail stores; Real-world; Reasoning ability; Training efficiency; Users' experiences},
	editor = {Rambow O. and Wanner L. and Apidianaki M. and Al-Khalifa H. and Di Eugenio B. and Schockaert S. and Darwish K. and Agarwal A.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176197-1},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hernandez-Suarez2024351,
	author = {Hernandez-Suarez, Aldo and Perez-Meana, Hector Manuel and Sanchez-Perez, Gabriel and Portillo-Portillo, Jose and Olivares-Mercado, Jesus and Toscano-Medina, Linda Karina},
	title = {Topic Modeling in the Darknet via Semi-Supervised Learning and Linguistic Transformers},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {389},
	pages = {351 – 364},
	doi = {10.3233/FAIA240383},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217044106&doi=10.3233%2fFAIA240383&partnerID=40&md5=1c7a5ecbda37d6190483c3be075af7ef},
	affiliations = {Instituto Politecnico Nacional, ESIME Culhuacan, Mexico City, 04440, Mexico},
	abstract = {In recent years, the darknet, a hidden part of the deep web associated with illicit activities, has been the subject of study due to the myths and mysteries surrounding it. Contemporary research aims to uncover the true topics hidden within this network using thematic analysis techniques, which are essential for cybercrime prevention and legal action. However, the dynamic and anonymous nature of the darknet poses the challenge of effectively navigating the TOR protocol to obtain and analyze samples from hidden sites. This paper presents an innovative approach to studying the darknet. Assuming limited prior knowledge of the original topics, a contextual relation-comparison technique with TinyBERT, a large language model, is used to generate super topics from previously identified hidden sites. From these super topics, keywords with contextual scores and weights are extracted, serving as input for a sensor that navigates the TOR network and aggregates new hidden sites. These sites are processed through semi-supervised learning to form clusters of sub-topics. Labels for each sub-topic propagate based on their similarity to the main topics and are ultimately classified in a fine-tuning layer of TinyBERT. The results demonstrate the identification of twelve classes of sub-topics in the darknet, related to drugs, hacking, marketplaces, pornography, and other areas, with a classification accuracy of 95.45%. © 2024 IOS Press. All rights reserved.},
	author_keywords = {bert; darknet; fine-tuning; llm; topic-clustering},
	keywords = {Contrastive Learning; Linguistics; Self-supervised learning; Bert; Darknets; Deep web; Fine tuning; Llm; Semi-supervised learning; Sub topics; Thematic analysis; Topic clustering; Topic Modeling; Semi-supervised learning},
	correspondence_address = {A. Hernandez-Suarez; Instituto Politecnico Nacional, ESIME Culhuacan, Mexico City, 04440, Mexico; email: alhernandezsu@ipn.mx},
	editor = {Fujita H. and Fujita H. and Perez-Meana H. and Hernandez-Matamoros A.},
	publisher = {IOS Press BV},
	issn = {09226389},
	isbn = {978-164368538-0},
	language = {English},
	abbrev_source_title = {Front. Artif. Intell. Appl.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Abdullah2025,
	author = {Abdullah, Abdullah and Kim, Seong Tae},
	title = {Automated Radiology Report Labeling in Chest X-Ray Pathologies: Development and Evaluation of a Large Language Model Framework},
	year = {2025},
	journal = {JMIR Medical Informatics},
	volume = {13},
	doi = {10.2196/68618},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002486799&doi=10.2196%2f68618&partnerID=40&md5=a0ebe940d78c7e07946bc9490008e14e},
	affiliations = {Department of Computer Science and Engineering, Kyung Hee University, Gyeonggi-do, Yongin, South Korea},
	abstract = {Background: Labeling unstructured radiology reports is crucial for creating structured datasets that facilitate downstream tasks, such as training large-scale medical imaging models. Current approaches typically rely on Bidirectional Encoder Representations from Transformers (BERT)-based methods or manual expert annotations, which have limitations in terms of scalability and performance. Objective: This study aimed to evaluate the effectiveness of a generative pretrained transformer (GPT)-based large language model (LLM) in labeling radiology reports, comparing it with 2 existing methods, CheXbert and CheXpert, on a large chest X-ray dataset (MIMIC Chest X-ray [MIMIC-CXR]). Methods: In this study, we introduce an LLM-based approach fine-tuned on expert-labeled radiology reports. Our model’s performance was evaluated on 687 radiologist-labeled chest X-ray reports, comparing F1 scores across 14 thoracic pathologies. The performance of our LLM model was compared with the CheXbert and CheXpert models across positive, negative, and uncertainty extraction tasks. Paired t tests and Wilcoxon signed-rank tests were performed to evaluate the statistical significance of differences between model performances. Results: The GPT-based LLM model achieved an average F1 score of 0.9014 across all certainty levels, outperforming CheXpert (0.8864) and approaching CheXbert’s performance (0.9047). For positive and negative certainty levels, our model scored 0.8708, surpassing CheXpert (0.8525) and closely matching CheXbert (0.8733). Statistically, paired t tests indicated no significant difference between our model and CheXbert (P=.35) but a significant improvement over CheXpert (P=.01). Wilcoxon signed-rank tests corroborated these findings, showing no significant difference between our model and CheXbert (P=.14) but confirming a significant difference with CheXpert (P=.005). The LLM also demonstrated superior performance for pathologies with longer and more complex descriptions, leveraging its extended context length. Conclusions: The GPT-based LLM model demonstrates competitive performance compared with CheXbert and outperforms CheXpert in radiology report labeling. These findings suggest that LLMs are a promising alternative to traditional BERT-based architectures for this task, offering enhanced context understanding and eliminating the need for extensive feature engineering. Furthermore, with large context length LLM-based models are better suited for this task as compared with the small context length of BERT based models. © Abdullah Abdullah, Seong Tae Kim.},
	author_keywords = {BERT; generative pre-trained transformers; GPT; labeling; large language model; LLM; radiology report; thoracic pathologies},
	correspondence_address = {S.T. Kim; Department of Computer Science and Engineering, Kyung Hee University, Yongin, 1732 Deogyeong-daero, Giheung-gu, Gyeonggi-do, 17104, South Korea; email: st.kim@khu.ac.kr},
	publisher = {JMIR Publications Inc.},
	issn = {22919694},
	language = {English},
	abbrev_source_title = {JMIR Med. Inform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Ye2025128,
	author = {Ye, Dezhi and Hu, Junwei and Fan, Jiabin and Tian, Bowen and Liu, Jie and Liang, Haijin and Ma, Jin},
	title = {Best Practices for Distilling Large Language Models into BERT for Web Search Ranking},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	pages = {128 – 135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000152550&partnerID=40&md5=0fc45660f609f548a99f40d9bd31fb77},
	affiliations = {Tencent, China},
	abstract = {Recent studies have highlighted the significant potential of Large Language Models (LLMs) as zero-shot relevance rankers. These methods predominantly utilize prompt learning to assess the relevance between queries and documents by generating a ranked list of potential documents. Despite their promise, the substantial costs associated with LLMs pose a significant challenge for their direct implementation in commercial search systems. To overcome this barrier and fully exploit the capabilities of LLMs for text ranking, we explore techniques to transfer the ranking expertise of LLMs to a more compact model similar to BERT, using a ranking loss to enable the deployment of less resource-intensive models. Specifically, we enhance the training of LLMs through Continued Pre-Training, taking the query as input and the clicked title and summary as output. We then proceed with supervised fine-tuning of the LLM using a rank loss, assigning the final token as a representative of the entire sentence. Given the inherent characteristics of autoregressive language models, only the final token </s> can encapsulate all preceding tokens. Additionally, we introduce a hybrid point-wise and margin MSE loss to transfer the ranking knowledge from LLMs to smaller models like BERT. This method creates a viable solution for environments with strict resource constraints. Both offline and online evaluations have confirmed the efficacy of our approach, and our model has been successfully integrated into a commercial web search engine as of February 2024. ©2025 Association for Computational Linguistics.},
	keywords = {Learning to rank; Online searching; Query languages; Search engines; Structured Query Language; Zero-shot learning; Auto-regressive; Best practices; Compact model; Fine tuning; Inherent characteristics; Language model; Pre-training; Search system; Text rankings; Web search rankings; Computational linguistics},
	editor = {Rambow O. and Wanner L. and Apidianaki M. and Al-Khalifa H. and Di Eugenio B. and Schockaert S. and Darwish K. and Agarwal A.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176197-1},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Han2024,
	author = {Han, Jin and Zheng, Zhe and Lu, Xin-Zheng and Chen, Ke-Yin and Lin, Jia-Rui},
	title = {Enhanced earthquake impact analysis based on social media texts via large language model},
	year = {2024},
	journal = {International Journal of Disaster Risk Reduction},
	volume = {109},
	doi = {10.1016/j.ijdrr.2024.104574},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194562764&doi=10.1016%2fj.ijdrr.2024.104574&partnerID=40&md5=388b1d7fad8311f67097cb1c1a168d5f},
	affiliations = {Key Laboratory of Digital Construction and Digital Twin, Ministry of Housing and Urban-Rural Development, Beijing, 100084, China},
	abstract = {Social media aids disaster response but suffers from noise, hindering accurate impact assessment and decision making for resilient cities, which few studies considered. To address the problem, this study proposes the first domain-specific LLM model and an integrated method for rapid earthquake impact assessment. First, a few categories are introduced to classify and filter microblogs considering their relationship to the physical and social impacts of earthquakes, and a dataset comprising 7282 earthquake-related microblogs from twenty earthquakes in different locations is developed as well. Then, with a systematic analysis of various influential factors, QuakeBERT, a domain-specific large language model (LLM), is developed and fine-tuned for accurate classification and filtering of microblogs. Meanwhile, an integrated method integrating public opinion trend analysis, sentiment analysis, and keyword-based physical impact quantification is introduced to assess both the physical and social impacts of earthquakes based on social media texts. Experiments show that data diversity and data volume dominate the performance of QuakeBERT and increase the macro average F1 score by 27 %, while the best classification model QuakeBERT outperforms the CNN- or RNN-based models by improving the macro average F1 score from 60.87 % to 84.33 %. Finally, the proposed approach is applied to assess two earthquakes with the same magnitude and focal depth. Results show that the proposed approach can effectively enhance the impact assessment process by accurate detection of noisy microblogs, which enables effective post-disaster emergency responses to create more resilient cities. © 2024 Elsevier Ltd},
	author_keywords = {BERT; Earthquake; Impact assessment; Large language model; Social impact; Social media; Text mining},
	correspondence_address = {J.-R. Lin; Key Laboratory of Digital Construction and Digital Twin, Ministry of Housing and Urban-Rural Development, Beijing, 100084, China; email: lin611@tsinghua.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {22124209},
	language = {English},
	abbrev_source_title = {Int. J. Disaster Risk Reduct.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Pavlyshenko2025148,
	author = {Pavlyshenko, Bohdan and Stasiuk, Mykola},
	title = {Using Large Language Models for Data Augmentation in Text Classification Models},
	year = {2025},
	journal = {International Journal of Computing},
	volume = {24},
	number = {1},
	pages = {148 – 154},
	doi = {10.47839/ijc.24.1.3886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003233908&doi=10.47839%2fijc.24.1.3886&partnerID=40&md5=2ac7bd19166f8145fe5d6517e95e6691},
	affiliations = {System Design Department, Ivan Franko National University of Lviv, Lviv, 79005, Ukraine},
	abstract = {This research considers the impact of data augmentation on multi-class text classification. A diverse news dataset comprising four categories was utilized for training and evaluation. Various transformer models, including BERT, DistilBERT, ALBERT, and RoBERTa, were employed to classify text across multiple categories. Based on the previous research on data augmentation, synonym replacement, antonym replacement, contextual word embedding, and the lambada method for data augmentation were chosen. Three mainstream LLMs were selected to investigate the capabilities of LLMs: LLaMA 3, GPT-4, and MistralAI. These models represent a diverse range of architectures and training data, allowing to assess the impact of different LLM capabilities on data augmentation performance. The performance of the aforementioned transformer models was evaluated using metrics such as accuracy, recall, precision, F1-score, training time, validation, and training loss. Experiments revealed that data augmentation significantly improved the performance of transformer models in text classification tasks, with lambada augmentation consistently outperforming other methods. However, model architecture and hyperparameter tuning also played a crucial role in achieving optimal results. ROBERTa, in particular, required careful hyperparameter adjustment to reach competitive performance levels. Obtained results have practical implications for developing NLP applications in low-resource languages, as data augmentation can help address the limitations of small datasets. © (2025), (Research Institute of Intelligent Computer Systems). All rights reserved.},
	author_keywords = {ALBERT; augmentation; BERT; DistilBERT; large language models; multi-class text classification; transformers; XLM-RoBERTa},
	publisher = {Research Institute of Intelligent Computer Systems},
	issn = {17276209},
	language = {English},
	abbrev_source_title = {Int. J. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Levkovich2024,
	author = {Levkovich, Inbar and Omar, Mahmud},
	title = {Evaluating of BERT-based and Large Language Mod for Suicide Detection, Prevention, and Risk Assessment: A Systematic Review},
	year = {2024},
	journal = {Journal of Medical Systems},
	volume = {48},
	number = {1},
	doi = {10.1007/s10916-024-02134-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213725616&doi=10.1007%2fs10916-024-02134-3&partnerID=40&md5=c1f048bd6e6b4440490f197744188133},
	affiliations = {Tel-Hai Academic College, Upper Galilee, Qiryat Shemona, 2208, Israel; Faculty of Medicine, Tel-Aviv University, Tel-Aviv, Israel},
	abstract = {Suicide constitutes a public health issue of major concern. Ongoing progress in the field of artificial intelligence, particularly in the domain of large language models, has played a significant role in the detection, risk assessment, and prevention of suicide. The purpose of this review was to explore the use of LLM tools in various aspects of suicide prevention. PubMed, Embase, Web of Science, Scopus, APA PsycNet, Cochrane Library, and IEEE Xplore—for studies published were systematically searched for articles published between January 1, 2018, until April 2024. The 29 reviewed studies utilized LLMs such as GPT, Llama, and BERT. We categorized the studies into three main tasks: detecting suicidal ideation or behaviors, assessing the risk of suicidal ideation, and preventing suicide by predicting attempts. Most of the studies demonstrated that these models are highly efficient, often outperforming mental health professionals in early detection and prediction capabilities. Large language models demonstrate significant potential for identifying and detecting suicidal behaviors and for saving lives. Nevertheless, ethical problems still need to be examined and cooperation with skilled professionals is essential. © The Author(s) 2024.},
	author_keywords = {Artificial Intelligence; Large Language Models; Suicide; Systematic Review},
	keywords = {Artificial Intelligence; Humans; Risk Assessment; Suicidal Ideation; Suicide; Suicide Prevention; artificial intelligence; automutilation; comparative study; controlled study; electronic health record; female; human; large language model; mental health care personnel; meta analysis; Quality Assessment of Diagnostic Accuracy Studies; Review; risk assessment; social media; suicidal behavior; suicidal ideation; suicide; suicide attempt; suicide prevention; systematic review; transfer of learning; validation process; artificial intelligence; procedures; psychology; risk assessment; suicidal ideation; suicide},
	correspondence_address = {I. Levkovich; Tel-Hai Academic College, Qiryat Shemona, Upper Galilee, 2208, Israel; email: levkovinb@telhai.ac.il},
	publisher = {Springer},
	issn = {01485598},
	coden = {JMSYD},
	pmid = {39738935},
	language = {English},
	abbrev_source_title = {J. Med. Syst.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Larrondo2024,
	author = {Larrondo, Paula Francisca and Frank, Brian M. and Ortiz, Julian},
	title = {Work-in-Progress: Fine-Tuning Large Language Models for Automated Feedback in Complex Engineering Problem-Solving},
	year = {2024},
	journal = {ASEE Annual Conference and Exposition, Conference Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202019874&partnerID=40&md5=eb41ad92f7c44aab9b33e5f035ce64bb},
	affiliations = {Queen's University, Canada},
	abstract = {This paper presents work in progress (WIP) toward using artificial intelligence (AI), specifically through Large Language Models (LLM), to support rapid quality feedback mechanisms within engineering educational settings.It describes applying to LLMs to improve the feedback processes by providing information directly to students, graders, or course instructors teaching courses focused on complex engineering problem-solving.We detail how fine-tuning an LLM with a small dataset from diverse problem scenarios achieves classification accuracies close to approximately 80%, even in new problems not included in the fine-tuning process.Traditionally, open-source LLMs, like BERT, have been fine-tuned in large datasets for specific domain tasks.Our results suggest this may not be as critical in achieving good performances as previously thought.Our findings demonstrated the potential for applying AI-supported personalized feedback through high-level prompts incentivizing students to critically self-assess their problem-solving process and communication.However, this study also highlights the need for further research into how semantic diversity and synthetic data augmentation can optimize training datasets and impact model performance. © American Society for Engineering Education, 2024.},
	author_keywords = {Automated formative feedback; Complex problem-solving; Engineering Design; Large Language Models},
	keywords = {Curricula; Engineering education; Open source software; Problem oriented languages; Students; Teaching; Automated feedback; Automated formative feedback; Complex engineering problems; Complex problem solving; Engineering design; Engineering problem solving; Fine tuning; Formative feedbacks; Language model; Large language model; Semantics},
	publisher = {American Society for Engineering Education},
	issn = {21535965},
	language = {English},
	abbrev_source_title = {ASEE Annu. Conf. Expos. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhou2024,
	author = {Zhou, Yihan and Chen, Yan and Rao, Xuanming and Zhou, Yukang and Li, Yuxin and Hu, Chao},
	title = {Leveraging Large Language Models and BERT for Log Parsing and Anomaly Detection},
	year = {2024},
	journal = {Mathematics},
	volume = {12},
	number = {17},
	doi = {10.3390/math12172758},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203646702&doi=10.3390%2fmath12172758&partnerID=40&md5=6405c28c90f865218ac9fcb5c6eb891e},
	affiliations = {School of Computer Science and Engineering, Central South University, Changsha, 410083, China; Logistics Department, Central South University, Changsha, 410083, China; Department of Electrical and Information Engineering, Hong Kong Polytechnic University, Hong Kong; School of Computer Science and Engineering, Nanyang Technological University, Singapore, 639798, Singapore; School of Electronic Information, Central South University, Changsha, 410083, China},
	abstract = {Computer systems and applications generate large amounts of logs to measure and record information, which is vital to protect the systems from malicious attacks and useful for repairing faults, especially with the rapid development of distributed computing. Among various logs, the anomaly log is beneficial for operations and maintenance (O&M) personnel to locate faults and improve efficiency. In this paper, we utilize a large language model, ChatGPT, for the log parser task. We choose the BERT model, a self-supervised framework for log anomaly detection. BERT, an embedded transformer encoder, with a self-attention mechanism can better handle context-dependent tasks such as anomaly log detection. Meanwhile, it is based on the masked language model task and next sentence prediction task in the pretraining period to capture the normal log sequence pattern. The experimental results on two log datasets show that the BERT model combined with an LLM performed better than other classical models such as Deelog and Loganomaly. © 2024 by the authors.},
	author_keywords = {anomaly log detection; BERT; large language models; self-attention; transformer},
	correspondence_address = {C. Hu; School of Electronic Information, Central South University, Changsha, 410083, China; email: huchao@csu.edu.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22277390},
	language = {English},
	abbrev_source_title = {Mathematics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Gautam2025,
	author = {Gautam, Dipak and Kellmeyer, Philipp},
	title = {Exploring the Credibility of Large Language Models for Mental Health Support: Protocol for a Scoping Review},
	year = {2025},
	journal = {JMIR Research Protocols},
	volume = {14},
	doi = {10.2196/62865},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000392738&doi=10.2196%2f62865&partnerID=40&md5=4497e4f83850b71f3a0b2213882dbd3a},
	affiliations = {School of Business Informatics and Mathematics, University of Manneim, Mannheim, Germany; Data and Web Science Group, School of Business Informatics and Mathematics, University of Manneim, Mannheim, Germany; Human-Technology Interaction Lab, Department of Neurosurgery, University of Freiburg, Medical Center, Freiburg im Breisgau, Germany; Institute for Biomedical Ethics and History of Medicine, University of Zurich, Zurich, Switzerland},
	abstract = {Background: The rapid evolution of large language models (LLMs), such as Bidirectional Encoder Representations from Transformers (BERT; Google) and GPT (OpenAI), has introduced significant advancements in natural language processing. These models are increasingly integrated into various applications, including mental health support. However, the credibility of LLMs in providing reliable and explainable mental health information and support remains underexplored. Objective: This scoping review systematically maps the factors influencing the credibility of LLMs in mental health support, including reliability, explainability, and ethical considerations. The review is expected to offer critical insights for practitioners, researchers, and policy makers, guiding future research and policy development. These findings will contribute to the responsible integration of LLMs into mental health care, with a focus on maintaining ethical standards and user trust. Methods: This review follows PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines and the Joanna Briggs Institute (JBI) methodology. Eligibility criteria include studies that apply transformer-based generative language models in mental health support, such as BERT and GPT. Sources include PsycINFO, MEDLINE via PubMed, Web of Science, IEEE Xplore, and ACM Digital Library. A systematic search of studies from 2019 onward will be conducted and updated until October 2024. Data will be synthesized qualitatively. The Population, Concept, and Context framework will guide the inclusion criteria. Two independent reviewers will screen and extract data, resolving discrepancies through discussion. Data will be synthesized and presented descriptively. Results: As of September 2024, this study is currently in progress, with the systematic search completed and the screening phase ongoing. We expect to complete data extraction by early November 2024 and synthesis by late November 2024. Conclusions: This scoping review will map the current evidence on the credibility of LLMs in mental health support. It will identify factors influencing the reliability, explainability, and ethical considerations of these models, providing insights for practitioners, researchers, policy makers, and users. These findings will fill a critical gap in the literature and inform future research, practice, and policy development, ensuring the responsible integration of LLMs in mental health services. ©Dipak Gautam, Philipp Kellmeyer.},
	author_keywords = {credibility; explainability; large language model; LLM; mental health; mobile phone},
	correspondence_address = {P. Kellmeyer; Data and Web Science Group, School of Business Informatics and Mathematics, University of Manneim, B6, 26 Mannheim, D-68159, Germany; email: philipp.kellmeyer@uni-mannheim.de},
	publisher = {JMIR Publications Inc.},
	issn = {19290748},
	language = {English},
	abbrev_source_title = {JMIR Res. Prot.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Benson202490,
	author = {Benson, Ryzen and Elia, Marianna and Hyams, Benjamin and Chang, Ji Hyun and Hong, Julian C.},
	title = {A Narrative Review on the Application of Large Language Models to Support Cancer Care and Research},
	year = {2024},
	journal = {Yearbook of medical informatics},
	volume = {33},
	number = {1},
	pages = {90 – 98},
	doi = {10.1055/s-0044-1800726},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003160962&doi=10.1055%2fs-0044-1800726&partnerID=40&md5=670fcff06c47cd99d1fb8e211576ad58},
	affiliations = {Department of Radiation Oncology, University of California, San Francisco, CA, United States; Bakar Computational Health Sciences Institute, University of California, San Francisco, CA, United States; School of Medicine, University of California, San Francisco, CA, United States; Department of Radiation Oncology, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, South Korea; UCSF UC Berkeley Joint Program in Computational Precision Health (CPH), San Francisco, CA, United States},
	abstract = {OBJECTIVES: The emergence of large language models has resulted in a significant shift in informatics research and carries promise in clinical cancer care. Here we provide a narrative review of the recent use of large language models (LLMs) to support cancer care, prevention, and research. METHODS: We performed a search of the Scopus database for studies on the application of bidirectional encoder representations from transformers (BERT) and generative-pretrained transformer (GPT) LLMs in cancer care published between the start of 2021 and the end of 2023. We present salient and impactful papers related to each of these themes. RESULTS: Studies identified focused on aspects of clinical decision support (CDS), cancer education, and support for research activities. The use of LLMs for CDS primarily focused on aspects of treatment and screening planning, treatment response, and the management of adverse events. Studies using LLMs for cancer education typically focused on question-answering, assessing cancer myths and misconceptions, and text summarization and simplification. Finally, studies using LLMs to support research activities focused on scientific writing and idea generation, cohort identification and extraction, clinical data processing, and NLP-centric tasks. CONCLUSIONS: The application of LLMs in cancer care has shown promise across a variety of diverse use cases. Future research should utilize quantitative metrics, qualitative insights, and user insights in the development and evaluation of LLM-based cancer care tools. The development of open-source LLMs for use in cancer care research and activities should also be a priority. The Author(s). This is an open access article published by Thieme under the terms of the Creative Commons Attribution License, permitting unrestricted use, distribution, and reproduction so long as the original work is properly cited. (https://creativecommons.org/licenses/by/4.0/).},
	keywords = {Biomedical Research; Decision Support Systems, Clinical; Humans; Language; Large Language Models; Natural Language Processing; Neoplasms; clinical decision support system; human; language; large language model; medical research; natural language processing; neoplasm; prevention and control; therapy},
	issn = {23640502},
	pmid = {40199294},
	language = {English},
	abbrev_source_title = {Yearb Med Inform},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Padilla Cuevas2024,
	author = {Padilla Cuevas, Josué and Reyes-Ortiz, José A. and Cuevas-Rasgado, Alma D. and Mora-Gutiérrez, Román A. and Bravo, Maricela},
	title = {MédicoBERT: A Medical Language Model for Spanish Natural Language Processing Tasks with a Question-Answering Application Using Hyperparameter Optimization},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {16},
	doi = {10.3390/app14167031},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202440936&doi=10.3390%2fapp14167031&partnerID=40&md5=973ebb5ab1960d76c7fb616adc0bad98},
	affiliations = {Computer Engineering, Universidad Autónoma del Estado de Mexico CU, Texcoco, 56259, Mexico; Systems Department, Autonomous Metropolitan University, Azcapotzalco, Mexico City, 02200, Mexico},
	abstract = {The increasing volume of medical information available in digital format presents a significant challenge for researchers seeking to extract relevant information. Manually analyzing voluminous data is a time-consuming process that constrains researchers’ productivity. In this context, innovative and intelligent computational approaches to information search, such as large language models (LLMs), offer a promising solution. LLMs understand natural language questions and respond accurately to complex queries, even in the specialized domain of medicine. This paper presents MédicoBERT, a medical language model in Spanish developed by adapting a general domain language model (BERT) to medical terminology and vocabulary related to diseases, treatments, symptoms, and medications. The model was pre-trained with 3 M medical texts containing 1.1 B words. Furthermore, with promising results, MédicoBERT was adapted and evaluated to answer medical questions in Spanish. The question-answering (QA) task was fine-tuned using a Spanish corpus of over 34,000 medical questions and answers. A search was then conducted to identify the optimal hyperparameter configuration using heuristic methods and nonlinear regression models. The evaluation of MédicoBERT was carried out using metrics such as perplexity to measure the adaptation of the language model to the medical vocabulary in Spanish, where it obtained a value of 4.28, and the average F1 metric for the task of answering medical questions, where it obtained a value of 62.35%. The objective of MédicoBERT is to provide support for research in the field of natural language processing (NLP) in Spanish, with a particular emphasis on applications within the medical domain. © 2024 by the authors.},
	author_keywords = {BERT; fine-tuning; hyperparameter optimization; LLM; MédicoBERT; NLP benchmark; pre-training model; question answering; Spanish medical language modeling},
	keywords = {Benchmarking; Computational linguistics; Disease control; Medical computing; Medical information systems; Medicinal chemistry; Modeling languages; Query languages; Regression analysis; Structured Query Language; Terminology; BERT; Fine tuning; Hyper-parameter optimizations; Language model; Language processing; Large language model; Medicobert; Natural language processing benchmark; Natural languages; Pre-training; Pre-training model; Question Answering; Spanish medical language modeling; Training model; Natural language processing systems},
	correspondence_address = {A.D. Cuevas-Rasgado; Computer Engineering, Universidad Autónoma del Estado de Mexico CU, Texcoco, 56259, Mexico; email: almadeliacuevas@gmail.com},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20763417},
	language = {English},
	abbrev_source_title = {Appl. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Xie2025511,
	author = {Xie, Yiran and Xiao, Debin and Wang, Ping and Liu, Shuming},
	title = {A Simple yet Efficient Prompt Compression Method for Text Classification Data Annotation Using LLM},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	pages = {511 – 521},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000218280&partnerID=40&md5=ab104c23473d7b996c40f0bf14cdda49},
	affiliations = {The Chinese University of Hong Kong, Shenzhen, China; Guangdong OPPO Mobile Telecommunications Corp., Ltd., Shenzhen, China},
	abstract = {Effectively balancing accuracy and cost is a critical challenge when using large language models (LLMs) for corpus annotation. This paper introduces a novel compression method based on keyword extraction (PCKE) that effectively reduces the number of prompt tokens in text classification annotation tasks, with minimal to no loss in accuracy. Our approach begins with an LLM that generates both category labels and relevant keywords from a small set of unannotated data. These outputs are used to train a BERT-based multi-task model capable of classification and keyword extraction. For larger unannotated corpora, this model extracts keywords which are then used in place of full texts for LLM annotation. The significant reduction in prompt tokens results in substantial cost savings. Furthermore, using a few well-chosen keywords ensures that classification accuracy is maintained. Extensive experiments validate that our method not only achieves a superior compression rate but also maintains high accuracy, outperforming existing general-purpose compression techniques. Our approach offers a practical and cost-efficient solution for large-scale text classification annotation using LLMs, particularly applicable in industrial settings. ©2025 Association for Computational Linguistics.},
	keywords = {Classification (of information); Data accuracy; % reductions; Compression methods; Corpus annotations; Critical challenges; Data annotation; Keywords extraction; Language model; Multi-task model; Simple++; Text classification; Computational linguistics},
	editor = {Rambow O. and Wanner L. and Apidianaki M. and Al-Khalifa H. and Di Eugenio B. and Schockaert S. and Darwish K. and Agarwal A.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176197-1},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Anders202589,
	author = {Anders, Michael and Paech, Barbara},
	title = {FeReRe: Feedback Requirements Relation Using Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science},
	volume = {15588 LNCS},
	pages = {89 – 105},
	doi = {10.1007/978-3-031-88531-0_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002719989&doi=10.1007%2f978-3-031-88531-0_7&partnerID=40&md5=97a028a428d5596cf35a4a6fda27734b},
	affiliations = {Heidelberg University, Im Neuenheimer Feld 205, Heidelberg, 69121, Germany},
	abstract = {Context and Motivation: Software must be improved continuously to meet the users’ expectations. User feedback from online sources allows developers to include the users in the development process when direct communication is impossible. To address the issues raised by feedback, developers must understand which functionalities the users are discussing. Question/Problem: However, manually relating feedback to requirements is too time-consuming. Automatic classification, on the other hand, struggles with the problem that developers and users use different languages when writing feedback and requirements. Principal Ideas/Results: In this paper, we introduce the FeReRe approach for feedback requirements relation. The approach uses a BERT classifier to perform feedback requirements relation on a per-sentence basis. We evaluate the BERT classifier’s performance on multiple datasets and compare it to the performance of the generative LLM GPT4o. BERT achieves an F2 of 0.91 when trained on all available datasets. GPT4o, on the other hand, performs the task poorly, achieving an F2 of only 0.30. Contribution: The paper presents a novel approach for feedback requirements relation along with multiple manually created datasets for training and testing of the presented approach. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {BERT; Feedback; GenAI; GPT; LLM; Relation; Requirements; Traceability},
	keywords = {Modeling languages; Problem oriented languages; Program processors; BERT; GenAI; GPT; Language model; LLM; Performance; Relation; Requirement; Traceability; User expectations; Classification (of information)},
	correspondence_address = {M. Anders; Heidelberg University, Heidelberg, Im Neuenheimer Feld 205, 69121, Germany; email: michael.anders@informatik.uni-heidelberg.de},
	editor = {Hess A. and Susi A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303188530-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Doneva2024,
	author = {Doneva, Simona Emilova and Qin, Sijing and Sick, Beate and Ellendorff, Tilia and Goldman, Jean-Philippe and Schneider, Gerold and Ineichen, Benjamin Victor},
	title = {Large language models to process, analyze, and synthesize biomedical texts: a scoping review},
	year = {2024},
	journal = {Discover Artificial Intelligence},
	volume = {4},
	number = {1},
	doi = {10.1007/s44163-024-00197-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212788933&doi=10.1007%2fs44163-024-00197-2&partnerID=40&md5=891b0268226914ea56dd28aa799650fb},
	affiliations = {Center for Reproducible Science, University of Zurich, Zurich, Switzerland; Division of Biostatistics, EBPI, University of Zurich, Zurich, Switzerland; Department of Computational Linguistics, University of Zurich, Zurich, Switzerland; Clinical Neuroscience Center, University of Zurich, Zurich, Switzerland; ZHAW School of Engineering, Zurich University of Applied Science (ZHAW), Winterthur, Switzerland},
	abstract = {The advent of large language models (LLMs) such as BERT and, more recently, GPT, is transforming our approach of analyzing and understanding biomedical texts. To stay informed about the latest advancements in this area, there is a need for up-to-date summaries on the role of LLM in Natural Language Processing (NLP) of biomedical texts. Thus, this scoping review aims to provide a detailed overview of the current state of biomedical NLP research and its applications, with a special focus on the evolving role of LLMs. We conducted a systematic search of PubMed, EMBASE, and Google Scholar for studies and conference proceedings published from 2017 to December 19, 2023, that develop or utilize LLMs for NLP tasks in biomedicine. We evaluated the risk of bias in these studies using a 3-item checklist. From 13,823 references, we selected 199 publications and conference proceedings for our review. LLMs are being applied to a wide array of tasks in the biomedical field, including knowledge management, text mining, drug discovery, and evidence synthesis. Prominent among these tasks are text classification, relation extraction, and named entity recognition. Although BERT-based models remain prevalent, the use of GPT-based models has substantially increased since 2023. We conclude that, despite offering opportunities to manage the growing volume of biomedical data, LLMs also present challenges, particularly in clinical medicine and evidence synthesis, such as issues with transparency and privacy concerns. © The Author(s) 2024.},
	author_keywords = {BERT; Bioinformatics; Biomedicine; Evidence synthesis; Large language models; Natural language processing},
	keywords = {Reviews; BERT; Biomedical text; Biomedicine; Evidence synthesis; Language model; Language processing; Large language model; Natural language processing; Natural languages; Scoping review; Natural language processing systems},
	correspondence_address = {S.E. Doneva; Center for Reproducible Science, University of Zurich, Zurich, Switzerland; email: simona.doneva@uzh.ch},
	publisher = {Springer Nature},
	issn = {27310809},
	language = {English},
	abbrev_source_title = {Discov. Artif. Intell.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Zhong2025,
	author = {Zhong, Qishuai and Sun, Aixin},
	title = {Punctuation Restoration: A Case Study of BERT-Based Models' Task-Specific Excellence},
	year = {2025},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	doi = {10.1109/ICASSP49660.2025.10889374},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003863129&doi=10.1109%2fICASSP49660.2025.10889374&partnerID=40&md5=9b84a11da5c5780757af2c3e36d9cc7d},
	affiliations = {Nanyang Technological University, Singapore},
	abstract = {Large Language Models (LLMs) have made remarkable strides in various tasks, yet their suitability for restoring punctuation in ASR-generated transcripts remains underexplored. Through extensive experiments, we demonstrate that LLMs tend to repeatedly use the same punctuation marks and alter input text tokens, in addition to incurring high computational costs. In contrast, a simple two-stage BERT-based method-which first identifies punctuation positions and then predicts the correct punctuation types-achieves the best accuracy with at least a 10x speed improvement. © 2025 IEEE.},
	author_keywords = {BERT; LLM; Punctuation Restoration},
	editor = {Rao B.D. and Trancoso I. and Sharma G. and Mehta N.B.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15206149},
	isbn = {979-835036874-1},
	coden = {IPROD},
	language = {English},
	abbrev_source_title = {ICASSP IEEE Int Conf Acoust Speech Signal Process Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2024,
	author = {Li, Wenchao and Liu, Haitao},
	title = {Applying large language models for automated essay scoring for non-native Japanese},
	year = {2024},
	journal = {Humanities and Social Sciences Communications},
	volume = {11},
	number = {1},
	doi = {10.1057/s41599-024-03209-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195378013&doi=10.1057%2fs41599-024-03209-9&partnerID=40&md5=2df4ec39be1d1b6ad1fd8d241c682779},
	affiliations = {Department of Japanese Studies, Zhejiang University, Hangzhou, China; Department of Linguistics and Applied Linguistics, Zhejiang University, Hangzhou, China},
	abstract = {Recent advancements in artificial intelligence (AI) have led to an increased use of large language models (LLMs) for language assessment tasks such as automated essay scoring (AES), automated listening tests, and automated oral proficiency assessments. The application of LLMs for AES in the context of non-native Japanese, however, remains limited. This study explores the potential of LLM-based AES by comparing the efficiency of different models, i.e. two conventional machine training technology-based methods (Jess and JWriter), two LLMs (GPT and BERT), and one Japanese local LLM (Open-Calm large model). To conduct the evaluation, a dataset consisting of 1400 story-writing scripts authored by learners with 12 different first languages was used. Statistical analysis revealed that GPT-4 outperforms Jess and JWriter, BERT, and the Japanese language-specific trained Open-Calm large model in terms of annotation accuracy and predicting learning levels. Furthermore, by comparing 18 different models that utilize various prompts, the study emphasized the significance of prompts in achieving accurate and reliable evaluations using LLMs. © The Author(s) 2024.},
	correspondence_address = {W. Li; Department of Japanese Studies, Zhejiang University, Hangzhou, China; email: widelia@zju.edu.cn},
	publisher = {Springer Nature},
	issn = {26629992},
	language = {English},
	abbrev_source_title = {Hum. Soc. Sci. Comm},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Chen2025,
	author = {Chen, David and Alnassar, Saif Addeen and Avison, Kate Elizabeth and Huang, Ryan S. and Raman, Srinivas},
	title = {Large Language Model Applications for Health Information Extraction in Oncology: Scoping Review},
	year = {2025},
	journal = {JMIR Cancer},
	volume = {11},
	doi = {10.2196/65984},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002838221&doi=10.2196%2f65984&partnerID=40&md5=86f8b13039c2c06c4fc6bb5567a98dfe},
	affiliations = {Temerty Faculty of Medicine, University of Toronto, Toronto, ON, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Radiation Oncology, BC Cancer Vancouver, Vancouver, BC, Canada},
	abstract = {Background: Natural language processing systems for data extraction from unstructured clinical text require expert-driven input for labeled annotations and model training. The natural language processing competency of large language models (LLM) can enable automated data extraction of important patient characteristics from electronic health records, which is useful for accelerating cancer clinical research and informing oncology care. Objective: This scoping review aims to map the current landscape, including definitions, frameworks, and future directions of LLMs applied to data extraction from clinical text in oncology. Methods: We queried Ovid MEDLINE for primary, peer-reviewed research studies published since 2000 on June 2, 2024, using oncology- and LLM-related keywords. This scoping review included studies that evaluated the performance of an LLM applied to data extraction from clinical text in oncology contexts. Study attributes and main outcomes were extracted to outline key trends of research in LLM-based data extraction. Results: The literature search yielded 24 studies for inclusion. The majority of studies assessed original and fine-tuned variants of the BERT LLM (n=18, 75%) followed by the Chat-GPT conversational LLM (n=6, 25%). LLMs for data extraction were commonly applied in pan-cancer clinical settings (n=11, 46%), followed by breast (n=4, 17%), and lung (n=4, 17%) cancer contexts, and were evaluated using multi-institution datasets (n=18, 75%). Comparing the studies published in 2022-2024 versus 2019-2021, both the total number of studies (18 vs 6) and the proportion of studies using prompt engineering increased (5/18, 28% vs 0/6, 0%), while the proportion using fine-tuning decreased (8/18, 44.4% vs 6/6, 100%). Advantages of LLMs included positive data extraction performance and reduced manual workload. Conclusions: LLMs applied to data extraction in oncology can serve as useful automated tools to reduce the administrative burden of reviewing patient health records and increase time for patient-facing care. Recent advances in prompt-engineering and fine-tuning methods, and multimodal data extraction present promising directions for future research. Further studies are needed to evaluate the performance of LLM-enabled data extraction in clinical domains beyond the training dataset and to assess the scope and integration of LLMs into real-world clinical environments. © 2025 JMIR Publications Inc.. All rights reserved.},
	author_keywords = {AI; artificial intelligence; chatbot; conversational agent; data extraction; digital health; electronic health record; health information; health technology; large language model; LLM; natural language processing; NLP; oncology; scoping review},
	keywords = {artificial intelligence; ChatGPT; clinical research; data extraction; digital health; human; information processing; interrater reliability; large language model; medical information; prompt engineering; publication; Review; systematic review; workload},
	correspondence_address = {S. Raman; Department of Radiation Oncology, BC Cancer Vancouver, Vancouver, 600 W 10th Ave, V5Z 4E6, Canada; email: srinivas.raman@bccancer.bc.ca},
	publisher = {JMIR Publications Inc.},
	issn = {23691999},
	language = {English},
	abbrev_source_title = {JMIR Cancer},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kulin2024588,
	author = {Kulin, Nikita I. and Muravyov, Sergey B.},
	title = {Advanced methods for knowledge injection in large language models; [Продвинутые методы внедрения знаний в больших языковых моделях]},
	year = {2024},
	journal = {Scientific and Technical Journal of Information Technologies, Mechanics and Optics},
	volume = {24},
	number = {4},
	pages = {588 – 593},
	doi = {10.17586/2226-1494-2024-24-4-588-593},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203181792&doi=10.17586%2f2226-1494-2024-24-4-588-593&partnerID=40&md5=f833c14533fe392de79abff17b094652},
	affiliations = {ITMO University, Saint Petersburg, 197101, Russian Federation},
	abstract = {Transformer-based language models have revolutionized Natural Language Processing tasks, with advancements in language modeling techniques. Current transformer architectures utilize attention mechanisms to model text dependencies effectively. Studies have shown that these models embed syntactic structures and knowledge, explaining their performance in tasks involving syntactic and semantic elements. However, transformer-based models are prone to hallucination where incorporated knowledge is not utilized effectively. To address this, methods are emerging to mitigate hallucination and integrate external knowledge sources like knowledge graphs (e.g., Freebase, WordNet, ConceptNet, ATOMIC). Knowledge graphs represent real-world knowledge through entities and relationships offering a potential injection point to enhance model performance in inference tasks. Various injection approaches, including input, architectural, and output injections, aim to incorporate knowledge from graphs into transformer models. Input injections modify data preprocessing, architectural injections add layers for knowledge integration, and output injections adjust error functions to correct knowledge incorporation during training. Despite ongoing research, a universal solution to hallucination remains elusive, and a standardized benchmark for comparing injection methods is lacking. This study investigates knowledge graphs as one of the methods to mitigate hallucination and their possible integration into Large Language Models. Comparative experiments across General Language Understanding Evaluation benchmark tasks demonstrated that ERNIE 3.0 and XLNet outperform other injection methods with the average scores of 91.1 % and 90.1 %. © Kulin N.I., Muravyov S.B., 2024.},
	author_keywords = {BERT; hallucination problem; knowledge graphs; knowledge injection methods; LLM},
	correspondence_address = {N.I. Kulin; ITMO University, Saint Petersburg, 197101, Russian Federation; email: kylin98@list.ru},
	publisher = {ITMO University},
	issn = {22261494},
	language = {English},
	abbrev_source_title = {Sci. Tech. J. Inf. Tech. Mech. Optics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Latif2024,
	author = {Latif, Ehsan and Zhai, Xiaoming},
	title = {Fine-tuning ChatGPT for automatic scoring},
	year = {2024},
	journal = {Computers and Education: Artificial Intelligence},
	volume = {6},
	doi = {10.1016/j.caeai.2024.100210},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184523347&doi=10.1016%2fj.caeai.2024.100210&partnerID=40&md5=b204de8b8aac19bd962b4ad8e8a0cf17},
	affiliations = {AI4STEM Education Center, University of Georgia, Athens, GA, United States},
	abstract = {This study highlights the potential of fine-tuned ChatGPT (GPT-3.5) for automatically scoring student written constructed responses using example assessment tasks in science education. The application of ChatGPT in research and academic fields has greatly enhanced productivity and efficiency. Recent studies on ChatGPT based on OpenAI's generative model GPT-3.5 proved its superiority in predicting the natural language with high accuracy and human-like responses. GPT-3.5 has been trained over enormous online language materials such as journals and Wikipedia; however, direct usage of pre-trained GPT-3.5 is insufficient for automatic scoring as students do not utilize the same language as journals or Wikipedia, and contextual information is required for accurate scoring. All of these imply that a fine-tuning of a domain-specific model using data for specific tasks can enhance model performance. In this study, we fine-tuned GPT-3.5 on six assessment tasks with a diverse dataset of middle-school and high-school student responses and expert scoring. The six tasks comprise two multi-label and four multi-class assessment tasks. We compare the performance of fine-tuned GPT-3.5 with the fine-tuned state-of-the-art Google's generated language model, BERT. The results show that in-domain training corpora constructed from science questions and responses for BERT achieved average accuracy = 0.838, SD = 0.069. GPT-3.5 shows a remarkable average increase (9.1%) in automatic scoring accuracy (mean = 9.15, SD = 0.042) for the six tasks, p =0.001 < 0.05. Specifically, for each of the two multi-label tasks (item 1 with 5 labels; item 2 with 10 labels), GPT-3.5 achieved significantly higher scoring accuracy than BERT across all the labels, with the second item achieving a 7.1% increase. The average scoring increase for the four multi-class items for GPT-3.5 was 10.6% compared to BERT. Our study confirmed the effectiveness of fine-tuned GPT-3.5 for automatic scoring of student responses on domain-specific data in education with high accuracy. We have released fine-tuned models for public use and community engagement. © 2024 The Author(s)},
	author_keywords = {Automatic scoring; BERT; Education; Finetune; GPT-3.5; Large language model (LLM)},
	keywords = {Computational linguistics; Education computing; Assessment tasks; Automatic scoring; BERT; Fine tuning; Finetune; GPT-3.5; High-accuracy; Language model; Large language model; Wikipedia; Students},
	correspondence_address = {X. Zhai; AI4STEM Education Center, University of Georgia, Athens, United States; email: xiaoming.zhai@uga.edu},
	publisher = {Elsevier B.V.},
	issn = {2666920X},
	language = {English},
	abbrev_source_title = {Comput. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 60; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Nowacki2025,
	author = {Nowacki, Arkadiusz and Sitek, Wojciech and Rybiński, Henryk},
	title = {LLM-based classifiers for discovering mental disorders},
	year = {2025},
	journal = {Journal of Intelligent Information Systems},
	doi = {10.1007/s10844-025-00934-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001925943&doi=10.1007%2fs10844-025-00934-8&partnerID=40&md5=9c98ecbbe2ddd8e8541d7619c35d3029},
	affiliations = {Institute of Computer Science, Warsaw University of Technology, Warszawa, Poland},
	abstract = {The increasing number of mental disorders is a serious problem in the modern world and can even lead to suicide if left untreated. In the age of digitalization, we move part of our lives to social networks, where we share the good and bad moments. This allows for the detection of early mental disorders (such as depression, excessive stress, or social phobia) that the user may not even be aware of. We address the problem of effectively using large language models (LLMs) to detect mental disorders. In particular, we propose modifying LLMs by adding appropriate layers to improve the classification parameters and build classifiers for discovering mental disorders from texts. We have performed experiments with PHI-2, PHI-3, Mistral, Flan-T5, and LLaMA 2/3/3.1, showing that such an approach gives a better prediction performance than zero-shot/few-shot for LLMs and classification by BERT-based models. The proposed architecture makes it possible to return a label thus giving a specific classification of the case, rather than an ambiguous answer text. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.},
	author_keywords = {Large language models; Mental disorders classification; Mental health analysis; Social media},
	keywords = {Classification (of information); Classification parameters; Language model; Large language model; Mental disorder classification; Mental disorders; Mental health; Mental health analyze; Model-based classifiers; Social media; Social phobias; Social networking (online)},
	correspondence_address = {A. Nowacki; Institute of Computer Science, Warsaw University of Technology, Warszawa, Poland; email: arkadiusz.nowacki.stud@pw.edu.pl},
	publisher = {Springer},
	issn = {09259902},
	coden = {JIISE},
	language = {English},
	abbrev_source_title = {J Intell Inform Syst},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Volkmer2024,
	author = {Volkmer, Sebastian and Meyer-Lindenberg, Andreas and Schwarz, Emanuel},
	title = {Large language models in psychiatry: Opportunities and challenges},
	year = {2024},
	journal = {Psychiatry Research},
	volume = {339},
	doi = {10.1016/j.psychres.2024.116026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196495175&doi=10.1016%2fj.psychres.2024.116026&partnerID=40&md5=9c7c8587798bc7e6ecf873bf672c0caf},
	affiliations = {Hector Institute for Artificial Intelligence in Psychiatry, Central Institute of Mental Health, Medical Faculty Mannheim, Heidelberg University, Mannheim, Germany; Department of Psychiatry and Psychotherapy, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg, Mannheim, Germany},
	abstract = {The ability of Large Language Models (LLMs) to analyze and respond to freely written text is causing increasing excitement in the field of psychiatry; the application of such models presents unique opportunities and challenges for psychiatric applications. This review article seeks to offer a comprehensive overview of LLMs in psychiatry, their model architecture, potential use cases, and clinical considerations. LLM frameworks such as ChatGPT/GPT-4 are trained on huge amounts of text data that are sometimes fine-tuned for specific tasks. This opens up a wide range of possible psychiatric applications, such as accurately predicting individual patient risk factors for specific disorders, engaging in therapeutic intervention, and analyzing therapeutic material, to name a few. However, adoption in the psychiatric setting presents many challenges, including inherent limitations and biases in LLMs, concerns about explainability and privacy, and the potential damage resulting from produced misinformation. This review covers potential opportunities and limitations and highlights potential considerations when these models are applied in a real-world psychiatric context. © 2024},
	author_keywords = {BERT; GPT; Hallucination; Llama; Medical question answering; PaLM; Therapy; Transformer},
	keywords = {Humans; Language; Mental Disorders; Psychiatry; Article; hallucination; health care cost; health care personnel; human; large language model; learning disorder; mental health service; psychiatry; psychosis; risk assessment; language; mental disease; procedures},
	correspondence_address = {E. Schwarz; Hector Institute for Artificial Intelligence in Psychiatry, Central Institute of Mental Health, Medical Faculty Mannheim, Heidelberg University, Mannheim, Germany; email: emanuel.schwarz@zi-mannheim.de},
	publisher = {Elsevier Ireland Ltd},
	issn = {01651781},
	coden = {PSRSD},
	pmid = {38909412},
	language = {English},
	abbrev_source_title = {Psychiatry Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Khan20248347,
	author = {Khan, Muhammad Asif and Prasad, Bhuyan Kaibalya and Qi, Guilin and Song, Wei and Ye, Fanghua and Ali, Zafar and Ullah, Irfan and Kefalas, Pavlos},
	title = {UTMGAT: a unified transformer with memory encoder and graph attention networks for multidomain dialogue state tracking},
	year = {2024},
	journal = {Applied Intelligence},
	volume = {54},
	number = {17-18},
	pages = {8347 – 8366},
	doi = {10.1007/s10489-024-05571-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196916524&doi=10.1007%2fs10489-024-05571-2&partnerID=40&md5=8cf8f795404e54cfda411496316629d9},
	affiliations = {School of Computer Science and Engineering Southeast University, Nanjing, China; National Institute of Technology, Department of Electronics and Communication Engineering, Rourkela, India; Research Center for Intelligent Robotics, Zhejiang Lab, Zhejiang Province, Hangzhou, China; University College London, London, United Kingdom; Department of Computer Science, Shaheed Benazir Bhutto University, Sheringal, Pakistan; Department of Informatics, Aristotle University, Thessaloniki, Greece},
	abstract = {Spoken dialogue systems (SDS) heavily rely on dialogue state tracking (DST) for success. However, providing sufficient computational power for training proves challenging, given that DST involves tracking states from both user and system utterances. While machine learning approaches have improved DST, they have notable limitations. These approaches often overlook unseen slot values during training and use two separate modules to extract, generate, or match slot values, leading to high time and resource consumption. Moreover, learning and deducing relevant values for related slots remain understudied challenges. To address these gaps, this paper introduces UTMGAT-a Unified Transformer with Memory Encoder and Graph Attention Networks (GAT) for Multidomain DST. UTMGAT employs a BERT tokenizer to construct user utterances and a candidate sets vocabulary, reducing the need for constant retraining when dealing with unseen values. It utilizes a single transformer to gather dialogue context for slots and generate slot values, enhancing prediction accuracy while reducing memory and computation time. UTMGAT incorporates an embedding layer aggregator to filter out unnecessary values, identify required nodes for GAT, and establish relationships among relevant values associated with related slots. This approach simplifies graph representation and diminishes required computation power. The input to the GAT maintains equal size with batch sizes, generated through padding. Finally, we have experimentally evaluated our model against several models including LLM approaches over four popular datasets with our approach outperforming all competing models except two approaches on one dataset. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Classification; Graph attention networks; Multi-domain dialogue state tracking; Spoken dialogue systems; Transformer},
	keywords = {Learning systems; Speech recognition; Computational power; Graph attention network; Machine learning approaches; Memory encoders; Multi-domain dialog state tracking; Multi-domains; Spoken dialogue system; State tracking; Time consumption; Transformer; Speech processing},
	correspondence_address = {G. Qi; School of Computer Science and Engineering Southeast University, Nanjing, China; email: gqi@seu.edu.cn; W. Song; Research Center for Intelligent Robotics, Hangzhou, Zhejiang Lab, Zhejiang Province, China; email: weisong@zhejianglab.com},
	publisher = {Springer},
	issn = {0924669X},
	coden = {APITE},
	language = {English},
	abbrev_source_title = {Appl Intell},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Li202411,
	author = {Li, Peiyan and Liu, Xiaomeng and Wang, Yongxing},
	title = {A Novel Method based on Large Language Model for MBTI Classification: A Novel MBTI Classification Method},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {11 – 16},
	doi = {10.1145/3675249.3675253},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201292966&doi=10.1145%2f3675249.3675253&partnerID=40&md5=d7761af8a3c1634a756f467929753de4},
	affiliations = {Department of Statistics, Columbia University, New York, 10027, NY, United States; State Key Laboratory of Media Convergence Production Technology and Systems Xinhua News Agency, Beijing, 100077, China},
	abstract = {Personality analysis has a wide and important application in psychology, helping us explain various psychological phenomena and the developmental laws of personality. Accurately identifying personality will contribute to research in fields such as cognitive science, public opinion analysis, and cybersecurity. The most widely used models in the field of personality recognition are the Big Five personality model and MBTI model in trait genre. With the rise of social media and Large Language Model(LLM), massive corpora and deep learning models have been used for personality analysis and have achieved good results. In view of this, this article introduces a novel method based on transformer-based pre-trained language model named mDeBERTa and uses the MBTI-500 and MBTI-1 datasets as examples to demonstrate the advantages of this model over traditional SVM models and BERT models. At the same time, we explore the possibility of using large models and multimodal data for more accurate personality analysis.  © 2024 ACM.},
	author_keywords = {large language model; MBTI; mDeBERTa},
	keywords = {Adversarial machine learning; Classification (of information); Deep learning; Classification methods; Cognitive science; In-field; Language model; Large language model; MBTI; MDeBERTa; Novel methods; Opinion analysis; Public opinions; Contrastive Learning},
	correspondence_address = {Y. Wang; State Key Laboratory of Media Convergence Production Technology and Systems Xinhua News Agency, Beijing, 100077, China; email: wangyongxing@chinaso.com},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071826-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Karlsen2024,
	author = {Karlsen, Egil and Luo, Xiao and Zincir-Heywood, Nur and Heywood, Malcolm},
	title = {Benchmarking Large Language Models for Log Analysis, Security, and Interpretation},
	year = {2024},
	journal = {Journal of Network and Systems Management},
	volume = {32},
	number = {3},
	doi = {10.1007/s10922-024-09831-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195918558&doi=10.1007%2fs10922-024-09831-x&partnerID=40&md5=fccd573e62ca6495facbaa37de76ff1a},
	affiliations = {Faculty of Computer Science, Dalhousie University, University Ave., Halifax, B3H 1W5, NS, Canada; Department of Management Science and Information Systems, Oklahoma State University, 370 Business Building, Stillwater, 74078, OK, United States},
	abstract = {Large Language Models (LLM) continue to demonstrate their utility in a variety of emergent capabilities in different fields. An area that could benefit from effective language understanding in cybersecurity is the analysis of log files. This work explores LLMs with different architectures (BERT, RoBERTa, DistilRoBERTa, GPT-2, and GPT-Neo) that are benchmarked for their capacity to better analyze application and system log files for security. Specifically, 60 fine-tuned language models for log analysis are deployed and benchmarked. The resulting models demonstrate that they can be used to perform log analysis effectively with fine-tuning being particularly important for appropriate domain adaptation to specific log types. The best-performing fine-tuned sequence classification model (DistilRoBERTa) outperforms the current state-of-the-art; with an average F1-Score of 0.998 across six datasets from both web application and system log sources. To achieve this, we propose and implement a new experimentation pipeline (LLM4Sec) which leverages LLMs for log analysis experimentation, evaluation, and analysis. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {BERT; GPT; Interpretation; LLM; Log analysis; NLP; Security},
	keywords = {Classification (of information); Cybersecurity; Well logging; BERT; GPT; Interpretation; Language model; Language understanding; Large language model; Log analysis; Log interpretation; Logfile; Security; Computational linguistics},
	correspondence_address = {E. Karlsen; Faculty of Computer Science, Dalhousie University, Halifax, University Ave., B3H 1W5, Canada; email: egil.karlsen@dal.ca},
	publisher = {Springer},
	issn = {10647570},
	coden = {JNSME},
	language = {English},
	abbrev_source_title = {J Network Syst Manage},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Miah2024,
	author = {Miah, Md Saef Ullah and Kabir, Md Mohsin and Sarwar, Talha Bin and Safran, Mejdl and Alfarhood, Sultan and Mridha, M.F.},
	title = {A multimodal approach to cross-lingual sentiment analysis with ensemble of transformer and LLM},
	year = {2024},
	journal = {Scientific Reports},
	volume = {14},
	number = {1},
	doi = {10.1038/s41598-024-60210-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191376952&doi=10.1038%2fs41598-024-60210-7&partnerID=40&md5=5dfa5118ff2e73f7d5ec692bb2812ac0},
	affiliations = {Department of Computer Science, American International University-Bangladesh, Dhaka, 1229, Bangladesh; Faculty of Informatics, Eötvös Loránd University, Budapest, 1117, Hungary; Research Chair of Online Dialogue and Cultural Communication, Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia; Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia},
	abstract = {Sentiment analysis is an essential task in natural language processing that involves identifying a text’s polarity, whether it expresses positive, negative, or neutral sentiments. With the growth of social media and the Internet, sentiment analysis has become increasingly important in various fields, such as marketing, politics, and customer service. However, sentiment analysis becomes challenging when dealing with foreign languages, particularly without labelled data for training models. In this study, we propose an ensemble model of transformers and a large language model (LLM) that leverages sentiment analysis of foreign languages by translating them into a base language, English. We used four languages, Arabic, Chinese, French, and Italian, and translated them using two neural machine translation models: LibreTranslate and Google Translate. Sentences were then analyzed for sentiment using an ensemble of pre-trained sentiment analysis models: Twitter-Roberta-Base-Sentiment-Latest, bert-base-multilingual-uncased-sentiment, and GPT-3, which is an LLM from OpenAI. Our experimental results showed that the accuracy of sentiment analysis on translated sentences was over 86% using the proposed model, indicating that foreign language sentiment analysis is possible through translation to English, and the proposed ensemble model works better than the independent pre-trained models and LLM. © The Author(s) 2024.},
	author_keywords = {Cross-lingual communication; Ensemble with LLM; Neural machine translation; Pretrained sentiment analyzer model; Sentiment analysis},
	keywords = {alanine aminotransferase; analyzer; article; diagnosis; human; Internet; large language model; natural language processing; politics; sentiment analysis; social media; tongue},
	correspondence_address = {M.F. Mridha; Department of Computer Science, American International University-Bangladesh, Dhaka, 1229, Bangladesh; email: firoz.mridha@aiub.edu; M. Safran; Research Chair of Online Dialogue and Cultural Communication, Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, 11543, Saudi Arabia; email: mejdl@ksu.edu.sa},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {38671064},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 49; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Javagal20251385,
	author = {Javagal, Bhavya N and Sharma, Sonal},
	title = {A Comprehensive Survey on Clinical Models for AI-Powered Medical Applications},
	year = {2025},
	journal = {4th International Conference on Sentiment Analysis and Deep Learning, ICSADL 2025 - Proceedings},
	pages = {1385 – 1391},
	doi = {10.1109/ICSADL65848.2025.10933337},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002454059&doi=10.1109%2fICSADL65848.2025.10933337&partnerID=40&md5=c93e0ea65184dd75296d9161702c2316},
	affiliations = {JAIN(Deemed to Be University), Department of Computer Science & Engineering, Karnataka, Bengaluru, 562112, India},
	abstract = {Automatic Clinical Text Identification and Classification is a Natural Language Processing (NLP) technique for decoding clinical texts to uncover hidden information. Clinical text analysis has a wide range of applications, including document classification based on clinical significance, disease diagnosis using Electronic Health Records (EHRs), medical chatbots, and more. The widespread application of clinical text analysis has pushed researchers to automate medical text analysis. NLP can capture, process, and organize information from unstructured text data with minimal manual effort, allowing employees to focus on more productive tasks. While NLP is effective for handling unstructured text, the vast amount of medical data requires more advanced methods. To process such large volumes of data, a Large Language Model (LLM), a type of NLP, achieves more effective results. This review aims to provide comprehensive guidance on clinical text classification, starting with unstructured text collection and progressing to the development and evaluation of LLMs. Over 40 research articles are reviewed. Although several LLM models are available, the review focuses on Clinical BERT, Clinical BigBird, and Clinical Longformer. These three models are evaluated based on various characteristics, including model size, architecture, performance, error-handling capability and more. The review helps in determining the most appropriate LLM based on clinical requirements. This review article will be a valuable resource for researchers working on clinical text classification.  © 2025 IEEE.},
	author_keywords = {Clinical Text; Electronic Health Record; Large Language Model; Natural Language Processing; Transfer Learning},
	keywords = {Clinical research; Diagnosis; Clinical text; Electronic health; Health records; Language model; Language processing; Large language model; Natural language processing; Natural languages; Text analysis; Transfer learning; Electronic health record},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152392-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Sentim. Anal. Deep Learn., ICSADL - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Baclayon2024240,
	author = {Baclayon, Charis Arlie Largo and Costelo, Kid Omar Rendon and Flores, Jeremy Jules Loyola and Sta. Romana, Cherry Lyn Cando},
	title = {Automated Handwritten Essay Evaluation in Moodle: Leveraging Google Vision OCR and Mistral 7b},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {240 – 246},
	doi = {10.1145/3696230.3696256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216510300&doi=10.1145%2f3696230.3696256&partnerID=40&md5=2fb6a179fb8a19101e998f642d9cd92c},
	affiliations = {College of Computer Studies, Cebu Institute of Technology - University, Philippines},
	abstract = {Traditional grading methods are often time-consuming and subjective, increasing the difficulties in maintaining academic integrity against the background of easy access to online resources. Even as pre-written and AI-generated content become even more available, handwritten essays offer one of the most viable ways of stimulating real learning and original thought among students. This study assessed the accuracy and efficiency of AI-powered grading to improve education amid these challenges. More precisely, the paper investigated the possibility of automatically grading the handwritten open-ended reflection essays of students in the “Living in the IT Era” course by leveraging AI. Through Optical Character Recognition (OCR), together with a fine-tuned and trained Large Language Model (LLM) Mistral 7b, the system replicated human-grading decisions in evaluating essays comprehensively. The predicted score and human-graded score were compared in evaluating the system. Analysis using BERT Score revealed a high degree of correlation between the two, with consistent precision (88.41%), recall (83.33%), and F1-score (85.78%). External user testing also revealed a positive perception: the system is perceived as user-friendly (usability: 4.28), generally understandable (comprehensibility: 3.68), and with functionalities relevant to educators’ needs (relevance: 4.0). This study adds to the expanding body of research on AI in education and lays the groundwork for future investigations in this area. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Essay Evaluation; Handwritten Essay Grading; Learning Management Systems; Moodle; Online Education; Plugin},
	keywords = {Contrastive Learning; Curricula; Optical character recognition; Academic integrity; Essay evaluation; Google+; Grading methods; Handwritten essay grading; Learning management system; Moodle; On-line education; Optical-; Plug-ins; Students},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071757-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shashwat2024173,
	author = {Shashwat, Kumar and Hahn, Francis and Millar, Stuart and Ou, Xinming},
	title = {Using LLM Embeddings with Similarity Search for Botnet TLS Certificate Detection},
	year = {2024},
	journal = {AISec 2024 - Proceedings of the 2024 Workshop on Artificial Intelligence and Security, Co-Located with: CCS 2024},
	pages = {173 – 183},
	doi = {10.1145/3689932.3694766},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216593051&doi=10.1145%2f3689932.3694766&partnerID=40&md5=c6598abf37387d32c325d3207d62d0ee},
	affiliations = {University of South Florida, Tampa, United States; Rapid7 LLC, Belfast, United Kingdom},
	abstract = {Modern botnets leverage TLS encryption to mask C&C server communications. TLS certificates used by botnets could exhibit subtle characteristics that facilitate detection. In this paper we investigate whether text features from TLS certificates can be represented by open-source and 3rd party vendor LLM text embeddings in a projected vector space, for the purpose of building a classifier to detect botnet certificates. Our method extracts informative features, generating vector representations for effective identification, creating a projected space that can be queried with test certificates via similarity search. Using a balanced dataset consisting of the publicly available SSLBL botnet certificates and TLS certificates used by popular websites, our evaluations show that C-BERT, an open-source model, emerges as the preferred choice within our proposed system rather than a vendor solution. C-BERT achieves a competitive F1 score of 0.994 on unseen test data, 97.9% accuracy on data gathered several months after an initial projected embedding space was created, and maintains performance in a simulated zero-day evaluation against four C&C groups, with an average F1 score of 0.946. Further evaluation on a random sample of 150,000 real-world certificates collected from a full internet scan between Jan 2024 to May 2024 predicts 13 potential botnet certificates, among which one was confirmed to be malicious by VirusTotal. Comparing with the scenario where no such tool exists, we randomly selected 1,300 certificates from these 150,000 certificates and ran them through VirusTotal, and none were confirmed to be malicious. This translates to 100 fold effort reduction in identifying botnet certificates in the wild. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Botnet classification; Clustering; kNN; LLMs; Nearest Neighbours; Similarity Search; Vector Databases; Vector Embeddings},
	keywords = {Bot (Internet); Botnet; Embeddings; Network security; Botnet classification; Botnets; Clusterings; Embeddings; KNN; LLM; Nearest-neighbour; Similarity search; Vector database; Vector embedding; Vectors},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840071228-9},
	language = {English},
	abbrev_source_title = {AISec - Proc. Workshop Artif. Intell. Secur., Co-Located: CCS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wirawan2025,
	author = {Wirawan, Alfiessa Widya and Baizal, Z.K.A.},
	title = {Carfin: Car Recommender System Based on Conversational Recommender System Using Large Language Model},
	year = {2025},
	journal = {ICADEIS 2025 - 2025 International Conference on Advancement in Data Science, E-learning and Information System: Integrating Data Science and Information System, Proceeding},
	doi = {10.1109/ICADEIS65852.2025.10933065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002276390&doi=10.1109%2fICADEIS65852.2025.10933065&partnerID=40&md5=bbe38529edb5fa3d331e5db18a4a2cde},
	affiliations = {School of Computing, Telkom University, Bandung, Indonesia},
	abstract = {Various approaches have been used to develop car recommender systems, but limitations remain in personalizing information. Existing recommender systems often provide less relevant and flexible recommendations because they do not fully understand users' needs. Therefore, there is a need for a car recommender system that can offer more personalized recommendations, understand user needs better, and allow for more flexible interactions between the system and the user. This research aims to address these limitations and open up opportunities to enhance the performance and personalization of recommender systems in the automotive field. We developed a car recommender system named Carfin, which utilizes a Large Language Model (LLM) based Conversational Recommender System (CRS) to provide more accurate recommendations that align with user preferences and allow more flexible interactions between the system and the user in the process of getting car recommendations. We performed fine-tuning on the GPT-4 model and prompted engineering to generate accurate recommendations. After fine-tuning, the model was implemented to interact with users through the Telegram platform. We then evaluated the model using BERT Precision, BERT Recall, BERT F1-Score, and Cosine Similarity metrics. The evaluation results showed a significant improvement in performance before and after fine-tuning. The evaluation of each BERT Precision metric increased from 0.8048 to 0.8541, BERT Recall from 0.8639 to 0.9183, BERT F1-Score from 0.8332 to 0.8850, and Cosine Similarity from 0.6590 to 0.8372. Based on these performance improvements, Carfin can provide personalized and relevant car recommendations through conversational interactions while focusing on the automotive domain.  © 2025 IEEE.},
	author_keywords = {Car Recommender System; Conversational Recommender System; Large Language Model; Preferences Elicitation},
	keywords = {Car recommender system; Conversational recommender systems; F1 scores; Fine tuning; Language model; Large language model; Performance; Personalized recommendation; Preference elicitation; User need},
	correspondence_address = {Z.K.A. Baizal; School of Computing, Telkom University, Bandung, Indonesia; email: baizal@telkomuniversity.ac.id},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151332-0},
	language = {English},
	abbrev_source_title = {ICADEIS - Int. Conf. Adv. Data Sci., E-learning Inf. Syst.: Integr. Data Sci. Inf. Syst., Proceeding},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Acharya20242,
	author = {Acharya, Jagrit and Ginde, Gouri},
	title = {Graph Neural Network vs. Large Language Model: A Comparative Analysis for Bug Report Priority and Severity Prediction},
	year = {2024},
	journal = {PROMISE 2024 - Proceedings of the 20th International Conference on Predictive Models and Data Analytics in Software Engineering, Co-located with: ESEC/FSE 2024},
	pages = {2 – 11},
	doi = {10.1145/3663533.3664042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199994508&doi=10.1145%2f3663533.3664042&partnerID=40&md5=1cf3d6bb045f3991db97630b89aea465},
	affiliations = {University of Calgary, Calgary, Canada},
	abstract = {A vast number of incoming bug reports demand effective methods to identify priority and severity for bug triaging. With increased technological advancement, machine learning and deep learning have been extensively examined to address this problem. Although Large Language Models (LLMs) such as Fine-tuned BERT (early generation LLM) have proven to capture context in the underlying textual data, severity and priority prediction demand additional features for understanding the relationships with other bug reports. This work utilizes the graph-based approach to model the bug reports and their other attributes, such as component, product and bug type information. It utilizes the relational intelligence of Graph Neural Network (GNN) to address the prioritization and severity assessment of bug reports in the Bugzilla bug tracking system. Initial tests on the Mozilla project dataset indicate that a project-wise predictive approach using GNNs yields higher accuracy in determining the priority and severity of bug reports compared to LLMs across multiple Mozilla projects, contributing to a notable advancement in the automation of bug severity and priority prediction tasks. Specifically, GNNs demonstrated a remarkable improvement over LLMs, increasing the priority prediction accuracy by 37% & 30% and severity prediction accuracy by 43% & 30% for Core and Firefox projects, respectively. Overall, GNN outperformed the Fine-tuned BERT (LLM) in predicting priority and severity for all the Mozilla projects. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {BERT; Graph Neural Networks; Large Language Model; Natural Language Processing; Requirement Engineering},
	keywords = {Computational linguistics; Deep learning; Forecasting; Graphic methods; Natural language processing systems; Statistical tests; BERT; Bug reports; Graph neural networks; Language model; Language processing; Large language model; Mozilla; Natural language processing; Natural languages; Requirement engineering; Graph neural networks},
	correspondence_address = {J. Acharya; University of Calgary, Calgary, Canada; email: jagrit.acharya1@ucalgary.ca},
	editor = {Shang W. and Lamothe M. and Wan Z.},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070675-2},
	language = {English},
	abbrev_source_title = {PROMISE - Proc. Int. Conf. Predict. Models Data Anal. Softw. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Arun202443,
	author = {Arun, C. and Karthick, S. and Samy, S.Selvakumara and Hariharan, B. and Lee, Po-Ming},
	title = {Generative AI models and LLM: Training techniques and evaluation metrics},
	year = {2024},
	journal = {Generative AI and LLMs: Natural Language Processing and Generative Adversarial Networks},
	pages = {43 – 67},
	doi = {10.1515/9783111425078-003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206228952&doi=10.1515%2f9783111425078-003&partnerID=40&md5=6fde40b3c57fca3b83115c59c1ca6b08},
	affiliations = {Department of Computational Intelligence School of Computing, SRM Institute of Science and Technology, Chennai, Tamil Nadu, India; University of Science and Technology, Tainan, Taiwan},
	abstract = {Generative artificial intelligence (AI) has been a prominent technique across data-driven applications, which uses deep learning architecture to learn the underlying characteristic of the sample to build the knowledge base in generating synthetic samples that mimic the real distribution. Generative AI models are ideal solutions where models suffer due to scarcity of data sample that hinders the training process be it text, video, audio, and image. Training the model plays a pivotal role, where it discovers the hidden pattern and understands the intrinsic behavior of samples that aid in generating realistic samples. The volume of data that is available for training and the computing power required pose threat on the performance of the intelligent systems, where large language models (LLM) has been an ideal solution. LLMs are generative AI systems that understand human language and provide intelligent, creative solutions to questions. Complex architecture of LLM allows them to capture the intricacies of language more precise, enabling to generate coherent and contextually relevant outputs. This chapter delves into comprehensive analysis on the well-known generative AI models such as generative adversarial networks, transformers, and LangChain. Generative AI employs different training techniques such as reinforcement learning, adversarial training, variational inference, transfer learning, and progressive training on diverse application domains. Furthermore, the study examines the crucial aspect of evaluating the effectiveness of generative models, using a variety of metrics ranging from BLUE, inception score, perplexity, Frechet inception distance, precision, ROUGE, recall, METEOR, BERT, MoverScore, and many more. A comparative analysis of these metrics offers insights into their respective advantages and disadvantages, aiding practitioners and researchers in selecting benchmarks that align with their specific use cases. © 2024 Walter de Gruyter GmbH, Berlin/Boston. All rights reserved.},
	author_keywords = {BERT; GAN; Generative AI; LangChain; LLM; Transformers; VAE},
	correspondence_address = {C. Arun; Department of Computational Intelligence School of Computing, SRM Institute of Science and Technology Chennai, Chennai, Tamil Nadu, India; email: arunc@srmist.edu.in},
	publisher = {De Gruyter},
	isbn = {978-311142507-8; 978-311142463-7},
	language = {English},
	abbrev_source_title = {Gener. AI and LLMs: Natural Lang. Process. and Gener. Advers. Netw.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hussain202551,
	author = {Hussain, Ali and Ali, Sikandar and Farwa, Umm E. and Mozumder, Md Ariful Islam and Kim, Hee-Cheol},
	title = {Foundation Models: From Current Developments, Challenges, and Risks to Future Opportunities},
	year = {2025},
	journal = {International Conference on Advanced Communication Technology, ICACT},
	pages = {51 – 58},
	doi = {10.23919/ICACT63878.2025.10936649},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002273842&doi=10.23919%2fICACT63878.2025.10936649&partnerID=40&md5=a1f4504bba362be2e3e89b5859adf368},
	affiliations = {Dept. of Digital Anti-Aging Healthcare, Inje University, Gimhae, 50834, South Korea; College of AI Convergence, Institute of Digital Anti-Aging Healthcare, u-AHRC, Inje University, Gimhae, 50834, South Korea},
	abstract = {Foundation models are a revolutionary technology in the field of artificial intelligence that could usher in an era of transformation in every field with its vision and language understating capabilities while maintaining remarkable performance. Here, we extensively review state-of-the-art foundation models in various fields such as LLMs, GPT, BERT, CLIP, etc. We also demonstrate some famous areas where foundation models are gaining much popularity, such as general foundation models, foundation models in the medical domain, education, law and finance, mathematics, autonomous driving, etc. These foundation models are trained on large-scale data by leveraging the capabilities of self-supervised learning approaches that ensure outperforming accuracy for relevant downstream tasks. They are successful due to pioneering architectural innovations, especially synergistically interleaving transformers and convolutional neural networks. These models have exhibited adaptability and resilience in various data patterns and conditions through sophisticated training paradigms such as self-supervised and supervised learning methods. While they hold transformative potential, they also have many challenges. The scale and quality of training data are still important predictors of model performance, and the need for interpretable and explainable AI systems becomes critically important. We highlight important research opportunities, high-performing computationally efficient and scalable architectures, and approaches to enable multimodal learning capacities. This review sheds light on the current state of foundation models and proposes a roadmap for their successful transitions. Copyright 2025 Global IT Research Institute (GIRI). All rights reserved.},
	author_keywords = {digital pathology foundation models; Foundation models; LLMs; self-supervised learning; vision-language models},
	keywords = {Contrastive Learning; Convolutional neural networks; Medical education; Supervised learning; Visual languages; 'current; Digital pathologies; Digital pathology foundation model; Foundation models; Language model; LLM; Performance; Revolutionary technology; Vision-language model; Self-supervised learning},
	correspondence_address = {A. Hussain; Dept. of Digital Anti-Aging Healthcare, Inje University, Gimhae, 50834, South Korea; email: alihussainnrana@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {17389445},
	isbn = {979-118842813-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Commun. Technol. ICACT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dong2024,
	author = {Dong, Rongpeng and Cheng, Xueliang and Kang, Mingyang and Qu, Yang},
	title = {Classification of lumbar spine disorders using large language models and MRI segmentation},
	year = {2024},
	journal = {BMC Medical Informatics and Decision Making},
	volume = {24},
	number = {1},
	doi = {10.1186/s12911-024-02740-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209539009&doi=10.1186%2fs12911-024-02740-8&partnerID=40&md5=29afe44622cfcb21454984ba5fdc4402},
	affiliations = {Department of Spinal Surgery, The Second Hospital of Jilin University, No. 218, Ziqiang Street, Nanguan District, Chuangchun, 130041, China},
	abstract = {Background: MRI is critical for diagnosing lumbar spine disorders but its complexity challenges diagnostic accuracy. This study proposes a BERT-based large language model (LLM) to enhance precision in classifying lumbar spine disorders through the integration of MRI data, textual reports, and numerical measurements. Methods: The segmentation quality of MRI data is evaluated using dice coefficients (cut-off: 0.92) and intersection over union (IoU) metrics (cut-off: 0.88) to ensure precise anatomical feature extraction. The CNN extracts key lumbar spine features, such as lumbar lordotic angle (LLA) and disc heights, which are tokenized as direct scalar values representing positional relationships. A data source of 28,065 patients with various disorders, including degenerative disc disease, spinal stenosis, and spondylolisthesis, is used to establish diagnostic standards. These standards are refined through post-CNN processing of MRI texture features. The BERT-based spinal LLM model integrates these CNN-extracted MRI features and numerical values through early fusion layers. Results: Segmentation analysis illustrate various lumbar spine disorders and their anatomical changes. The model achieved high performance, with all key metrics nearing 0.9, demonstrating its effectiveness in classifying conditions like spondylolisthesis, herniated disc, and spinal stenosis. External validation further confirmed the model’s generalizability across different populations. External validation on 514 expert-validated MRI cases further confirms the model’s clinical relevance and generalizability. The BERT-based model classifies 61 combinations of lumbar spine disorders. Conclusions: The BERT-based spinal LLM significantly improves the precision of lumbar spine disorder classification, supporting accurate diagnosis and treatment planning. © The Author(s) 2024.},
	author_keywords = {BERT-based large language model; Lumbar spine disorders; MRI data; Multimodal data integration; Precision classification},
	keywords = {Humans; Lumbar Vertebrae; Magnetic Resonance Imaging; Spinal Diseases; Spinal Stenosis; Spondylolisthesis; classification; diagnostic imaging; human; lumbar vertebra; nuclear magnetic resonance imaging; spine disease; spondylolisthesis; vertebral canal stenosis},
	correspondence_address = {Y. Qu; Department of Spinal Surgery, The Second Hospital of Jilin University, Chuangchun, No. 218, Ziqiang Street, Nanguan District, 130041, China; email: quy@jlu.edu.cn},
	publisher = {BioMed Central Ltd},
	issn = {14726947},
	pmid = {39558285},
	language = {English},
	abbrev_source_title = {BMC Med. Informatics Decis. Mak.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Zuo2024158,
	author = {Zuo, Xiaorui and Chen, Yao-Tsung and Härdle, Wolfgang Karl},
	title = {Emoji driven crypto assets market reactions},
	year = {2024},
	journal = {Management and Marketing},
	volume = {19},
	number = {2},
	pages = {158 – 178},
	doi = {10.2478/mmcks-2024-0008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198981994&doi=10.2478%2fmmcks-2024-0008&partnerID=40&md5=d007d8e5cb34eaa2a4fb8abede0c3c4f},
	affiliations = {Fudan University, Shanghai, China; Ida Institute Digital Assets, Bucharest University of Economic Studies, Bucharest, Romania; Department of Information Management and Finance, College of Management, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Brc Blockchain Research Center, Humboldt Universität zu Berlin, Berlin, Germany; Faculty of Mathematics and Physics, Charles University, Prague, Czech Republic; National Yang Ming Chiao Tung University, Dept Information Management and Finance, Hsinchu, Taiwan},
	abstract = {In the burgeoning realm of cryptocurrency, social media platforms like Twitter have become pivotal in influencing market trends and investor sentiments. In our study, we leverage GPT-4 and a fine-tuned transformer-based BERT model for a multimodal sentiment analysis, focusing on the impact of emoji sentiment on cryptocurrency markets. By translating emojis into quantifiable sentiment data, we correlate these insights with key market indicators such as BTC Price and the VCRIX index. Our architecture's analysis of emoji sentiment demonstrated a distinct advantage over FinBERT's pure text sentiment analysis in such predicting power. This approach may be fed into the development of trading strategies aimed at utilizing social media elements to identify and forecast market trends. Crucially, our findings suggest that strategies based on emoji sentiment can facilitate the avoidance of significant market downturns and contribute to the stabilization of returns. This research underscores the practical benefits of integrating advanced AI-driven analyzes into financial strategies, offering a nuanced perspective on the interaction between digital communication and market dynamics in an academic context.  © 2024 Xiaorui Zuo et al., published by Sciendo.},
	author_keywords = {bitcoin; crypto; emoji; LLM; VCRIX},
	correspondence_address = {Y.-T. Chen; Department of Information Management and Finance, College of Management, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; email: ytchenjp@nycu.edu.tw},
	publisher = {Sciendo},
	issn = {18420206},
	language = {English},
	abbrev_source_title = {Manage. Mark.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Roumeliotis2024,
	author = {Roumeliotis, Konstantinos I. and Tselikas, Nikolaos D. and Nasiopoulos, Dimitrios K.},
	title = {Next-Generation Spam Filtering: Comparative Fine-Tuning of LLMs, NLPs, and CNN Models for Email Spam Classification},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {11},
	doi = {10.3390/electronics13112034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195798466&doi=10.3390%2felectronics13112034&partnerID=40&md5=845c190161bd6d8b8d9612db4539e6e9},
	affiliations = {Department of Informatics and Telecommunications, University of Peloponnese, Akadimaikou G. K. Vlachou Street, Tripoli, 22131, Greece; Department of Agribusiness and Supply Chain Management, School of Applied Economics and Social Sciences, Agricultural University of Athens, Athens, 11855, Greece},
	abstract = {Spam emails and phishing attacks continue to pose significant challenges to email users worldwide, necessitating advanced techniques for their efficient detection and classification. In this paper, we address the persistent challenges of spam emails and phishing attacks by introducing a cutting-edge approach to email filtering. Our methodology revolves around harnessing the capabilities of advanced language models, particularly the state-of-the-art GPT-4 Large Language Model (LLM), along with BERT and RoBERTa Natural Language Processing (NLP) models. Through meticulous fine-tuning tailored for spam classification tasks, we aim to surpass the limitations of traditional spam detection systems, such as Convolutional Neural Networks (CNNs). Through an extensive literature review, experimentation, and evaluation, we demonstrate the effectiveness of our approach in accurately identifying spam and phishing emails while minimizing false positives. Our methodology showcases the potential of fine-tuning LLMs for specialized tasks like spam classification, offering enhanced protection against evolving spam and phishing attacks. This research contributes to the advancement of spam filtering techniques and lays the groundwork for robust email security systems in the face of increasingly sophisticated threats. © 2024 by the authors.},
	author_keywords = {LLM classification; LLM fine-tuning; phishing attacks; phishing detection; phishing email; spam classification; spam detection; spam detection systems; spam email; spam filtering},
	correspondence_address = {K.I. Roumeliotis; Department of Informatics and Telecommunications, University of Peloponnese, Tripoli, Akadimaikou G. K. Vlachou Street, 22131, Greece; email: k.roumeliotis@uop.gr},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@ARTICLE{Tang20243757,
	author = {Tang, Yongjian and Hasan, Rakebul and Runkler, Thomas},
	title = {FsPONER: Few-Shot Prompt Optimization for Named Entity Recognition in Domain-Specific Scenarios},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {392},
	pages = {3757 – 3764},
	doi = {10.3233/FAIA240936},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216628699&doi=10.3233%2fFAIA240936&partnerID=40&md5=db0c165de13a2ddf3c4fd69f93734491},
	affiliations = {Technical University of Munich, Germany; Siemens AG, Munich, Germany},
	abstract = {Large Language Models (LLMs) have provided a new pathway for Named Entity Recognition (NER) tasks. Compared with fine-tuning, LLM-powered prompting methods avoid the need for training, conserve substantial computational resources, and rely on minimal annotated data. Previous studies have achieved comparable performance to fully supervised BERT-based fine-tuning approaches on general NER benchmarks. However, none of the previous approaches has investigated the efficiency of LLM-based few-shot learning in domain-specific scenarios. To address this gap, we introduce FsPONER, a novel approach for optimizing few-shot prompts, and evaluate its performance on domain-specific NER datasets, with a focus on industrial manufacturing and maintenance, while using multiple LLMs - GPT-4-32K, GPT-3.5-Turbo, LLaMA 2-chat, and Vicuna. FsPONER consists of three few-shot selection methods based on random sampling, TF-IDF vectors, and a combination of both. We compare these methods with a general-purpose GPT-NER method as the number of few-shot examples increases and evaluate their optimal NER performance against fine-tuned BERT and LLaMA 2-chat. In the considered real-world scenarios with data scarcity, FsPONER with TF-IDF surpasses fine-tuned models by approximately 10% in F1 score. © 2024 The Authors.},
	keywords = {Analog differential analyzers; Supervised learning; Zero-shot learning; Computational resources; Domain specific; Fine tuning; Industrial maintenance; Industrial manufacturing; Language model; Model-based OPC; Named entity recognition; Optimisations; Performance; Benchmarking},
	correspondence_address = {Y. Tang; Technical University of Munich, Germany; email: yongjian.tang@tum.de},
	editor = {Endriss U. and Melo F.S. and Bach K. and Bugarin-Diz A. and Alonso-Moral J.M. and Barro S. and Heintz F.},
	publisher = {IOS Press BV},
	issn = {09226389},
	isbn = {978-164368548-9},
	language = {English},
	abbrev_source_title = {Front. Artif. Intell. Appl.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Silverman20241391,
	author = {Silverman, Anna L. and Sushil, Madhumita and Bhasuran, Balu and Ludwig, Dana and Buchanan, James and Racz, Rebecca and Parakala, Mahalakshmi and El-Kamary, Samer and Ahima, Ohenewaa and Belov, Artur and Choi, Lauren and Billings, Monisha and Li, Yan and Habal, Nadia and Liu, Qi and Tiwari, Jawahar and Butte, Atul J. and Rudrapatna, Vivek A.},
	title = {Algorithmic Identification of Treatment-Emergent Adverse Events From Clinical Notes Using Large Language Models: A Pilot Study in Inflammatory Bowel Disease},
	year = {2024},
	journal = {Clinical Pharmacology and Therapeutics},
	volume = {115},
	number = {6},
	pages = {1391 – 1399},
	doi = {10.1002/cpt.3226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187178037&doi=10.1002%2fcpt.3226&partnerID=40&md5=33c33a196e3063242fb655ee9eea6328},
	affiliations = {Division of Gastroenterology and Hepatology, Department of Medicine, Mayo Clinic, Phoenix, AZ, United States; Department of Medicine, University of California, San Diego, La Jolla, CA, United States; Bakar Computational Health Sciences Institute, San Francisco, CA, United States; United States Food and Drug Administration, Silver Spring, MD, United States; Department of Public Health, University of California, Berkeley, Berkeley, CA, United States; Center for Data-Driven Insights and Innovation, University of California Health, Oakland, CA, United States; Division of Gastroenterology and Hepatology, Department of Medicine, University of California, San Francisco, San Francisco, CA, United States},
	abstract = {Outpatient clinical notes are a rich source of information regarding drug safety. However, data in these notes are currently underutilized for pharmacovigilance due to methodological limitations in text mining. Large language models (LLMs) like Bidirectional Encoder Representations from Transformers (BERT) have shown progress in a range of natural language processing tasks but have not yet been evaluated on adverse event (AE) detection. We adapted a new clinical LLM, University of California – San Francisco (UCSF)-BERT, to identify serious AEs (SAEs) occurring after treatment with a non-steroid immunosuppressant for inflammatory bowel disease (IBD). We compared this model to other language models that have previously been applied to AE detection. We annotated 928 outpatient IBD notes corresponding to 928 individual patients with IBD for all SAE-associated hospitalizations occurring after treatment with a non-steroid immunosuppressant. These notes contained 703 SAEs in total, the most common of which was failure of intended efficacy. Out of eight candidate models, UCSF-BERT achieved the highest numerical performance on identifying drug-SAE pairs from this corpus (accuracy 88–92%, macro F1 61–68%), with 5–10% greater accuracy than previously published models. UCSF-BERT was significantly superior at identifying hospitalization events emergent to medication use (P < 0.01). LLMs like UCSF-BERT achieve numerically superior accuracy on the challenging task of SAE detection from clinical notes compared with prior methods. Future work is needed to adapt this methodology to improve model performance and evaluation using multicenter data and newer architectures like Generative pre-trained transformer (GPT). Our findings support the potential value of using large language models to enhance pharmacovigilance. © 2024 The Authors. Clinical Pharmacology & Therapeutics © 2024 American Society for Clinical Pharmacology and Therapeutics.},
	keywords = {Adverse Drug Reaction Reporting Systems; Algorithms; Data Mining; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Female; Hospitalization; Humans; Immunosuppressive Agents; Inflammatory Bowel Diseases; Male; Natural Language Processing; Pharmacovigilance; Pilot Projects; adalimumab; etanercept; golimumab; immunosuppressive agent; infliximab; Janus kinase inhibitor; tofacitinib; tumor necrosis factor inhibitor; ustekinumab; vedolizumab; immunosuppressive agent; adult; algorithm; Article; California; controlled study; drug safety; female; gastrointestinal disease; generative pretrained transformer; heart disease; hospitalization; human; infection; infestation; inflammatory bowel disease; information source; large language model; major clinical study; male; middle aged; natural language processing; neoplasm; neurologic disease; pharmacovigilance; pilot study; prediction; translational science; adverse drug reaction; data mining; electronic health record; natural language processing; procedures},
	correspondence_address = {V.A. Rudrapatna; Bakar Computational Health Sciences Institute, San Francisco, United States; email: vivek.rudrapatna@ucsf.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {00099236},
	coden = {CLPTA},
	pmid = {38459719},
	language = {English},
	abbrev_source_title = {Clin. Pharmacol. Ther.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Fu20251909,
	author = {Fu, Mengyi and Wang, Pan and Liu, Minyao and Zhang, Ze and Zhou, Xiaokang},
	title = {IoV-BERT-IDS: Hybrid Network Intrusion Detection System in IoV Using Large Language Models},
	year = {2025},
	journal = {IEEE Transactions on Vehicular Technology},
	volume = {74},
	number = {2},
	pages = {1909 – 1921},
	doi = {10.1109/TVT.2024.3402366},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193537710&doi=10.1109%2fTVT.2024.3402366&partnerID=40&md5=8fed3bbe000fdf6fc45dbf2991dde078},
	affiliations = {Nanjing University of Post and Telecommunications, School of Modern Posts, Nanjing, 210003, China; Shiga University, Faculty of Data Science, Hikone, 522-8522, Japan; RIKEN, RIKEN Center for Advanced Intelligence Project, Tokyo, 103-0027, Japan; Kansai University, Faculty of Business Data Science, Osaka, 565-0823, Japan},
	abstract = {The traditional vehicular ad hoc network (VANET) gradually evolved into the Internet of Vehicles (IoV), which has also become a potential target for attacks and faces security challenges in an open network environment. Intrusion detection systems (IDS) based on machine learning (ML) and deep learning (DL) are introduced to mitigate security threats. However, existing ML/DL-based IDS suffer from challenges in IoV environments. First, due to the limitations of ML/DL-based methods, classification performance is unsatisfactory when they extract only unidirectional contextual features or spatial characteristics. Second, existing research on in-vehicle network IDS often limits validation and testing to a static dataset of a single vehicle model. This approach may not adequately address diverse potential attacks in a dynamic environment. Third, few studies of hybrid IDS can simultaneously implement in-vehicle and extra-vehicle network intrusion detection. Large language models (LLM) have shown outstanding applications in fields such as natural language processing (NLP) and computer vision (CV). In particular, bidirectional encoder representations from transformers (BERT) obtain new state-of-the-art results on eleven famous NLP tasks. Consequently, this paper introduces a hybrid network IDS in IoV utilising LLM, denoted as IoV-BERT-IDS. This framework encompasses four modules: semantic extractor (SE), input embedding, IoV-BERT-IDS pre-training, and IoV-BERT-IDS fine-tuning. To conform to the BERT model, the semantic extractor is introduced to transform traffic data devoid of apparent semantics into contextual semantics, comprising bidirectional and unidirectional SE. Through SE, controller area network (CAN) data is transformed into a CAN byte sentence (CBS), while extra-vehicle network traffic data is transformed into a traffic byte sentence (TBS). Additionally, two pre-training tasks, the masked byte word model (MBWM) and next byte sentence prediction (NBSP) are proposed to acquire bidirectional contextual features from contextual semantics. These features can be adapted to downstream tasks in both in-vehicle and extra-vehicle networks through fine-tuning. Experiments demonstrate that IoV-BERT-IDS outperforms in CICIDS, BoT-IoT, Car-Hacking, and In-vehicle network intrusion detection challenge (IVN-IDS) datasets and shows good generalisation capabilities to in-vehicle networks of different vehicles.  © 2024 IEEE.},
	author_keywords = {BERT; Internet of Vehicle; intrusion detection system; large language model; pre-training model},
	keywords = {Control system synthesis; Controllers; Deep learning; Intrusion detection; Natural language processing systems; Network architecture; Network coding; Network security; Personal computing; Statistical tests; Vehicle to vehicle communications; Vehicles; Vehicular ad hoc networks; Bidirectional control; Bidirectional encoder representation from transformer; Computational modelling; Encodings; Internet of vehicle; Intrusion Detection Systems; Language model; Language processing; Large language model; Natural language processing; Natural languages; Pre-training; Pre-training model; Task analysis; Telecommunications traffic; Training model; Semantics},
	correspondence_address = {P. Wang; Nanjing University of Post and Telecommunications, School of Modern Posts, Nanjing, 210003, China; email: wangpan@njupt.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {00189545},
	coden = {ITVTA},
	language = {English},
	abbrev_source_title = {IEEE Trans. Veh. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Chalehchaleh2025258,
	author = {Chalehchaleh, Razieh and Farahbakhsh, Reza and Crespi, Noel},
	title = {Enhancing Multilingual Fake News Detection Through LLM-Based Data Augmentation},
	year = {2025},
	journal = {Studies in Computational Intelligence},
	volume = {1189 SCI},
	pages = {258 – 270},
	doi = {10.1007/978-3-031-82435-7_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002048436&doi=10.1007%2f978-3-031-82435-7_21&partnerID=40&md5=d45e657899bfdf9fc3adee1fea51ab90},
	affiliations = {Télécom SudParis, Institut Polytechnique de Paris, Palaiseau, France},
	abstract = {The rapid growth of online news consumption has intensified the spread of misinformation, underscoring the critical need for effective fake news detection methods. Despite significant advancements in this area, the scarcity and inadequacy of high-quality labeled datasets necessary for training effective detection models remains a major challenge. In this paper, we introduce a novel approach to address this issue by leveraging large language models (LLMs) for data augmentation. Specifically, we employ Llama 3 to generate multiple synthetic news samples per original article, enriching existing fake news datasets to enhance fake news detection. We explore various augmentation strategies like different augmentation rates, random or similarity-based subsampling, and selectively augmenting data from specific classes to optimize the augmented datasets to train better classifiers. We evaluate the efficacy of our approach using BERT-based classifiers on two multilingual datasets. Our findings reveal notable improvements particularly when augmenting only the fake class with rate 1. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Data Augmentation; Large Language Models (LLMs); Multilingual Fake News Detection},
	correspondence_address = {R. Chalehchaleh; Télécom SudParis, Institut Polytechnique de Paris, Palaiseau, France; email: razieh.chalehchaleh@telecom-sudparis.eu},
	editor = {Cherifi H. and Donduran M. and Rocha L.M. and Cherifi C. and Varol O.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {1860949X},
	isbn = {978-303182434-0},
	language = {English},
	abbrev_source_title = {Stud. Comput. Intell.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Genest202550077,
	author = {Genest, Pierre-Yves and Portier, Pierre-Edouard and Egyed-Zsigmond, Elod and Lovisetto, Martino},
	title = {OWNER — Toward Unsupervised Open-World Named Entity Recognition},
	year = {2025},
	journal = {IEEE Access},
	volume = {13},
	pages = {50077 – 50105},
	doi = {10.1109/ACCESS.2025.3552122},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001712514&doi=10.1109%2fACCESS.2025.3552122&partnerID=40&md5=24ecbbfbbbef64a2bb6c36711eae2464},
	affiliations = {Alteca, Villeurbanne, 69100, France; Université Claude Bernard Lyon 1, INSA Lyon, CNRS, LIRIS, UMR5205, Villeurbanne, 69621, France; Caisse d’Epargne Rhône Alpes, Lyon, 69003, France},
	abstract = {Named Entity Recognition (NER) is a crucial task in Natural Language Processing (NLP), traditionally addressed through supervised learning, which requires extensive annotated corpora. This requirement poses challenges, particularly in specialized domains with limited labeled data. In response, the field has shifted towards lower-resource approaches, such as few-shot and zero-shot learning, which reduce the dependency on annotated data. However, even zero-shot models require prior knowledge of entity types, limiting their applicability in exploratory scenarios. In this context, we introduce OWNER, our unsupervised and open-world NER model, designed to operate without annotated documents or predefined entity types. OWNER leverages Encoder-only Language Models like BERT to infer and organize entities into dynamic entity types through a two-step process: mention detection and entity typing. Mention detection employs a BIO sequence labeling approach to locate entities, while entity typing uses BERT-based embeddings, refined through contrastive learning, for clustering and naming entity types. This method allows OWNER to automatically identify and structure unknown entity types, offering advantages for exploratory dataset analysis and knowledge graph construction. Our experimental evaluation on 13 domain-specific datasets demonstrates that OWNER surpasses existing LLM-based open-world NER models and remains competitive with more supervised and closed-world zero-shot models. OWNER’s architecture provides a lightweight, easily deployable solution that advances the state of the art in unsupervised and open-world NER. The source code of OWNER is publicly available at https://github.com/alteca/OWNER, facilitating future research in this domain. © 2013 IEEE.},
	author_keywords = {Named entity recognition; open information extraction; open-world named entity recognition; unsupervised named entity recognition},
	keywords = {Adversarial machine learning; Knowledge graph; Labeled data; Metadata; Natural language processing systems; Open Data; Self-supervised learning; Supervised learning; Unsupervised learning; Entity-types; Named entity recognition; Natural languages; Open information extraction; Open world; Open-world named entity recognition; Recognition models; Unsupervised named entity recognition; Zero-shot learning},
	correspondence_address = {P.-Y. Genest; Alteca, Villeurbanne, 69100, France; email: pygenest@alteca.fr},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Wu2024,
	author = {Wu, Da and Yang, Jingye and Wang, Kai},
	title = {Exploring the reversal curse and other deductive logical reasoning in BERT and GPT-based large language models},
	year = {2024},
	journal = {Patterns},
	volume = {5},
	number = {9},
	doi = {10.1016/j.patter.2024.101030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205832199&doi=10.1016%2fj.patter.2024.101030&partnerID=40&md5=4f12b27e8890757842b1cba73dfbdea1},
	affiliations = {Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Children's Hospital of Philadelphia, Philadelphia, 19104, PA, United States; Department of Mathematics, University of Pennsylvania, Philadelphia, 19104, PA, United States; Department of Pathology and Laboratory Medicine, University of Pennsylvania, Philadelphia, 19104, PA, United States},
	abstract = {The “Reversal Curse” describes the inability of autoregressive decoder large language models (LLMs) to deduce “B is A” from “A is B,” assuming that B and A are distinct and can be uniquely identified from each other. This logical failure suggests limitations in using generative pretrained transformer (GPT) models for tasks like constructing knowledge graphs. Our study revealed that a bidirectional LLM, bidirectional encoder representations from transformers (BERT), does not suffer from this issue. To investigate further, we focused on more complex deductive reasoning by training encoder and decoder LLMs to perform union and intersection operations on sets. While both types of models managed tasks involving two sets, they struggled with operations involving three sets. Our findings underscore the differences between encoder and decoder models in handling logical reasoning. Thus, selecting BERT or GPT should depend on the task's specific needs, utilizing BERT's bidirectional context comprehension or GPT's sequence prediction strengths. © 2024 The Author(s)},
	author_keywords = {auto-regressive model; BERT; bidirectional encoder; deductive logical reasoning; GPT; large language model; LLM; reversal curse},
	keywords = {Encoding (symbols); Knowledge graph; Modeling languages; Autoregressive modelling; Bidirectional encoder; Bidirectional encoder representation from transformer; Deductive logical reasoning; Generative pretrained transformer; Language model; Large language model; Logical reasoning; Reversal curse; Decoding},
	correspondence_address = {K. Wang; Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Children's Hospital of Philadelphia, Philadelphia, 19104, United States; email: wangk@chop.edu},
	publisher = {Cell Press},
	issn = {26663899},
	language = {English},
	abbrev_source_title = {Patterns},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zahid2024,
	author = {Zahid, Idrees A. and Joudar, Shahad Sabbar and Albahri, A.S. and Albahri, O.S. and Alamoodi, A.H. and Santamaría, Jose and Alzubaidi, Laith},
	title = {Unmasking large language models by means of OpenAI GPT-4 and Google AI: A deep instruction-based analysis},
	year = {2024},
	journal = {Intelligent Systems with Applications},
	volume = {23},
	doi = {10.1016/j.iswa.2024.200431},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202898001&doi=10.1016%2fj.iswa.2024.200431&partnerID=40&md5=4cc6d26d76be74ed5196ab5cd1a3c0db},
	affiliations = {University of Technology, Baghdad, Iraq; Technical College, Imam Ja'afar Al-Sadiq University, Baghdad, Iraq; Australian Technical and Management College, Melbourne, Australia; Computer Techniques Engineering Department, Mazaya University College, Nasiriyah, Iraq; Applied Science Research Center, Applied Science Private University, Amman, Jordan; MEU Research Unit, Middle East University, Amman, Jordan; Department of Computer Science, University of Jaén, Jaén, 23071, Spain; School of Mechanical, Medical, and Process Engineering, Queensland University of Technology, Brisbane, 4000, QLD, Australia; Centre for Data Science, Queensland University of Technology, Brisbane, 4000, QLD, Australia},
	abstract = {Large Language Models (LLMs) have become a hot topic in AI due to their ability to mimic human conversation. This study compares the open artificial intelligence generative pretrained transformer-4 (GPT-4) model, based on the (GPT), and Google's artificial intelligence (AI), which is based on the Bidirectional Encoder Representations from Transformers (BERT) framework in terms of the defined capabilities and the built-in architecture. Both LLMs are prominent in AI applications. First, eight different capabilities were identified to evaluate these models, i.e. translation accuracy, text generation, factuality, creativity, intellect, deception avoidance, sentiment classification, and sarcasm detection. Next, each capability was assessed using instructions. Additionally, a categorized LLM evaluation system has been developed by means of using ten research questions per category based on this paper's main contributions from a prompt engineering perspective. It should be highlighted that GPT-4 and Google AI successfully answered 85 % and 68,7 % of the study prompts, respectively. It has been noted that GPT-4 better understands prompts than Google AI, even with verbal flaws, and tolerates grammatical errors. Moreover, the GPT-4 based approach was more precise, accurate, and succinct than Google AI, which was sometimes verbose and less realistic. While GPT-4 beats Google AI in terms of translation accuracy, text generation, factuality, intellectuality, creativity, and deception avoidance, Google AI outperforms the former when considering sarcasm detection. Both sentiment classification models did work properly. More importantly, a human panel of judges was used to assess and evaluate the model comparisons. Statistical analysis of the judges' ratings revealed more robust results based on examining the specific uses, limitations, and expectations of both GPT-4 and Google AI-based approaches. Finally, the two approaches' transformers, parameter sizes, and attention mechanisms have been examined. © 2024},
	author_keywords = {Deception avoidance; Google AI; Instruction-based analysis; OpenAI GPT-4; Sarcasm detection; Transformers},
	keywords = {Deep learning; Deception avoidance; Google artificial intelligence; Google+; Instruction-based analyze; Language model; Openai generative pretrained transformer-4; Sarcasm detection; Sentiment classification; Text generations; Transformer; Distribution transformers},
	correspondence_address = {L. Alzubaidi; School of Mechanical, Medical, and Process Engineering, Queensland University of Technology, Brisbane, 4000, Australia; email: l.alzubaidi@qut.edu.au},
	publisher = {Elsevier B.V.},
	issn = {26673053},
	language = {English},
	abbrev_source_title = {Intell. Syst. Applications.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{2025,
	title = {COLING 2025 - 31st International Conference on Computational Linguistics, Proceedings of the New Horizons in Computational Linguistics for Religious Texts, Coling-Rel 2025},
	year = {2025},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000210737&partnerID=40&md5=4972db0c7bb643e7a979e2cd9e78eb83},
	abstract = {The proceedings contain 9 papers. The topics discussed include: comparative analysis of religious texts: NLP approaches to the Bible, Quran, and Bhagavad Gita; messages from the Quran and the Bible in Mandarin through factor analysis with syntactic and semantic tags; semantic analysis of jurisprudential Zoroastrian Texts in Pahlavi: a word embedding approach for an extremely under-resourced, extinct language; multi-stage training of bilingual Islamic LLM for neural passage retrieval; automated translation of Islamic literature using large language models: Al-Shamela library application; automated authentication of Quranic verses using BERT (bidirectional encoder representations from transformers) based language models; and leveraging AI to bridge classical Arabic and modern standard Arabic for text simplification.},
	editor = {Yagi S. and Sawalha M. and Sawalha M. and Abu Shawar B. and AlShdaifat A.T. and Abbas N.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {979-889176203-9},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shukla2024335,
	author = {Shukla, Shiv Shankar Prasad and Singh, Maheshwari Prasad},
	title = {Exploring ensemble optimized voting and stacking classifiers through Cross-validation for early detection of suicidal ideation},
	year = {2024},
	journal = {Journal of Intelligent and Fuzzy Systems},
	volume = {47},
	number = {5-6},
	pages = {335 – 349},
	doi = {10.3233/JIFS-234506},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214699462&doi=10.3233%2fJIFS-234506&partnerID=40&md5=5bf9cf4e15a05120d2c96b5ca1acde10},
	affiliations = {Department of Computer Science Engineering, National Institute of Technology Patna, Bihar, Patna, India},
	abstract = {Detecting behavioral changes associated with suicidal ideation on social media is essential yet complex. While machine learning and deep learning hold promise in this regard, current studies often lack generalizability due to single dataset reliance. Traditional embedding techniques struggle with semantic analysis,leading to challenges in achieving high accuracy models and conventional validation methods have data drift limitations. To address these challenges, this study proposes a novel evaluation approach using natural language processing across diverse platforms like Twitter and Reddit. By integrating BERT embedding, adept at handling semantic nuances, with an optimized Stacked Classifier combining different base classifiers and XGBoost as the meta-classifier, the model excels in swiftly detecting signs of suicidal ideation compared to the Voting Classifier, i.e., the combination of Decision Tree, Random Forest, Gradient Boost and XGBoost and several machine learning models. Additionally, the study explores advanced embedding techniques like MUSE and LLM, and deep learning models including Bi-LSTM, Bi-GRU, and Text-CNN for comparison.This ensemble approach aims to create a model that is not only interpretable but also robust, reducing computational complexity and enhancing resilience against noisy data - common challenges faced in text classification tasks. Through K-fold validation, which involves partitioning the dataset into k equal-sized subsets or "folds"and training the model k times, using k-1 folds for training and one-fold for testing each time, the proposed model achieves impressive accuracy rates of 97% on Reddit and 96% on Twitter datasets, underscoring its effectiveness in identifying suicidal ideation across social media platforms.  © 2024 - IOS Press. All rights reserved.},
	author_keywords = {BERT; Bi-GRU; Bi-LSTM; MUSE; Stacked Classifier; suicidal ideation; Voting Classifier},
	keywords = {Adversarial machine learning; Contrastive Learning; Decision trees; Deep learning; Embeddings; Natural language processing systems; Tweets; BERT; Bi-GRU; Bi-LSTM; Cross validation; Embedding technique; MUSE; Stacked classifier; Stackings; Suicidal ideation; Voting classifiers; Semantics},
	correspondence_address = {S.S.P. Shukla; Department of Computer Science Engineering, National Institute of Technology Patna, Patna, Bihar, 800005, India; email: shivs.phd19.cs@nitp.ac.in},
	publisher = {IOS Press BV},
	issn = {10641246},
	language = {English},
	abbrev_source_title = {J. Intelligent Fuzzy Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ginige202426,
	author = {Ginige, Yasod and Dahanayaka, Thilini and Seneviratne, Suranga},
	title = {TrafficGPT: An LLM Approach for Open-Set Encrypted Traffic Classification},
	year = {2024},
	journal = {Asian Internet Engineering Conference, AINTEC 2024},
	pages = {26 – 35},
	doi = {10.1145/3674213.3674217},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203281424&doi=10.1145%2f3674213.3674217&partnerID=40&md5=165b31d81d28bb7708b0ed375cf26c15},
	affiliations = {The University of Sydney, Australia},
	abstract = {Encrypted traffic has been known to be vulnerable to traffic analysis attacks that exploit the statistical features of encrypted traffic flows, such as packet sizes, timing, and direction, to infer information about the underlying content, which undermines the privacy guarantees of end-to-end encryption. While state-of-the-art attacks leverage deep learning models to achieve high accuracy, most attacks work under the less realistic closed-set assumption. Deploying such attacks in practice requires addressing the open-set scenario, which allows the models to filter out target content from other background traffic. Concurrently, Large Language Models (LLM) are increasingly gaining traction due to their ability to adapt to diverse tasks in domains outside NLP, especially in applications with sequential data. Inspired by this, our work introduces TrafficGPT, a novel traffic analysis attack that leverages GPT-2, a popular LLM, to enhance feature extraction, thereby improving the open-set performance of downstream classification. We use five existing encrypted traffic datasets to show how the feature extraction by GPT-2 improves the open-set performance of traffic analysis attacks compared to ET-BERT and CNN-based approaches by 12.7% and 13.7%, respectively. © 2024 Owner/Author.},
	author_keywords = {Encrypted traffic analysis; Large Language models; Open-set classification},
	keywords = {Cryptography; Deep learning; Traffic control; Encrypted traffic; Encrypted traffic analyze; Features extraction; Language model; Large language model; Modeling approach; Open-set classification; Performance; Traffic analysis; Traffic analysis attacks; Differential privacy},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070985-2},
	language = {English},
	abbrev_source_title = {Asian Internet Eng. Conf., AINTEC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Shalinda2025,
	author = {Shalinda, Damidu and Asanka, Dinesh},
	title = {Scoring System for Academic Essay Questions with Personalised Feedback Generation},
	year = {2025},
	journal = {2025 5th International Conference on Advanced Research in Computing: Converging Horizons: Uniting Disciplines in Computing Research through AI Innovation, ICARC 2025 - Proceedings},
	doi = {10.1109/ICARC64760.2025.10962903},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004546754&doi=10.1109%2fICARC64760.2025.10962903&partnerID=40&md5=abeb3f80ce296baccf52ff715ce0af09},
	affiliations = {University of Kelaniya, Department of Industrial Management, Kelaniya, Sri Lanka},
	abstract = {This study presents an advanced Automated Essay Scoring (AES) system that seeks to enhance academic evaluation systems by integrating an LLM such as BERT, GPT-3, and GPT-4. This study employs few-shot learning technology to enable models to learn to adapt to different themes of essays and student styles. Provides human-in-the-loop feedback to achieve accuracy and scalability by incorporating manual annotation and LLM-assisted annotation. The combination of automated scoring and actionable trait-specific feedback integrates this broad-generating scoring system with individualized pedagogical support. Evaluation indicates that this system would likely lead to rather outstanding educational improvements through providing precise constructive alignments to academic standards and rubric space. This work extends AES technologies for personalized learning against existing gaps of feedback quality and accessibility.  © 2025 IEEE.},
	author_keywords = {Automated Essay Scoring (AES); Few-Shot Learning; Large Language Models (LLMs); Personalized Feedback Rubric-Based Evaluation},
	keywords = {Engineering education; Automated essay scoring; Few-shot learning; Language model; Large language model; Learn+; Learning technology; Personalized feedback; Personalized feedback rubric-based evaluation; Scoring systems; Educational robots},
	correspondence_address = {D. Shalinda; University of Kelaniya, Department of Industrial Management, Kelaniya, Sri Lanka; email: kumaraa-im19012@stu.kln.ac.lk},
	editor = {Ishanka U.A.P. and Herath G.A.C.A. and Prasanth S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833153098-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Res. Comput.: Converging Horizons: Uniting Discipl. Comput. Res. through AI Innov., ICARC - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024113,
	author = {Yang, Dongju and Huang, Juntao},
	title = {Chinese Scientific Literature Annotation Method Based on Large Language Model},
	year = {2024},
	journal = {Jisuanji Gongcheng/Computer Engineering},
	volume = {50},
	number = {9},
	pages = {113 – 120},
	doi = {10.19678/j.issn.1000-3428.0068400},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210576819&doi=10.19678%2fj.issn.1000-3428.0068400&partnerID=40&md5=d6a7d34a1d33c0db7be09d03eccd1c31},
	affiliations = {School of Information, North China University of Technology, Beijing, 100144, China; Beijing Key Laboratory on Integration and Analysis of Large-scale Stream Data, Beijing, 100144, China},
	abstract = {High-quality annotated data are crucial for Natural Language Processing (NLP) tasks in the field of Chinese scientific literature. A method of annotation based on a Large Language Model(LLM) was proposed to address the lack of high-quality annotated corpora and the issules of inconsistent and inefficient manual annotation in Chinese scientific literature. First, a fine-grained annotation specification suitable for multi-domain Chinese scientific literature was established to clarify entity types and annotation granularity. Second, a structured text annotation prompt template and a generation parser were designed. The annotation task of Chinese scientific literature was set up as a single-stage, single-round question-and-answer process in which the annotation specifications and text to be annotated were filled into the corresponding slots of the prompt template to construct the task prompt. This prompt was then injected into the LLM to generate output text containing annotation information. Finally, the structured annotation data were obtained by the parser. Subsequently, using prompt learning based on LLM, the Annotated Chinese Scientific Literature(ACSL) entity dataset was generated, which contains 10000 annotated documents and 72536 annotated entities distributed across 48 disciplines. For ACSL, three baseline models based on RoBERTa-wwm-ext, a configuration of the Robustly optimized Bidirectional Encoder Representations from Transformers (RoBERT) approach, were proposed. The experimental results demonstrate that the BERT + Span model performs best on long-span entity recognition in Chinese scientific literature, achieving an F1 value of 0.335. These results serve as benchmarks for future research. © 2024, Editorial Office of Computer Engineering. All rights reserved.},
	author_keywords = {Chinese scientific literature; information extraction; Large Language Model (LLM); prompt learning; text annotation method},
	correspondence_address = {J. Huang; School of Information, North China University of Technology, Beijing, 100144, China; email: huangjuntao@mail.ncut.edu.cn},
	publisher = {Editorial Office of Computer Engineering},
	issn = {10003428},
	coden = {JISGE},
	language = {Chinese},
	abbrev_source_title = {Jisuanji Gongcheng},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2024,
	author = {Zhang, Yice and Xu, Hongling and Zhang, Delong and Xu, Ruifeng},
	title = {A Hybrid Approach to Dimensional Aspect-Based Sentiment Analysis Using BERT and Large Language Models},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {18},
	doi = {10.3390/electronics13183724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205074056&doi=10.3390%2felectronics13183724&partnerID=40&md5=799d2bce898abcf44ec820b2f5a78658},
	affiliations = {Harbin Institute of Technology, Shenzhen, 518067, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies, Shenzhen, 518067, China; Peng Cheng Laboratory, Shenzhen, 518055, China},
	abstract = {Dimensional aspect-based sentiment analysis (dimABSA) aims to recognize aspect-level quadruples from reviews, offering a fine-grained sentiment description for user opinions. A quadruple consists of aspect, category, opinion, and sentiment intensity, which is represented using continuous real-valued scores in the valence–arousal dimensions. To address this task, we propose a hybrid approach that integrates the BERT model with a large language model (LLM). Firstly, we develop both the BERT-based and LLM-based methods for dimABSA. The BERT-based method employs a pipeline approach, while the LLM-based method transforms the dimABSA task into a text generation task. Secondly, we evaluate their performance in entity extraction, relation classification, and intensity prediction to determine their advantages. Finally, we devise a hybrid approach to fully utilize their advantages across different scenarios. Experiments demonstrate that the hybrid approach outperforms BERT-based and LLM-based methods, achieving state-of-the-art performance with an F1-score of 41.7% on the quadruple extraction. © 2024 by the authors.},
	author_keywords = {aspect-based sentiment analysis; BERT; dimensional sentiment analysis; large language models},
	correspondence_address = {R. Xu; Harbin Institute of Technology, Shenzhen, 518067, China; email: xuruifeng@hit.edu.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Albuquerque20252332,
	author = {Albuquerque, Josmario and Rienties, Bart and Holmes, Wayne and Hlosta, Martin},
	title = {From hype to evidence: exploring large language models for inter-group bias classification in higher education},
	year = {2025},
	journal = {Interactive Learning Environments},
	volume = {33},
	number = {3},
	pages = {2332 – 2354},
	doi = {10.1080/10494820.2024.2408554},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003763161&doi=10.1080%2f10494820.2024.2408554&partnerID=40&md5=f7d1b9e929bdcab43e65a0e7df41f694},
	affiliations = {Institute of Educational Technology, The Open University, Milton Keynes, United Kingdom; Institute of Education, University College London, London, United Kingdom; Institute for Distance Learning and eLearning Research, Swiss Distance University of Applied Sciences, Brig, Switzerland},
	abstract = {Inter-group biases can diminish student achievements in several ways. Yet, manually identifying those biases in vast learning texts is challenging because of their subtle nature. In the light of processing nuanced language, approaches based on large language models (LLMs) have emerged as promising mechanisms (e.g. ChatGPT). However, their potential for classifying bias in learning text seems under-explored. This study examines the ability of three LLMs (BERT, GPT, and PaLM) to classify inter-group bias within learning texts. Accordingly, 2024 sentences from 91 Higher Education (HE) courses at The Open University UK were assessed for potential biases by LLM-based approaches. Then, we used a sub-sample of sentences (n = 30) for comparison with student classifications. The models suggested varying degrees of biases within the larger sample (BERT = 49.5%; GPT = 10.2%; PaLM = 11.0%). However, varied agreement levels were found within the sub-samples, where Kappa values for model-to-model and model-to-human comparisons ranged from.0 to.77. This underscores the complexity of inter-group bias in learning texts where context and culture can be crucial. We discuss the relevance of those potential biases for learning settings and advocate for tools that are both context- and culture-aware, ensuring more inclusive learning experiences. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {artificial intelligence; bias in text; higher education; inter-group bias; Large language models; online learning},
	correspondence_address = {J. Albuquerque; Institute of Educational Technology, The Open University, Milton Keynes, United Kingdom; email: josmario.albuquerque@open.ac.uk},
	publisher = {Routledge},
	issn = {10494820},
	language = {English},
	abbrev_source_title = {Interact. Learn. Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Afshar2024,
	author = {Afshar, Majid and Gao, Yanjun and Gupta, Deepak and Croxford, Emma and Demner-Fushman, Dina},
	title = {On the role of the UMLS in supporting diagnosis generation proposed by Large Language Models},
	year = {2024},
	journal = {Journal of Biomedical Informatics},
	volume = {157},
	doi = {10.1016/j.jbi.2024.104707},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201697608&doi=10.1016%2fj.jbi.2024.104707&partnerID=40&md5=8cc2070355095c5dc56032f1c3e52329},
	affiliations = {University of Wisconsin School of Medicine and Public Health, 750 Highland Ave, Madison, 53726, WI, United States; National Library of Medicine, NIH, HHS, 8600 Rockville Pike, Bethesda, 20894, MD, United States},
	abstract = {Objective: Traditional knowledge-based and machine learning diagnostic decision support systems have benefited from integrating the medical domain knowledge encoded in the Unified Medical Language System (UMLS). The emergence of Large Language Models (LLMs) to supplant traditional systems poses questions of the quality and extent of the medical knowledge in the models’ internal knowledge representations and the need for external knowledge sources. The objective of this study is three-fold: to probe the diagnosis-related medical knowledge of popular LLMs, to examine the benefit of providing the UMLS knowledge to LLMs (grounding the diagnosis predictions), and to evaluate the correlations between human judgments and the UMLS-based metrics for generations by LLMs. Methods: We evaluated diagnoses generated by LLMs from consumer health questions and daily care notes in the electronic health records using the ConsumerQA and Problem Summarization datasets. Probing LLMs for the UMLS knowledge was performed by prompting the LLM to complete the diagnosis-related UMLS knowledge paths. Grounding the predictions was examined in an approach that integrated the UMLS graph paths and clinical notes in prompting the LLMs. The results were compared to prompting without the UMLS paths. The final experiments examined the alignment of different evaluation metrics, UMLS-based and non-UMLS, with human expert evaluation. Results: In probing the UMLS knowledge, GPT-3.5 significantly outperformed Llama2 and a simple baseline yielding an F1 score of 10.9% in completing one-hop UMLS paths for a given concept. Grounding diagnosis predictions with the UMLS paths improved the results for both models on both tasks, with the highest improvement (4%) in SapBERT score. There was a weak correlation between the widely used evaluation metrics (ROUGE and SapBERT) and human judgments. Conclusion: We found that while popular LLMs contain some medical knowledge in their internal representations, augmentation with the UMLS knowledge provides performance gains around diagnosis generation. The UMLS needs to be tailored for the task to improve the LLMs predictions. Finding evaluation metrics that are aligned with human judgments better than the traditional ROUGE and BERT-based scores remains an open research question. © 2024 Elsevier Inc.},
	author_keywords = {Artificial intelligence; Differential diagnoses; Evaluation methodology; Knowledge representation (computer); Natural language processing; Unified medical language system},
	keywords = {Decision Support Systems, Clinical; Diagnosis, Computer-Assisted; Electronic Health Records; Humans; Machine Learning; Natural Language Processing; Unified Medical Language System; Decision support systems; Domain Knowledge; Electronic health record; Unified Modeling Language; alanine aminotransferase; Differential diagnosis; Evaluation methodologies; Knowledge representation (computer); Knowledge-representation; Language model; Language processing; Natural language processing; Natural languages; System knowledge; Unified medical language systems; Article; artificial intelligence; benchmarking; decision support system; electronic health record; human; knowledge; large language model; natural language processing; prediction; scoring system; Unified Medical Language System; clinical decision support system; computer assisted diagnosis; electronic health record; machine learning; procedures; Knowledge representation},
	correspondence_address = {M. Afshar; Madison, 600 Highland Avenue, 53792, United States; email: majid.afshar@wisc.edu},
	publisher = {Academic Press Inc.},
	issn = {15320464},
	coden = {JBIOB},
	pmid = {39142598},
	language = {English},
	abbrev_source_title = {J. Biomed. Informatics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Glicksberg20241921,
	author = {Glicksberg, Benjamin S and Timsina, Prem and Patel, Dhaval and Sawant, Ashwin and Vaid, Akhil and Raut, Ganesh and Charney, Alexander W and Apakama, Donald and Carr, Brendan G and Freeman, Robert and Nadkarni, Girish N and Klang, Eyal},
	title = {Evaluating the accuracy of a state-of-the-art large language model for prediction of admissions from the emergency room},
	year = {2024},
	journal = {Journal of the American Medical Informatics Association},
	volume = {31},
	number = {9},
	pages = {1921 – 1928},
	doi = {10.1093/jamia/ocae103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201786452&doi=10.1093%2fjamia%2focae103&partnerID=40&md5=fb8a868510125d6c891fb44d8bee8d74},
	affiliations = {Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Institute for Healthcare Delivery Science, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Department of Emergency Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Department of Population Health Science and Policy, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States},
	abstract = {Background: Artificial intelligence (AI) and large language models (LLMs) can play a critical role in emergency room operations by augmenting decision-making about patient admission. However, there are no studies for LLMs using real-world data and scenarios, in comparison to and being informed by traditional supervised machine learning (ML) models. We evaluated the performance of GPT-4 for predicting patient admissions from emergency department (ED) visits. We compared performance to traditional ML models both naively and when informed by few-shot examples and/or numerical probabilities. Methods: We conducted a retrospective study using electronic health records across 7 NYC hospitals. We trained Bio-Clinical-BERT and XGBoost (XGB) models on unstructured and structured data, respectively, and created an ensemble model reflecting ML performance. We then assessed GPT-4 capabilities in many scenarios: through Zero-shot, Few-shot with and without retrieval-augmented generation (RAG), and with and without ML numerical probabilities. Results: The Ensemble ML model achieved an area under the receiver operating characteristic curve (AUC) of 0.88, an area under the precision-recall curve (AUPRC) of 0.72 and an accuracy of 82.9%. The naïve GPT-4's performance (0.79 AUC, 0.48 AUPRC, and 77.5% accuracy) showed substantial improvement when given limited, relevant data to learn from (ie, RAG) and underlying ML probabilities (0.87 AUC, 0.71 AUPRC, and 83.1% accuracy). Interestingly, RAG alone boosted performance to near peak levels (0.82 AUC, 0.56 AUPRC, and 81.3% accuracy). Conclusions: The naïve LLM had limited performance but showed significant improvement in predicting ED admissions when supplemented with real-world examples to learn from, particularly through RAG, and/or numerical probabilities from traditional ML models. Its peak performance, although slightly lower than the pure ML model, is noteworthy given its potential for providing reasoning behind predictions. Further refinement of LLMs with real-world data is necessary for successful integration as decision-support tools in care settings. © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.},
	author_keywords = {admission prediction; BERT; clinical informatics; emergency department; GPT-4; health informatics; large language models (LLMs); machine learning (ML); predictive modeling; retrieval-augmented generation (RAG); transformers},
	keywords = {adult; aged; Article; Bio-Clinical-BERT model; clinical reasoning; comparative study; correlation coefficient; cross validation; data accuracy; electronic health record; emergency department visit; emergency ward; female; generative pretrained transformer; hospital admission; human; large language model; major clinical study; male; medical informatics; prediction; predictive model; qualitative analysis; receiver operating characteristic; retrieval augmented generation; retrospective study; sequence learning; supervised machine learning; urban health; XGBoost model},
	correspondence_address = {E. Klang; Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, United States; email: eyal.klang@mountsinai.org; G.N. Nadkarni; The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, United States; email: girish.nadkarni@mountsinai.org},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@ARTICLE{Cochran2025,
	author = {Cochran, Keith and Cohn, Clayton and Rouet, Jean Francois and Hastings, Peter},
	title = {Comparing Text Augmentation by GPT-3.5 and Llama3 for Evaluating Student Responses},
	year = {2025},
	journal = {International Journal of Artificial Intelligence in Education},
	doi = {10.1007/s40593-025-00473-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003492423&doi=10.1007%2fs40593-025-00473-x&partnerID=40&md5=4d84d241f84199912e335efb605e522d},
	affiliations = {School of Computing, DePaul University, 243 South Wabash Avenue, Chicago, 60604, IL, United States; Department of Computer Science, Vanderbilt University, Nashville, 37240, TN, United States; Université de Poitiers, Poitiers Cedex 9, 86073, France},
	abstract = {Writing is a critical educational task because it encompasses so many skills necessary for the modern world, including vocabulary and grammar acquisition, critical thinking, adapting to different audiences, and determining how best to communicate one’s ideas. However, written assignments are notoriously time-consuming for teachers to grade, and timely feedback is critical for students’ learning. Automated evaluation can provide quick student feedback while easing the manual evaluation burden for teachers. Current machine learning-based methods of evaluating student textual responses have met with varying degrees of success. One main challenge in training these models is the scarcity of student-generated data. Large volumes of training data are needed to create accurate models, and few educational tasks are large enough. To overcome this data scarcity issue, text augmentation techniques have been used to balance and expand the data set so that classification models can be trained with higher accuracy, providing more useful feedback for teachers and students. This paper examines the performance of text augmentation using two Large Language Models (LLMs) to provide supplemental texts for training models for classifying student answers in English and French educational tasks. Our results show that text generation can dramatically improve model performance on small data sets over simple self-augmentation, especially when the LLM is set to generate more varied responses. © International Artificial Intelligence in Education Society 2025.},
	author_keywords = {BERT; Data augmentation; Educational texts; GPT-3.5; Llama3 70b; Natural language processing; Text generation},
	keywords = {Context sensitive grammars; Contrastive Learning; Metadata; Natural language processing systems; Personnel training; Students; BERT; Data augmentation; Educational text; GPT-3.5; Language processing; Llama3 70b; Natural language processing; Natural languages; Teachers'; Text generations; Teaching},
	correspondence_address = {K. Cochran; School of Computing, DePaul University, Chicago, 243 South Wabash Avenue, 60604, United States; email: kcochr11@depaul.edu; P. Hastings; School of Computing, DePaul University, Chicago, 243 South Wabash Avenue, 60604, United States; email: phasting@depaul.edu},
	publisher = {Springer},
	issn = {15604292},
	language = {English},
	abbrev_source_title = {Int. J. Artif. Intell. Educ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ben Shoham2024,
	author = {Ben Shoham, Ofir and Rappoport, Nadav},
	title = {CPLLM: Clinical prediction with large language models},
	year = {2024},
	journal = {PLOS Digital Health},
	volume = {3},
	number = {12},
	doi = {10.1371/journal.pdig.0000680},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211718531&doi=10.1371%2fjournal.pdig.0000680&partnerID=40&md5=49bd57965786b7b7b5be0ceef0ec076c},
	affiliations = {Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Israel},
	abstract = {We present Clinical Prediction with Large Language Models (CPLLM), a method that involves fine-tuning a pre-trained Large Language Model (LLM) for predicting clinical disease and readmission. We utilized quantization and fine-tuned the LLM using prompts. For diagnostic predictions, we predicted whether patients would be diagnosed with a target disease during their next visit or in the subsequent diagnosis, leveraging their historical medical records. We compared our results to various baselines, including Retain and Med-BERT, the latter of which is the current state-of-the-art model for disease prediction using temporal structured EHR data. In addition, we also evaluated CPLLM’s utility in predicting hospital readmission and compared our method’s performance with benchmark baselines. Our experiments ultimately revealed that our proposed method, CPLLM, surpasses all the tested models in terms of PR-AUC and ROC-AUC metrics, providing state-of-the-art performance as a tool for predicting disease diagnosis and patient hospital readmission without requiring pre-training on medical data. Such a method can be easily implemented and integrated into the clinical workflow to help care providers plan next steps for their patients. © 2024 Ben Shoham, Rappoport. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	correspondence_address = {N. Rappoport; Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Israel; email: nadavrap@bgu.ac.il},
	publisher = {Public Library of Science},
	issn = {27673170},
	language = {English},
	abbrev_source_title = {PLOS Digit. Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Yerkebulan2025331,
	author = {Yerkebulan, Alimzhan and Mansurova, Madina and Abdildayeva, Assel and Sharip, Olzhas},
	title = {Research on the Application of Large Language Models (LLM) for Improving Recruitment Efficiency and Accuracy},
	year = {2025},
	journal = {Lecture Notes in Computer Science},
	volume = {15683 LNAI},
	pages = {331 – 344},
	doi = {10.1007/978-981-96-6008-7_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004255625&doi=10.1007%2f978-981-96-6008-7_24&partnerID=40&md5=ff6a59c531ea627bb103bf7b01420be8},
	affiliations = {Al-Farabi Kazakh National University, Almaty, Kazakhstan},
	abstract = {In the modern world, artificial intelligence technologies are actively implemented in various fields of activity, including personnel management. In the article, this method of using large language models (LLM) to automate the recruitment process through resume analysis. Based on the aisale.kz product, ByteMachine conducted a study on the effectiveness of using LLM in the parliament of candidate qualifications taking into account the requirements of vacancies. Experiments were conducted using models based on the BERT design, during which real results and vacancies were analyzed. The results of measuring the accuracy and completeness indicators, indicating the capabilities of the models, effectively assess the suitability of candidates. Comparison with conservative recruitment methods revealed the importance of taking into account processing time and increasing the objectivity of assessments. The limitations of models associated with taking into account the qualitative characteristics of candidates are discussed and ways to overcome them are provided. The need for further results of the search for algorithms and the provision of additional data to clarify accuracy estimates is noted. A conclusion is made about the significant potential of LLM in the transformational processes of recruiting and the prospects for their development in the field of personnel management. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Artificial Intelligence (AI) in HR; Large Language Models (LLM); Natural Language Processing (NLP)},
	keywords = {Empowerment of personnel; Human resource management; Artificial intelligence  in HR; Artificial intelligence technologies; Candidate qualifications; Language model; Language processing; Large language model; Natural language processing; Natural languages; Personnel management; Recruitment process; Natural language processing systems},
	correspondence_address = {A. Yerkebulan; Al-Farabi Kazakh National University, Almaty, Kazakhstan; email: ayerkebulan19@gmail.com; A. Abdildayeva; Al-Farabi Kazakh National University, Almaty, Kazakhstan; email: abass_81@mail.ru},
	editor = {Nguyen N.T. and Matsuo T. and Gaol F.L. and Manolopoulos Y. and Fujita H. and Hong T.-P. and Wojtkiewicz K.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981966007-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bhiwgade2025,
	author = {Bhiwgade, Akash Wamanrao and Nagrale, Nilesh and Patil Bedekar, Pragati and Sheikh, Sayara Bano},
	title = {Integrating Open-Source LLMs with Retrieval-Augmented Generation for Obstetrics and Gynecology Domain},
	year = {2025},
	journal = {2025 IEEE International Students' Conference on Electrical, Electronics and Computer Science, SCEECS 2025},
	doi = {10.1109/SCEECS64059.2025.10940324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002708212&doi=10.1109%2fSCEECS64059.2025.10940324&partnerID=40&md5=5f6aa5e232919571eea493a2b9b6428d},
	affiliations = {Tulsiramji Gaikwad Patil College of Engineering and Technology, Department of Information and Technology, Maharashtra, Nagpur, India},
	abstract = {In this research paper, we address the integration of Large Language Models (LLM) with Retrieval Augmented Generation (RAG) to enhance clinical decision support and address patient doubts in the Obstetrics and Gynecology (OBGYN) domain. The research mainly tries to explore on How open source LLM's can effectively retrieve and generate the relevant responses in the OBGYN domain. The research methodology includes two components: Data Ingestion, which reads the input text data and stores it to a vector database in an embedded format and Data Retriever-Generation, which retrieves the relevant information from the vector database and use it for accurate response generation. The method includes data collection from esteemed medical databases, LLM model selection, integration with RAG and evaluation of the generated outputs. The methodology uses Bio-Mistral 7B fine-tuned LLM with PubMed Bert embeddings. The LLM responses are evaluated using the Ragas framework, context precision and context recall to measure the performance of retrieval system, faithfulness to measure hallucinations and answer relevancy to measure how relevant the answers are to the input query. The evaluated results confirm that the research has improved the accuracy as well as the contextual relevancy of the information in the OBGYN domain. This research provides a robust architecture for integration of Artificial Intelligence for supporting clinical decision making and information retrieval in specialized medical domains. This research can be extended with the upcoming advancements in the field of Artificial Intelligence and Data Science. © 2025 IEEE.},
	author_keywords = {AI in Healthcare; Clinical Decision Support; Information Retrieval; Large Language Models; Machine Learning; Natural Language Processing; OBGYN; Retrieval Augmented Generation; Text Generation; Women's Health},
	keywords = {Clinical research; Diseases; Metadata; Natural language processing systems; Obstetrics; Oncology; Online searching; Pathology; Query languages; AI in healthcare; Clinical decision support; Language model; Language processing; Large language model; Machine-learning; Natural language processing; Natural languages; Obstetric and gynecology; Retrieval augmented generation; Text generations; Women's health; Gynecology},
	correspondence_address = {A.W. Bhiwgade; Tulsiramji Gaikwad Patil College of Engineering and Technology, Department of Information and Technology, Nagpur, Maharashtra, India; email: akash555bhiwgade@gmail.com},
	editor = {Mangal T.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152983-3},
	language = {English},
	abbrev_source_title = {IEEE Int. Students' Conf. Electr., Electron. Comput. Sci., SCEECS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gao2024,
	author = {Gao, Yan and Xiong, Guanyu and Li, Haijiang and Richards, Jarrod},
	title = {Exploring bridge maintenance knowledge graph by leveraging GrapshSAGE and text encoding},
	year = {2024},
	journal = {Automation in Construction},
	volume = {166},
	doi = {10.1016/j.autcon.2024.105634},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199297205&doi=10.1016%2fj.autcon.2024.105634&partnerID=40&md5=e57a047d034c74069b65e44c6a48e72f},
	affiliations = {BIM for Smart Engineering Centre, School of Engineering, Cardiff University, Cardiff, CF24 3AA, United Kingdom; Centregreat Rail Limited, Bridgend, CF31 2AD, United Kingdom},
	abstract = {Knowledge graphs (KGs) are crucial in documenting bridge maintenance expertise. However, existing KG schemas lack integration of bridge design and practical inspection insights. Meanwhile, traditional methods for node feature initialization, relying on meticulous manual encoding or word embeddings, are inadequate for real-world maintenance textual data. To address these challenges, this paper introduces a bridge maintenance-oriented KG (BMKG) schema and approaches for graph data mining, including node-layer classification and link prediction. These methods leverage large language model (LLM)-based text encoding combined with GraphSAGE, demonstrating excellent performance in semantic enrichment and KG completion on deficient BMKGs. Additionally, ablation studies reveal the superiority of the pre-trained BERT text encoder and the L2 distance pairwise scoring calculator. Furthermore, a practical implementation framework integrating these approaches is developed for routine bridge maintenance, which can facilitate various practical applications, such as maintenance planning, and has the potential to enhance the efficiency of engineers' documentation work. © 2024 The Author(s)},
	author_keywords = {Bridge maintenance knowledge graph; Graph neural networks; Link prediction; Node classification; Text encoding},
	keywords = {Classification (of information); Data mining; Directed graphs; Encoding (symbols); Knowledge graph; Knowledge management; Maintenance; Network coding; Semantics; Text processing; Bridge design; Bridge maintenance knowledge graph; Bridges maintenance; Encodings; Feature initialization; Graph neural networks; Knowledge graphs; Link prediction; Node classification; Text encoding; Graph neural networks},
	correspondence_address = {H. Li; BIM for Smart Engineering Centre, School of Engineering, Cardiff University, Cardiff CF24 3AA, United Kingdom; email: LiH@cardiff.ac.uk},
	publisher = {Elsevier B.V.},
	issn = {09265805},
	coden = {AUCOE},
	language = {English},
	abbrev_source_title = {Autom Constr},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Farruque20241013,
	author = {Farruque, Nawshad and Goebel, Randy and Sivapalan, Sudhakar and Zaïane, Osmar R.},
	title = {Depression symptoms modelling from social media text: an LLM driven semi-supervised learning approach},
	year = {2024},
	journal = {Language Resources and Evaluation},
	volume = {58},
	number = {3},
	pages = {1013 – 1041},
	doi = {10.1007/s10579-024-09720-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189466714&doi=10.1007%2fs10579-024-09720-4&partnerID=40&md5=6ec9d2378e76fc81fcd2c41e53db811a},
	affiliations = {Department of Computing Science, Faculty of Science, Alberta Machine Intelligence Institute (AMII), University of Alberta, Edmonton, T6G 2E8, AB, Canada; Department of Psychiatry, Faculty of Medicine and Dentistry, University of Alberta, Edmonton, T6G 2H5, AB, Canada},
	abstract = {A fundamental component of user-level social media language based clinical depression modelling is depression symptoms detection (DSD). Unfortunately, there does not exist any DSD dataset that reflects both the clinical insights and the distribution of depression symptoms from the samples of self-disclosed depressed population. In our work, we describe a semi-supervised learning (SSL) framework which uses an initial supervised learning model that leverages (1) a state-of-the-art large mental health forum text pre-trained language model further fine-tuned on a clinician annotated DSD dataset, (2) a Zero-Shot learning model for DSD, and couples them together to harvest depression symptoms related samples from our large self-curated depressive tweets repository (DTR). Our clinician annotated dataset is the largest of its kind. Furthermore, DTR is created from the samples of tweets in self-disclosed depressed users Twitter timeline from two datasets, including one of the largest benchmark datasets for user-level depression detection from Twitter. This further helps preserve the depression symptoms distribution of self-disclosed tweets. Subsequently, we iteratively retrain our initial DSD model with the harvested data. We discuss the stopping criteria and limitations of this SSL process, and elaborate the underlying constructs which play a vital role in the overall SSL process. We show that we can produce a final dataset which is the largest of its kind. Furthermore, a DSD and a Depression Post Detection model trained on it achieves significantly better accuracy than their initial version. © The Author(s) 2024.},
	author_keywords = {Bidirectional Encoder Representations from Transformers (BERT); Depression detection; Depression symptoms detection; Mental-BERT; Semi-supervised learning; Zero-shot learning},
	correspondence_address = {N. Farruque; Department of Computing Science, Faculty of Science, Alberta Machine Intelligence Institute (AMII), University of Alberta, Edmonton, T6G 2E8, Canada; email: nawshad@ualberta.ca},
	publisher = {Springer Science and Business Media B.V.},
	issn = {1574020X},
	language = {English},
	abbrev_source_title = {Lang. Resour. Eval.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Bendebane2025586,
	author = {Bendebane, Lamia and Laboudi, Zakaria and Saighi, Asma and Bouziane, Seif Eddine},
	title = {Fine-Tuning the BERT Model to Predict Depression and Anxiety Using Multi-Labeled Twitter Data},
	year = {2025},
	journal = {4th International Conference on Sentiment Analysis and Deep Learning, ICSADL 2025 - Proceedings},
	pages = {586 – 591},
	doi = {10.1109/ICSADL65848.2025.10932995},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002439377&doi=10.1109%2fICSADL65848.2025.10932995&partnerID=40&md5=097f786539ccc186a93e5f5514b2e774},
	affiliations = {University of Oum El Bouaghi, Research Laboratory on Computer Science's Complex Systems (ReLa(CS)2), Algeria; University of Oum El Bouaghi, Laboratory of Artificial Intelligence and Autonomous Things (LIAOA), Algeria; National School of Artificial Intelligence Algiers, Department of Intelligent Systems Engineering, Algeria},
	abstract = {Studying mental health through social media data has become an emerging area of research, notably for the detection of depression and anxiety. In this regard, many researches have been conducted, yielding very satisfactory results (e.g., [1]-[3]). However, most of these studies have addressed each of these two mental disorders separately. This is due to the overlap of symptoms associated with depression and anxiety that makes distinguishing between them significantly challenging. Based on this context, this work leverages pretrained large language models (LLMs) to develop efficient multi-class models for predicting both depression and anxiety. For this purpose, a small, multi-labeled Twitter dataset is first constructed. Then, a pre-trained BERT-based uncased model is fine-tuned for six epochs on the dataset, resulting in a model referred to as DAC-BERT. Finally, the DAC-BERT model is evaluated and compared against both hybrid deep learning models and other LLM-based models. The obtained results show that DAC-BERT model outperforms existing approaches, achieving accuracies of up to 97.20% on a multi-labeled dataset containing normal, depressive, and anxious tweets, and up to 96.50% on a dataset with only normal and depressive tweets. These findings highlight the promising potential of fine-tuning LLMs for predicting mental health disorders, particularly depression and anxiety.  © 2025 IEEE.},
	author_keywords = {anxiety; BERT; depression; large language model; Social media},
	keywords = {Deep learning; Anxiety; BERT; Depression; Fine tuning; Language model; Large language model; Mental disorders; Mental health; Multi-class models; Social media; Tweets},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152392-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Sentim. Anal. Deep Learn., ICSADL - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang202537572,
	author = {Wang, Meng and Kim, Jisu and Yan, Yuting},
	title = {Syntactic-Aware Text Classification Method Embedding the Weight Vectors of Feature Words},
	year = {2025},
	journal = {IEEE Access},
	volume = {13},
	pages = {37572 – 37590},
	doi = {10.1109/ACCESS.2025.3545877},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001066835&doi=10.1109%2fACCESS.2025.3545877&partnerID=40&md5=0e48381989d13399690588eb1685896a},
	affiliations = {Chinese Academy of Science, National Science Library, Beijing, 100190, China; Renmin University of China, School of Applied Economics, Beijing, 100872, China; Yunnan College of Finance and Economics, Kunming, 650399, China},
	abstract = {Text classification is the process of categorizing sentences into predefined classes on the basis of their meanings or functions. In this context, feature words play a crucial role in representing the core meaning and key information of sentences, reflecting the main content and deep semantics of scientific literature. Optimizing text classification models using feature words is an important task in the information mining of scientific literature. To address text classification considering feature words, this study constructs a set of feature words from a linguistic perspective and quantitatively expresses the weight differences of various feature words on the basis of syntactic structure features. By embedding the weight information, absolute position, relative position, and contextual information of feature words into pre-trained models, the universal text classification models considering feature word vector weights is established. The analysis of hyperparameter space relationships reveals that the hyperparameter settings are not simple linear relationships and that their interactions are often nonlinear and complex. Employing the Bayesian optimization algorithm facilitates the model in finding the optimal hyperparameters while reducing computational costs. Based on the public dataset RCMR 280K, the experimental results demonstrate that considering feature words enables the model to capture sentence structure and features in text classification task, improving the recognition accuracy of the model. Compared with base models (BERT, SciBERT, RoBERTa and ModernBERT) and their regularized models which consider feature words, the improved ModernBERT, which is based on weighted feature word vectors, achieves an average F1 of 95.8% in the recognition tasks of research objective, method, result and conclusion sentences, an improvement of 1.2%, 0.8%, 1.1%, and 0.9%, respectively. In addition, the results show that large language models (LLMs) exhibit robust performance in text classification tasks, with the fine-tuned GLM4-9B achieving superior performance by reaching an average F1 of 91.9%. This model can be applied to sentence recognition and classification tasks in various domains. By updating or replacing the feature word table, the model can be adapted to recognize and classify different types of sentences, providing a theoretical basis or model foundation for other downstream tasks. More details and model weights are public at https://huggingface.co/wmsr22/Classification/tree/main.  © 2013 IEEE.},
	author_keywords = {Bayesian optimization; feature word weight; LLM; position embedding; pre-trained model; Text classification},
	keywords = {Classification (of information); Embeddings; Syntactics; Vector spaces; Bayesian optimization; Classification tasks; Embeddings; Feature word weight; Feature words; Language model; Large language model; Position embedding; Pre-trained model; Text classification; Semantics},
	correspondence_address = {J. Kim; Renmin University of China, School of Applied Economics, Beijing, 100872, China; email: jisu0127@ruc.edu.cn; Y. Yan; Yunnan College of Finance and Economics, Kunming, 650399, China; email: 2024044@ynczy.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kaushal2024,
	author = {Kaushal, Anukriti and Lin, Chia-Chen and Chauhan, Rishabh and Kumar, Rajeev},
	title = {Charting the Growth of Text Summarisation: A Data-Driven Exploration of Research Trends and Technological Advancements},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {23},
	doi = {10.3390/app142311462},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211896085&doi=10.3390%2fapp142311462&partnerID=40&md5=7a82431afb0ad203a9e9f53759a09ba8},
	affiliations = {Department of Computer Science and Engineering, Delhi Technological University, Delhi, 110042, India; Department of Computer Science and Information Engineering, National Chin-Yi University of Technology, Taichung, 411030, Taiwan},
	abstract = {Text summarisation plays a pivotal role in efficiently processing large volumes of textual data, making it an indispensable tool across diverse domains such as healthcare, legal, education, and journalism. It addresses the challenge of information overload by condensing or generating concise, meaningful summaries that improve decision-making, enhance accessibility, and save valuable time. Advances in artificial intelligence continue to propel the growth of text summarisation research, particularly with the evolution from traditional extractive approaches to cutting-edge abstractive models like BERT and GPT, as well as emerging innovations in multimodal and multilingual summarisation. To trace the development of this field, this study integrates bibliometric analysis and an in-depth survey, leveraging data from the Web of Science database to explore citation trends, uncover influential contributors, and highlight emerging research areas. Furthermore, bibliometric and critical evaluations are employed to outline strategic pathways and propose future directions for the continued advancement of the field. By incorporating sophisticated visualisation tools such as VOSviewer and RawGraphs, the analysis provides an enriched understanding of the field’s trajectory, identifying significant methodologies, landmark contributions, and existing gaps. This comprehensive exploration not only underscores the progress achieved in text summarisation but also serves as an invaluable resource for shaping forthcoming research endeavours and inspiring innovation in this dynamic area of study. © 2024 by the authors.},
	author_keywords = {bibliometric analysis; LLM; NLP; text summarisation; WoS},
	keywords = {Bibliographic retrieval systems; Bibliographies; Data assimilation; Data handling; Bibliometrics analysis; Data driven; Indispensable tools; Large volumes; LLM; Research trends; Technological advancement; Text Summarisation; Textual data; WoS; Spatio-temporal data},
	correspondence_address = {A. Kaushal; Department of Computer Science and Engineering, Delhi Technological University, Delhi, 110042, India; email: anukritikaushal30@gmail.com; C.-C. Lin; Department of Computer Science and Information Engineering, National Chin-Yi University of Technology, Taichung, 411030, Taiwan; email: ally.cclin@ncut.edu.tw},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20763417},
	language = {English},
	abbrev_source_title = {Appl. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Taleb2024,
	author = {Taleb, Ikbal and Navaz, Alramzana Nujum and Serhani, Mohamed Adel},
	title = {Leveraging Large Language Models for Enhancing Literature-Based Discovery},
	year = {2024},
	journal = {Big Data and Cognitive Computing},
	volume = {8},
	number = {11},
	doi = {10.3390/bdcc8110146},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210421594&doi=10.3390%2fbdcc8110146&partnerID=40&md5=f3ab8ea4cff143c16174ebfec7141de1},
	affiliations = {College of Technological Innovation, Zayed University, Abu Dhabi P.O. Box 144534, United Arab Emirates; Department of Computer Science and Software Engineering, College of Information Technology, UAE University, Al Ain P.O. Box 15551, United Arab Emirates; Department of Information Systems, University of Sharjah, Sharjah P.O. Box 27272, United Arab Emirates},
	abstract = {The exponential growth of biomedical literature necessitates advanced methods for Literature-Based Discovery (LBD) to uncover hidden, meaningful relationships and generate novel hypotheses. This research integrates Large Language Models (LLMs), particularly transformer-based models, to enhance LBD processes. Leveraging LLMs’ capabilities in natural language understanding, information extraction, and hypothesis generation, we propose a framework that improves the scalability and precision of traditional LBD methods. Our approach integrates LLMs with semantic enhancement tools, continuous learning, domain-specific fine-tuning, and robust data cleansing processes, enabling automated analysis of vast text and identification of subtle patterns. Empirical validations, including scenarios on the effects of garlic on blood pressure and nutritional supplements on health outcomes, demonstrate the effectiveness of our LLM-based LBD framework in generating testable hypotheses. This research advances LBD methodologies, fosters interdisciplinary research, and accelerates discovery in the biomedical domain. Additionally, we discuss the potential of LLMs in drug discovery, highlighting their ability to extract and present key information from the literature. Detailed comparisons with traditional methods, including Swanson’s ABC model, highlight our approach’s advantages. This comprehensive approach opens new avenues for knowledge discovery and has the potential to revolutionize research practices. Future work will refine LLM techniques, explore Retrieval-Augmented Generation (RAG), and expand the framework to other domains, with a focus on dehallucination. © 2024 by the authors.},
	author_keywords = {BERT; biomedical literature; generative AI; hypothesis generation; literature-based discovery; LLM; SBERT; semantic enhancement; SLM; Swanson’s ABC model},
	keywords = {Drug discovery; Semantics; ABC model; BERT; Biomedical literature; Generative AI; Hypotheses generation; Language model; Large language model; Literature-based discoveries; SBERT; Semantic enhancements; SLM; Swanson’s ABC model; Blood pressure},
	correspondence_address = {A.N. Navaz; Department of Computer Science and Software Engineering, College of Information Technology, UAE University, Al Ain P.O. Box 15551, United Arab Emirates; email: 201570182@uaeu.ac.ae},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {25042289},
	language = {English},
	abbrev_source_title = {Big Data Cogn. Computing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Chen20241,
	author = {Chen, Hongzheng and Zhang, Jiahao and Du, Yixiao and Xiang, Shaojie and Yue, Zichao and Zhang, Niansong and Cai, Yaohui and Zhang, Zhiru},
	title = {Understanding the Potential of FPGA-based Spatial Acceleration for Large Language Model Inference},
	year = {2024},
	journal = {ACM Transactions on Reconfigurable Technology and Systems},
	volume = {18},
	number = {1},
	pages = {1 – 29},
	doi = {10.1145/3656177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003451636&doi=10.1145%2f3656177&partnerID=40&md5=929ceb768038b1eb2c9d4c40641b4eb6},
	affiliations = {Cornell University, 136 Hoy Rd, Ithaca, 14850, NY, United States; Tsinghua University, 30 Shuangqing Rd, Beijing, 100190, China},
	abstract = {Recent advancements in large language models (LLMs) boasting billions of parameters have generated a significant demand for efficient deployment in inference workloads. While hardware accelerators for Transformer-based models have been extensively studied, the majority of existing approaches rely on temporal architectures that reuse hardware units for different network layers and operators. However, these methods often encounter challenges in achieving low latency due to considerable memory access overhead. This article investigates the feasibility and potential of model-specific spatial acceleration for LLM inference on field-programmable gate arrays (FPGAs). Our approach involves the specialization of distinct hardware units for specific operators or layers, facilitating direct communication between them through a dataflow architecture while minimizing off-chip memory accesses. We introduce a comprehensive analytical model for estimating the performance of a spatial LLM accelerator, taking into account the on-chip compute and memory resources available on an FPGA. This model can be extended to multi-FPGA settings for distributed inference. Through our analysis, we can identify the most effective parallelization and buffering schemes for the accelerator and, crucially, determine the scenarios in which FPGA-based spatial acceleration can outperform its GPU-based counterpart. To enable more productive implementations of an LLM model on FPGAs, we further provide a library of high-level synthesis (HLS) kernels that are composable and reusable. This library will be made available as open-source. To validate the effectiveness of both our analytical model and HLS library, we have implemented Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformers (GPT2) on an AMD Xilinx Alveo U280 FPGA device. Experimental results demonstrate our approach can achieve up to 13.4× speedup when compared to previous FPGA-based accelerators for the BERT model. For GPT generative inference, we attain a 2.2× speedup compared to Design for Excellence, an FPGA overlay, in the prefill stage, while achieving a 1.9× speedup and a 5.7× improvement in energy efficiency compared to the NVIDIA A100 GPU in the decode stage.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {FPGA; hardware acceleration; high-level synthesis; large language models},
	keywords = {Analog storage; Band structure; Benchmarking; Charged particles; Computer graphics equipment; Computer software reusability; Digital storage; Electron correlations; Fermi surface; Fermions; Hadrons; Integrated circuit design; Neutrons; Particle beams; Plasmons; Problem oriented languages; Reusability; Semiconductor storage; SGML; Supersymmetry; Field programmables; Field-programmable gate array; Hardware acceleration; Hardware units; High-level synthesis; Language model; Large language model; Memory access; Model inference; Programmable gate array; High level synthesis},
	correspondence_address = {Z. Zhang; Cornell University, Ithaca, 136 Hoy Rd, 14850, United States; email: zhiruz@cornell.edu},
	publisher = {Association for Computing Machinery},
	issn = {19367406},
	language = {English},
	abbrev_source_title = {ACM Trans. Reconfigurable Technol. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Yoo2024,
	author = {Yoo, Byunghwa and Kim, Kyung-Joong},
	title = {Finding deceivers in social context with large language models and how to find them: the case of the Mafia game},
	year = {2024},
	journal = {Scientific Reports},
	volume = {14},
	number = {1},
	doi = {10.1038/s41598-024-81997-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213560283&doi=10.1038%2fs41598-024-81997-5&partnerID=40&md5=ce3d972f60bba57fe3a09933e715bc12},
	affiliations = {AI Graduate School, Gwangju Institute of Science and Technology, Gwangju, 61005, South Korea; School of Integrated Technology, Gwangju Institute of Science and Technology, Gwangju, 61005, South Korea},
	abstract = {Lies are ubiquitous and often happen in social interactions. However, socially conducted deceptions make it hard to get data since people are unlikely to self-report their intentional deception behaviors, especially malicious ones. Social deduction games, a type of social game where deception is a key gameplay mechanic, can be a good alternative to studying social deceptions. Hence, we utilized large language models’ (LLMs) high performance in solving complex scenarios that require reasoning and prompt engineering to detect deceivers in the game of Mafia given only partial information and found such an approach acquired better accuracy than previous BERT-based methods in human data and even surpassed human accuracy. Furthermore, we conducted extensive experiments and analyses to find out the strategies behind LLM’s reasoning process so that humans could understand the gist of LLM’s strategy. © The Author(s) 2024.},
	keywords = {Deception; Game Theory; Games, Experimental; Humans; Language; Male; Social Behavior; article; deception; game; human; large language model; male; prompt engineering; reasoning; self report; social environment; social interaction; deception; game; language; social behavior},
	correspondence_address = {K.-J. Kim; AI Graduate School, Gwangju Institute of Science and Technology, Gwangju, 61005, South Korea; email: kjkim@gist.ac.kr},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {39730776},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Shaik20251617,
	author = {Shaik, Khaja Ahmed and Xie, Shengyuan and Cruz, Francisco and Sandoval, Eduardo Benitez},
	title = {A Fuzzy Supervisory Framework for Real-Time Optimization of Robot Output and LLM Performance in HRI},
	year = {2025},
	journal = {ACM/IEEE International Conference on Human-Robot Interaction},
	pages = {1617 – 1620},
	doi = {10.1109/HRI61500.2025.10974222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004876041&doi=10.1109%2fHRI61500.2025.10974222&partnerID=40&md5=6af40c309bee315e92c335da3114c614},
	affiliations = {School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, Australia; Escuela de Ingeniería, Universidad Central de Chile, Santiago, Chile; School of Art and Design, University of New South Wales, Sydney, Australia},
	abstract = {Human-robot interaction plays a vital role in pushing the capabilities of socially interactive robots by enabling them to deliver content with high emotional intelligence. This research focuses on a supervisory fuzzy framework for constantly evaluating and improving the content delivered by the robot utilizing multimodal inputs and advanced intelligent algorithms. The main reason for using fuzzy logic is that it mimics human decision-making by providing a percentage-based measure of closeness. In this project, ARI Robot is being used with an LLM integration, which enables the user to communicate with the robot. Different algorithms were integrated for the classification of multimodal inputs, BERT (Bidirectional Encoder Representations from Transformers) for the classification of content, Wav2Vec 2.0 for classifying the tone of the user while interacting with the robot, and OpenFace for classifying the facial expression of the user. All of these inputs are then supervised by a fuzzy system with predefined rules to evaluate the content delivered and provide feedback for refinement. The proposed framework ensures an overall evaluation of content delivery, providing intelligent feedback to the ARI robot to improve interaction quality. By integrating these advanced models with fuzzy logic, the system mimics human-like judgment in assessing the interaction of verbal and non-verbal indications, making the way for emotionally intelligent robots in a social world. © 2025 IEEE.},
	author_keywords = {Fuzzy System; Human Robot Interaction; Multi-modality},
	keywords = {Collaborative robots; Emotional intelligence; Industrial robots; Intelligent robots; Emotional intelligence; Fuzzy supervisory; Fuzzy-Logic; Humans-robot interactions; Interactive robot; Multi-modality; Multimodal inputs; Performance; Realtime optimizations (RTO); Research focus; Social robots},
	correspondence_address = {K.A. Shaik; School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia; email: k.shaik@student.unsw.edu.au},
	publisher = {IEEE Computer Society},
	issn = {21672148},
	isbn = {979-835037893-1},
	language = {English},
	abbrev_source_title = {ACM/IEEE Int. Conf. Hum.-Rob. Interact.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2025,
	author = {Chen, Jing and Wei, Zhihua and Shen, Wen and Shang, Rui},
	title = {Infusing Multi-Hop Medical Knowledge Into Smaller Language Models for Biomedical Question Answering},
	year = {2025},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	doi = {10.1109/JBHI.2025.3547444},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000648344&doi=10.1109%2fJBHI.2025.3547444&partnerID=40&md5=2311e7a95d57056b101ca65102446bf2},
	affiliations = {Tongji University, Department of Computer Science and Technology, Shanghai, 201804, China},
	abstract = {MedQA-USMLE is a challenging biomedical question answering (BQA) task, as its questions typically involve multi-hop reasoning. To solve this task, BQA systems should possess substantial medical professional knowledge and strong medical reasoning capabilities. While state-of-the-art larger language models, such as Med-PaLM 2, have overcome this challenge, smaller language models (SLMs) still struggle with it. To bridge this gap, we introduces a multi-hop medical knowledge infusion (MHMKI) procedure to endow SLMs with medical reasoning capabilities. Specifically, we categorize MedQA-USMLE questions into distinct reasoning types, then create pre-training instances tailored to each type of questions with the semi-structured information and hyperlinks of Wikipedia articles. To enable SLMs to efficiently capture the multi-hop knowledge embedded in these instances, we design a reasoning chain masked language model for further pre-training of BERT models. Moreover, we transform these pre-training instances into a combined question answering dataset for intermediate fine-tuning of GPT models. We evaluate MHMKI with six SLMs (three BERT models and three GPT models) across five datasets spanning three BQA tasks. Results show that MHMKI benefits SLMs in nearly all tasks, especially those requiring multi-hop reasoning. For instance, the accuracy of MedQA-USMLE shows a significant increase of 5.3% on average.  © 2013 IEEE.},
	author_keywords = {BERT; GPT; LLM; medical reasoning; multi-hop question answering},
	keywords = {Hypertext systems; BERT; Biomedical question answering; GPT; Language model; LLM; Medical knowledge; Medical reasonings; Multi-hop question answering; Multi-hops; Question Answering; Question answering},
	correspondence_address = {Z. Wei; Tongji University, Department of Computer Science and Technology, Shanghai, 201804, China; email: zhihua_wei@tongji.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21682194},
	coden = {ITIBF},
	language = {English},
	abbrev_source_title = {IEEE J. Biomedical Health Informat.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Agarwal2025,
	author = {Agarwal, Siddharth and Wood, David and Murray, Benjamin A. K. and Wei, Yiran and Busaidi, Ayisha Al and Kafiabadi, Sina and Guilhem, Emily and Lynch, Jeremy and Townend, Matthew and Mazumder, Asif and Barker, Gareth J. and Cole, James H. and Sasieni, Peter and Ourselin, Sebastien and Modat, Marc and Booth, Thomas C.},
	title = {Impact of hospital-specific domain adaptation on BERT-based models to classify neuroradiology reports},
	year = {2025},
	journal = {European Radiology},
	doi = {10.1007/s00330-025-11500-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000299752&doi=10.1007%2fs00330-025-11500-9&partnerID=40&md5=1d3137de50bcdb49d08c9393dc587e84},
	affiliations = {School of Biomedical Engineering & Imaging Sciences, King’s College London, Becket House, London, United Kingdom; Department of Neuroradiology, Ruskin Wing, King’s College Hospital NHS Foundation Trust, London, United Kingdom; Guy’s and St Thomas’ NHS Foundation Trust, Great Maze Pond, London, United Kingdom; Department of Neuroimaging, Institute of Psychiatry, Psychology, & Neuroscience, King’s College London, London, United Kingdom; Centre for Medical Image Computing, Department of Computer Science, University College London, London, United Kingdom; Clinical Trials Unit, King’s College London, Guy’s Campus, Great Maze Pond, London, United Kingdom},
	abstract = {Objectives: To determine the effectiveness of hospital-specific domain adaptation through masked language modelling (MLM) on BERT-based models’ performance in classifying neuroradiology reports, and to compare these models with open-source large language models (LLMs). Materials and methods: This retrospective study (2008–2019) utilised 126,556 and 86,032 MRI brain reports from two tertiary hospitals—King’s College Hospital (KCH) and Guys and St Thomas’ Trust (GSTT). Various BERT-based models, including RoBERTa, BioBERT and RadBERT, underwent MLM on unlabelled reports from these centres. The downstream tasks were binary abnormality classification and multi-label classification. Performances of models with and without hospital-specific domain adaptation were compared against each other and LLMs on internal (KCH) and external (GSTT) hold-out test sets. Model performances for binary classification were compared using 2-way and 1-way ANOVA. Results: All models that underwent hospital-specific domain adaptation performed better than their baseline counterparts (all p-values < 0.001). For binary classification, MLM on all available unlabelled reports (194,467 reports) yielded the highest balanced accuracies (KCH: mean 97.0 ± 0.4% (standard deviation), GSTT: 95.5 ± 1.0%), after which no differences between BERT-based models remained (1-way ANOVA, p-values > 0.05). There was a log-linear relationship between the number of reports and performance. LLama-3.0 70B was the best-performing LLM (KCH: 97.1%, GSTT: 94.0%). Multi-label classification demonstrated consistent performance improvements from MLM for all abnormality categories. Conclusion: Hospital-specific domain adaptation should be considered best practice when deploying BERT-based models in new clinical settings. When labelled data is scarce or unavailable, LLMs can serve as a viable alternative, assuming adequate computational power is accessible. Key Points: Question BERT-based models can classify radiology reports, but it is unclear if there is any incremental benefit from additional hospital-specific domain adaptation. Findings Hospital-specific domain adaptation resulted in the highest BERT-based model accuracies and performance scaled log-linearly with the number of reports. Clinical relevance BERT-based models after hospital-specific domain adaptation achieve the best classification results provided sufficient high-quality training labels. When labelled data is scarce, LLMs such as Llama-3.0 70B are a viable alternative provided there are sufficient computational resources. © The Author(s) 2025.},
	author_keywords = {Language modelling; Natural language processing; Neuroradiology; Pretraining; Transformers},
	correspondence_address = {T.C. Booth; School of Biomedical Engineering & Imaging Sciences, King’s College London, Becket House, London, United Kingdom; email: thomas.booth@kcl.ac.uk},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09387994},
	coden = {EURAE},
	language = {English},
	abbrev_source_title = {Eur. Radiol.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Luo2024,
	author = {Luo, Donger and Sun, Qi and Li, Xinheng and Bai, Chen and Yu, Bei and Geng, Hao},
	title = {Knowing The Spec to Explore The Design via Transformed Bayesian Optimization},
	year = {2024},
	journal = {Proceedings - Design Automation Conference},
	doi = {10.1145/3649329.3658262},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211117420&doi=10.1145%2f3649329.3658262&partnerID=40&md5=9a2fffcaae5cfe12f7c62160ca6ed885},
	affiliations = {ShanghaiTech University, China; Zhejiang University, China; Chinese University of Hong Kong, Hong Kong; Shanghai Engineering Research Center of Energy Efficient and Custom Ai Ic, China},
	abstract = {AI chip scales expediently in the large language models (LLMs) era. In contrast, the existing chip design space exploration (DSE) methods, aimed at discovering optimal yet often infeasible or un-produceable Pareto-front designs, are hindered by neglect of design specifications. In this paper, we propose a novel Spec-driven transformed Bayesian optimization framework to find expected optimal RISC-V SoC architecture designs for LLM tasks. The highlights of our framework lie in a tailored transformed Gaussian process (GP) model prioritizing specified target metrics and a customized acquisition function (EHRM) in multi-objective optimization. Extensive experiments on large-scale RISC-V SoC architecture design explorations for LLMs, such as Transformer, BERT, and GPT-1, demonstrate that our method not only can effectively find the design according to QoR values from the spec, but also outperforms 34.59% in ADRS over state-of-the-art approach with only 66.67% runtime overhead. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	keywords = {Gaussian distribution; Integrated circuit design; Optimal systems; Pareto principle; Printed circuit design; Problem oriented languages; Space applications; System-on-chip; Architecture designs; Bayesian optimization; Chip design; Chip-scale; Design space exploration; Design specification; Exploration methods; Language model; Pareto front; SoC architecture; Space research},
	correspondence_address = {H. Geng; ShanghaiTech University, China; email: genghao@shanghaitech.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {0738100X},
	isbn = {979-840070601-1},
	coden = {PDAWD},
	language = {English},
	abbrev_source_title = {Proc Des Autom Conf},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Srinivasan20241626,
	author = {Srinivasan, Sriram and Sheng, Stephen and Deshmukh, Rishabh and Luo, Chen and Dattatreya, Yesh and Sanyal, Subhajit and Vishwanathan, S.V.N.},
	title = {Bi-CAT: Improving Robustness of LLM-based Text Rankers to Conditional Distribution Shifts},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {1626 – 1633},
	doi = {10.1145/3589335.3651947},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194472965&doi=10.1145%2f3589335.3651947&partnerID=40&md5=97c1e15c7ebf554bc737fb03af92f59d},
	affiliations = {Amazon LLC, United States},
	abstract = {Retrieval and ranking lie at the heart of several applications like search, question-answering, and recommendations. The use of Large language models (LLMs) such as BERT in these applications have shown promising results in recent times. Recent works on text-based retrievers and rankers show promising results by using bi-encoders (BE) architecture with BERT like LLMs for retrieval and a cross-attention transformer (CAT) architecture BERT or other LLMs for ranking the results retrieved. Although the use of CAT architecture for re-ranking improves ranking metrics, their robustness to data shifts is not guaranteed. In this work we analyze the robustness of CAT-based rankers. Specifically, we show that CAT rankers are sensitive to item distribution shifts conditioned on a query, we refer to this as conditional item distribution shift (CIDS). CIDS naturally occurs in large online search systems as the retrievers keep evolving, making it challenging to consistently train and evaluate rankers with the same item distribution. In this paper, we formally define CIDS and show that while CAT rankers are sensitive to this, BE models are far more robust to CIDS. We propose a simple yet effective approach referred to as Bi-CAT which augments BE model outputs with CAT rankers, to significantly improve the robustness of CAT rankers without any drop in in-distribution performance. We conducted a series of experiments on two publicly available ranking datasets and one dataset from a large e-commerce store. Our results on dataset with CIDS demonstrate that the Bi-CAT model significantly improves the robustness of CAT rankers by roughly 100-1000bps in F1 without any reduction in in-distribution model performance. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {information retrieval; language models; ranker; robustness},
	keywords = {Architecture; Computational linguistics; Information retrieval; Online systems; Conditional distribution; Datum shifts; Encoder architecture; Language model; Model-based OPC; Question Answering; Ranker; Re-ranking; Robustness; Search system; Large datasets},
	correspondence_address = {S. Srinivasan; Amazon LLC, United States; email: srirs@amazon.com; S. Sheng; Amazon LLC, United States; email: shenstep@amazon.com},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070172-6},
	language = {English},
	abbrev_source_title = {WWW Companion - Companion Proc. ACM Web Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Gupta20248,
	author = {Gupta, Ojasvi and De La Cuadra Lozano, Marta and Busalim, Abdelsalam and R Jaiswal, Rajesh and Quille, Keith},
	title = {Harmful Prompt Classification for Large Language Models},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {8 – 14},
	doi = {10.1145/3701268.3701271},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216580620&doi=10.1145%2f3701268.3701271&partnerID=40&md5=2cb43226fff0258e0703b36eda0d6edf},
	affiliations = {Technological University Dublin, Dublin, Ireland},
	abstract = {Over the last few years, using LLM chatbots like ClaudeAI, Co-pilot and ChatGPT for text generation has become a regular habit for many, with over 100 million weekly users flocking to ChatGPT alone. One side effect of such vast usage of these models is undesirable prompts being submitted to the model. This not only risks data and model poisoning if done repeatedly but also causes harm to society through the responses provided by the models, which are then in turn trained on such models. It is the onus of the model creators and company to address these undesirable prompts based on the type of harm present. To this end, model developers have started conducting Red-teaming of LLMs, a form of evaluation that elicits model vulnerabilities potentially leading to such undesirable behaviours. There are existing classifiers that detect whether a prompt is harmful and censor the models' responses for safe user access. However, for developers, more metadata on the category of danger that a prompt presents equips them with a capability to prepare for such attacks on the model based on the frequency and type of harm. Additionally, in cases where further investigation is required, companies can report problematic user behaviour to the authorities. Hence the importance of categorising harmful prompts. We propose a sub-category based prompt classifier that identifies the specific type of harm that a damaging prompt is addressing to help content moderators and governance functions take further actions. Using explainable AI methods, we focused on both black-box and white-box testing of models and explored Linear SVM, KNN and BERT for further sub-classifying harmful prompts, and obtained accuracies of 92%, 85% and 87% respectively. © 2024 Copyright held by the owner/author(s).},
	keywords = {Model checking; Black boxes; Chatbots; Language model; Model response; Model-based OPC; Red teaming; Side effect; Text generations; User behaviors; Users access; Black-box testing},
	correspondence_address = {O. Gupta; Technological University Dublin, Dublin, Ireland; email: x00205759@mytudublin.ie},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071159-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Yang2025,
	author = {Yang, Hongchao and Wang, Yunjia and Seow, Chee Kiat and Li, Zengke and Sun, Meng and De Cock, Cedric and Bi, Jingxue and Joseph, Wout and Plets, David},
	title = {NLOS Identification and Ranging Trustworthiness for Indoor Positioning with LLM-based UWB-IMU Fusion},
	year = {2025},
	journal = {IEEE Transactions on Instrumentation and Measurement},
	doi = {10.1109/TIM.2025.3554900},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001520922&doi=10.1109%2fTIM.2025.3554900&partnerID=40&md5=0a8861e9439b562518116b21b7000fcf},
	affiliations = {China University of Ming and Technology, Key Laboratory of Land Environment and Disaster Monitoring, Xuzhou, 221116, China; University of Glasgow, School of Computing Science, Glasgow, G12 8Rz, United Kingdom; Ghent University, Dept. of Information Technology Imec-Waves, Ghent, Belgium; Shandong Jianzhu University, School of Survering and Geo-Informatics, Jinan, 250101, China},
	abstract = {In the rapidly evolving Internet of Things (IoT) landscape, accurate indoor positioning is increasingly vital. The proposed algorithm synergizes Ultra-Wideband (UWB) sensor with Inertial measurement unit (IMU) and Artificial Intelligence to obtain precise positioning in Non-Line-of-Sight (NLOS) scenarios. In the proposed UWB module, Large language model (LLM) such as Bidirectional Encoder Representations from Transformers (BERT) algorithm is designed to utilize the Channel Impulse Response (CIR) for effective NLOS identification and UWB ranging trustworthiness evaluation. Concurrently, the IMU module is also designed with BERT to recognize various pedestrian activity states, thereby optimizing positioning. BERT's self attention mechanism and deep learning bidirectional training efficiently extract essential features from sequential data, capturing both local and global information. The integration of both UWB and IMU through a proposed tightly coupled algorithm significantly boosts positioning performance. Experiment campaigns demonstrate an average NLOS identification accuracy, Line-of-Sight (LOS) and F2 of 98.8%, 99.4% and 0.9926, respectively. These performance surpass the state-of-the-art Least Squares Support Vector Machine (LS-SVM), Convolutional Neural Network (CNN), CNN with Long Short-Term Memory (CNN-LSTM) up to 17.66% in NLOS identification. In terms of pedestrian activity recognition using BERT, the BERT algorithm achieves a precision(recall) of 99.3%(99.4%), notably outperforming CNN and CNN-LSTM by 17.9%(16.2%) and 11.9%(10.9%), respectively. Finally, the UWB-IMU algorithm significantly enhances positioning accuracy by 80.5%, outperforming Kalman, LSTM-EKF, and Particle filter methods by 68.1%, 48.3%, and 45.0%, respectively. The proposed approach presents a robust solution for indoor positioning for IoT applications, particularly in challenging NLOS environments. © 1963-2012 IEEE.},
	author_keywords = {Channel Impulse Response (CIR); indoor positioning system (IPS); Inertial measurement unit (IMU); Large language model (LLM); Transformer; Ultra-Wideband (UWB)},
	keywords = {Amplitude modulation; Binary images; Channel coding; Convolutional neural networks; Formal concept analysis; Frequency division multiplexing; Image acquisition; Image analysis; Image coding; Image quality; Image segmentation; Image texture; Image thinning; Intermodulation; Kalman filters; Long short-term memory; Network coding; Radial basis function networks; Shot noise; Slow light; Steganography; Time difference of arrival; Channel impulse response; Indoor positioning; Indoor positioning system; Inertial measurement unit; Inertial measurements units; Language model; Large language model; Positioning system; Transformer; Ultra-wideband; Ultrawide band; Impulse response},
	correspondence_address = {H. Yang; China University of Ming and Technology, Key Laboratory of Land Environment and Disaster Monitoring, Xuzhou, 221116, China; email: yang@cumt.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {00189456},
	coden = {IEIMA},
	language = {English},
	abbrev_source_title = {IEEE Trans. Instrum. Meas.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tangherlini2024519,
	author = {Tangherlini, Timothy R. and Chen, Ruofei},
	title = {Travels with BERT: Surfacing the intertextuality in Hans Christian Andersen's travel writing and fairy tales through the network lens of large language model-based topic modeling},
	year = {2024},
	journal = {Orbis Litterarum},
	volume = {79},
	number = {6},
	pages = {519 – 562},
	doi = {10.1111/oli.12458},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199282755&doi=10.1111%2foli.12458&partnerID=40&md5=34ab0c6657071f03e5fb5516d54001b0},
	affiliations = {Department of Scandinavian, University of California Berkeley, Berkeley, CA, United States; Department of Electrical Engineering and Computer Science, UCLA, Los Angeles, CA, United States},
	abstract = {Hans Christian Andersen's fairy tales have garnered the greatest popular and scholarly attention despite the interdependence of works across the broad range of his artistic production. We read Andersen's fairy tales in concert with his travel writing to highlight the intertextual aspects that cross these seemingly distinct genres. We leverage recent advances in large language models (LLM) and network theory to generate representations that facilitate user exploration of these intertextual interdependencies across genres and across time. In the first part of our study, we use BERTopic and an LLM model fine-tuned for nineteenth-century Danish literary language to present independent and combined topic models of the two corpuses. This approach supports multi-scalar analysis of intertextual elements within and across these corpuses, thereby implementing a method for macroscopic reading. In the second part of the study, we develop a series of networked representations of the dependencies between fairy tales, where these dependencies are generated on the basis of the shared intertextual topic space of the fairy tales and the travel writing. © 2024 The Author(s). Orbis Litterarum published by John Wiley & Sons Ltd.},
	author_keywords = {computational literary analysis; fairy tales; Hans Christian Andersen; large language models; networks; search; topic modeling; travel writing},
	correspondence_address = {T.R. Tangherlini; Department of Scandinavian, University of California Berkeley, Berkeley, United States; email: tango@berkeley.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {01057510},
	language = {English},
	abbrev_source_title = {Orb. Litt.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Hu2025,
	author = {Hu, Kaimiao and He, Yuan and Wei, Jianguo and Sun, Changming and Geng, Jie and Wei, Leyi and Su, Ran},
	title = {BFGTP: A BERT-Guided Two-Stage Molecular Representation Learning Framework for Toxicity Prediction},
	year = {2025},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	doi = {10.1109/JBHI.2025.3556766},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002041492&doi=10.1109%2fJBHI.2025.3556766&partnerID=40&md5=b78af3bf11617d5b264ff1ad3d4d8159},
	affiliations = {Tianjin University, College of Intelligence and Computing, Tianjin, 30000, China; CSIRO Data61, Sydney, 1710, NSW, Australia; Tianjin University, Tianjin Key Laboratory of Cardiovascular Emergency and Critical Care, Tianjin Municipal Science and Technology Bureau, Department of Cardiology, Chest Hospital, Tianjin, China; Macao Polytechnic University, Centre for Artificial Intelligence driven Drug Discovery, Faculty of Applied Science, Macao; Xiamen University, School of Informatics, Xiamen, China},
	abstract = {Accurate prediction of molecular toxicity is vital for drug development. Most mainstream methods rely on fingerprints or graph-based feature extraction, the emergence of large language models (LLMs) offers new prospects for molecular representation learning in toxicity prediction. Although several studies attempt to leverage LLMs to integrate molecular sequence data for pretraining molecular representations, certain limitations remain. Current LLM-based approaches usually utilize solely on class embedding features, overlooking the rich information in sequence embedding. Moreover, integrating pre-trained molecular representations with multi-modal molecular data may further enhance performance in toxicity prediction. To address these challenges, we propose BFGTP, a BERT-guided two-stage molecular representation learning framework for toxicity prediction. Firstly, we design independent encoders for molecular descriptions of three modalities, where the fingerprint encoder with dual level attention mechanisms effectively integrates multi-category fingerprints. Then, the two-stage guide strategy is introduced to fully utilize the prior knowledge of LLMs, employing contrastive learning to align and fuse the tri-modal representations and knowledge distillation to align predicted value distributions. BFGTP ultimately combines fingerprint and graph representations to predict molecular toxicity. Experiments on seven toxicity datasets show that BFGTP outperforms baselines, achieving the highest AUC on five datasets and the best average performance across five evaluation metrics. Ablation studies, t-SNE visualization and case study confirm the effectiveness of BFGTP's components and its ability to capture meaningful molecular representations. ©2013 IEEE.},
	author_keywords = {feature alignment; Molecular toxicity prediction; predicted distribution alignment; tri-modal molecular representations; two-stage guided learning},
	keywords = {Adversarial machine learning; Alignment; Graph embeddings; Knowledge representation; Prediction models; Feature alignment; Language model; Learning frameworks; Molecular representations; Molecular toxicities; Molecular toxicity prediction; Predicted distribution alignment; Toxicity predictions; Tri-modal molecular representation; Two-stage guided learning; Contrastive Learning},
	correspondence_address = {J. Wei; Tianjin University, College of Intelligence and Computing, Tianjin, 30000, China; email: jianguo@tju.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21682194},
	coden = {ITIBF},
	language = {English},
	abbrev_source_title = {IEEE J. Biomedical Health Informat.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Soleimani20244823,
	author = {Soleimani, Mohsen and Seyyedi, Navisa and Ayyoubzadeh, Seyed Mohammad and Kalhori, Sharareh Rostam Niakan and Keshavarz, Hamidreza},
	title = {Practical Evaluation of ChatGPT Performance for Radiology Report Generation},
	year = {2024},
	journal = {Academic Radiology},
	volume = {31},
	number = {12},
	pages = {4823 – 4832},
	doi = {10.1016/j.acra.2024.07.020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201314794&doi=10.1016%2fj.acra.2024.07.020&partnerID=40&md5=a8fc49c0dc4e4e9f3ba709db88f31121},
	affiliations = {Department of Health Information Management and Medical Informatics, School of Allied Medical Sciences, Tehran University of Medical Sciences, Tehran, Iran; Health Information Management Research Centre, Tehran University of Medical Sciences, Tehran, Iran; Peter L. Reichertz Institute for Medical Informatics, TU Braunschweig and Hannover Medical School, Braunschweig, Germany; Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran},
	abstract = {Rationale and Objectives: The process of generating radiology reports is often time-consuming and labor-intensive, prone to incompleteness, heterogeneity, and errors. By employing natural language processing (NLP)-based techniques, this study explores the potential for enhancing the efficiency of radiology report generation through the remarkable capabilities of ChatGPT (Generative Pre-training Transformer), a prominent large language model (LLM). Materials and Methods: Using a sample of 1000 records from the Medical Information Mart for Intensive Care (MIMIC) Chest X-ray Database, this investigation employed Claude.ai to extract initial radiological report keywords. ChatGPT then generated radiology reports using a consistent 3-step prompt template outline. Various lexical and sentence similarity techniques were employed to evaluate the correspondence between the AI assistant-generated reports and reference reports authored by medical professionals. Results: Results showed varying performance among NLP models, with Bart (Bidirectional and Auto-Regressive Transformers) and XLM (Cross-lingual Language Model) displaying high proficiency (mean similarity scores up to 99.3%), closely mirroring physician reports. Conversely, DeBERTa (Decoding-enhanced BERT with disentangled attention) and sequence-matching models scored lower, indicating less alignment with medical language. In the Impression section, the Word-Embedding model excelled with a mean similarity of 84.4%, while others like the Jaccard index showed lower performance. Conclusion: Overall, the study highlights significant variations across NLP models in their ability to generate radiology reports consistent with medical professionals' language. Pairwise comparisons and Kruskal–Wallis tests confirmed these differences, emphasizing the need for careful selection and evaluation of NLP models in radiology report generation. This research underscores the potential of ChatGPT to streamline and improve the radiology reporting process, with implications for enhancing efficiency and accuracy in clinical practice. © 2024 The Association of University Radiologists},
	author_keywords = {AI-assisted radiology; ChatGPT; Large Language Model; NLP-based evaluation; Radiology report generation},
	keywords = {Artificial Intelligence; Electronic Health Records; Humans; Natural Language Processing; Radiology; Radiology Information Systems; adult; Article; artificial intelligence; ChatGPT; clinical decision support system; clinical practice; comparative study; data base; electric potential; evaluation study; generative pretrained transformer; human; intensive care; Kruskal Wallis test; language model; large language model; medical information; natural language processing; radiologist; singular value decomposition; task performance; thorax radiography; electronic health record; radiology; radiology information system},
	correspondence_address = {N. Seyyedi; Department of Health Information Management and Medical Informatics, School of Allied Medical Sciences, Tehran University of Medical Sciences, Tehran, Iran; email: n-seyyedi@razi.tums.ac.ir},
	publisher = {Elsevier Inc.},
	issn = {10766332},
	coden = {ARADF},
	pmid = {39142976},
	language = {English},
	abbrev_source_title = {Acad. Radiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Kumari2025,
	author = {Kumari, Laxmi and Serasiya, Shilpa and Bharti, Santosh},
	title = {Deep Learning Approach for Evaluating Fairness in LLMs},
	year = {2025},
	journal = {1st International Conference on Sustainable Energy Technologies and Computational Intelligence: Towards Sustainable Energy Transition, SETCOM 2025},
	doi = {10.1109/SETCOM64758.2025.10932507},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002271861&doi=10.1109%2fSETCOM64758.2025.10932507&partnerID=40&md5=a9304225cb9ef4e5c9eb988ddada7c72},
	affiliations = {Kalol Institute of Technology & Research Center, Gujarat, Kalol, India; Pandit Deendayal Energy University, Computer Science and Engineering, Gandhinagar, India},
	abstract = {Large Language Models (LLMs) are prone to bias that can be introduced in the dataset itself or in the training phase. This can make their output lacking in fairness and hinder certain discriminated groups on the basis of stereotypes that the LLM may have been fed with or learnt. In today's day and age, LLMs are used to make major decisions and thus it is crucial to identify and remove such bias. In this paper, we have focused on identifying the bias present in medium-sized LLMs such as BERT, RoBERTA, DeBERTa and GPT-1 using bias evaluation metrics such as intrinsic and extrinsic. Both the metrics have been used and bias has been identified in the datasets that the LLMs are being trained on (intrinsic bias) as well as in the outputs of the LLMs for certain queries (extrinsic bias).  © 2025 IEEE.},
	author_keywords = {Bias; Cosine Similarity; Extrinsic; Fairness; Intrinsic; Large Language Models},
	keywords = {Adversarial machine learning; Deep learning; Federated learning; Structured Query Language; Bias; Cosine similarity; Extrinsic; Fairness; Intrinsic; Language model; Large language model; Learn+; Learning approach; Training phasis; Contrastive Learning},
	correspondence_address = {L. Kumari; Kalol Institute of Technology & Research Center, Kalol, Gujarat, India; email: laxmimect2014@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152054-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Sustain. Energy Technol. Comput. Intell.: Towards Sustain. Energy Transit., SETCOM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jędrzejewski2025247,
	author = {Jędrzejewski, Sebastian and Szmurło, Robert},
	title = {Cloze-tests generation for foreign language learning using transformer networks; [Generowanie testów Cloze’a do nauki języków obcych przy użyciu sieci Transformer]},
	year = {2025},
	journal = {Przeglad Elektrotechniczny},
	number = {3},
	pages = {247 – 250},
	doi = {10.15199/48.2025.03.57},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001196144&doi=10.15199%2f48.2025.03.57&partnerID=40&md5=75afc8b4b99cd350c3624fd4f2f304d3},
	affiliations = {Politechnika Warszawska, Wydział Elektryczny, ul. Koszykowa 75, Warszawa, 00-661, Poland},
	abstract = {The aim of the paper is to evaluate the transformers network LLM for automatic generation of tests for English language learners with classical approaches. The kind of test we investigate is referred to as cloze test, which are paragraphs of text with gaps which should be filled in by the learners. In the paper, we compare recurrent neural networks to transformer networks (BERT and ELECTRA). Additionally the authors make the training and testing datasets available publicly. The approach related to application of LLMs is based on paper by Felice at al. [2]. In the presented research we extend the loss function and apply extra metrics based on Kullback-Leibler Divergence Loss to improve space distribution of the gaps. © 2025 Wydawnictwo SIGMA-NOT. All rights reserved.},
	author_keywords = {cloze-test; LLM; recurrent neural networks; transformer networks},
	publisher = {Wydawnictwo SIGMA-NOT},
	issn = {00332097},
	language = {English},
	abbrev_source_title = {Prz. Elektrotech.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gabriel2024,
	author = {Gabriel, Rodney A. and Litake, Onkar and Simpson, Sierra and Burton, Brittany N. and Waterman, Ruth S. and Macias, Alvaro A.},
	title = {On the development and validation of large language model-based classifiers for identifying social determinants of health},
	year = {2024},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	volume = {121},
	number = {39},
	doi = {10.1073/pnas.2320716121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204418498&doi=10.1073%2fpnas.2320716121&partnerID=40&md5=328799cd144a7c447f46f1467054e4e4},
	affiliations = {Division of Perioperative Informatics, Department of Anesthesiology, University of California,, La Jolla, San Diego, 92037, CA, United States; Department of Biomedical Informatics, University of California, San Diego Health, La Jolla, 92037, CA, United States; Department of Anesthesiology, University of California, Los Angeles, 90095, CA, United States},
	abstract = {The assessment of social determinants of health (SDoH) within healthcare systems is crucial for comprehensive patient care and addressing health disparities. Current challenges arise from the limited inclusion of structured SDoH information within electronic health record (EHR) systems, often due to the lack of standardized diagnosis codes. This study delves into the transformative potential of large language models (LLM) to overcome these challenges. LLM-based classifiers—using Bidirectional Encoder Representations from Transformers (BERT) and A Robustly Optimized BERT Pretraining Approach (RoBERTa)—were developed for SDoH concepts, including homelessness, food insecurity, and domestic violence, using synthetic training datasets generated by generative pre-trained transformers combined with authentic clinical notes. Models were then validated on separate datasets: Medical Information Mart for Intensive Care-III and our institutional EHR data. When training the model with a combination of synthetic and authentic notes, validation on our institutional dataset yielded an area under the receiver operating characteristics curve of 0.78 for detecting homelessness, 0.72 for detecting food insecurity, and 0.83 for detecting domestic violence. This study underscores the potential of LLMs in extracting SDoH information from clinical text. Automated detection of SDoH may be instrumental for healthcare providers in identifying at-risk patients, guiding targeted interventions, and contributing to population health initiatives aimed at mitigating disparities. Copyright © 2024 the Author(s). Published by PNAS. This open access article is distributed under Creative Commons Attribution License 4.0 (CC BY).},
	author_keywords = {AI; large language models; social determinants of health},
	keywords = {Domestic Violence; Electronic Health Records; Food Insecurity; Humans; Ill-Housed Persons; Social Determinants of Health; accuracy; Article; caloric intake; classifier; controlled study; development; diagnostic test accuracy study; domestic violence; electronic health record; electronic medical record; food insecurity; generative pretrained transformer; health care; health care access; health care personnel; health care system; health disparity; homelessness; human; intensive care; language; large language model; lung cancer; machine learning; medical information; natural language processing; non small cell lung cancer; open access publishing; patient care; population health; quality of life; reliability; robot-assisted prostatectomy; sensitivity and specificity; social determinants of health; total quality management; training; validation process; domestic violence; electronic health record; food insecurity; homeless person},
	correspondence_address = {R.A. Gabriel; Division of Perioperative Informatics, Department of Anesthesiology, University of California,, San Diego, La Jolla, 92037, United States; email: ragabriel@health.ucsd.edu},
	publisher = {National Academy of Sciences},
	issn = {00278424},
	coden = {PNASA},
	pmid = {39284061},
	language = {English},
	abbrev_source_title = {Proc. Natl. Acad. Sci. U. S. A.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}@CONFERENCE{Vindbjerg2024109,
	author = {Vindbjerg, Lukas Koch and Esterle, Lukas},
	title = {Generative Models for Temporal-Based Task Definition},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion, ACSOS-C 2024},
	pages = {109 – 114},
	doi = {10.1109/ACSOS-C63493.2024.00040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214848895&doi=10.1109%2fACSOS-C63493.2024.00040&partnerID=40&md5=a2f3aa408afe16302d8e093e718e5aca},
	affiliations = {Aarhus University, Department of Electircal and Computer Engineering, Denmark; Aarhus University, Department of Electrical and Computer Engineering, DIGIT, Denmark},
	abstract = {Autonomous systems rely on artificial intelligence to perform their tasks more effectively. With the increasing complexity of tasks, it is essential to provide a structured way to define tasks. This paper explores a novel approach to extract task definitions with temporal information using generative models. The approach combines the strengths of the T5 and BERT models to understand and sequence tasks. Specifically, the BERT model classifies the temporal relationship between tasks before the T5 model is used to generate the DSL sequence. Furthermore, we present a simple DSL for a household robot use-case and a dataset of natural language commands with temporal information. The model is trained on this dataset and evaluated on its ability to generate accurate and temporally ordered task definitions.  © 2024 IEEE.},
	author_keywords = {Autonomous Systems; BERT; LLMs; robots; T5; task generation; temporal information},
	keywords = {Generative adversarial networks; Autonomous system; BERT; Generative model; Household robots; LLM; Simple++; T5; Task generations; Temporal information; Temporal relationships; Adversarial machine learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038976-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Auton. Comput. Self-Organ. Syst. Companion, ACSOS-C},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Alcántara20242251,
	author = {Alcántara, Tania and García-Vázquez, Omar and Hernandez, Mayte and Calvo, Hiram and Desiderio, Alan},
	title = {LyricScraper: A Dataset of Spanish Song Lyrics Created via Web Scraping and Dual-labeling for LLM Classification},
	year = {2024},
	journal = {Computacion y Sistemas},
	volume = {28},
	number = {4},
	pages = {2251 – 2260},
	doi = {10.13053/CyS-28-4-5292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213881821&doi=10.13053%2fCyS-28-4-5292&partnerID=40&md5=0283f61dc25713e307604452321fe661},
	affiliations = {Instituto Politécnico Nacional, Centro de Investigación en Computación, Mexico City, Mexico; Instituto Politécnico Nacional, Escuela Superior de Ingeniería Mecánica y Eléctrica, Mexico City, Mexico},
	abstract = {Songs represent a powerful means of expressing emotions through melody and lyrics. This study focuses on understanding and classifying emotions present in songs, ranging from positive and negative to neutral emotions. This classification and understanding would not be possible without data, which was gathered using a proprietary web scraping algorithm to collect lyrics data online. Subsequently, a pseudo-labeling approach based on BERT was employed to assign sentiment labels to these lyrics, leveraging BERT’s ability to comprehend context and semantic relationships in language. This process enhanced the dataset’s quality and contributed to the success of sentiment analysis in songs. The new dataset addressed challenges related to sentence length by providing examples of song lyrics of varying lengths, facilitating more effective model training. Additionally, data imbalance was addressed through careful sample selection, representing a wide range of emotions in songs. This new dataset underwent classification using large-scale language models, achieving promising results. The accuracy metric reached an impressive 97.66% for DistilBERT and 97.83% for the F1 metric, highlighting the effectiveness of this approach in song sentiment analysis. This study underscores the importance of understanding emotions in songs and offers practical solutions to enhance the capabilities of language models in this task. © 2024 Instituto Politecnico Nacional. All rights reserved.},
	author_keywords = {deep learning; NLP; pseudo labeling; web scraping},
	correspondence_address = {H. Calvo; Instituto Politécnico Nacional, Centro de Investigación en Computación, Mexico City, Mexico; email: hcalvo@cic.ipn.mx},
	publisher = {Instituto Politecnico Nacional},
	issn = {14055546},
	language = {English},
	abbrev_source_title = {Comput. Sist.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee2024872,
	author = {Lee, Sanghyub John and Tony Lee, Hyunseo and Lee, Kiseong},
	title = {Enhancing Emotion Detection through ChatGPT-Augmented Text Transformation in Social Media Text},
	year = {2024},
	journal = {IEEE International Workshop on Robot and Human Communication, RO-MAN},
	pages = {872 – 879},
	doi = {10.1109/RO-MAN60168.2024.10731460},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209775529&doi=10.1109%2fRO-MAN60168.2024.10731460&partnerID=40&md5=54c6cdfc58d4ada020b95418a9441add},
	affiliations = {University of Auckland, The Department of Marketing, Auckland, 1010, New Zealand; Hankuk University of Foreign Studies, Department of Electronics Engineering, Yongin, 17035, South Korea; Humanities Research Institute, Chung-Ang University, Seoul, 06974, South Korea},
	abstract = {Social networking services (SNS) provide a rich source of user-generated emotion-expressed text. However, deciphering the emotion from these texts, often marked by vernacular expressions and abbreviations, poses significant challenges. This study introduces a novel approach to enhance emotion detection by converting SNS informal texts into everyday language using ChatGPT, resulting in a generative large language model (LLM). The study uses ten publicly available emotion datasets and a unique tweet dataset, augmented through ChatGPT. Three models were trained for comparison: one using original texts (n=408,359), another with ChatGPT-augmented texts (n=408,359), and the last with a combination of both (n=816,718). The four transformer models, RoBERTa, BERT, DistilBERT, and XLM-RoBERTa, trained with the combined dataset outperformed those trained solely on original texts, indicating that converting SNS vernacular text into everyday language improves emotion detection. The study provides significant insights for enhancing emotion analysis in human-robot interaction and other fields reliant on accurate emotion detection, demonstrating the potential of LLMs in natural language processing (NLP) data augmentation.  © 2024 IEEE.},
	keywords = {Human robot interaction; Tweets; Emotion analysis; Emotion detection; Everyday language; Humans-robot interactions; Language model; Social media; Social networking services; Three models; Transformer modeling; User-generated; Emotion Recognition},
	correspondence_address = {K. Lee; Humanities Research Institute, Chung-Ang University, Seoul, 06974, South Korea; email: goory@cau.ac.kr},
	publisher = {IEEE Computer Society},
	issn = {19449445},
	isbn = {979-835037502-2},
	language = {English},
	abbrev_source_title = {IEEE Int. Workshop Robot Human Commun., RO-MAN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Yeh2024660,
	author = {Yeh, Min-Hsuan and Wan, Ruyuan and Huang, Ting-Hao},
	title = {COCOLOFA: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {660 – 677},
	doi = {10.18653/v1/2024.emnlp-main.39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217818434&doi=10.18653%2fv1%2f2024.emnlp-main.39&partnerID=40&md5=ed7e2e93d960de90e0d0b4e5d423f875},
	affiliations = {University of Wisconsin-Madison, Madison, WI, United States; The Pennsylvania State University, University Park, PA, United States},
	abstract = {Detecting logical fallacies in texts can help users spot argument flaws, but automating this detection is not easy. Manually annotating fallacies in large-scale, real-world text data to create datasets for developing and validating detection models is costly. This paper introduces COCOLOFA, the largest known English logical fallacy dataset, containing 7,706 comments for 648 news articles, with each comment labeled for fallacy presence and type. We recruited 143 crowd workers to write comments embodying specific fallacy types (e.g., slippery slope) in response to news articles. Recognizing the complexity of this writing task, we built an LLM-powered assistant into the workers' interface to aid in drafting and refining their comments. Experts rated the writing quality and labeling validity of COCOLOFA as high and reliable. BERT-based models fine-tuned using COCOLOFA achieved the highest fallacy detection (F1=0.86) and classification (F1=0.87) performance on its test set, outperforming the state-of-the-art LLMs. Our work shows that combining crowdsourcing and LLMs enables us to more effectively construct datasets for complex linguistic phenomena that crowd workers find challenging to produce on their own. COCOLOFA is public at CoCoLoFa.org/. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Large datasets; Spatio-temporal data; Detection models; Labelings; Large-scales; News articles; Performance; Real-world; Test sets; Text data; Workers'; Writing quality; Crowdsourcing},
	editor = {Al-Onaizan Y. and Bansal M. and Chen Y.-N.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176164-3},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Zhao2024,
	author = {Zhao, Yan and Li, Zhongyun and Pan, Yushan and Wang, Jiaxing and Zhang, Zhiman and Wang, Yihong},
	title = {LB-KBQA:Large-language-model and BERT based Knowledge-Based Question and Answering System},
	year = {2024},
	journal = {IEEE International Conference on Industrial Informatics (INDIN)},
	doi = {10.1109/INDIN58382.2024.10774538},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215509637&doi=10.1109%2fINDIN58382.2024.10774538&partnerID=40&md5=5ae2358b5db7be9257f9d892c628f659},
	affiliations = {XJTLU, Suzhou, China; University of Liverpool, Liverpool, United Kingdom; Dept. School of Advanced Technology, XJTLU, Suzhou, China; Shenzhen Experimental School, Shenzhen, China},
	abstract = {Generative Artificial Intelligence (AI), because of its emergent abilities, has empowered various fields, one typical of which is large language models (LLMs). One of the typical application fields of Generative AI is large language models (LLMs), and the natural language understanding capability of LLM is dramatically improved when compared with conventional AI-based methods. The natural language understanding capability has always been a barrier to the intent recognition performance of the Knowledge-Based-Question-and-Answer (KBQA) system, which arises from linguistic diversity and the newly appeared intent. Conventional AI-based methods for intent recognition can be divided into semantic parsing-based and model-based approaches. However, both of the methods suffer from limited resources in intent recognition. To address this issue, we propose a novel KBQA system based on a Large Language Model(LLM) and BERT (LB-KBQA). With the help of generative AI, our proposed method could detect newly appeared intent and acquire new knowledge. In experiments on financial domain question answering, our model has demonstrated superior effectiveness. © 2024 IEEE.},
	author_keywords = {Generative AI; KBQA; LLM},
	keywords = {Semantics; Application fields; Generative artificial intelligence; Intent recognition; Knowledge based; Knowledge-based-question-and-answer; Language model; Large language model; Natural language understanding; Question and answer system; Typical application; Generative adversarial networks},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19354576},
	isbn = {979-833152747-1},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Ind. Informatics (INDIN)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Goswami2024,
	author = {Goswami, Anuradha and Kaur, Guneet and Tayal, Shivam and Verma, Anuj and Verma, Meenakshi},
	title = {Analyzing the efficacy of Deep Learning and Transformer models in classifying Human and LLM-Generated Text},
	year = {2024},
	journal = {2024 8th International Conference on Computing, Communication, Control and Automation, ICCUBEA 2024},
	doi = {10.1109/ICCUBEA61740.2024.10775153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215114008&doi=10.1109%2fICCUBEA61740.2024.10775153&partnerID=40&md5=4285982d3db1ad2875d9fa6862306bf8},
	affiliations = {Symbiosis Institute of Business Management, Bangalore, India; Symbiosis Internationl( Deemed) University, Pune, India; Symbiosis International (Deemed University), Symbiosis Centre for Management Studies, Bangalore, India},
	abstract = {Large Language Models (LLM) are widely accepted by the humans for their powerful ability to understand, follow and create human-like text. The text generation capabilities of LLMs have reached such a height that it is now comparable to text generated by human.LLMs are a powerful subset of Artificial Intelligence (AI)models, trained on huge amount of human-written text to create indistinguishable content. AI models have taken an important step ahead in constructing hyper-realistic content which can be in any modality such as text, image, and video. The output content generated by these models can be hard to distinguish from human-written content as these models are iteratively trained on texts written by human. Further this has got serious implications across various domains, including news reporting, information fraud, academic plagiarism, data manipulation, financial fraud, theft and deep fakes. The abilities of AI-generated text pose a significant challenge, blurring the lines of differentiation between human and machine-created content. Therefore, to effectively navigate the evolving landscape of AI-generated text, we need a robust and reliable AI text detection model. This study leverages a substantial dataset of 100,000 entries. empowering our model with adaptability across various domains. By employing diverse word embedding techniques along with machine and deep learning models, we explore optimal configurations for exceptional performance. Notably, we implement pre-trained models like BERT and DeBERTa on this extensive corpus, potentially representing the first such application. The resulting models demonstrate remarkable accuracy exceeding 95% across all configurations, signifying a robust advancement in differentiating AI generated text from human written one. © 2024 IEEE.},
	author_keywords = {BERT; DeBERTa; Human generated text; LLM-generated Text; Pre-trained model; Transformers; Word embedding},
	keywords = {Adversarial machine learning; Contrastive Learning; Crime; Deep learning; Distribution transformers; Human form models; BERT; DeBERTa; Embeddings; Human generated text; Language model; Large language model-generated text; Learning models; Pre-trained model; Transformer; Word embedding; Embeddings},
	correspondence_address = {A. Goswami; Symbiosis Institute of Business Management, Bangalore, India; email: anuradha@sibm.edu.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039177-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput., Commun., Control Autom., ICCUBEA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Amin2024,
	author = {Amin, Muhammad Saad and Anselma, Luca and Mazzei, Alessandro},
	title = {Data Augmentation for Low-Resource Italian NLP: Enhancing Semantic Processing with DRS},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3878},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214427403&partnerID=40&md5=5a8ac2838fcaa58db83aec6867fcb530},
	affiliations = {Department of Computer Science, University of Turin, Italy},
	abstract = {Discourse Representation Structure (DRS), a formal meaning representation, has shown promising results in semantic parsing and natural language generation tasks for high-resource languages like English. This paper investigates enhancing the application of DRS to low-resource Italian Natural Language Processing (NLP), in both semantic parsing (Text-to-DRS) and natural language generation (DRS-to-Text). To address the scarcity of annotated corpora for Italian DRS, we propose a novel data augmentation technique that involves the use of external linguistic resources including: (i) WordNet for common nouns, adjectives, adverbs, and verbs; (ii) LLM-generated named entities for proper nouns; and (iii) rule-based algorithms for tense augmentation. This approach not only increases the quantity of training data but also introduces linguistic diversity, which is crucial for improving model performance and robustness. Using this augmented dataset, we developed neural semantic parser and generator models that demonstrated enhanced generalization ability compared to models trained on non-augmented data. We evaluated the effect of semantic data augmentation using two state-of-the-art transformer-based neural sequence-to-sequence models, i.e., byT5 and IT5. Our implementation shows promising results for Italian semantic processing. Data augmentation significantly increased the performance of semantic parsing from 76.10 to 90.56 (+14.46%) F1-SMATCH score and generation with 37.79 to 57.48 (+19.69%) BLEU, 30.83 to 40.95 (+10.12%) METEOR, 81.66 to 90.97 (+9.31%) COMET, 54.84 to 70.88 (+16.04%) chrF, and 88.86 to 92.97 (+4.11%) BERT scores. These results demonstrate the effectiveness of our novel augmentation approach in enhancing semantic processing capabilities for low-resource languages like Italian. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {Data augmentation; generation; Italian semantic processing; low-resource NLP; semantic parsing},
	keywords = {Data assimilation; Metadata; Natural language processing systems; Network security; Spatio-temporal data; Data augmentation; Discourse representation; Generation; Italian semantic processing; Language processing; Low-resource natural language processing; Natural language generation; Natural languages; Semantic parsing; Semantic processing; Semantics},
	correspondence_address = {M.S. Amin; Department of Computer Science, University of Turin, Italy; email: muhammadsaad.amin@unito.it},
	editor = {Dell'Orletta F. and Lenci A. and Montemagni S. and Sprugnoli R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Khennouche2024,
	author = {Khennouche, Feriel and Elmir, Youssef and Djebari, Nabil and Boubchir, Larbi and Laouid, Abdelkader and Bounceur, Ahcene},
	title = {Comparative Analysis and Application of Large Language Models on FAQ Chatbots},
	year = {2024},
	journal = {CINS 2024 - 2nd International Conference on Computational Intelligence and Network Systems},
	doi = {10.1109/CINS63881.2024.10864428},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219557085&doi=10.1109%2fCINS63881.2024.10864428&partnerID=40&md5=fd9da1b07264e6ec034e4618b0683938},
	affiliations = {Laboratoire LITAN, École supérieure en Sciences et Technologies de l’Informatique et du Numérique Amizour, Bejaia, 06300, Algeria; SGRE-lab, Bechar, Algeria; Laboratoire d’informatique Médical (LIMED), Université de Bejaia, Targa Ouzemour, Bejaia, 06000, Algeria; LIASD research Laboratory, University of Paris, 8 2 rue de la Liberté, Saint-Denis, 93526, France; LIAP Laboratory, University of El Oued, PO Box 789, El Oued, 39000, Algeria; College of Computing and Informatics, University of Sharjah, Sharjah, United Arab Emirates},
	abstract = {This paper presents a comprehensive evaluation of advanced large language models (LLMs) including GPT, BART, BERT, and T5, fine-tuned using a specialized FAQ dataset from ESTIN, a higher education institution. The study aims to assess the performance of these LLM models in generating accurate and contextually relevant responses to common queries. These models were evaluated using key metrics such as evaluation loss (eval loss) and ROUGE scores (ROUGE-1 and ROUGE-2), which measure the alignment between the generated responses and the reference answers. The experiment results show that BERT outperforms the other models, achieving a lowest eval loss and highest ROUGE-1 and ROUGE-2 scores, making it the most effective model in this context. The findings underscore the potential of BERT in educational AI applications. Finally, some future research directions are discussed, including the integration of additional models and the enhancement of the FAQ dataset to further improve performance. ©2024 IEEE.},
	author_keywords = {BART; BERT; FAQ Chatbot; fine-tunning; GPT; LLM; T5},
	keywords = {BART; BERT; Chatbots; Comparative analyzes; FAQ chatbot; Fine-tunning; GPT; Language model; Large language model; T5},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833150410-6},
	language = {English},
	abbrev_source_title = {CINS - Int. Conf. Comput. Intell. Netw. Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shukla2024,
	author = {Shukla, Sanidhya Madhav and Magoo, Chandni and Garg, Puneet},
	title = {Comparing Fine Tuned-LMs for Detecting LLM-Generated Text},
	year = {2024},
	journal = {Proceedings of the 2024 3rd Edition of IEEE Delhi Section Flagship Conference, DELCON 2024},
	doi = {10.1109/DELCON64804.2024.10866497},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219299262&doi=10.1109%2fDELCON64804.2024.10866497&partnerID=40&md5=95424b4bcb993b034773f676b9c2ed12},
	affiliations = {Manav Rachna University, Computer Science and Engineering dept., Faridabad, India; Kiet Group of Institutions, Department of CSE-AI, U.P., Ghaziabad, India},
	abstract = {With the introduction of LLMs (Large Language Models), NLP has demonstrated strong skills in a variety of applications, including question answering, language translation, and text summarization. As a result, their use in our day-to-day activities and at work has gained general acceptability. It is nevertheless imperative to develop cutting-edge procedures or approaches since, despite their enormous capabilities, they are still unable to live up to human expectations. It is crucial to apply the cutting-edge methods that enable LLMs to specialize in specific fields and reduce any potential for abuse. In contrast, our study has concentrated on employing fine-tuned LLM as detectors to determine whether a text was produced by a machine or by a person. Comparing how well various fine-tuned LMs function as content detectors-that is, as indicators of whether or not material is generated by LLMs-is the goal of this research. Three distinct fine-tuned LLMs are used to solve this binary classification problem: Fas'I'Text, also known as Generative Pre- Trained Transformers; DistilBERT; and BERT, or Bidirectional Encoder Representations from Transformers. The models were tested using various performance metrics, including precision, recall, Fl score, MCC, NPV, and FDR. The results showed that the BERT model outperformed the FasTText and DistilBERT models, which displayed overfitting tendencies when fine-tuned under comparable settings.  © 2024 IEEE.},
	author_keywords = {Bag of Words; Comparative Analysis; FT-LM; LLM; LLM-generated text detection; LM; Transformer-based LMs},
	keywords = {Classification (of information); Linguistics; Robotics; Signal encoding; Text mining; Translation (languages); Bag of words; Comparative analyzes; FT-LM; Language model; Large language model; Large language model-generated text detection; LM; Text detection; Transformer-based LM; Character recognition},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151859-2},
	language = {English},
	abbrev_source_title = {Proc. Ed. IEEE Delhi Sect. Flagship Conf., DELCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Julianto2024391,
	author = {Julianto and Widodo, Agung Mulyo and Firmansyah, Gerry and Tjahjono, Budi},
	title = {Large Language Models Using Transformers in Chat Bot Based on Artificial Intelligence},
	year = {2024},
	journal = {Proceedings - ICE3IS 2024: 4th International Conference on Electronic and Electrical Engineering and Intelligent System: Leading-Edge Technologies for Sustainable Societies},
	pages = {391 – 396},
	doi = {10.1109/ICE3IS62977.2024.10775970},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215115731&doi=10.1109%2fICE3IS62977.2024.10775970&partnerID=40&md5=52c8981aa211b81bd7600ec392494acc},
	affiliations = {Esa Unggul University, Faculty of Computer Science, Jakarta, Indonesia},
	abstract = {Users usually use Information Retrieval to search for information or data using keywords. The problem is that sometimes users get incomplete or raw information or data as a list sorted with a ranking system. The chatbox should also be interactive; users can ask and answer questions continuously and naturally as if chatting. Deep Learning can be used for interactive question-and-answer chat boxes. However, LLM can be another alternative for answering sentences spoken like humans and can help users get interactive answers and topics only in Constitutional Court decisions. This paper proposes using LLM for Question Answering in chatboxes using LLM and Embedding Models obtained from HuggingFace and GPT4ALL, which support Indonesian and are multilingual. The dataset was obtained by web scraping from the MKRI website. The evaluation uses Multiple Choice Questions with a total of 100 questions based on the decision letter of the constitutional court by counting the number of correct questions. The evaluation results can only get the highest score of 0.26 F1-Score. Another paper model has an excellent F1-Score because BERT-based QA using classification like VNLawBERT can achieve a 0.91 F1-Score. However, the LLM model is like DISC-LawLLM with F1-Score 0.37. For our Embedding models, they can underperform only F1-Score 0.02. However, compared with GPT, these values are very different; the GPT-4o Mini alone can get 0.72 F1-Score, whereas the GPT-3.5 alone can get a score of 0.38 F1-Score. © 2024 IEEE.},
	author_keywords = {Chatbot; Large Language Models; The Constitutional Court Decisions of the Republic of Indonesia},
	keywords = {Bot (Internet); Classification (of information); Deep learning; Distribution transformers; Embeddings; Information retrieval; Chat bots; Chatbots; Court decisions; Embeddings; F1 scores; Indonesia; Language model; Large language model; Ranking system; The constitutional court decision of the republic of indonesia; Question answering},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037836-8},
	language = {English},
	abbrev_source_title = {Proc. - ICE3IS: Int. Conf. Electron. Electr. Eng. Intell. Syst.: Lead.-Edge Technol. Sustain. Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen2024,
	author = {Chen, Chin-Po and Li, Jeng-Lin},
	title = {Profiling Patient Transcript Using Large Language Model Reasoning Augmentation for Alzheimer's Disease Detection},
	year = {2024},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	doi = {10.1109/EMBC53108.2024.10782161},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214972889&doi=10.1109%2fEMBC53108.2024.10782161&partnerID=40&md5=f3eef67c631729329fdbf20e5d74b814},
	affiliations = {Inventec Corporation, Digital Center, Taipei, Taiwan},
	abstract = {Alzheimer's disease (AD) stands as the predominant cause of dementia, characterized by a gradual decline in speech and language capabilities. Recent deeplearning advancements have facilitated automated AD detection through spontaneous speech. However, common transcript-based detection methods directly model text patterns in each utterance without a global view of the patient's linguistic characteristics, resulting in limited discriminability and interpretability. Despite the enhanced reasoning abilities of large language models (LLMs), there remains a gap in fully harnessing the reasoning ability to facilitate AD detection and model interpretation. Therefore, we propose a patient-level transcript profiling framework leveraging LLM-based reasoning augmentation to systematically elicit linguistic deficit attributes. The summarized embeddings of the attributes are integrated into an Albert model for AD detection. The framework achieves 8.51% ACC and 8.34% F1 improvements on the ADReSS dataset compared to the baseline without reasoning augmentation. Our further analysis shows the effectiveness of our identified linguistic deficit attributes and the potential to use LLM for AD detection interpretation. © 2024 IEEE.},
	author_keywords = {Alzheimer's disease; BERT; dementia; large language model; reasoning},
	keywords = {Alzheimer Disease; Humans; Natural Language Processing; Neurodegenerative diseases; Alzheimers disease; BERT; Dementia; Disease detection; Language capability; Language model; Large language model; Model reasonings; Reasoning; Reasoning ability; Alzheimer disease; diagnosis; genetics; human; natural language processing; pathophysiology; Linguistics},
	correspondence_address = {C.-P. Chen; Inventec Corporation, Digital Center, Taipei, Taiwan; email: chen.jackcp@inventec.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {1557170X},
	isbn = {979-835037149-9},
	pmid = {40039256},
	language = {English},
	abbrev_source_title = {Proc. Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. EMBS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jeong2024489,
	author = {Jeong, Jae-Hoon and Park, Hyunho},
	title = {Development of a False Alarm Classification and Prediction Model Using Transformer-Based Large Language Model},
	year = {2024},
	journal = {Journal of Korean Institute of Communications and Information Sciences},
	volume = {49},
	number = {4},
	pages = {489 – 502},
	doi = {10.7840/kics.2024.49.4.489},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193697898&doi=10.7840%2fkics.2024.49.4.489&partnerID=40&md5=4fc85bd6a5421235585f57f20c5ee1ad},
	affiliations = {Electronics and Telecommunications Research Institute, South Korea; Koraen National Police University, South Korea},
	abstract = {The 112 emergency reporting system is the police's front line for public safety, and rapid dispatch and incident handling are of the utmost importance. False reports are problematic in that they not only waste police power, but also make it difficult to respond to situations that need help. In order to respond to the increase in false reports, this researcher proposes a 112 false report classification and prediction model based on deep learning. This model receives the report text summarized by the 112 situation room receptionist and determines whether the report is false or misidentified. Mistaken reports are almost impossible to detect on the surface from the point of view of the person who filed the report. Because of this, the researcher conducted an experiment dividing data containing all false reports and data containing only malicious false reports. Model training was performed with the same hyperparameters for five models with transformer structures: BERT, KoBERT, ELECTRA, and RoBERTa. This study is significant in that it took a problem-solving approach to the police's actual security work using natural language processing and LLM. It is expected that the results of this study will help identify malicious false reports and support police decision-making. © 2024, Korean Institute of Communications and Information Sciences. All rights reserved.},
	author_keywords = {112; Binary Classification; False Alarm; NLP; Transformer},
	correspondence_address = {J.-H. Jeong; Koraen National Police University, South Korea; email: 20210042@police.ac.kr},
	publisher = {Korean Institute of Communications and Information Sciences},
	issn = {12264717},
	language = {Korean},
	abbrev_source_title = {J. Korean. Inst. Commun. Inf. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Maity2024342,
	author = {Maity, Krishanu and Chaulwar, Amit Tulsidas and Vala, Vanraj and Guntur, Ravi Sankar},
	title = {NanoBERT: An Extremely Compact Language Model},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {342 – 349},
	doi = {10.1145/3632410.3632451},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183575231&doi=10.1145%2f3632410.3632451&partnerID=40&md5=67b74a5a795209fcea681e96dfc1f8a7},
	affiliations = {Samsung R and D Bangalore, Karnataka, Bangalore, India},
	abstract = {Language model pre-training, such as in BERT model, has led to significant improvements in natural language processing tasks. Although many approaches such as quantization, knowledge distillation, etc. have been proposed to compress language models, they are still not suitable for deployment on resource-constrained edge devices like mobiles. In this work, we propose to replace the token embedding matrix, an expensive layer in Transformer model, with trainable rank decomposition matrices. Building upon this approach, we introduce NanoBERT, a lightweight BERT model that is nearly 17 × smaller than BERT-Tiny (the smallest open source pre-trained BERT model), yet attains comparable performance on various NLP tasks such as text classification, named entity recognition, etc. We extend this model by combining it with parameter efficient fine-tuning technique, named LoRA, for further compression in multi-task scenarios.  © 2024 Owner/Author.},
	author_keywords = {LLM; LoRA; On-Device AI; Transformers},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; Text processing; Embedding matrices; Language model; Language processing; LLM; LoRA; Natural languages; On-device AI; Pre-training; Quantisation; Transformer; Distillation},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071634-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@BOOK{Campesato20241,
	author = {Campesato, Oswald},
	title = {Large Language ModeLs for deveLopers: A Prompt-based Exploration},
	year = {2024},
	journal = {Large Language Models for Developers: A Prompt-based Exploration},
	pages = {1 – 1012},
	doi = {10.1515/9781501520938},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217333075&doi=10.1515%2f9781501520938&partnerID=40&md5=e5e8196c7ea7dfc9d6f9f89c1c68a8b0},
	abstract = {This book offers a thorough exploration of Large Language Models (LLMs), guiding developers through the evolving landscape of generative AI and equipping them with the skills to utilize LLMs in practical applications. Designed for developers with a foundational understanding of machine learning, this book covers essential topics such as prompt engineering techniques, fine-tuning methods, attention mechanisms, and quantization strategies to optimize and deploy LLMs. Beginning with an introduction to generative AI, the book explains distinctions between conversational AI and generative models like GPT-4 and BERT, laying the groundwork for prompt engineering (Chapters 2 and 3). Some of the LLMs that are used for generating completions to prompts include Llama-3.1 405B, Llama 3, GPT-4o, Claude 3, Google Gemini, and Meta AI. Readers learn the art of creating effective prompts, covering advanced methods like Chain of Thought (CoT) and Tree of Thought prompts. As the book progresses, it details fine-tuning techniques (Chapters 5 and 6), demonstrating how to customize LLMs for specific tasks through methods like LoRA and QLoRA, and includes Python code samples for hands-on learning. Readers are also introduced to the transformer architecture’s attention mechanism (Chapter 8), with step-by-step guidance on implementing self-attention layers. For developers aiming to optimize LLM performance, the book concludes with quantization techniques (Chapters 9 and 10), exploring strategies like dynamic quantization and probabilistic quantization, which help reduce model size without sacrificing performance. FEATURES: Covers the full lifecycle of working with LLMs, from model selection to deployment. Includes code samples using practical Python code for implementing prompt engineering, fine-tuning, and quantization. Teaches readers to enhance model efficiency with advanced optimization techniques. Includes companion files with code and images -- available from the publisher. © 2024 by Mercury Learning and Information. An Imprint of DeGruyter Inc. All rights reserved.},
	author_keywords = {Data Science; Generative AI. He is the author/co-author of over forty-five books including Google Gemini for Python; GPT-4 for Developers (all Mercury Learning); Large Language Models; Oswald Campesato (San Francisco, CA) specializes in Deep Learning; Python},
	publisher = {De Gruyter},
	isbn = {978-150152093-8; 978-150152095-2},
	language = {English},
	abbrev_source_title = {Large Language Models for Developers: A Prompt-based Exploration},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Baddour2024,
	author = {Baddour, Moussa and Paquelet, Stephane and Rollier, Paul and De Tayrac, Marie and Dameron, Olivier and Labbe, Thomas},
	title = {Phenotypes Extraction from Text: Analysis and Perspective in the LLM Era},
	year = {2024},
	journal = {International IEEE Conference  proceedings, IS},
	number = {2024},
	doi = {10.1109/IS61756.2024.10705235},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208419027&doi=10.1109%2fIS61756.2024.10705235&partnerID=40&md5=100c2cd1ee6520fb0c6d6608a1d89e92},
	affiliations = {Institute of Research and Technology b<>com, Rennes, France; B<>com, Rennes, France; University Hospital of Rennes, Rennes, France; Univ Rennes, Inria, Cnrs, Irisa - Umr 6074, Rennes, France; Orange, Rennes, France},
	abstract = {Collecting the relevant list of patient phenotypes, known as deep phenotyping, can significantly improve the final diagnosis. As textual clinical reports are the richest source of phenotypes information, their automatic extraction is a critical task. The main challenges of this Information Extraction (IE) task are to identify precisely the text spans related to a phenotype and to link them unequivocally to referenced entities from a source such as the Human Phenotype Ontology (HPO). Recently, Language Models (LMs) have been the most suc-cessful approach for extracting phenotypes from clinical reports. Solutions such as PhenoBERT, relying on BERT or GPT, have shown promising results when applied to datasets built on the hypothesis that most phenotypes are explicitly mentioned in the text. However, this assumption is not always true in medical genetics. Hence, although the LMs carry powerful semantic abilities, their contributions are not clear compared to syntactic string-matching steps that are used within the current pipelines. The goal of this study is to improve phenotype extraction from clinical notes related to genetic diseases. Our contributions are threefold: First, we provide a clear definition of the phenotype extraction task from free text, along with a high-level overview of the involved functions. Second, we conduct an in-depth analysis of PhenoBERT, one of the best existing solutions, to evaluate the proportion of phenotypes predicted with simple string-matching. Third, we demonstrate how utilizing and incorporating large language models (LLMs) for span detection step can improve performance especially with implicit phenotypes. In addition, this experiment revealed that the annotations of existing dataset are not exhaustive, and that LLM can identify relevant spans missed by human labelers.  © 2024 IEEE.},
	author_keywords = {embed dings; entity linking; genetic; LLM; phenoBERT; phenotype},
	keywords = {Embed ding; Entity linking; Genetic; Language model; Large language model; Phenobert; Phenotype; Phenotyping; String matching; Text analysis; Semantics},
	editor = {Sgurev V. and Jotsov V. and Piuri V. and Doukovska L. and Yoshinov R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {28324145},
	isbn = {979-835035098-2},
	language = {English},
	abbrev_source_title = {Int. IEEE Conf. Intell. Syst. Proc., IS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Deng20245743,
	author = {Deng, Jamie and Wu, Yusen and Yesha, Yelena and Nguyen, Phuong},
	title = {Improving VTE Identification through Language Models from Radiology Reports: A Comparative Study of Mamba, Phi-3 Mini, and BERT},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2024},
	pages = {5743 – 5749},
	doi = {10.1109/BIBM62325.2024.10822229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217280105&doi=10.1109%2fBIBM62325.2024.10822229&partnerID=40&md5=d922efdc193f9c1f79f08ef7bc898a5c},
	affiliations = {University of Miami, Department of Computer Science, Miami, FL, United States; University of Miami, Frost Institute for Data Science and Computing, Miami, FL, United States; University of Miami, Department of Radiology, Miami, FL, United States},
	abstract = {Venous thromboembolism (VTE) is a critical cardio-vascular condition, encompassing deep vein thrombosis (DVT) and pulmonary embolism (PE). Accurate and timely identification of VTE is essential for effective medical care. This study builds upon our previous work, which addressed VTE detection using deep learning methods for DVT and a hybrid approach combining deep learning and rule-based classification for PE. Our earlier approaches, while effective, had two major limitations: they were complex and required expert involvement for feature engineering of the rule set. To overcome these challenges, we utilize the Mamba architecture-based classifier. This model achieves remarkable results, with a 97% accuracy and F1 score on the DVT dataset and a 98% accuracy and F1 score on the PE dataset. In contrast to the previous hybrid method on PE identification, the Mamba classifier eliminates the need for hand-engineered rules, significantly reducing model complexity while maintaining comparable performance. Additionally, we evaluated a lightweight Large Language Model (LLM), Phi-3 Mini, in detecting VTE. While this model delivers competitive results, outperforming the baseline BERT models, it proves to be computationally intensive due to its larger parameter set. Our evaluation shows that the Mamba-based model demonstrates superior performance and efficiency in VTE identification, offering an effective solution to the limitations of previous approaches. © 2024 IEEE.},
	author_keywords = {BERT; LLM; Mamba; NLP; SSM; VTE},
	keywords = {Cardiology; Classification (of information); Contrastive Learning; Mammography; Pulmonary diseases; Radiology; BERT; Deep vein thrombosis; F1 scores; Language model; Large language model; Mamba; Performance; Pulmonary embolism; SSM; Venous thromboembolism; Deep learning},
	correspondence_address = {Y. Wu; University of Miami, Frost Institute for Data Science and Computing, Miami, United States; email: yxw1259@miami.edu},
	editor = {Cannataro M. and Zheng H. and Gao L. and Cheng J. and de Miranda J.L. and Zumpano E. and Hu X. and Cho Y.-R. and Park T.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038622-6},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Bioinform. Biomed., BIBM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Benita20241381,
	author = {Benita, J. and Tej, Kosireddy Vivek Charan and Kumar, E. Vinay and Subbarao, G. Venkata and Venkatesh, C.H.},
	title = {Implementation of Retrieval-Augmented Generation (RAG) in Chatbot Systems for Enhanced Real-Time Customer Support in E-Commerce},
	year = {2024},
	journal = {3rd International Conference on Automation, Computing and Renewable Systems, ICACRS 2024 - Proceedings},
	pages = {1381 – 1388},
	doi = {10.1109/ICACRS62842.2024.10841586},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217359984&doi=10.1109%2fICACRS62842.2024.10841586&partnerID=40&md5=11aeb8b0fd4a8efd1f73c23889387da7},
	affiliations = {Department of Computer Science and Engineering, Kalasalingam Academy of Research and Education, Virudhunagar, Krishnankoil, India},
	abstract = {This research study presents an advanced chatbot for e-commerce platforms using Retrieval-Augmented Generation (RAG), a technology that significantly enhances conversational AI by combining retrieval and generative techniques. E-commerce platforms handle diverse customer queries, including product inquiries, order tracking, and troubleshooting, where traditional chatbots often fail to provide accurate responses, leading to user dissatisfaction. The RAG-based chatbot addresses this by retrieving relevant information from sources like product catalogs, FAQs, and customer reviews and generating responses tailored to specific queries. This approach ensures accurate, contextually relevant answers that improve customer satisfaction, streamline service processes, and reduce errors. By leveraging the RAG framework, this solution provides robust, scalable customer support that enhances engagement and optimizes the e-commerce experience. © 2024 IEEE.},
	author_keywords = {assistance; BERTs; customer care; E-commerce; Embedding; Enhancement; GPT; LLMs; python; RAG; Services; tokens; Vector Database; Vectors; virtual experience},
	keywords = {Application programming interfaces (API); Marketplaces; Online searching; Problem oriented languages; Real time systems; Reviews; Sales; Search engines; Virtual reality; Assistance; BERT; Customer care; Embeddings; Enhancement; GPT; LLM; Retrieval-augmented generation; Service; Token; Vector database; Virtual experience; Customer satisfaction},
	correspondence_address = {J. Benita; Department of Computer Science and Engineering, Kalasalingam Academy of Research and Education, Krishnankoil, Virudhunagar, India; email: benitaj2014@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833153242-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Autom., Comput. Renew. Syst., ICACRS - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vileikyte2024249,
	author = {Vileikyte, Brigita and Lukoševičius, Mantas and Stankevičius, Lukas},
	title = {Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3885},
	pages = {249 – 258},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214823463&partnerID=40&md5=98714c57cc34a8ea0fe983b76c4c6485},
	affiliations = {Kaunas University of Technology, Faculty of Informatics, StudentuSt. 50, Lithuania},
	abstract = {Sentiment analysis is a widely researched area within Natural Language Processing (NLP), attracting significant interest due to the advent of automated solutions. Despite this, the task remains challenging because of the inherent complexity of languages and the subjective nature of sentiments. It is even more challenging for less-studied and lessresourced languages such as Lithuanian. Our review of existing Lithuanian NLP research reveals that traditional machine learning methods and classification algorithms have limited effectiveness for the task. In this work, we address sentiment analysis of Lithuanian five-star-based online reviews from multiple domains that we collect and clean. We apply transformer models to this task for the first time, exploring the capabilities of pre-trained multilingual Large Language Models (LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the inherent difficulty of the task, the fine-tuned models perform quite well, especially when the sentiments themselves are less ambiguous: 80.74% and 89.61% testing recognition accuracy of the most popular one- and five-star reviews respectively. They significantly outperform current commercial state-of-the-art general-purpose LLM GPT-4. We openly share our fine-tuned LLMs online. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {BERT; Deep Learning; Lithuanian Online Reviews; multilingual LLMs; Opinion mining; Sentiment analysis; T5; Transformer model},
	keywords = {Adversarial machine learning; Contrastive Learning; Economic and social effects; Electric transformer testing; Natural language processing systems; Subjective testing; BERT; Deep learning; Language model; Lithuanian online review; Multilingual large language model; Online reviews; Opinion mining; Sentiment analysis; T5; Transformer modeling; Deep learning},
	correspondence_address = {B. Vileikyte; Kaunas University of Technology, Faculty of Informatics, StudentuSt. 50, Lithuania; email: brigita.vileikyte@outlook.com; L. Stankevičius; Kaunas University of Technology, Faculty of Informatics, StudentuSt. 50, Lithuania; email: lukas.stankevicius@ktu.lt},
	editor = {Veitaite I. and Lopata A. and Krilavicius T. and Wozniak M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Overos2024,
	author = {Overos, Henry David and Hlatky, Roman and Pathak, Ojashwi and Goers, Harriet and Gouws-Dewar, Jordan and Smith, Katy and Chew, Keith Padraic and Birnir, Jóhanna K and Liu, Amy H},
	title = {Coding with the machines: Machine-assisted coding of rare event data},
	year = {2024},
	journal = {PNAS Nexus},
	volume = {3},
	number = {5},
	doi = {10.1093/pnasnexus/pgae165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194159158&doi=10.1093%2fpnasnexus%2fpgae165&partnerID=40&md5=4748d39263c40fc8b05b1ad05bcb9887},
	affiliations = {University of Maryland, College Park, MD, United States; University of North Texas, Denton, TX, United States; University of Texas at Austin, Austin, TX, United States; School of Politics and Global Studies, Arizona State University, Tempe, AZ, United States},
	abstract = {While machine coding of data has dramatically advanced in recent years, the literature raises significant concerns about validation of LLM classification showing, for example, that reliability varies greatly by prompt and temperature tuning, across subject areas and tasks - especially in "zero-shot"applications. This paper contributes to the discussion of validation in several different ways. To test the relative performance of supervised and semi-supervised algorithms when coding political data, we compare three models' performances to each other over multiple iterations for each model and to trained expert coding of data. We also examine changes in performance resulting from prompt engineering and pre-processing of source data. To ameliorate concerns regarding LLM's pre-training on test data, we assess performance by updating an existing dataset beyond what is publicly available. Overall, we find that only GPT-4 approaches trained expert coders when coding contexts familiar to human coders and codes more consistently across contexts. We conclude by discussing some benefits and drawbacks of machine coding moving forward.  © 2024 The Author(s). Published by Oxford University Press on behalf of National Academy of Sciences.},
	author_keywords = {BERT; GPT; machine coding; machine learning; political event data},
	correspondence_address = {J.K. Birnir; University of Maryland, College Park, United States; email: jkbirnir@umd.edu},
	publisher = {National Academy of Sciences},
	issn = {27526542},
	language = {English},
	abbrev_source_title = {PNAS Nexus},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Henry2024,
	author = {Henry, Matthew Martianus and Heryanto, Nur Adhianti and Isnan, Mahmud and Nugroho, Kuncahyo Setyo and Pardamean, Bens},
	title = {Automatic Multiple Choice Question Generation: A Systematic Literature Review},
	year = {2024},
	journal = {Proceeding of 2024 9th International Conference on Information Technology and Digital Applications, ICITDA 2024},
	doi = {10.1109/ICITDA64560.2024.10810102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216592546&doi=10.1109%2fICITDA64560.2024.10810102&partnerID=40&md5=45845c6c3a616c00f5ce8454b0f2a885},
	affiliations = {Bina Nusantara University, Bioinformatics and Data Science Research Center, Jakarta, 11480, Indonesia; School of Computer Science, Bina Nusantara University, Computer Science Department, Jakarta, 11480, Indonesia; Bina Nusantara University, Binus Graduate Program, Computer Science Department, Jakarta, 11480, Indonesia},
	abstract = {Despite their drawbacks, multiple-choice questions (MCQ) have been widely used to assess the students' understanding of lectures through examinations. The development of automatic MCQ generation is beneficial, especially for educators. As a starting point for further development, a Systematic Literature Review (SLR) is conducted to uncover current trends, future challenges, and opportunities in automatic MCQ generation. Previously, an SLR was conducted, but it lacks coverage of the utilization of transformer-based models. This SLR covers the development of automatic MCQ generation using either traditional or advanced approaches such as Transformers. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework was used to gather the data from Scopus, IEEE Xplore, SpringerLink, arXiv, and Semantic Scholar. The included articles must be open-access computer science conference papers or journal articles and written in English less than five years ago. Four independent reviewers analyzed the research workflow, evaluation metric, and dataset used in each study. There are 18 included studies, where 17% (n = 3) studies are from 2024, 33% (n = 6) studies are from 2023, 22% (n = 4) studies are from 2022, 11% (n = 2) studies are from 2021, and 17% (n = 3) studies are from 2020. There are 33% (n = 6) of the studies used the traditional feature-based engineering approach, 39% (n = 7) of the studies used the Transformer-based model fine-tuning approach, and the remaining used novel approaches. The study found that BERT variants are the most utilized Transformer-based model in automatic MCQ. The research notes some challenges, but also open various opportunities for further research, including Large Language Model (LLM) utilization for automatic MCQ generation, the utilization BERT-based models for standardized machine-learned evaluation metrics, and the initiative for the creation of an MCQ dataset benchmark.  © 2024 IEEE.},
	author_keywords = {Multiple choice question; question generation; systematic literature review; Transformer model},
	keywords = {Distribution transformers; 'current; Evaluation metrics; Further development; Future challenges; Meta-analysis; Multiple-choice questions; Question generation; Systematic literature review; Systematic Review; Transformer modeling; Semantics},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151073-2},
	language = {English},
	abbrev_source_title = {Proceeding Int. Conf. Inf. Technol. Digit. Appl., ICITDA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Etheredge2024,
	author = {Etheredge, Analee J. and Hosmer, Samuel and Crossa, Aldo and Suss, Rachel and Torrey, Mark},
	title = {What is in a food store name? Leveraging large language models to enhance food environment data},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence},
	volume = {7},
	doi = {10.3389/frai.2024.1476950},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212688107&doi=10.3389%2ffrai.2024.1476950&partnerID=40&md5=e82b45a606f167b2740f37c988497321},
	affiliations = {Center for Population Health Data Science, NYC Department of Health and Mental Hygiene, New York, NY, United States},
	abstract = {Introduction: It is not uncommon to repurpose administrative food data to create food environment datasets in the health department and research settings; however, the available administrative data are rarely categorized in a way that supports meaningful insight or action, and ground-truthing or manually reviewing an entire city or neighborhood is rate-limiting to essential operations and analysis. We show that such categorizations should be viewed as a classification problem well addressed by recent advances in natural language processing and deep learning—with the advent of large language models (LLMs). Methods: To demonstrate how to automate the process of categorizing food stores, we use the foundation model BERT to give a first approximation to such categorizations: a best guess by store name. First, 10 food retail classes were developed to comprehensively categorize food store types from a public health perspective. Results: Based on this rubric, the model was tuned and evaluated (F1micro = 0.710, F1macro = 0.709) on an extensive storefront directory of New York City. Second, the model was applied to infer insights from a large, unlabeled dataset using store names alone, aiming to replicate known temporospatial patterns. Finally, a complimentary application of the model as a data quality enhancement tool was demonstrated on a secondary, pre-labeled restaurant dataset. Discussion: This novel application of an LLM to the enumeration of the food environment allowed for marked gains in efficiency compared to manual, in-person methods, addressing a known challenge to research and operations in a local health department. Copyright © 2024 Etheredge, Hosmer, Crossa, Suss and Torrey.},
	author_keywords = {administrative food data; deep learning; food environment classification; food store name; health department; large language models; machine learning; natural language processing},
	correspondence_address = {A.J. Etheredge; Center for Population Health Data Science, NYC Department of Health and Mental Hygiene, New York, United States; email: aetheredge@health.nyc.gov; A. Crossa; Center for Population Health Data Science, NYC Department of Health and Mental Hygiene, New York, United States; email: acrossa@health.nyc.gov},
	publisher = {Frontiers Media SA},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Aggarwal2024,
	author = {Aggarwal, Kush and Singh, Sahib and Parul and Pal, Vipin and Yadav, Satyendra Singh},
	title = {A Framework for Enhancing Accuracy in AI Generated Text Detection Using Ensemble Modelling},
	year = {2024},
	journal = {2024 IEEE Region 10 Symposium, TENSYMP 2024},
	doi = {10.1109/TENSYMP61132.2024.10752173},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211917632&doi=10.1109%2fTENSYMP61132.2024.10752173&partnerID=40&md5=f2cb3d6a03764724c8d741eec0f71639},
	affiliations = {Nsut, Department of Computer Engineering, Delhi, India; Nit Meghalaya, Department of Electronics & Communication Engineering, India},
	abstract = {With the proliferation of AI-driven technologies, the generation of synthetic text has become increasingly prevalent, posing significant challenges in distinguishing between human-generated and AI-generated content (LLM). To mitigate this challenge, novel approach is proposed in this paper for AI-generated text detection through ensemble modelling based framework, leveraging the strengths of multiple state-of-the-art language models. Proposed Ensemble model integrates BERT, DeBERTa, and a custom ensemble method, each contributing to the collective decision-making process with weighted predictions. A diverse dataset sourced from various online platforms is used and this dataset comprises both human-written and AI-generated text samples. A fine-tuning strategy is used that dynamically adjusts the weights of the ensemble model based on the validation accuracy of each constituent model, while applying a cosine learning rate scheduler during training to optimize performance. The effectiveness of the ensemble model is evaluated using standard performance metrics such as accuracy, recall and F1 score. Proposed model achieved an accuracy over 94% and high recall of 98% through the ensemble framework, demonstrating accuracy improvement by 4.1% over BERT and and robustness in detecting AI-generated text across different domains and languages. The research contributes to advancing the field of AI-generated text detection and addresses critical challenges in content moderation and verification in online environments.  © 2024 IEEE.},
	author_keywords = {AI text; ensemble models; fine-tuning; LLM; NLP; weight optimization},
	keywords = {AI text; Ensemble models; Fine tuning; Language model; LLM; Model-based OPC; Multiple state; State of the art; Text detection; Weight optimization},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036486-6},
	language = {English},
	abbrev_source_title = {IEEE Reg. 10 Symp., TENSYMP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Luo20241354,
	author = {Luo, Kun and Qin, Minghao and Liu, Zheng and Xiao, Shitao and Zhao, Jun and Liu, Kang},
	title = {Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {1354 – 1365},
	doi = {10.18653/v1/2024.emnlp-main.80},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217769448&doi=10.18653%2fv1%2f2024.emnlp-main.80&partnerID=40&md5=09cf278e7a67f10da3defc585533e76e},
	affiliations = {The Key Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Beijing Academy of Artificial Intelligence, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China},
	abstract = {Pre-trained language models like BERT and T5 serve as crucial backbone encoders for dense retrieval. However, these models often exhibit limited generalization capabilities and face challenges in improving in-domain accuracy. Recent research has explored using large language models (LLMs) as retrievers, achieving state-of-the-art performance across various tasks. Despite these advancements, the specific benefits of LLMs over traditional retrievers and the impact of different LLM configurations-such as parameter sizes, pre-training duration, and alignment processes-on retrieval tasks remain unclear. In this work, we conduct a comprehensive empirical study on six key dimensions of dense retrieval capabilities, including in-domain accuracy, data efficiency, zero-shot generalization, lengthy retrieval, instruction-based retrieval, and multi-task learning. We evaluate over 15 different backbone LLMs and non-LLMs. Our findings reveal that larger models and extensive pre-training consistently enhance in-domain accuracy and data efficiency. Additionally, larger models demonstrate significant potential in zero-shot generalization, lengthy retrieval, instruction-based retrieval, and multi-task learning. These results underscore the advantages of LLMs as versatile and effective backbone encoders in dense retrieval, providing valuable insights for future research and development in this field. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Content based retrieval; Encoding (symbols); Multi-task learning; Empirical assessment; Generalisation; Generalization capability; Language model; Large models; Model configuration; Multitask learning; Pre-training; Recent researches; State-of-the-art performance; Zero-shot learning},
	correspondence_address = {Z. Liu; Beijing Academy of Artificial Intelligence, Beijing, China; email: zhengliu1026@gmail.com; K. Liu; The Key Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; email: kliu@nlpr.ia.ac.cn},
	editor = {Al-Onaizan Y. and Bansal M. and Chen Y.-N.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176164-3},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Navarro2024,
	author = {Navarro, Laura M. Parra and Batista, Evelyn C. S. and Pacheco, Marco Aurelio C.},
	title = {Exploring State-of-The-Art LLMs from BERT to XLNet: A study over Question Answering},
	year = {2024},
	journal = {2024 IEEE Latin American Conference on Computational Intelligence, LA-CCI 2024 - Proceedings},
	doi = {10.1109/LA-CCI62337.2024.10814828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216528871&doi=10.1109%2fLA-CCI62337.2024.10814828&partnerID=40&md5=39cb0cd30a173182a1c980a34ef8ce7e},
	affiliations = {Pontifical Catholic University of Rio de Janeiro, Department of Electrical Engineering, Rio de Janeiro, 22451-900, Brazil},
	abstract = {In recent years, both academia and industry have witnessed significant advancements in Large Language Models (LLMs) research, with models like ChatGPT garnering extensive attention from society. These advancements in LLM technology have exerted a profound influence on the entire AI community, potentially revolutionizing how we design and utilize AI systems. Among Natural Language Processing (NLP) tasks, Question Answering (QA) has gained increasing attention. In this paper, we provide an overview of the advancements in LLMs, covering background, major findings, and fine-Tuning experiments conducted from BERT to XLNet models on the SQuAD v1.1 and SQuAD v2.0 datasets for the QA task. Our evaluation of various encoder-only models on SQuAD tasks reveals that RoBERTa consistently demonstrates the best performance, achieving the highest Exact Match (EM) and F1 scores on both the SQuAD 1.1 and SQuAD 2.0 datasets. Additionally, we find that Flan T5-base yields even better results, boasting an EM of 77.9% and an F1 Score of 81.2%.  © 2024 IEEE.},
	author_keywords = {evaluation; Large Language Models; natural language processing; Question Answering; survey},
	keywords = {Large datasets; Evaluation; F1 scores; Language model; Language processing; Large language model; Modeling technology; Natural language processing; Natural languages; Question Answering; State of the art; Natural language processing systems},
	correspondence_address = {L.M.P. Navarro; Pontifical Catholic University of Rio de Janeiro, Department of Electrical Engineering, Rio de Janeiro, 22451-900, Brazil; email: laurap@puc-rio.com.br},
	editor = {Orjuela-Canon A.D.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037457-5},
	language = {English},
	abbrev_source_title = {IEEE Lat. American Conf. Comput. Intell., LA-CCI - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hu202422105,
	author = {Hu, Beizhe and Sheng, Qiang and Cao, Juan and Shi, Yuhui and Li, Yang and Wang, Danding and Qi, Peng},
	title = {Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {20},
	pages = {22105 – 22113},
	doi = {10.1609/aaai.v38i20.30214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185609765&doi=10.1609%2faaai.v38i20.30214&partnerID=40&md5=4ccb58be5d8846e8d53898767df72354},
	affiliations = {CAS Key Lab of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; National University of Singapore, Singapore},
	abstract = {Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good advisor for SLMs by providing multi-perspective instructive rationales. To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection (ARG), in which SLMs selectively acquire insights on news analysis from the LLMs' rationales. We further derive a rationale-free version of ARG by distillation, namely ARG-D, which services cost-sensitive scenarios without querying LLMs. Experiments on two real-world datasets demonstrate that ARG and ARG-D outperform three types of baseline methods, including SLM-based, LLM-based, and combinations of small and large language models. © 2024, Association for the Advancement of Artifcial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Computational linguistics; Fake detection; Large datasets; 'current; Cost-sensitive; Empirical studies; Language model; Model-based OPC; Multi-perspective; Performance; Real-world; Real-world datasets; Service costs; Distillation},
	correspondence_address = {Q. Sheng; CAS Key Lab of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, China; email: shengqiang18z@ict.ac.cn},
	editor = {Wooldridge M. and Dy J. and Natarajan S.},
	publisher = {Association for the Advancement of Artificial Intelligence},
	issn = {21595399},
	language = {English},
	abbrev_source_title = {Proc. AAAI Conf. Artif. Intell.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 62; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Rafique2024,
	author = {Rafique, Khushnood Adil and Pansuriya, Maulik and Wawrzik, Frank and Grimm, Christoph},
	title = {Decoding Domain-Specific NER: A Performance Evaluation of ChatGPT, Bi-LSTM, and BERT},
	year = {2024},
	journal = {2024 11th International Conference on Machine Intelligence Theory and Applications, MiTA 2024},
	doi = {10.1109/MiTA60795.2024.10751683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215508141&doi=10.1109%2fMiTA60795.2024.10751683&partnerID=40&md5=8e32068d058a7d696393eb9b36ee37e7},
	affiliations = {University of Kaiserslautern-Landau (RPTU), Kaiserslautern, Germany},
	abstract = {Named Entity Recognition (NER) is a vital method in natural language processing (NLP), extracting information by identifying and categorizing entities in textual data. This study delves into the dynamic landscape of NER models, considering recent advances in transfer learning with transformers like Bidirectional Encoder Representations from Transformers (BERT) and large language models such as ChatGPT. We evaluate and compare their performances on a custom domain-specific and limited corpus. Utilizing state-of-the-art techniques, we model multi-layered prompts for ChatGPT, concurrently utilizing the Bidirectional Long Short-Term Memory Networks (Bi-LSTM) model and fine-tuning a pre-trained BERT model for NER on the corpus. Our study offers crucial insights into these models' viability under constrained, domain-specific dataset conditions, given the effectiveness of transfer learning and zeroshot classification with large language models. Our experimental results highlight that Bi-LSTM excels over ChatGPT and finetuned BERT on the custom dataset, with the added benefit of faster training times. We emphasize the importance of considering domain and task-specific factors and corpus size when selecting a model. © 2024 IEEE.},
	author_keywords = {BERT; Bi-LSTM; ChatGPT; Information Extraction; Knowledge Base Construction; LLMs; Named Entity Recognition; Natural Language Processing; Transfer learning; Transformers},
	keywords = {Decoding; Large datasets; Modeling languages; Natural language processing systems; Transfer learning; Bidirectional encoder representation from transformer; Bidirectional long short-term memory network; ChatGPT; Information extraction; Knowledge-base construction; Language processing; LLM; Memory network; Named entity recognition; Natural language processing; Natural languages; Short term memory; Transfer learning; Transformer; Long short-term memory},
	correspondence_address = {K.A. Rafique; University of Kaiserslautern-Landau (RPTU), Kaiserslautern, Germany; email: khushnood.rafique@cs.uni-kl.de},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038567-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Mach. Intell. Theory Appl., MiTA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yerima2024537,
	author = {Yerima, Suleiman Y. and Vinod, P. and Shaalan, Khaled},
	title = {A Transformer Embedding-Based Model for Malicious DGA-Generated Domain Detection},
	year = {2024},
	journal = {Proceedings - 2024 IEEE 16th International Conference on Communication Systems and Network Technologies, CICN 2024},
	pages = {537 – 541},
	doi = {10.1109/CICN63059.2024.10847389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218028184&doi=10.1109%2fCICN63059.2024.10847389&partnerID=40&md5=9735872d66c1736462683317527040d2},
	affiliations = {The British University in Dubai, Faculty of Engineering and It, Dubai, United Arab Emirates; Cochin University of Science and Technology, Department of Computer Applications, Kerala, Kochi, 682022, India; The British University in Dubai, Department of Computer Science, Dubai, United Arab Emirates},
	abstract = {Domain Generation Algorithms (DGA) techniques are frequently used by cybercriminals to make malware more evasive by generating thousands of fake domain names that prevent established security solutions from effectively discovering or disrupting attacks. The proliferation of DGA has increased the difficulty of distinguishing genuine domains from fake ones, thus necessitating the investigation of new approaches to improve detection efficiency. Therefore, in this paper we propose a method for detecting malicious DGA domain names based on the Generative Pre-Trained Transformer (GPT) Large Language Model (LLM). Our approach utilizes GPT to learn dense vector representations with the aim of enabling more effective detection of the malicious domains by machine learning algorithms. The system is implemented and evaluated using a publicly available dataset and compared to widely-used techniques such TF-IDF, Bag-of-Words, N-grams, word2vec as well as to two variants of BERT. The results of our experiments demonstrates the superiority of the GPT-based technique over the others, with the best performance recorded by the XGboost classifier achieving the highest accuracy of 93.1% compared to the other machine learning algorithms. © 2024 IEEE.},
	author_keywords = {BERT; DGA domain detection; Distil-BERT; Generative Pre-trained Transformers; Machine Learning; N-grams; TF-IDF; Word2vec},
	keywords = {Distribution transformers; Machine learning; Malware; Modeling languages; BERT; Distill-BERT; Domain detections; Domain generation algorithm domain detection; Generation algorithm; Generative pre-trained transformer; Machine-learning; N-grams; TF-IDF; Word2vec; Adversarial machine learning},
	editor = {Tomar G.S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833150526-4},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Commun. Syst. Netw. Technol., CICN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Abdedaiem2024397,
	author = {Abdedaiem, Amin and Dahou, Abdelhalim Hafedh and Cheragui, Mohamed Amine and Mathiak, Brigitte},
	title = {FASSILA: A Corpus for Algerian Dialect Fake News Detection and Sentiment Analysis},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {244},
	pages = {397 – 407},
	doi = {10.1016/j.procs.2024.10.214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211204588&doi=10.1016%2fj.procs.2024.10.214&partnerID=40&md5=f00cdd977df04285b1bbbd87eac27813},
	affiliations = {Department of Mathematics and Computer Science, Ahmed Draia University, Adrar, 01000, Algeria; GESIS - Leibniz-Institute for the Social Sciences, Cologne, 50667, Germany},
	abstract = {In the context of low-resource languages, the Algerian dialect (AD) faces challenges due to the absence of annotated corpora, hindering its effective processing, notably in Machine Learning (ML) applications reliant on corpora for training and assessment. This study outlines the development process of a specialized corpus for Fake News (FN) detection and sentiment analysis (SA) in AD called FASSILA. This corpus comprises 10,087 sentences, encompassing over 19,497 unique words in AD, addresses the language's significant lack of linguistic resources, and covers seven distinct domains. We propose an FN detection and SA annotation scheme detailing the data collection, cleaning, and labeling. The remarkable Inter-Annotator Agreement indicates that the annotation scheme produces high-quality and consistent annotations. Subsequent classification experiments using BERT-based and ML models are presented, demonstrating promising results and highlighting avenues for further research. The dataset is currently freely available to facilitate future advancements in the field. © 2024 The Authors. Published by Elsevier B.V.},
	author_keywords = {Algerian Dialect; Corpus; Deep learning; Fake News; LLMs; Machine learning; Sentiment Analysis},
	keywords = {Contrastive Learning; Algerian dialect; Annotation scheme; Corpus; Deep learning; Fake news; LLM; Low resource languages; Machine learning applications; Machine-learning; Sentiment analysis; Adversarial machine learning},
	correspondence_address = {M.A. Cheragui; Department of Mathematics and Computer Science, Ahmed Draia University, Adrar, 01000, Algeria; email: m_cheragui@univ-adrar.edu.dz},
	editor = {Shaalan K. and El-Beltagy S.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Arikkat2024644,
	author = {Arikkat, Dincy R. and Abhinav, M. and Binu, Navya and Parvathi, M. and Biju, Navya and Arunima, K.S. and Vinod, P. and Rehiman Rafidha, K.A. and Conti, Mauro},
	title = {IntellBot: Retrieval Augmented LLM Chatbot for Cyber Threat Knowledge Delivery},
	year = {2024},
	journal = {Proceedings - 2024 IEEE 16th International Conference on Communication Systems and Network Technologies, CICN 2024},
	pages = {644 – 651},
	doi = {10.1109/CICN63059.2024.10847404},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218027658&doi=10.1109%2fCICN63059.2024.10847404&partnerID=40&md5=72642b21c060a9a6becd6a16b15324f0},
	affiliations = {Cochin University of Science and Technology, Department of Computer Applications, Kerala, India; University of Padua, Department of Mathematics, Padua, Italy},
	abstract = {In the evolving field of cybersecurity, AI-driven chatbots are valuable. Unlike rigid rule-based bots, Large Language Model (LLM) based chatbots can provide flexible, context-aware responses across various domains. This research introduces IntellBot, a sophisticated cybersecurity chatbot built using advanced LLMs, Langchain, and a Retrieval-Augmented Generation model. IntellBot aggregates data from diverse sources, creating a comprehensive knowledge base on vulnerabilities, recent cyber threats, and emerging trends. It offers intelligent responses to enhance threat intelligence, incident response, and overall security awareness. A two-stage evaluation yielded high accuracy, with a BERT score above 0.8 and cosine similarity from 0.8 to 1, while RAGAS assessments scores consistently over 0.77, confirming the system's effectiveness. © 2024 IEEE.},
	author_keywords = {Cyber Security; Large Language Model; Retrieval-Augmented Generation; Security Chatbot; Threat Intelligence},
	keywords = {Bot (Internet); Cyber attacks; Chatbots; Cyber security; Cyber threats; Knowledge delivery; Language model; Large language model; Retrieval-augmented generation; Rule based; Security chatbot; Threat intelligence; Chatbots},
	correspondence_address = {; ; ; ; ; ; },
	editor = {Tomar G.S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833150526-4},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Commun. Syst. Netw. Technol., CICN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Shi202422294,
	author = {Shi, Wenqi and Xu, Ran and Zhuang, Yuchen and Yu, Yue and Sun, Haotian and Wu, Hang and Yang, Carl and Wang, May D.},
	title = {MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {22294 – 22314},
	doi = {10.18653/v1/2024.emnlp-main.1244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208958037&doi=10.18653%2fv1%2f2024.emnlp-main.1244&partnerID=40&md5=c5db1b827308358a597f1630c192e68d},
	affiliations = {Georgia Tech, United States; Emory University, United States},
	abstract = {Despite their improved capabilities in generation and reasoning, adapting large language models (LLMs) to the biomedical domain remains challenging due to their immense size and privacy concerns. In this study, we propose MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards biomedical applications. Instead of fine-tuning the entire LLM, MedAdapter effectively adapts the original model by fine-tuning only a small BERT-sized adapter to rank candidate solutions generated by LLMs. Experiments on four biomedical tasks across eight datasets demonstrate that MedAdapter effectively adapts both white-box and black-box LLMs in biomedical reasoning, achieving average performance improvements of 18.24% and 10.96%, respectively, without requiring extensive computational resources or sharing data with third parties. MedAdapter also yields enhanced performance when combined with train-time adaptation, highlighting a flexible and complementary solution to existing adaptation methods. Faced with the challenges of balancing model performance, computational resources, and data privacy, MedAdapter provides an efficient, privacy-preserving, cost-effective, and transparent solution for adapting LLMs to the biomedical domain. © 2024 Association for Computational Linguistics.},
	keywords = {Black-box testing; Differential privacy; Biomedical applications; Biomedical domain; Computational resources; Fine tuning; Language model; Medical reasonings; Original model; Performance; Privacy concerns; Test time; Computational linguistics},
	editor = {Al-Onaizan Y. and Bansal M. and Chen Y.-N.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176164-3},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Sriram2024177038,
	author = {Sriram, Suthir and Karthikeya, C.H. and Kishore Kumar, K.P. and Vijayaraj, Nivethitha and Murugan, Thangavel},
	title = {Leveraging Local LLMs for Secure In-System Task Automation with Prompt-Based Agent Classification},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {177038 – 177049},
	doi = {10.1109/ACCESS.2024.3505298},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210964708&doi=10.1109%2fACCESS.2024.3505298&partnerID=40&md5=3f9988e642d27748b2a4bd195d45f064},
	affiliations = {Amrita School of Computing, Amrita Vishwa Vidyapeetham, Department of Computer Science and Engineering, Chennai, 601103, India; United Arab Emirates University, College of Information and Technology, Al Ain, United Arab Emirates},
	abstract = {Recent progress in the field of intelligence has led to the creation of powerful large language models (LLMs). While these models show promise in improving personal computing experiences concerns surrounding data privacy and security have hindered their integration with sensitive personal information. In this study, a new framework is proposed to merge LLMs with personal file systems, enabling intelligent data interaction while maintaining strict privacy safeguards. The methodology organizes tasks based on LLM agents, which apply designated tags to the tasks before sending them to specific LLM modules. Every module is has its own function, including file search, document summarization, code interpretation, and general tasks, to make certain that all processing happens locally on the user's device. Findings indicate high accuracy across agents: classification agent managed to get an accuracy rating of 86%, document summarization reached a BERT score of 0.9243. The key point of this framework is that it splits the LLM system into modules, which enables future development by integrating new task-specific modules as required. Findings suggest that integrating local LLMs can significantly improve interactions with file systems without compromising data privacy.  © 2013 IEEE.},
	author_keywords = {few-shot prompting; File system; LangChain; LLM; prompt engineering},
	keywords = {Classification (of information); Data accuracy; Data integration; Differential privacy; Sensitive data; Data privacy and securities; Document summarization; Few-shot prompting; Filesystem; Langchain; Language model; Large language model; Prompt engineering; Recent progress; Task automation; File organization},
	correspondence_address = {C.H. Karthikeya; Amrita School of Computing, Amrita Vishwa Vidyapeetham, Department of Computer Science and Engineering, Chennai, 601103, India; email: karthikeya2204@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Song20248512,
	author = {Song, Bochuan and Fan, Xiaoxuan and Jia, Quanye and Xin, Rui and Zhang, Zhi},
	title = {Structured Intention Generation with Multimodal Graph Transformers: The MMIntent-LLM Framework},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Big Data, BigData 2024},
	pages = {8512 – 8519},
	doi = {10.1109/BigData62323.2024.10826116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218049717&doi=10.1109%2fBigData62323.2024.10826116&partnerID=40&md5=bf4c512b6959b630360fbbd1748f9626},
	affiliations = {China Electric Power Research Institute, Beijing, China; State Grid Hebei Information and Telecommunication Branch, Beijing, China},
	abstract = {In the task of answering questions related to electricity knowledge, accurately understanding user intentions is fundamental to building an effective reasoning process. Questions in this domain often cover complex issues such as troubleshooting, electricity bill consultation, and electricity safety. User queries frequently involve multiple aspects and varying levels of information. Traditional single-modal methods struggle to fully address these diverse needs. Intention understanding plays a crucial role in constructing a clear and logical reasoning chain by accurately identifying the user's core requirements. Through in-depth analysis of user intentions, the system can better organize and reason with multimodal information such as text, voice, and images - leading to logically coherent and accurate responses. Intention understanding not only enhances the accuracy of the reasoning process but also significantly improves the response efficiency and service quality of the electricity knowledge question-and-answer system. Current approaches to intention analysis primarily rely on classification-based methods, which limit the flexibility and richness of intent understanding. To broaden the scope and depth of user intent recognition, we introduce MMIntent-LLM, a novel framework that combines T5 with a Graph Transformer to generate structured intent representations from multimodal social media content. Our approach introduces three key innovations: (1) a structured intention reasoning framework based on ATOMIC, which provides a systematic method for decomposing intent generation into interpretable components; (2) a graph-based alignment mechanism for multimodal data (text and images) that ensures semantic consistency across modalities; and (3) an adaptive fine-tuning strategy that effectively transfers knowledge from pre-trained language models to the specific intent generation task. Extensive experiments on our multimodal social intention dataset show that MMIntent-LLM achieves state-of-the-art performance, improving the average BERT score by 8.7% and human evaluation scores by 12.3% compared to baseline methods. © 2024 IEEE.},
	author_keywords = {Intention analysis; multimodal; reasoning chain},
	keywords = {Classification (of information); Distribution transformers; Knowledge graph; Metadata; Modula (programming language); Question answering; Structured Query Language; Electricity bill; Electricity safety; Intent generations; Intention analyze; Intention understanding; Multi-modal; Reasoning chain; Reasoning process; User query; User's intentions; Semantics},
	correspondence_address = {B. Song; China Electric Power Research Institute, Beijing, China; email: songbochuan@epri.sgcc.com.cn},
	editor = {Ding W. and Lu C.-T. and Wang F. and Di L. and Wu K. and Huan J. and Nambiar R. and Li J. and Ilievski F. and Baeza-Yates R. and Hu X.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036248-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2024348,
	author = {Zhang, Mo and Johnson, Matthew and Ruan, Chunyi},
	title = {Investigating Sampling Impacts on an LLM-Based AI Scoring Approach: Prediction Accuracy and Fairness},
	year = {2024},
	journal = {Journal of Measurement and Evaluation in Education and Psychology},
	volume = {15},
	pages = {348 – 360},
	doi = {10.21031/epod.1561580},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214032151&doi=10.21031%2fepod.1561580&partnerID=40&md5=da7c6f724e968525986c89f0ca99ce45},
	affiliations = {Educational Testing Service, New Jersey, United States},
	abstract = {AI scoring capabilities are commonly implemented in educational assessments as a supplement or replacement to human scoring, with significant interest in leveraging large language models for scoring. In order to use AI scoring capability responsibly, the AI scores should be accurate and fair. In this study, we explored one approach to potentially mitigate bias in AI scoring by using equal-allocation stratified sampling for AI model training. The data set included 13 open-ended short-response items in a K-12 state science assessment. Empirical results suggested that stratification did not improve or worsen fairness evaluations on the AI models. BERT based AI scoring models resulting from the stratified sampling method but trained on much less data performed comparably to models resulting from simple random sampling in terms of overall prediction accuracy and fairness on the subgroup level. Limitations and future research are also discussed. © 2024 Association of Measurement and Evaluation in Education and Psychology (EPODDER). All rights reserved.},
	author_keywords = {AI scoring; educational assessment; fairness; large language model; prediction accuracy; sampling},
	correspondence_address = {M. Zhang; Educational Testing Service, New Jersey, United States; email: mzhang@ets.org},
	publisher = {Association of Measurement and Evaluation in Education and Psychology (EPODDER)},
	issn = {13096575},
	language = {English},
	abbrev_source_title = {J. Measure. Eval. Psychol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Karra2024191,
	author = {Karra, Rachid and Lasfar, Abdelali},
	title = {Analysis of QA System Behavior against Context and Question Changes},
	year = {2024},
	journal = {International Arab Journal of Information Technology},
	volume = {21},
	number = {2},
	pages = {191 – 200},
	doi = {10.34028/iajit/21/2/2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187480835&doi=10.34028%2fiajit%2f21%2f2%2f2&partnerID=40&md5=b66c2ccfa014eeb49c374cd9df38261e},
	affiliations = {Department of Computer Science, Mohammed V University, Morocco},
	abstract = {Data quality has gained increasing attention across various research domains, including pattern recognition, image processing, and Natural Language Processing (NLP). The goal of this paper is to explore the impact of data quality (both questions and context) on Question-Answering (QA) system performance. We introduced an approach to enhance the results of the QA system through context simplification. The strength of our methodology resides in the utilization of human-scale NLP models. This approach promotes the utilization of multiple specialized models within the workflow to enhance the QA system’s outcomes, rather than relying solely on resource-intensive Large Language Model (LLM). We demonstrated that this method improves the correct response rate of the QA system without modification or additional training of the model. In addition, we conducted a cross-disciplinary study involving NLP and linguistics. We analyzed QA system results to showcase their correlation with readability and text complexity linguistic metrics using Coh-Metrix. Lastly, we explore the robustness of Bidirectional Encoder Representations from Transformers (BERT) and Reliable National Entrance Test (R-NET) models when confronted with noisy questions. © 2024, Zarka Private University. All rights reserved.},
	author_keywords = {Adversarial attacks; BERT; data quality; question answering; simplification},
	publisher = {Zarka Private University},
	issn = {16833198},
	language = {English},
	abbrev_source_title = {Int. Arab J. of Info. Tech.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Ferreira2024,
	author = {Ferreira, Tarcísio Lima and Oliveira, Marcelo Costa and De Almeida Vieira, Thales Miranda},
	title = {Comparative Study of Large Language Models for Lung-RADS Classification in Portuguese CT Reports},
	year = {2024},
	journal = {2024 IEEE 24th International Conference on Bioinformatics and Bioengineering, BIBE 2024},
	doi = {10.1109/BIBE63649.2024.10820460},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217180835&doi=10.1109%2fBIBE63649.2024.10820460&partnerID=40&md5=a7de559c22ad9b58b449b6eced32d408},
	affiliations = {Computing Institute, (UFAL), Federal University of Alagoas (UFAL), Maceió, Brazil},
	abstract = {Lung cancer has the highest mortality rate among all cancer types for both males and females. It is estimated that lung cancer accounts for 21% of cancer deaths in each gender. This alarming statistic highlights the significant impact of lung cancer on overall cancer mortality, underscoring the urgent need for effective prevention, early detection, and treatment strategies to combat this disease. Lung cancer screening (LCS) is a process that involves carefully selecting high-risk individuals, primarily current or former heavy smokers. It includes annual low-dose computed tomography scans and meticulous interpretation of results followed by appropriate follow-up care. Adherence to LCS follow-up is essential for maximizing the life-saving benefits of this preventive measure. Multiple professional societies, such as the American College of Radiology (ACR) and Fleischner Society, have published guidelines for managing patients with pulmonary nodules. Lung CT Screening Reporting & Data System is a quality assurance tool designed to standardize the reporting of lung cancer screening CT scans and provide consistent management recommendations. In this context, this work aims to evaluate whether large language models (LLM) could accurately identify and extract lung nodules' characteristics from unstructured chest CT reports in the Portuguese, based on the Lung-RADS classification system. This work assessed the effectiveness of three LLMs: Gemini, GPT-4-o, Llama-3 70B, and a BERT model BioBERTpt. Our findings indicate that LLMs, especially GPT-4-o, have significant potential in automating the extraction of lung nodule characteristics for Lung-RADS classification, which could aid radiologists in their work. Notably, GPT-4-o with few-shot learning using Prompt 4 emerged as the best model, achieving an F1-score of 0.89. Our results highlight the potential of LLMs to assist radiologists in accurately classifying lung nodules according to the Lung-RADS criteria, streamlining the diagnostic process. © 2024 IEEE.},
	author_keywords = {Chest CT report; Information extraction; Large language model; Lung cancer; Lung-RADS; Named entity recognition; Natural language processing},
	keywords = {Computerized tomography; Diagnosis; Disease control; Diseases; Radiology; Chest CT; Chest CT report; Information extraction; Language model; Language processing; Large language model; Lung Cancer; Lung-RADS; Named entity recognition; Natural language processing; Natural languages; Lung cancer},
	editor = {Filipovic N.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151862-2},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Bioinform. Bioeng., BIBE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Ngee2024,
	author = {Ngee, Hui Qian and Ganesh, Asha and Azmi, Muhammad Aizat Noor and Tang, Tiong Yew and Mukred, Muaadh and Mohammed, Fathey and Ahmad, Adi Affandi Bin},
	title = {Environmental, Social and Governance (ESG) Scores Automation in Global Reporting Initiative (GRI) with Natural Language Processing},
	year = {2024},
	journal = {2024 7th International Conference on Internet Applications, Protocols, and Services, NETAPPS 2024},
	doi = {10.1109/NETAPPS63333.2024.10823436},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217398819&doi=10.1109%2fNETAPPS63333.2024.10823436&partnerID=40&md5=65b61d2cd34a4607f9aa48c895285bfb},
	affiliations = {Department of Business Analytics, Sunway Business School, Sunway University, No. 5, Jalan Universiti, Selangor Darul Ehsan, Bandar Sunway, 47500, Malaysia; Research Centre For Human-Machine Collaboration (HUMAC), School of Engineering and Technology, Sunway University, No. 5, Jalan Universiti, Selangor Darul Ehsan, Bandar Sunway, 47500, Malaysia; School of Computing, Universiti Utara Malaysia (UUM), Sintok, Kedah, 06010, Malaysia},
	abstract = {The increasing importance of Environmental, Social, and Governance (ESG) factors in making investment decisions has triggered a noteworthy transformation in the global investing scenario. This study investigates various distilled BERT models in Python, including all-MiniLM-L12-v2, all-MiniLM-L6-v2, all-mpnet-base-v2, and paraphraseMiniLM-L6v2, to improve the accuracy and efficiency of ESG scoring. The performance of these models will undertake a detailed evaluation employing the F1 score criteria, which will offer an understanding of the accuracy and consistency of the scoring outputs produced by each model. The reason for this detailed review is to pledge a strong valuation of the effectiveness of the automated scoring procedure. The study shows that utilising textual similarity for ESG rating considerably decreases the time needed in comparison to the conventional human scoring procedure. Throughout the time of this study, all-MiniLM-L6-v2 was used as the base comparison model, however, it was observed that the all-mpnet-base-v2 model provided a relatively better F1 score due to its value being determined by its 768-dimensional embeddings. Embeddings with better length possess the volume to cover more difficult and subtle semantic representations, therefore potentially yielding superior performance. In the result finding summary, all- mpnet-base-v2 has the highest F1 score compared with the experiment's sentence transformers. © 2024 IEEE.},
	author_keywords = {Automation; ESG; Large Language Model; LLM; Score},
	keywords = {Decision making; Economic and social effects; Investments; Natural language processing systems; Semantics; Embeddings; Environmental, social and governance; F1 scores; Global Reporting Initiative; Language model; Large language model; LLM; Natural languages; Performance; Score; Embeddings},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151951-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Internet Appl., Protocols, Serv., NETAPPS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Paul2024,
	author = {Paul, Bidyarthi and Preotee, Faika Fairuj and Sarker, Shuvashis and Muhammad, Tashreef},
	title = {Improving Bangla Regional Dialect Detection Using BERT, LLMs, and XAI},
	year = {2024},
	journal = {2024 IEEE Conference on Computing Applications and Systems, COMPAS 2024},
	doi = {10.1109/COMPAS60761.2024.10796843},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215519819&doi=10.1109%2fCOMPAS60761.2024.10796843&partnerID=40&md5=a77b4a8fdaf6a63dd389251b5d3ec201},
	affiliations = {Ahsanullah University of Science and Technology, Department of Computer Science and Engineering, Dhaka, 1208, Bangladesh; Southeast University, Department of Computer Science and Engineering, Dhaka, 1208, Bangladesh},
	abstract = {This research addresses the challenge of identifying and categorizing Bangla regional dialects through the application of sophisticated natural language processing techniques. Automated translation, digital content personalization, and speech recognition systems are all improved by precise dialect detection, which is a result of the linguistic diversity in Bangladesh. Few-shot learning techniques were used to compare the performance of transformer-based models, specifically Bangla BERT, with state-of-the-art large language models such as GPT-3.5 Turbo and Gemini 1.5 Pro, and to fine-tune them. The methodology entailed the utilization of a diverse regional Bangla speech samples from the Vasantor dataset, which encompassed regions including Mymensingh, Chittagong, Barishal, Noakhali, and Sylhet. In order to enhance the interpretability of the model, implementation of Local Interpretable Model-agnostic Explanations (LIME) was done. The Bangla BERT model achieved the highest accuracy of 88.74%. GPT-3.5 Turbo's few-shot learning exhibited substantial potential, with an accuracy rate of 64%. These results underscore the significance of hyperparameter optimization and fine-tuning in the enhancement of regional dialect detection models.  © 2024 IEEE.},
	author_keywords = {Bangla BERT; Bangla dialect detection; Explainable AI; LLM},
	keywords = {Computational linguistics; Computer aided language translation; Contrastive Learning; Image coding; Image compression; Image thinning; Modeling languages; Natural language processing systems; Speech enhancement; Zero-shot learning; Automated translation; Bangla BERT; Bangla dialect detection; Content personalization; Digital contents; Explainable AI; Language processing techniques; LLM; Natural languages; Speech recognition systems; Speech recognition},
	correspondence_address = {B. Paul; Ahsanullah University of Science and Technology, Department of Computer Science and Engineering, Dhaka, 1208, Bangladesh; email: bidyarthipaul01@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152976-5},
	language = {English},
	abbrev_source_title = {IEEE Conf. Comput. Appl. Syst., COMPAS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Srivastava2024,
	author = {Srivastava, Santosh Kumar and Routray, Susmi and Bag, Surajit and Gupta, Shivam and Zhang, Justin Zuopeng},
	title = {Exploring the Potential of Large Language Models in Supply Chain Management: A Study Using Big Data},
	year = {2024},
	journal = {Journal of Global Information Management},
	volume = {32},
	number = {1},
	doi = {10.4018/JGIM.335125},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182888134&doi=10.4018%2fJGIM.335125&partnerID=40&md5=ad3c879f7056929ee4411a486386ddc5},
	affiliations = {Institute of Management Technology, Ghaziabad, India; Research Center, Léonard de Vinci Pôle Universitaire, France; Department of Information Systems, Supply Chain Management and Decision Support, NEOMA Business School, France; University of North Florida, United States},
	abstract = {This study aims to identify emerging topics, themes, and potential areas for applying large language models (LLMs) in supply chain management through data triangulation. This study involved the synthesis of 33 published articles and a total of 3421 social media documents, including tweets, posts, expert opinions, and industry reports on utilizing LLMs in supply chain management. By employing BERT models, four core themes were derived: Supply chain optimization, supply chain risk and security management, supply chain knowledge management, and automated contract intelligence, which provides the present status of LLM in the supply chain. The results of this study will empower managers to identify prospective applications and areas for improvement, affording them a comprehensive understanding of the antecedents, decisions, and outcomes detailed in the framework. The insights garnered from this study are highly valuable to both researchers and managers, equipping them to harness the latest advancements in LLM technology and its role within supply chain management. © 2024 IGI Global. All rights reserved.},
	author_keywords = {BERT; Large language model; Social Media; Supply chain management},
	keywords = {Big data; Computational linguistics; Knowledge management; Social networking (online); BERT; Emerging topics; Expert opinion; Four-core; Language model; Large language model; Social media; Supply chain optimization; Supply chain security; Supply-chain risks; Supply chain management},
	publisher = {IGI Global},
	issn = {10627375},
	language = {English},
	abbrev_source_title = {J. Global Inf. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access}
}

@CONFERENCE{Biji2024840,
	author = {Biji, Divya Mary and Kim, Yong-Woon},
	title = {Evaluating the Performance of Large Language Models in Classifying Numerical Data},
	year = {2024},
	journal = {International Conference on ICT Convergence},
	pages = {840 – 844},
	doi = {10.1109/ICTC62082.2024.10827495},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217636025&doi=10.1109%2fICTC62082.2024.10827495&partnerID=40&md5=ed2eee2cf102bdea28452d2daceee75a},
	affiliations = {Elmcad Co. Ltd, Seoul, South Korea; Christ University, Pune, India},
	abstract = {In recent years, large language models (LLMs) such as BERT, DistilBERT, RoBERTa, and XLNet have revolutionized natural language processing (NLP) tasks due to their powerful representation capabilities. This research investigates the efficacy of these LLMs in the novel domain of numerical data classification by transforming numerical data into textual formats. The study involves converting numerical data points into descriptive strings and leveraging the advanced text processing capabilities of LLMs to classify them into predefined categories. We conduct a comparative analysis of BERT, DistilBERT, RoBERTa, and XLNet, evaluating their performance using standard metrics such as accuracy, precision, recall, and F1-score. Our experimental results demonstrate the potential of these models in accurately classifying numerical data, highlighting the strengths and limitations of each model. This research opens new avenues for applying LLMs beyond traditional NLP tasks, providing insights into their applicability for structured data classification. © 2024 IEEE.},
	author_keywords = {BERT; Large Language Model (LLM); Pre trained Language models},
	keywords = {Classification (of information); Data assimilation; Data handling; Metadata; BERT; Data classification; Language model; Language processing; Large language model; Natural languages; Numerical data; Performance; Pre trained language model; Natural language processing systems},
	publisher = {IEEE Computer Society},
	issn = {21621233},
	isbn = {979-835036463-7},
	language = {English},
	abbrev_source_title = {Int. Conf. ICT Convergence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Patel20244903,
	author = {Patel, Urjitkumar and Yeh, Fang-Chun and Gondhalekar, Chinmay and Nalluri, Hari},
	title = {FANAL - Financial Activity News Alerting Language Modeling Framework},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Big Data, BigData 2024},
	pages = {4903 – 4912},
	doi = {10.1109/BigData62323.2024.10825891},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218007434&doi=10.1109%2fBigData62323.2024.10825891&partnerID=40&md5=202375547791dfb04af41de31a6b0483},
	abstract = {In the rapidly evolving financial sector, the accurate and timely interpretation of market news is essential for stakeholders needing to navigate unpredictable events. This paper introduces FANAL (Financial Activity News Alerting Language Modeling Framework), a specialized BERT-based framework engineered for real-time financial event detection and analysis, categorizing news into twelve distinct financial categories. FANAL leverages silver-labeled data processed through XGBoost and employs advanced fine-tuning techniques, alongside ORBERT (Odds Ratio BERT), a novel variant of BERT fine-tuned with ORPO (Odds Ratio Preference Optimization) for superior class-wise probability calibration and alignment with financial event relevance. We evaluate FANAL's performance against leading large language models, including GPT-4o, Llama-3.1 8B, and Phi-3, demonstrating its superior accuracy and cost efficiency. This framework sets a new standard for financial intelligence and responsiveness, significantly outstripping existing models in both performance and affordability. © 2024 IEEE.},
	author_keywords = {BERT; Empirical Cost Analysis; Finance Event Modeling; Financial News Alerts; Financial Risk Analysis; Generative AI (Gen AI); Large Language Models (LLM); Machine Learning; Natural Language Processing (NLP)},
	keywords = {Cost benefit analysis; Cost effectiveness; Decentralized finance; Financial data processing; Financial markets; Labeled data; Natural language processing systems; Risk analysis; Risk perception; BERT; Cost analysis; Empirical cost analyze; Event model; Finance event modeling; Financial news; Financial news alert; Financial risk analysis; Generative AI; Language model; Language processing; Large language model; Machine-learning; Natural language processing; Natural languages; News alerts; Risk assessment},
	correspondence_address = {U. Patel; email: urjitkumar.patel@spglobal.com},
	editor = {Ding W. and Lu C.-T. and Wang F. and Di L. and Wu K. and Huan J. and Nambiar R. and Li J. and Ilievski F. and Baeza-Yates R. and Hu X.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036248-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Tang2024207,
	author = {Tang, Jinwen and Guo, Qiming and Zhao, Yunxin and Shang, Yi},
	title = {Decoding Linguistic Nuances in Mental Health Text Classification Using Expressive Narrative Stories},
	year = {2024},
	journal = {Proceedings - 2024 IEEE 6th International Conference on Cognitive Machine Intelligence, CogMI 2024},
	pages = {207 – 216},
	doi = {10.1109/CogMI62246.2024.00035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217419917&doi=10.1109%2fCogMI62246.2024.00035&partnerID=40&md5=795a2d54a43a595c18d2b5b0fa6eb44d},
	affiliations = {Electrical Engineering and Computer Science Department, University of Missouri, Columbia, MO, United States; Department of Computer Science, Texas A&M University-Corpus Christi, Corpus Christi, TX, United States},
	abstract = {Recent advancements in Natural Language Processing (NLP) have spurred significant interest in analyzing social media text data for identifying linguistic features indicative of mental health issues. However, the domain of Expressive Narrative Stories (ENS)-deeply personal and emotionally charged narratives that offer rich psychological insights-remains underexplored. This study bridges this gap by utilizing a dataset sourced from Reddit, focusing on ENS from individuals with and without self-declared depression. Our research evaluates the utility of advanced language models, BERT and MentalBERT, against traditional models such as SVM, Naive Bayes, and Logistic Regression. We find that traditional models are notably sensitive to the absence of explicit topic-related words, which could risk their potential to extend applications to emotional expressive narratives that lack clear mental health terminology. Despite MentalBERT’s design to better handle psychiatric contexts, it demonstrated a dependency on specific topic words for classification accuracy, raising concerns about its application in scenarios where explicit mental health terms are sparse (P-value < 0.05). In contrast, BERT(128) exhibited minimal sensitivity to the absence of topic words in ENS, suggesting its superior capability to understand deeper linguistic features, making it more effective for real-world applications that require nuanced text analysis. Both BERT and MentalBERT excel at recognizing linguistic nuances and maintaining classification accuracy even when narrative order is disrupted-a crucial capability in mental health narratives. This resilience is statistically significant, with sentence shuffling showing substantial impacts on model performance (P-value < 0.05), especially evident in ENS comparisons between individuals with and without mental health declarations. These findings underscore the importance of exploring ENS for deeper insights into mental health-related narratives, advocating for a nuanced approach to mental health text analysis that moves beyond mere keyword detection. This study paves the way for more sophisticated, context-aware analyses in NLP applications, aiming to enhance the understanding of linguistic patterns associated with mental health conditions. © 2024 IEEE.},
	author_keywords = {Artificial Intelligence; Explainability; LLM; Mental Health; NLP; Psychiatry; Social Media},
	keywords = {Linguistics; Natural language processing systems; Explainability; Language processing; Linguistic features; LLM; Mental health; Natural language processing; Natural languages; Psychiatry; Social media; Traditional models; Electronic health record},
	correspondence_address = {J. Tang; Electrical Engineering and Computer Science Department, University of Missouri, Columbia, United States; email: jt4cc@umsystem.edu; Y. Zhao; Electrical Engineering and Computer Science Department, University of Missouri, Columbia, United States; email: zhaoy@umsystem.edu; Y. Shang; Electrical Engineering and Computer Science Department, University of Missouri, Columbia, United States; email: shangy@umsystem.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038672-1},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Cogn. Mach. Intell., CogMI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Rostam2024233,
	author = {Rostam, Zhyar Rzgar K and Kertész, Gábor},
	title = {Fine-Tuning Large Language Models for Scientific Text Classification: A Comparative Study},
	year = {2024},
	journal = {LINDI 2024 - 6th IEEE International Symposium on Logistics and Industrial Informatics, Proceedings},
	pages = {233 – 238},
	doi = {10.1109/LINDI63813.2024.10820432},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217618511&doi=10.1109%2fLINDI63813.2024.10820432&partnerID=40&md5=d677b312d86489b6c4f72be0e72077b2},
	affiliations = {Doctoral School of Applied Informatics and Applied Mathematics, Óbuda University, Budapest, Hungary; Óbuda University, John von Neumann Faculty of Informatics, Budapest, Hungary},
	abstract = {The exponential growth of online textual content across diverse domains has necessitated advanced methods for automated text classification. Large Language Models (LLMs) based on transformer architectures have shown significant success in this area, particularly in natural language processing (NLP) tasks. However, general-purpose LLMs often struggle with domain-specific content, such as scientific texts, due to unique challenges like specialized vocabulary and imbalanced data. In this study, we fine-tune four state-of-the-art LLMs BERT, SciBERT, BioBERT, and BlueBERT on three datasets derived from the WoS-46985 dataset to evaluate their performance in scientific text classification. Our experiments reveal that domain-specific models, particularly SciBERT, consistently outperform general-purpose models in both abstract-based and keyword-based classification tasks. Additionally, we compare our achieved results with those reported in the literature for deep learning models, further highlighting the advantages of LLMs, especially when utilized in specific domains. The findings emphasize the importance of domain-specific adaptations for LLMs to enhance their effectiveness in specialized text classification tasks.  © 2024 IEEE.},
	author_keywords = {Domain-specific text classification; Fine-tuning LLMs; LLM performance evaluation; Text representation; Transformer-based language models},
	keywords = {Classification (of information); Contrastive Learning; Natural language processing systems; Text processing; Domain specific; Domain-specific text classification; Fine tuning; Fine-tuning large language model; Language model; Large language model performance evaluation; Model performance evaluations; Text classification; Text representation; Transformer-based language model; Deep learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151619-2},
	language = {English},
	abbrev_source_title = {LINDI - IEEE Int. Symp. Logist. Ind. Informatics, Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Di Palo20243675,
	author = {Di Palo, Flavio and Singhi, Prateek and Fadlallah, Bilal},
	title = {Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {3675 – 3687},
	doi = {10.18653/v1/2024.emnlp-main.215},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217750252&doi=10.18653%2fv1%2f2024.emnlp-main.215&partnerID=40&md5=232c35085ad33d05bf80694065236f7d},
	affiliations = {Amazon, United States},
	abstract = {Large Language Models (LLMs) face significant challenges at inference time due to their high computational demands. To address this, we present Performance-Guided Knowledge Distillation (PGKD), a cost-effective and high-throughput solution for production text classification applications. PGKD utilizes teacher-student Knowledge Distillation to distill the knowledge of LLMs into smaller, task-specific models. PGKD establishes an active learning routine between the student model and the LLM; the LLM continuously generates new training data leveraging hard-negative mining, student model validation performance, and early-stopping protocols to inform the data generation. By employing a cyclical, performance-aware approach tailored for highly multi-class, sparsely annotated datasets prevalent in industrial text classification, PGKD effectively addresses training challenges and outperforms traditional BERT-base models and other knowledge distillation methods on several multi-class classification datasets. Additionally, cost and latency benchmarking reveals that models fine-tuned with PGKD are up to 130X faster and 25X less expensive than LLMs for inference on the same classification task. While PGKD is showcased for text classification tasks, its versatile framework can be extended to any LLM distillation task, including language generation, making it a powerful tool for optimizing performance across a wide range of AI applications. © 2024 Association for Computational Linguistics.},
	keywords = {Active learning; Benchmarking; Classification (of information); Inference engines; Personnel training; Students; Teaching; Classification tasks; Computational demands; Cost effective; Effective throughput; High-throughput; Language model; Model knowledge; Performance; Student Modeling; Text classification; Computational linguistics},
	editor = {Al-Onaizan Y. and Bansal M. and Chen Y.-N.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176164-3},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Mahajan20247393,
	author = {Mahajan, Yash and Bansal, Naman and Blanco, Eduardo and Karmaker, Santu},
	title = {ALIGN-SIM: A Task-Free Test Bed for Evaluating and Interpreting Sentence Embeddings through Semantic Similarity Alignment},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Findings of EMNLP 2024},
	pages = {7393 – 7428},
	doi = {10.18653/v1/2024.findings-emnlp.436},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217622678&doi=10.18653%2fv1%2f2024.findings-emnlp.436&partnerID=40&md5=d71467fd51229e1601c44c4aa5da588f},
	affiliations = {Auburn University, United States; University of Arizona, United States; University of Central Florida, United States},
	abstract = {Sentence embeddings play a pivotal role in a wide range of NLP tasks, yet evaluating and interpreting these real-valued vectors remains an open challenge to date, especially in a task-free setting. To address this challenge, we introduce a novel task-free test bed for evaluating and interpreting sentence embeddings. Our test bed consists of five semantic similarity alignment criteria, namely, semantic distinction, synonym replacement, antonym replacement, paraphrasing without negation, and sentence jumbling. Using these criteria, we examined five classical (e.g., Sentence-BERT, Universal Sentence Encoder (USE), etc.) and eight LLM-induced sentence embedding techniques (e.g., LLaMA2, GPT-3, OLMo, etc.) to test whether their semantic similarity spaces align with what a human mind would naturally expect. Our extensive experiments with 13 different sentence encoders revealed that none of the studied embeddings aligned with all the five semantic similarity alignment criteria. Yet, most encoders performed highly on the SentEval dataset, a popular task-specific benchmark. This finding demonstrates a significant limitation of the current practice in sentence embedding evaluation and associated popular benchmarks, a critical issue that needs careful attention and reassessment by the NLP community. Finally, we conclude the paper by highlighting the utility of the proposed alignment-based test bed for analyzing sentence embeddings in a novel way, especially in a task-free setting. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Embeddings; Materials testing apparatus; Testbeds; Critical issues; Current practices; Embedding technique; Embeddings; Human mind; Novel task; Real valued vector; Semantic similarity; Similarity spaces; Test bed; Semantics},
	editor = {Al-Onaizan Y. and Bansal M. and Chen Y.-N.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176168-1},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Find. EMNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Papatheodosiou20242539,
	author = {Papatheodosiou, Persephone and Panagoulias, Dimitrios P. and Virvou, Maria and Tsihrintzis, George A. and Bonakis, Anastasios and Dikeos, Dimitrios},
	title = {Leveraging Artificial Intelligence for personalised insomnia-sleep calibration via the Big Five Personality Traits},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {2539 – 2548},
	doi = {10.1016/j.procs.2024.09.723},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213387349&doi=10.1016%2fj.procs.2024.09.723&partnerID=40&md5=7ff21c9205bdbb082eba2134b82adb4c},
	affiliations = {Sleep Research Unit, Department of Psychiatry, School of Medicine, National and Kapodistrian University of Athens, Athens, 12462, Greece; Department of Informatics, University of Piraeus, Address, Piraeus, 185 34, Greece; Second Department of Neurology, School of Medicine, National and Kapodistrian University of Athens, Athens, 12462, Greece},
	abstract = {This paper introduces Morpheas, an AI-empowered sleep evaluation and calibration system that leverages state-of-the-art technologies, like Large Language Models (LLMs) and Named Entity Recognition (NER). Morpheas integrates Sequential Language Model Integration (SLMI) workflows to simulate the initial steps of sleep disorder diagnosis, utilizing the GPT-4 engine enhanced with Rules of Conduct. Using SLMI and medical and psychological diagnostic tools, we propose a novel multi-step personalisation methodology for creating a gradation system for the improvement of patient-AI interactions. To test and showcase this personalisation approach, we simulate keeping a sleep diary for diagnosing insomnia using a trait-based personalised LLM aimed at addressing sleep concerns. For this purpose, we apply the Big Five Personality Traits (BFPT) where LLMs are again used to extract the responses and facilitate the patient throughout the process, providing guidance and explanation. We then extract the entities from these interactions with NER, in order to identify patterns, provide an explainability basis for patients and effectively customize Cognitive Behavioral Therapy for Insomnia (CBTi), whether through one-on-one sessions or via digital platforms. © 2024 The Authors.},
	author_keywords = {AI-empowered software engineering; BERT; GPT; Insomnia; Large Language Models; Personalisation; Sleep-therapy},
	keywords = {Artificial intelligence; Personalized medicine; AI-empowered software engineering; BERT; Big five; GPT; Insomnia; Language model; Large language model; Personality traits; Personalizations; Sleep-therapy; Sleep research},
	correspondence_address = {D.P. Panagoulias; Department of Informatics, University of Piraeus, Piraeus, Address, 185 34, Greece; email: panagoulias_d@yahoo.gr},
	editor = {Flearmoy J.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Voigt20241,
	author = {Voigt, Frederic and Calero, Jose Alcarez and Dahal, Keshav and Wang, Qi and Luck, Kai Von and Stelldinger, Peer},
	title = {Adapting Speech Models for Stock Price Prediction},
	year = {2024},
	journal = {ICCCMLA 2024 - 6th International Conference on Cybernetics, Cognition and Machine Learning Applications},
	pages = {1 – 8},
	doi = {10.1109/ICCCMLA63077.2024.10871633},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219524854&doi=10.1109%2fICCCMLA63077.2024.10871633&partnerID=40&md5=cddab65b7887ede425c0bc942f637911},
	affiliations = {University of the West of Scotland, United Kingdom; Hamburg University of Applied Sciences, Department of Computer Science, Hamburg, Germany; University of the West of Scotland, School of Computing, Engineering & Physical Sciences, Paisley, United Kingdom},
	abstract = {Large language models (LLMs) have demonstrated remarkable success in the field of natural language processing (NLP). Despite their origins in NLP, these algorithms possess the theoretical capability to process any data type represented in an NLP-like format. In this study, we use stock data to illustrate three methodologies for processing regression data with LLMs, employing tokenization and contextualized embeddings. By leveraging the well-known LLM algorithm Bidirectional Encoder Representations from Transformers (BERT) [1], we apply quantitative stock price prediction methodologies to predict stock prices and stock price movements, showcasing the versatility and potential of LLMs in financial data analysis.  © 2024 IEEE.},
	author_keywords = {finance; fintech; large language models; machine learning; natural language processing; quantitative stock price prediction; stock movement prediction},
	keywords = {Costs; Electronic trading; Financial markets; Fintech; Natural language processing systems; Language model; Language processing; Large language model; Machine-learning; Movement prediction; Natural language processing; Natural languages; Quantitative stock price prediction; Stock movement; Stock movement prediction; Stock price prediction; Prediction models},
	correspondence_address = {F. Voigt; University of the West of Scotland, United Kingdom; email: b01742821@studentmail.uws.ac.uk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833150579-0},
	language = {English},
	abbrev_source_title = {ICCCMLA - Int. Conf. Cybern., Cogn. Mach. Learn. Appl.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Krumov20241652,
	author = {Krumov, Kristiyan and Boytcheva, Svetla and Koytchev, Ivan},
	title = {SU-FMI at SemEval-2024 Task 5: From BERT Fine-Tuning to LLM Prompt Engineering - Approaches in Legal Argument Reasoning},
	year = {2024},
	journal = {SemEval 2024 - 18th International Workshop on Semantic Evaluation, Proceedings of the Workshop},
	pages = {1652 – 1658},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209566047&partnerID=40&md5=39907be468acf755bcc70f569e3b8d6a},
	affiliations = {FMI, Sofia University, Bulgaria; Ontotext, Bulgaria},
	abstract = {This paper presents our approach and findings for SemEval-2024 Task 5, focusing on legal argument reasoning. We explored the effectiveness of fine-tuning pre-trained BERT models and the innovative application of large language models (LLMs) through prompt engineering in the context of legal texts. Our methodology involved a combination of techniques to address the challenges posed by legal language processing, including handling long texts and optimizing natural language understanding (NLU) capabilities for the legal domain. Our contributions were validated by achieving a third-place ranking on the SemEval 2024 Task 5 Leaderboard. The results underscore the potential of LLMs and prompt engineering in enhancing legal reasoning tasks, offering insights into the evolving landscape of NLU technologies within the legal field. © 2024 Association for Computational Linguistics.},
	keywords = {Fine tuning; Language model; Language processing; Legal arguments; Legal domains; Legal reasoning; Legal texts; Natural language understanding; Reasoning tasks; Third places; Frequency standards},
	editor = {Ojha A.K. and Dohruoz A.S. and Madabushi H.T. and Da San Martino G. and Rosenthal S. and Rosa A.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176107-0},
	language = {English},
	abbrev_source_title = {SemEval - Int. Workshop Semantic Eval., Proc. Workshop},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{2024,
	title = {IAI4CH 2024 - Proceedings of the 3rd Workshop on Artificial Intelligence for Cultural Heritage, co-located with the 23rd International Conference of the Italian Association for Artificial Intelligence, AIxIA 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3865},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213708974&partnerID=40&md5=77724c8f72714ba8af197480368c1b16},
	abstract = {The proceedings contain 15 papers. The topics discussed include: new frontiers in digital libraries: the trajectory of digital humanities through a computational lens; how BERT speaks Shakespearean English? evaluating historical bias in masked language models; constructing a knowledge graph for Italian cinema divas’ autobiographies; transfer learning for renaissance illuminated manuscripts: starting a journey from classification to interpretation; saliency-driven 3D reconstruction and printing for accessible museums; using ontologies for LLM applications in cultural heritage; intelligent human-computer interaction in innovative ai solutions in travel and its impact on the e-society; digital augmented reality app for historic architecture; ontological representation of narrative places for cinema archives; and developing a comprehensive dataset for enhancing social inclusion and cohesion through citizen curation in cultural heritage.},
	editor = {Damiano R. and Ferilli S. and Striani M. and Striani M. and Silvello G. and de' Bianchi B.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mihir2024,
	author = {Mihir, T. Krishna and Harsha, K.Venkata Sai and Nitya, S.Yuva and Krishna, G. Bala and Anamalamudi, Satish and Sivarajan, Sruthi},
	title = {Machine Learning Approaches to Identify AI-Generated Text: a Comparative Analysis},
	year = {2024},
	journal = {Intelligent Computing and Emerging Communication Technologies, ICEC 2024},
	doi = {10.1109/ICEC59683.2024.10837481},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218048596&doi=10.1109%2fICEC59683.2024.10837481&partnerID=40&md5=136c3e572b9aacb9aaac6d702009649b},
	affiliations = {SRM University, Department of Cse, AP, Amaravati, India},
	abstract = {Large-scale language models (LLMs), such as the GPT-4 from OpenAI and the Pathways Language Model from Google, have become indispensable to our daily lives and work, frequently being used without our conscious knowledge. Though study indicates that even crowdsourcing professionals have trouble identifying human-generated content from AI-generated content, subtle defects in AI writing continue to make this tough to perform. Even though these models have many benefits and the potential to totally change the way people work and learn, they have also drawn a lot of attention due to their potential drawbacks. One notable use of LLMs that demonstrates their potential for task automation is the generation of academic reports or articles with little to no human input. As a result, scientists have concentrated on creating detectors to deal with possible wrongdoing related to information provided by LLM. However, current methods frequently ignore the vital component of generalizability in favor of accuracy on small datasets. Our study offers a thorough examination of machine learning (ML) techniques that are intended to differentiate text produced by artificial intelligence (AI) from language created by humans. We attempt to use a Kaggle dataset in order to gain greater insight into the data collection procedure. To address the challenge of accurately and reliably detecting text produced by artificial intelligence (AI), we explore various machine learning approaches. We examine a broad spectrum of algorithms taking into account performance measures and their generalizability to different datasets and scenarios. By providing a more thorough explanation of the significance of LLMs, the challenges they provide, and the specific focus of our study, we broaden the abstract and lay the foundation for a thorough analysis of ML algorithms for text identification.  © 2024 IEEE.},
	author_keywords = {Academic Dishonesty; BERT; Contextual Encoding; Fake content detection; Paraphrasing Attacks},
	keywords = {Contrastive Learning; Crowdsourcing; Machine learning; Academic dishonesty; BERT; Content detection; Contextual encoding; Encodings; Fake content detection; Language model; Large-scales; Machine learning approaches; Paraphrasing attack; Adversarial machine learning},
	correspondence_address = {T.K. Mihir; SRM University, Department of Cse, Amaravati, AP, India; email: krishnamihir_t@srmap.edu.in},
	editor = {Mishra S.K. and Dash J.K. and Enduri M.K. and Manikandan V.M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833150843-2},
	language = {English},
	abbrev_source_title = {Intell. Comput. Emerg. Commun. Technol., ICEC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sheikhi202438,
	author = {Sheikhi, Saeid and Kostakos, Panos and Pirttikangas, Susanna},
	title = {Effective Anomaly Detection in 5G Networks via Transformer-Based Models and Contrastive Learning},
	year = {2024},
	journal = {Proceedings of the 8th Cyber Security in Networking Conference: AI for Cybersecurity, CSNet 2024},
	pages = {38 – 43},
	doi = {10.1109/CSNet64211.2024.10851755},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218340516&doi=10.1109%2fCSNet64211.2024.10851755&partnerID=40&md5=3699e9f7efef07c030fb5d3acfdbbb53},
	affiliations = {University of Oulu, Center for Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, Oulu, 90014, Finland},
	abstract = {In this paper, we present a novel approach to anomaly detection in 5G networks using contrastive learning and transformer-based models. Leveraging the power of self-supervision mechanisms, we aim to enhance the detection of anomalous network activities that can compromise the secu-rity and reliability of 5G networks. The methodology involves the use of pretrained transformer models (DistilBERT, BERT, RoBERTa, and ALBERT) as encoders, followed by a projection layer to reduce the dimensionality of the embeddings. We employ a contrastive learning objective to train the models, encouraging the separation of normal and anomalous data points. The trained models are evaluated on a custom 5G testbed dataset, which simulates various normal operations and attack scenarios. Our experimental results demonstrate that DistilBERT, RoBERTa, and ALBERT achieve high accuracy, precision, recall, and Fl-score, significantly outperforming BERT. We provide a comprehensive visualization analysis of each model's performance to illustrate their effectiveness. The findings underscore the effectiveness of contrastive learning combined with transformer-based architectures in achieving robust anomaly detection in 5G networks, offering valuable insights for future research and practical implementations in enhancing network security.  © 2024 IEEE.},
	author_keywords = {5G security; Anomaly Detection; Cybersecurity; LLM; Transformer Models},
	keywords = {5G mobile communication systems; Queueing networks; 5g security; Anomaly detection; Cyber security; Embeddings; Learning objectives; LLM; Network activities; Power; Supervision mechanisms; Transformer modeling; Contrastive Learning},
	editor = {Ganascia J.-G. and Pujolle G. and Noura H. and Salman O. and Hariss K. and El Husseini F. and El Madhoun N.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833153410-3},
	language = {English},
	abbrev_source_title = {Proc. Cyber Secur. Netw. Conf.: AI Cybersecur., CSNet},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bedwa2024,
	author = {Bedwa, Mukul and Hooda, Nishtha and Kumar, Vikram},
	title = {Comparative Performance Analysis of Large Language Models for Deployment in Women's Healthcare Mobile Applications},
	year = {2024},
	journal = {Proceedings of the 2024 3rd Edition of IEEE Delhi Section Flagship Conference, DELCON 2024},
	doi = {10.1109/DELCON64804.2024.10867016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219474855&doi=10.1109%2fDELCON64804.2024.10867016&partnerID=40&md5=0746f8efd06ca9b3682388558e5a34e3},
	affiliations = {School of Computing, Indian Institute of Information Technology, Una, India},
	abstract = {Large Language Models (LLMs) have sparked considerable interest among researchers across diverse disciplines considering their remarkable text generation and processing capabilities. Their capabilities have the potential to promise better health awareness among female users when integrated with women-specific chatbot services. Therefore, this study aims to compare the LLM models BERT, DistilBERT, Roberta, DialoGPT, TinyLLAMA, and GPT-2 by fine-tuning them on a health-specific dataset and evaluating their efficiency in generating information and engaging responses. Our analysis suggests that text-generation models are well-positioned to deliver more engaging answers and may prove instrumental in effectively enhancing health awareness among women.  © 2024 IEEE.},
	author_keywords = {AI in Health care; Domain-Specific Chatbots; Fine-tuning; Large Language Models; Natural Language Processing},
	keywords = {Electronic health record; mHealth; AI in health care; Chatbots; Domain specific; Domain-specific chatbot; Fine tuning; Language model; Language processing; Large language model; Natural language processing; Natural languages; Natural language processing systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151859-2},
	language = {English},
	abbrev_source_title = {Proc. Ed. IEEE Delhi Sect. Flagship Conf., DELCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Preiksaitis2024,
	author = {Preiksaitis, Carl and Ashenburg, Nicholas and Bunney, Gabrielle and Chu, Andrew and Kabeer, Rana and Riley, Fran and Ribeira, Ryan and Rose, Christian},
	title = {The Role of Large Language Models in Transforming Emergency Medicine: Scoping Review},
	year = {2024},
	journal = {JMIR Medical Informatics},
	volume = {12},
	doi = {10.2196/53787},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000299843&doi=10.2196%2f53787&partnerID=40&md5=5c3645ec714a53dfe89fefabb477ba3a},
	affiliations = {Department of Emergency Medicine, Stanford University School of Medicine, Palo Alto, CA, United States},
	abstract = {Background: Artificial intelligence (AI), more specifically large language models (LLMs), holds significant potential in revolutionizing emergency care delivery by optimizing clinical workflows and enhancing the quality of decision-making. Although enthusiasm for integrating LLMs into emergency medicine (EM) is growing, the existing literature is characterized by a disparate collection of individual studies, conceptual analyses, and preliminary implementations. Given these complexities and gaps in understanding, a cohesive framework is needed to comprehend the existing body of knowledge on the application of LLMs in EM. Objective: Given the absence of a comprehensive framework for exploring the roles of LLMs in EM, this scoping review aims to systematically map the existing literature on LLMs’ potential applications within EM and identify directions for future research. Addressing this gap will allow for informed advancements in the field. Methods: Using PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) criteria, we searched Ovid MEDLINE, Embase, Web of Science, and Google Scholar for papers published between January 2018 and August 2023 that discussed LLMs’ use in EM. We excluded other forms of AI. A total of 1994 unique titles and abstracts were screened, and each full-text paper was independently reviewed by 2 authors. Data were abstracted independently, and 5 authors performed a collaborative quantitative and qualitative synthesis of the data. Results: A total of 43 papers were included. Studies were predominantly from 2022 to 2023 and conducted in the United States and China. We uncovered four major themes: (1) clinical decision-making and support was highlighted as a pivotal area, with LLMs playing a substantial role in enhancing patient care, notably through their application in real-time triage, allowing early recognition of patient urgency; (2) efficiency, workflow, and information management demonstrated the capacity of LLMs to significantly boost operational efficiency, particularly through the automation of patient record synthesis, which could reduce administrative burden and enhance patient-centric care; (3) risks, ethics, and transparency were identified as areas of concern, especially regarding the reliability of LLMs’ outputs, and specific studies highlighted the challenges of ensuring unbiased decision-making amidst potentially flawed training data sets, stressing the importance of thorough validation and ethical oversight; and (4) education and communication possibilities included LLMs’ capacity to enrich medical training, such as through using simulated patient interactions that enhance communication skills. Conclusions: LLMs have the potential to fundamentally transform EM, enhancing clinical decision-making, optimizing workflows, and improving patient outcomes. This review sets the stage for future advancements by identifying key research areas: prospective validation of LLM applications, establishing standards for responsible use, understanding provider and patient perceptions, and improving physicians’ AI literacy. Effective integration of LLMs into EM will require collaborative efforts and thorough evaluation to ensure these technologies can be safely and effectively applied. © Carl Preiksaitis, Nicholas Ashenburg, Gabrielle Bunney, Andrew Chu, Rana Kabeer, Fran Riley, Ryan Ribeira, Christian Rose.},
	author_keywords = {AI; AI literacy; artificial intelligence; Bard; BERT; Bidirectional Encoder Representations from Transformers; ChatGPT; China; clinical decision support; communication; decision support; education; emergency care; emergency medicine; ethics; generative pretrained transformer; GPT; health literacy; large language model; LLM; Med-PaLM; medical education; medical training; natural language processing; NLP; Pathways Language Model; physician; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; PRISMA; risk; scoping review; United States; US; workflow efficiency; workflow efficiency},
	correspondence_address = {C. Preiksaitis; Department of Emergency Medicine, Stanford University School of Medicine, Palo Alto, 900 Welch Road Suite 350, 94304, United States; email: cpreiksaitis@stanford.edu},
	publisher = {JMIR Publications Inc.},
	issn = {22919694},
	language = {English},
	abbrev_source_title = {JMIR Med. Inform.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Abbas2024,
	author = {Abbas, Asim and Lee, Mark and Shanavas, Niloofer and Kovatchev, Venelin},
	title = {Clinical concept annotation with contextual word embedding in active transfer learning environment},
	year = {2024},
	journal = {Digital Health},
	volume = {10},
	doi = {10.1177/20552076241308987},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212926527&doi=10.1177%2f20552076241308987&partnerID=40&md5=51e3a8b9a3d52b1bdfa198dbc82d21d6},
	affiliations = {School of Computer Science, University of Birmingham, Birmingham, United Kingdom; School of Computer Science, University of Birmingham, Abu Dhabi, United Kingdom},
	abstract = {Objective: The study aims to present an active learning approach that automatically extracts clinical concepts from unstructured data and classifies them into explicit categories such as Problem, Treatment, and Test while preserving high precision and recall and demonstrating the approach through experiments using i2b2 public datasets. Methods: Initially labeled data are acquired from a lexical-based approach in sufficient amounts to perform an active learning process. A contextual word embedding similarity approach is adopted using BERT base variant models such as ClinicalBERT, DistilBERT, and SCIBERT to automatically classify the unlabeled clinical concept into explicit categories. Additionally, deep learning and large language model (LLM) are trained on acquiring label data through active learning. Results: Using i2b2 datasets (426 clinical notes), the lexical-based method achieved precision, recall, and F1-scores of 76%, 70%, and 73%. SCIBERT excelled in active transfer learning, yielding precision of 70.84%, recall of 77.40%, F1-score of 73.97%, and accuracy of 69.30%, surpassing counterpart models. Among deep learning models, convolutional neural networks (CNNs) trained with embeddings (BERTBase, DistilBERT, SCIBERT, ClinicalBERT) achieved training accuracies of 92–95% and testing accuracies of 89–93%. These results were higher compared to other deep learning models. Additionally, we individually evaluated these LLMs; among them, ClinicalBERT achieved the highest performance, with a training accuracy of 98.4% and a testing accuracy of 96%, outperforming the others. Conclusions: The proposed methodology enhances clinical concept extraction by integrating active learning and models like SCIBERT and CNN. It improves annotation efficiency while maintaining high accuracy, showcasing potential for clinical applications. © The Author(s) 2024.},
	author_keywords = {active transfer learning; clinical concept annotation; Clinical concept extraction; contextual word embedding; information extraction; large language models},
	keywords = {adult; article; controlled study; convolutional neural network; deep learning; diagnosis; diagnostic test accuracy study; human; large language model; learning environment; male; transfer of learning},
	correspondence_address = {A. Abbas; School of Computer Science, University of Birmingham, Birmingham, Edgbaston Campus, B15 2TT, United Kingdom; email: axa2233@student.bham.ac.uk},
	publisher = {SAGE Publications Inc.},
	issn = {20552076},
	language = {English},
	abbrev_source_title = {Digit. Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Matisons2024,
	author = {Matisons, Ralfs and Pirta, Ruta and Grabis, Janis},
	title = {A short-dive into transformer based language models: A literature review},
	year = {2024},
	journal = {ITMS - International Scientific Conference on Information Technology and Management Science of Riga Technical University},
	number = {2024},
	doi = {10.1109/ITMS64072.2024.10741950},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214427046&doi=10.1109%2fITMS64072.2024.10741950&partnerID=40&md5=afacebca00e245805c6c82738f0a82b0},
	affiliations = {Information Technology Institute, Riga Technical University, Riga, Latvia},
	abstract = {In today's era of the interconnected world, a large number of textual data is generated each second. This textual information includes a description of things, such as, product reviews, which are shared on platforms, such as, 'Facebook' or 'X'. Natural language processing or NLP is the application of machine learning and other computational techniques to better understand the text and how to represent the text. This paper focuses on the analysis of currently available LLMs, their architecture, and key differences. During the literature review, three models have been chosen, BERT, GPT and T5, since all three models offer key innovations in LLM architecture. © 2024 IEEE.},
	author_keywords = {BERT; GPT; LLM; T5; Transformer based Large Language Models},
	keywords = {Computational linguistics; Computer simulation languages; Modeling languages; Natural language processing systems; Program processors; BERT; GPT; Language model; Literature reviews; LLM; T5; Textual data; Textual information; Three models; Transformer based large language model; Economic and social effects},
	editor = {Grabis J. and Romanovs A. and Narigina M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {27716953},
	isbn = {979-833153383-0},
	language = {English},
	abbrev_source_title = {ITMS - Int. Sci. Conf. Inf. Technol. Manag. Sci. Riga Tech. Univ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Panagoulias20241181,
	author = {Panagoulias, Dimitrios P. and Virvou, Maria and Tsihrintzis, George A.},
	title = {Knowledge Space reduction via Sequential Language Model Integration},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {1181 – 1190},
	doi = {10.1016/j.procs.2024.09.544},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213296767&doi=10.1016%2fj.procs.2024.09.544&partnerID=40&md5=c9881d40337ea461979e574306a64776},
	affiliations = {Department of Informatics, University of Piraeus, Address, Piraeus, 185 34, Greece},
	abstract = {In Large Language Models (LLMs), such as GPT, BERT, Mistral or others, “reducing the domain space” for text generation involves limiting the range of content that can be utilized for generating responses. This approach aims at enhancing the relevance and precision of the text produced. While various strategies exist to achieve this, this work explores Sequential Language Model Integration (SLMI), which mirrors the organization and distribution of knowledge across different fields of expertise. More specifically, SLMI is the technique of linking multiple LLMs (LLM-Chains) in a systematic manner. In this paper, we refer to a process of choosing, linking and connecting LLMs with other services (often to complete a generative task, invoke external functions and machine learning services, or tackle problems) as “Large Language Models as a Service”. We outline the development and evaluation process of an SLMI methodology to refine response accuracy. Focusing on the medical field, we also establish a framework for knowledge reduction based on “knowledge paths”, analogous to the distinct specializations within medicine. We apply this framework to a dermatology case study and utilize our evaluation pipeline to assess the results. Reducing the knowledge domain from medicine in general down to dermatology, we tested our methodology and found gains regarding accuracy and diagnostic improvement, as well as a reduction in costs regarding total tokens generated. © 2024 The Authors.},
	author_keywords = {AI-empowered software engineering; BERT; GPT; Large Language Models},
	keywords = {Artificial intelligence; Problem oriented languages; Report generators; AI-empowered software engineering; BERT; GPT; Knowledge spaces; Language model; Large language model; Models integration; Sequential languages; Space reductions; Text generations; Dermatology},
	correspondence_address = {D.P. Panagoulias; Department of Informatics, University of Piraeus, Piraeus, Address, 185 34, Greece; email: panagouliasd@yahoo.gr},
	editor = {Flearmoy J.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{He2024132,
	author = {He, Minghua and Jia, Tong and Duan, Chiming and Cai, Huaqian and Li, Ying and Huang, Gang},
	title = {LLMeLog: An Approach for Anomaly Detection based on LLM-enriched Log Events},
	year = {2024},
	journal = {Proceedings - International Symposium on Software Reliability Engineering, ISSRE},
	pages = {132 – 143},
	doi = {10.1109/ISSRE62328.2024.00023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214585296&doi=10.1109%2fISSRE62328.2024.00023&partnerID=40&md5=f4edf6c442a51cf80eb5fee0718eb386},
	affiliations = {Peking University, School of Software and Microelectronics, Beijing, China; Peking University, Institute for Artificial Intelligence, Beijing, China; Peking University, School of Computer Science, Beijing, China; Peking University, National Engineering Research Center for Software Engineering, Beijing, China},
	abstract = {Log-based anomaly detection is an essential task in maintaining software reliability. Existing log-based anomaly detection approaches often consist of three key phases: log parsing, event embedding, and model construction. Event embedding efficiently extracts semantic information from log events and produces vector representations of log events. However, existing event embedding methods suffer from two key problems. First, semantic noises are buried in log events leading to inevitable gaps between the obtained semantics from log events and their essential meanings. Second, there exists a gap between general semantic embedding and the specific embedding requirement of anomaly detection tasks. To mitigate these problems and improve the quality of representations of log events, we propose a novel anomaly detection approach named LLMeLog. It leverages the capabilities of large language models (LLMs) to enrich the contents of log events with in-context learning techniques. Then it utilizes the enriched log events to fine-Tune a pre-Trained BERT model. At last, it trains a transformer-based anomaly detection model with the event representations produced by the pre-Trained BERT model. Evaluation results on three public log datasets show that LLMeLog achieves the best performance across all datasets, boasting F1-scores exceeding 99%. Besides, when using only 10% of labeled data as training data, our approach can still achieve over 90% F1-scores. © 2024 IEEE.},
	author_keywords = {Anomaly Detection; Large Language Models; Log Analysis},
	keywords = {Anomaly detection; Embeddings; Labeled data; Anomaly detection; Detection approach; Embeddings; F1 scores; Language model; Large language model; Log analysis; Model construction; Semantics Information; Software-Reliability; Semantics},
	correspondence_address = {T. Jia; Peking University, Institute for Artificial Intelligence, Beijing, China; email: jia.tong@pku.edu.cn; Y. Li; Peking University, National Engineering Research Center for Software Engineering, Beijing, China; email: li.ying@pku.edu.cn},
	publisher = {IEEE Computer Society},
	issn = {10719458},
	isbn = {979-835035388-4},
	coden = {PSSRF},
	language = {English},
	abbrev_source_title = {Proc. Int. Symp. Softw. Reliab. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Oad2024164491,
	author = {Oad, Ammar and Hamza Farooq, Muhammad and Zafar, Amna and Ayesha Akram, Beenish and Zhou, Ruogu and Dong, Feng},
	title = {Fake News Classification Methodology With Enhanced BERT},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {164491 – 164502},
	doi = {10.1109/ACCESS.2024.3491376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208734881&doi=10.1109%2fACCESS.2024.3491376&partnerID=40&md5=1d47ea0e71f4c9ca2793ac9788cff220},
	affiliations = {Shaoyang University, Faculty Of Information Engineering, Shaoyang, 422000, China; KICS, University Of Engineering And Technology Lahore (UET Lahore), National Center Of Artificial Intelligence, Lahore, 54890, Pakistan; University Of Engineering And Technology Lahore, Department Of Computer Science, Lahore, 54890, Pakistan; University Of Engineering And Technology, Department Of Computer Engineering, Lahore, 54890, Pakistan; Hunan Vocational College Of Commerce, Changsha, 410205, China},
	abstract = {News serves as a vital source of information for staying updated on various aspects of life worldwide. However, massive volume of information available on social media platforms makes it challenging to extract meaningful insights. Additionally, dispersion of false information has grown broader, often serving specific agendas. In this work, we present a novel fake news classification methodology based on an enhanced BERT deep learning model which is trained on self-developed PolitiTweet datasets along with benchmarked Buzzfeed dataset. The PolitiTweet dataset is augmented to solve class imbalance problem and improve data diversity to capture regional language nuances, cultural references that help in more accurate detection of fake news. For this purpose, We enhance BERTbase model by adding 3 additional layers namely Linear Layer, Dropout Layer, Activation Layer and fine tuned the model to train enhanced BERT classifier. The fine tuned BERT model trained on augmented dataset is capable of capturing patterns and nuances within the data, giving better classification results. Subsequently, the enhanced BERT model is evaluated against BERTbase model for further elaboration on the generalisibility and effective performance of the fine tuned model for real-world cases. The enhanced BERT model achieved an accuracy of 85% on Buzzfeed and 98% on PolitiTweet. In comparison the baseline BERT models achieved an average accuracy of 81% and 88%, respectively. The proposed Enhanced BERT model uses a mix of pre-training strategies with fine-tuning techniques to achieve better performance. The developed research data is available online at: https://www.kaggle.com/datasets/ameerhamza123/pak-tweets.  © 2013 IEEE.},
	author_keywords = {Bidirectional encoder representations from transformers (BERT); deep learning (DL); fake news classification; gradient boosting classifier; large language model (LLM); machine learning (ML); natural language processing; transformers},
	keywords = {Adversarial machine learning; Classification (of information); Contrastive Learning; Distribution transformers; Economic and social effects; Natural language processing systems; Tweets; Bidirectional encoder representation from transformer; Boosting classifiers; Deep learning; Fake news classification; Gradient boosting; Gradient boosting classifier; Language model; Language processing; Large language model; Machine learning; Machine-learning; Natural language processing; Natural languages; Transformer; Deep learning},
	correspondence_address = {A. Oad; Shaoyang University, Faculty Of Information Engineering, Shaoyang, 422000, China; email: ammar.oad@hnsyu.edu.cn; R. Zhou; Hunan Vocational College Of Commerce, Changsha, 410205, China; email: zruogu@outlook.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Saha2024185401,
	author = {Saha, Binita and Saha, Utsha and Malik, Muhammad Zubair},
	title = {QuIM-RAG: Advancing Retrieval-Augmented Generation With Inverted Question Matching for Enhanced QA Performance},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {185401 – 185410},
	doi = {10.1109/ACCESS.2024.3513155},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212041668&doi=10.1109%2fACCESS.2024.3513155&partnerID=40&md5=2787b32bb282e6b32a106bed4253d074},
	affiliations = {North Dakota State University, Fargo, 58108, ND, United States},
	abstract = {This work presents a novel architecture for building Retrieval-Augmented Generation (RAG) systems to improve Question Answering (QA) tasks from a target corpus. Large Language Models (LLMs) have revolutionized the analyzing and generation of human-like text. These models rely on pre-trained data and lack real-time updates unless integrated with live data tools. RAG enhances LLMs by integrating online resources and databases to generate contextually appropriate responses. However, traditional RAG still encounters challenges like information dilution and hallucinations when handling vast amounts of data. Our approach addresses these challenges by converting corpora into a domain-specific dataset and RAG architecture is constructed to generate responses from the target document. We introduce QuIM-RAG (Question-to-question Inverted Index Matching), a novel approach for the retrieval mechanism in our system. This strategy generates potential questions from document chunks and matches these with user queries to identify the most relevant text chunks for generating accurate answers. We have implemented our RAG system on top of the open-source Meta-LLaMA3-8B-instruct model by Meta Inc. that is available on Hugging Face. We constructed a custom corpus of 500+ pages from a high-traffic website accessed thousands of times daily for answering complex questions, along with manually prepared ground truth QA for evaluation. We compared our approach with traditional RAG models using BERT-Score and RAGAS, state-of-the-art metrics for evaluating LLM applications. Our evaluation demonstrates that our approach outperforms traditional RAG architectures on both metrics.  © 2013 IEEE.},
	author_keywords = {ChatGPT; GPT-3.5-turbo; hallucination mitigation; information dilution; Large language models (LLMs); Meta-LLaMA3-8B-instruct; question answering (QA); retrieval-augmented generation (RAG)},
	keywords = {Large datasets; Metadata; Network security; Online searching; Structured Query Language; Domain specific; Domain-specific dataset; GPT-3.5-turbo; Hallucination; Information dilution; Language model; Large language model; Meta-LLaMA3-8b-instruct; Question-answer pairs; Retrieval-augmented generation; Question answering},
	correspondence_address = {B. Saha; North Dakota State University, Fargo, 58108, United States; email: binita.saha@ndsu.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Qiu2024,
	author = {Qiu, Yunjian and Jin, Yan},
	title = {ChatGPT and finetuned BERT: A comparative study for developing intelligent design support systems},
	year = {2024},
	journal = {Intelligent Systems with Applications},
	volume = {21},
	doi = {10.1016/j.iswa.2023.200308},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179389129&doi=10.1016%2fj.iswa.2023.200308&partnerID=40&md5=b622d52159c7dd3f26869950501a113e},
	affiliations = {Department of Aerospace & Mechanical Engineering, University of Southern California, Los Angeles, 90089, CA, United States},
	abstract = {Large Language Models (LLMs), like ChatGPT, have sparked considerable interest among researchers across diverse disciplines owing to their remarkable text processing and generation capabilities. While ChatGPT is typically employed for tasks involving general knowledge, researchers increasingly explore the potential of this LLM-based tool in specific domains to enhance productivity. This study aims to compare the performance of a finetuned BERT model with that of ChatGPT on a domain-specific dataset in the context of developing an intelligent design support system. Through experiments conducted on classification and generation tasks, the knowledge transfer and elicitation abilities of ChatGPT are examined and contrasted with those of the finetuned BERT model. The findings indicate that ChatGPT exhibits comparable performance to the finetuned BERT model in sentence-level classification tasks but struggles with short sequences. However, ChatGPT's classification performance significantly improves when a few-shot setting is applied. Moreover, it can filter out unrelated data and enhance dataset quality by assimilating the underlying domain knowledge. Regarding content generation, ChatGPT with a zero-shot setting produces informative and readable output for domain-specific questions, albeit with an excessive amount of unrelated information, which can burden readers. In conclusion, ChatGPT demonstrates a promising potential for application in facilitating data labeling, knowledge transfer, and knowledge elicitation tasks. With minimal guidance, ChatGPT can substantially enhance the efficiency of domain experts in accomplishing their objectives. The findings suggest a nuanced integration of artificial intelligence (AI) with human expertise, bridging the gap from mere classification models to sophisticated human-analogous text generation systems. This signals a future in AI-augmented engineering design where the robust capabilities of AI technologies integrate with human creativity and innovation, creating a dynamic interactions to redefine how we tackle design challenges. © 2023 The Authors},
	author_keywords = {Knowledge elicitation; Knowledge transferring; Language model; Text classification; Text generation},
	keywords = {Classification (of information); Computational linguistics; Domain Knowledge; Knowledge management; Zero-shot learning; Comparatives studies; Design support systems; Domain specific; Intelligent designs; Knowledge transfer; Knowledge transferring; Language model; Performance; Text classification; Text generations; Text processing},
	correspondence_address = {Y. Jin; Department of Aerospace & Mechanical Engineering, University of Southern California, Los Angeles, 90089, United States; email: yjin@usc.edu},
	publisher = {Elsevier B.V.},
	issn = {26673053},
	language = {English},
	abbrev_source_title = {Intell. Syst. Applications.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Gold Open Access}
}

@CONFERENCE{Choaib20242516,
	author = {Choaib, Mohammad and Garouani, Moncef and Bouneffa, Mourad and Mohanna, Yasser},
	title = {IoT Sensor Selection in Cyber-Physical Systems: Leveraging Large Language Models as Recommender Systems},
	year = {2024},
	journal = {10th 2024 International Conference on Control, Decision and Information Technologies, CoDIT 2024},
	pages = {2516 – 2519},
	doi = {10.1109/CoDIT62066.2024.10708357},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208248054&doi=10.1109%2fCoDIT62066.2024.10708357&partnerID=40&md5=42ef666ee326a944f6e72cefe61fdc8f},
	affiliations = {Univ. Littoral Côte d'Opale, Lisic, Calais, France; Department of Electronics and Physics, Hadat, Lebanon; Université Toulouse Capitole, Irit, Umr 5505 Cnrs, UT1, Toulouse, France},
	abstract = {The emergence of Industry 4.0 has led a significant shift towards the widespread integration of Cyber Physical Systems(CPSs) across diverse industrial domains. Yet, the intricate design and implementation of these systems necessitate adept knowledge and expertise, posing challenges for researchers and engineers. In response, this paper introduces IoT-AID, a Cyber Physical Recommendation System aimed at alleviating these challenges. Leveraging the capabilities of large language models (LLMs) as decision support systems, IoT-AID relies on state-of-the-art techniques such as BERT and Sentence Transformers for semantic understanding and context-aware recommendations. Through a comprehensive exploration and evaluation, this study sheds light on the efficacy and potential of LLM-driven recommendation systems within the realm of CPSs, offering insights crucial for navigating the complexities of Industry 4.0 integration. © 2024 IEEE.},
	keywords = {Decentralized systems; Decision support systems; Distribution transformers; Cybe-physical systems; Cyber physicals; Cyber-physical systems; Decision supports; Design and implementations; Language model; On state; Sensor selection; State-of-the-art techniques; Support systems; Semantics},
	correspondence_address = {M. Choaib; Univ. Littoral Côte d'Opale, Lisic, Calais, France; email: mohammad.choaib@etu.univ-littoral.fr},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037397-4},
	language = {English},
	abbrev_source_title = {Int. Conf. Control, Decis. Inf. Technol., CoDIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hagen20244283,
	author = {Hagen, Tim and Scells, Harrisen and Potthast, Martin},
	title = {Revisiting Query Variation Robustness of Transformer Models},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Findings of EMNLP 2024},
	pages = {4283 – 4296},
	doi = {10.18653/v1/2024.findings-emnlp.248},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217619304&doi=10.18653%2fv1%2f2024.findings-emnlp.248&partnerID=40&md5=b5064bf320492ce923752a66002d4f3a},
	affiliations = {University of Kassel, hessian.AI, Germany; ScaDS.AI},
	abstract = {The most commonly used transformers for retrieval at present, BERT and T5, have been shown not to be robust to query variations such as typos or paraphrases. Although this is an important prerequisite for their practicality, this problem has hardly been investigated. More recent large language models (LLMs), including instruction-tuned LLMs, have not been analyzed yet, and only one study looks beyond typos. We close this gap by reproducing this study and extending it with a systematic analysis of more recent models, including Sentence-BERT, CharacterBERT, E5-Mistral, AnglE, and Ada v2. We further investigate if instruct-LLMs can be prompted for robustness. Our results are mixed in that the previously observed robustness issues for cross-encoders also apply to bi-encoders that use much larger LLMs, albeit to a lesser extent. While further LLM scaling may improve their embeddings, their cost-effective use for all but large deployments is limited. Training data that includes query variations allows LLMs to be fine-tuned for more robustness, but focusing on a single category of query variation may even degrade the effectiveness on others. © 2024 Association for Computational Linguistics.},
	keywords = {Ada (programming language); Encoding (symbols); Problem oriented languages; Query languages; Query processing; Structured Query Language; Cost effective; Embeddings; Language model; Robustness issues; Scalings; Systematic analysis; Training data; Transformer modeling; Computational linguistics},
	editor = {Al-Onaizan Y. and Bansal M. and Chen Y.-N.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176168-1},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Find. EMNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Laato2024662,
	author = {Laato, Joonatan and Kanerva, Jenna and Loehr, John and Lummaa, Virpi and Ginter, Filip},
	title = {Extracting Social Connections from Finnish Karelian Refugee Interviews Using LLMs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3834},
	pages = {662 – 680},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210826583&partnerID=40&md5=9e03f02690522bd4c15398d7ca524479},
	affiliations = {TurkuNLP, Department of Computing, University of Turku, Finland; Lammi Biological Station, Faculty of Biological and Environmental Sciences, University of Helsinki, Finland; Department of Biology, University of Turku, Finland},
	abstract = {We performed a zero-shot information extraction study on a historical collection of 89,339 brief Finnish-language interviews of refugee families relocated post-WWII from Finnish Eastern Karelia. Our research objective is two-fold. First, we aim to extract social organizations and hobbies from the free text of the interviews, separately for each family member. These can act as a proxy variable indicating the degree of social integration of refugees in their new environment. Second, we aim to evaluate several alternative ways to approach this task, comparing a number of generative models and a supervised learning approach, to gain a broader insight into the relative merits of these different approaches and their applicability in similar studies. We find that the best generative model (GPT-4) is roughly on par with human performance, at an F-score of 88.8%. Interestingly, the best open generative model (Llama-3-70B-Instruct) reaches almost the same performance, at 87.7% F-score, demonstrating that open models are becoming a viable alternative for some practical tasks even on non-English data. Additionally, we test a supervised learning alternative, where we fine-tune a Finnish BERT model (FinBERT) using GPT-4 generated training data. By this method, we achieved an F-score of 84.1% already with 6K interviews up to an F-score of 86.3% with 30k interviews. Such an approach would be particularly appealing in cases where the computational resources are limited, or there is a substantial mass of data to process. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Finnish; information extraction; Karelian refugees; LLM; zero-shot extraction},
	keywords = {Contrastive Learning; Data assimilation; Economic and social effects; Generative adversarial networks; Metadata; Supervised learning; F-score; Finnish; Generative model; Information extraction; Karelian refugee; LLM; Research objectives; Social connection; Social organizations; Zero-shot extraction; Zero-shot learning},
	editor = {Haverals W. and Koolen M. and Thompson L. and Koolen M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen20241186,
	author = {Chen, Xiaoyu and Du, Shuxin and Qiu, Yi},
	title = {Continuous Pre-training of TAPAS Model with E-commerce Structured Data},
	year = {2024},
	journal = {Proceedings of 2024 IEEE 4th International Conference on Information Technology, Big Data and Artificial Intelligence, ICIBA 2024},
	pages = {1186 – 1189},
	doi = {10.1109/ICIBA62489.2024.10868941},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219107706&doi=10.1109%2fICIBA62489.2024.10868941&partnerID=40&md5=6a27d45a004d706b15d9485b946d61b5},
	affiliations = {Huzhou University, School of Engineering, Zhejiang, China; Huzhou Key Laboratory of Intelligent Sensing and Optimal Control for Industrial Systems, Zhejiang, China},
	abstract = {Currently, large models perform extremely well in natural language processing (NLP). Pre-trained large-scale language models (such as GPT-4, BERT, T5, etc.) have achieved significant performance improvements in a variety of NLP tasks. However, applying these models to specific domains still faces significant challenges, such as lack of domain-specific knowledge and insufficient adaptation to domain-specific structured data. In this article, we take the e-commerce field as an example, clean and convert various collected e-commerce structured data into specific formats, and conduct continuous pre-training of the TAPAS model. During the pre-training process, parameters are gradually adjusted through backpropagation to minimize the loss function to improve the accuracy of the model. By comparing various indicators with other models. Experimental results show that the TAPAS model after continuous pre-training shows better performance in processing structured data tasks in the e-commerce field, significantly improving its accuracy in tasks such as question answering and information extraction in this field. © 2024 IEEE.},
	author_keywords = {indicators; llm; loss function; specific fields},
	keywords = {Marketplaces; E- commerces; Language processing; Large models; Llm; Loss functions; Natural languages; Performance; Pre-training; Specific field; Structured data; Data accuracy},
	correspondence_address = {S. Du; Huzhou University, School of Engineering, Zhejiang, China; email: shxdu@zjhu.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036358-6},
	language = {English},
	abbrev_source_title = {Proc. IEEE Int. Conf. Inf. Technol., Big Data Artif. Intell., ICIBA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yan2024404,
	author = {Yan, Jin},
	title = {Large Language Model (LLM) Text Generation Detection: A BERT-BiLSTM Approach with Attention Mechanisms},
	year = {2024},
	journal = {2024 4th International Conference on Electronic Information Engineering and Computer Technology, EIECT 2024},
	pages = {404 – 407},
	doi = {10.1109/EIECT64462.2024.10866488},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219568071&doi=10.1109%2fEIECT64462.2024.10866488&partnerID=40&md5=2a04261a2dd501502c57e16b4ccd18de},
	affiliations = {School of Computer Science and Engineering, Macau University of Science and Technology, 999078, Macao},
	abstract = {With the enhancement of Large Language Models (LLMs) performance, the demand for reliable methods to distinguish AI-generated text from human-written content is steadily growing. This study presents a novel detection framework based on a hybrid architecture integrating BERT, BiLSTM, and Talking-Heads Attention mechanisms. By leveraging BERT's contextual embedding capabilities, BiLSTM's sequential dependency capture, and an enhanced attention layer, the proposed model achieves significant improvements in classification accuracy and robustness. Experiments conducted on the GPT Reddit Dataset (GRiD) demonstrate the efficacy of the model, achieving an accuracy of 98.5% and an F1-score of 96.3%, outperforming many models such as SVM, ALBERT, and RoBERTa. The findings indicate that this approach successfully addresses the challenges posed by increasingly human-like text generated by advanced LLMs, offering a promising solution for maintaining digital content integrity. © 2024 IEEE.},
	author_keywords = {Attention Mechanisms; BERT; BiLSTM; Large Language Model; Natural Language Processing},
	keywords = {Classification (of information); Modeling languages; Attention mechanisms; BERT; BiLSTM; Language model; Language processing; Large language model; Modeling performance; Natural language processing; Natural languages; Text generations; Natural language processing systems},
	correspondence_address = {J. Yan; School of Computer Science and Engineering, Macau University of Science and Technology, 999078, Macao; email: 2109853gii30010@student.must.edu.mo},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152885-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Electron. Inf. Eng. Comput. Technol., EIECT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Naqvi2024,
	author = {Naqvi, Syed Meesam Raza and Ghufran, Mohammad and Varnier, Christophe and Nicod, Jean-Marc and Javed, Kamran and Zerhouni, Noureddine},
	title = {Unlocking maintenance insights in industrial text through semantic search},
	year = {2024},
	journal = {Computers in Industry},
	volume = {157-158},
	doi = {10.1016/j.compind.2024.104083},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188519230&doi=10.1016%2fj.compind.2024.104083&partnerID=40&md5=97a9f364cd867e17c11c6f0bc815c83c},
	affiliations = {SUPMICROTECH, CNRS, institut FEMTO-ST, Besançon, F-25000, France; Fives CortX, Lyon, 69200, France; Department of Computer Engineering, National University of Technology (NUTECH), Islamabad, 44000, Pakistan},
	abstract = {Maintenance records in Computerized Maintenance Management Systems (CMMS) contain valuable human knowledge on maintenance activities. These records primarily consist of noisy and unstructured texts written by maintenance experts. The technical nature of the text, combined with a concise writing style and frequent use of abbreviations, makes it difficult to be processed through classical Natural Language Processing (NLP) pipelines. Due to these complexities, this text must be normalized before feeding to classical machine learning models. Developing these custom normalization pipelines requires manual labor and domain expertise and is a time-consuming process that demands constant updates. This leads to the under-utilization of this valuable source of information to generate insights to help with maintenance decision support. This study proposes a Technical Language Processing (TLP) pipeline for semantic search in industrial text using BERT (Bidirectional Encoder Representations), a transformer-based Large Language Model (LLM). The proposed pipeline can automatically process complex unstructured industrial text and does not require custom preprocessing. To adapt the BERT model for the target domain, three unsupervised domain fine-tuning techniques are compared to identify the best strategy for leveraging available tacit knowledge in industrial text. The proposed approach is validated on two industrial maintenance records from the mining and aviation domains. Semantic search results are analyzed from a quantitative and qualitative perspective. Analysis shows that TSDAE, a state-of-the-art unsupervised domain fine-tuning technique, can efficiently identify intricate patterns in the industrial text regardless of associated complexities. BERT model fine-tuned with TSDAE on industrial text achieved a precision of 0.94 and 0.97 for mining excavators and aviation maintenance records, respectively. © 2024 Elsevier B.V.},
	author_keywords = {Industrial information retrieval; Large Language Models; Maintenance decision support; Navigating human knowledge; Semantic search; Technical Language Processing},
	keywords = {Computational linguistics; Decision support systems; Knowledge management; Maintenance; Natural language processing systems; Semantic Web; Semantics; Decision supports; Human knowledge; Industrial information retrieval; Language model; Language processing; Large language model; Maintenance decision support; Maintenance decisions; Navigating human knowledge; Semantic search; Technical language processing; Technical languages; Pipelines},
	correspondence_address = {S.M.R. Naqvi; AS2M Department, Besançon, Femto-st, 26 Rue de l’Épitaphe, 25000, France; email: syedmeesam.naqvi@femto-st.fr},
	publisher = {Elsevier B.V.},
	issn = {01663615},
	coden = {CINUD},
	language = {English},
	abbrev_source_title = {Comput Ind},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Cao2024662,
	author = {Cao, Danyang and Cheng, Cheng},
	title = {Survey on Deep Learning Applications in Automated Chinese Poetry Composition},
	year = {2024},
	journal = {2024 5th International Conference on Artificial Intelligence and Computer Engineering, ICAICE 2024},
	pages = {662 – 666},
	doi = {10.1109/ICAICE63571.2024.10864023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218441550&doi=10.1109%2fICAICE63571.2024.10864023&partnerID=40&md5=a38aa6658e653c57dbbf3319274e57a3},
	affiliations = {College of Information Science and Technology, North China University of Technology, Beijing, China},
	abstract = {Chinese poetry generation is a challenging task in natural language processing that requires meeting various criteria, including structure, phonetics, and semantics. Early research employed methods such as genetic algorithms and statistical machine translation models; however, the quality and diversity of the generated poetry were limited. With the advancement of deep learning, recurrent neural networks (RNNs) and transformer models have become mainstream approaches due to their ability to capture long-distance dependencies. Reinforcement learning has also been introduced to enhance the diversity and coherence of generated poetry. Additionally, large-scale pretrained models based on BERT and GPT have shown the ability to produce high-quality poetry after fine-tuning. Nevertheless, current technologies still face challenges regarding poetry quality, precision in format control, and consistency in theme and emotion, indicating a need for further theoretical and technical exploration in the future  © 2024 IEEE.},
	author_keywords = {End to end system; generation of poetry; LLM; Reinforcement learning; Transformer},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep neural networks; Machine translation; Natural language processing systems; Recurrent neural networks; Reinforcement learning; Semantics; End-to-end systems; Generation of poetry; Language processing; LLM; Machine translation models; Natural languages; Recurrent neural network model; Reinforcement learnings; Statistical machine translation; Transformer; Deep reinforcement learning},
	correspondence_address = {D. Cao; College of Information Science and Technology, North China University of Technology, Beijing, China; email: ufocdy@163.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152891-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Artif. Intell. Comput. Eng., ICAICE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xia2024,
	author = {Xia, Yufei and Han, Zhiyin and Li, Yawen and He, Lingyun},
	title = {Credit scoring model for fintech lending: An integration of large language models and FocalPoly loss},
	year = {2024},
	journal = {International Journal of Forecasting},
	doi = {10.1016/j.ijforecast.2024.07.005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211207025&doi=10.1016%2fj.ijforecast.2024.07.005&partnerID=40&md5=a6dbaf11a9be313e9e31c61c3c1f3fbd},
	affiliations = {Business School, Jiangsu Normal University, Jiangsu, Xuzhou, 221116, China; School of Economics and Management, China University of Mining and Technology, Jiangsu, Xuzhou, 221116, China},
	abstract = {Fintech lending experiences high credit risk and needs an efficient credit scoring model, but it also faces limited data sources and severe class imbalance. We develop a novel two-stage credit scoring model (called LLM-FP-CatBoost) by solving the two issues simultaneously. Large language models (LLMs) initially extract narrative data as a supplementary credit dataset. A new FocalPoly loss is then incorporated with CatBoost to handle the class imbalance problem. Extensive comparisons demonstrate that the proposed LLM-FP-CatBoost significantly outperforms the benchmarks in most circumstances. When making pairwise comparisons between LLMs on the fintech lending dataset, we found that the Chinese-specific LLM, i.e., ERNIE 4.0, achieves the best overall performance, followed by GPT-4 and BERT-based models. The performance decomposition reveals that the superiority is mainly attributed to the new data source extracted by the LLMs. The SHAP algorithm further ensures the interpretability of LLM-FP-CatBoost. The superiority of the proposed LLM-FP-CatBoost model remains robust to hyperparameters of the loss function, specific LLMs, and other extraction methods of narrative data. Finally, we discuss some managerial implications concerning credit scoring in fintech lending. © 2024 International Institute of Forecasters},
	author_keywords = {BERT; Credit scoring; ERNIE 4.0; Fintech lending; Focal loss; GPT-4; Imbalanced learning; Large language model},
	correspondence_address = {Y. Xia; Business School, Jiangsu Normal University, Xuzhou, Jiangsu, 221116, China; email: 6020180093@jsnu.edu.cn},
	publisher = {Elsevier B.V.},
	issn = {01692070},
	coden = {IJFOE},
	language = {English},
	abbrev_source_title = {Int. J. Forecast.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Fangyu2024770,
	author = {Fangyu, Gao and Di, Chen and Shuai, Yang and Zhenghu, Hao and Qiong, Wu and Xu, Zhang},
	title = {Research on Enhancing Technology Transfer Efficiency through Artificial Intelligence and Recommendation Algorithms},
	year = {2024},
	journal = {Proceedings - 2024 3rd International Conference on Data Analytics, Computing and Artificial Intelligence, ICDACAI 2024},
	pages = {770 – 773},
	doi = {10.1109/ICDACAI65086.2024.00145},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218347360&doi=10.1109%2fICDACAI65086.2024.00145&partnerID=40&md5=1c0cc9965b458d3a90a87224b68f8b98},
	affiliations = {China Electric Equipment Group, Hunan University of Science and Technology, Shanghai, China; Nankai University, Shanghai, China; Shandong University, Shanghai, China; Science and Technology Research Institute, Tsinghua University, Shanghai, China; Beijing State Grid Fuda Technology Development Co., Ltd., University of Melbourne, Beijing, China; Beijing State Grid Fuda Technology Development Co., Ltd., University College London, Beijing, China},
	abstract = {This paper adopts a language processing model and semantic recommendation model to realize the intelligent matching of scientific research achievements and market demand in the electrical equipment industry, aiming to improve the transformation process of scientific research and innovation achievements into practical applications. Through in-depth demand analysis, the key data characteristics of both market demand and scientific research achievement are defined, and the corresponding information feature database is constructed. Pre training based on Bert model can accurately understand the scientific and technological achievements, scientific and technological needs, scientific research literature, patent documents and other contents in the field of electrical equipment. On this basis, an LFM implicit semantic recommendation algorithm model is added to realize the accurate matching between scientific research achievements and market scientific and technological needs. It is the first time for this technology recommendation in the field of transformation of scientific and technological achievements of electrical equipment. © 2024 IEEE.},
	author_keywords = {LFM model; recommendation algorithm; s-Large Language Model (LLM); scientific and technological demand and conversion rate of scientific and technological achievements},
	keywords = {Market Research; Conversion rates; Demand rates; Language model; LFM model; Recommendation algorithms; Research achievements; S-large language model; Scientific and technological achievements; Scientific and technological demand and conversion rate of scientific and technological achievement; Scientific researches; Semantics},
	correspondence_address = {Z. Xu; Beijing State Grid Fuda Technology Development Co., Ltd., University College London, Beijing, China; email: 508594138@qq.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833151903-2},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Data Anal., Comput. Artif. Intell., ICDACAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang2024189,
	author = {Zhang, Yutao and Ai, Jun},
	title = {Semantic-Weighted Word Error Rate Based on BERT for Evaluating Automatic Speech Recognition Models},
	year = {2024},
	journal = {Proceedings - 2024 11th International Conference on Dependable Systems and Their Applications, DSA 2024},
	pages = {189 – 198},
	doi = {10.1109/DSA63982.2024.00034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216934883&doi=10.1109%2fDSA63982.2024.00034&partnerID=40&md5=049232e72530163f964356145fd39c8c},
	affiliations = {Beihang University, School of Reliability and Systems Engineering, Beijing, China},
	abstract = {To address the limitations of traditional evaluation metrics, which fail to differentiate the importance of words and cannot provide detailed, accurate assessments of Automatic Speech Recognition (ASR) models, this paper introduces the Semantic-Weighted Word Error Rate (SWWER). SWWER leverages the BERT model to assign weights to each word based on its contribution to the semantic content of the text, enabling a more accurate and nuanced evaluation of ASR models. Additionally, to provide a more comprehensive assessment of ASR models from both lexical and semantic perspectives, this study proposes a hybrid evaluation metric, H-eval, defined as the harmonic mean of SWWER and Semantic Similarity (SD). Furthermore, this paper explores the potential of integrating Large Language Models (LLMs) in correcting ASR transcriptions. Notably, SWWER effectively reflects the impact of LLM corrections on the transcribed text, indicating that for the same number of erroneous words, higher weights assigned to these errors correlate with greater semantic loss, potentially implying less effective corrections by the LLM. The SWWER and H-eval merics proposed in this paper not only offer precise and comprehensive evaluations but also provide new insights for improving ASR systems and optimizing their performance through the use of LLMs.  © 2024 IEEE.},
	author_keywords = {Automatic Speech Recognition; BERT; Large Language Model; Semantic Similarity; Semantic-Weighted Word Error Rate},
	keywords = {Error statistics; Speech recognition; Automatic speech recognition; BERT; Evaluation metrics; Language model; Large language model; Recognition models; Semantic content; Semantic similarity; Semantic-weighted word error rate; Word error rate; Semantics},
	correspondence_address = {J. Ai; Beihang University, School of Reliability and Systems Engineering, Beijing, China; email: aijun@buaa.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833153239-0},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Dependable Syst. Their Appl., DSA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Iwamoto2024243,
	author = {Iwamoto, Keisuke and Shimada, Kazutaka},
	title = {Dataset Construction and Verification for Detecting Factual Inconsistency in Japanese Summarization},
	year = {2024},
	journal = {Proceedings - 2024 16th IIAI International Congress on Advanced Applied Informatics, IIAI-AAI 2024},
	pages = {243 – 248},
	doi = {10.1109/IIAI-AAI63651.2024.00054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208094978&doi=10.1109%2fIIAI-AAI63651.2024.00054&partnerID=40&md5=88b070d711bc32e7bb807e968cef67aa},
	affiliations = {Kyushu Institute of Technology, Department of Creative Informatics, Fukuoka, Japan; Kyushu Institute of Technology, Department of Artificial Intelligence, Fukuoka, Japan},
	abstract = {Abstractive document summarization is one of the most important tasks in natural language processing. Many approaches based on large language models have been proposed. However, it is known that the output of LLM often includes hallucinations, such as factual inconsistency. Therefore, detecting factual inconsistencies in a summary is one important task for summarization. One solution for the detection is to utilize machine learning techniques. In general, machine learning approaches require a large number of training data to generate a robust model. However, it is difficult automatically to collect article-summary pairs with factual inconsistency from the Web because hand-written summaries on the Web are usually correct. Moreover, some existing datasets are written in English. In this paper, we propose some approaches to construct Japanese datasets with factual inconsistency automatically. For this purpose, we utilize two approaches from previous studies: FactCC and SumFC. In addition, we propose a new approach to construct summaries with exaggerated expressions, as a variety of factual inconsistencies. We call the datasets JFactCC, JSumFC, and JExnoS. For JExnoS, we utilize a two-stage approach based on GPT-4 and BART for the generation of summaries with exaggerated expressions from correct article-summary pairs. We also verify the usefulness of each constructed dataset through an experiment about factual inconsistency detection with BERT.  © 2024 IEEE.},
	author_keywords = {BART; BERT; Dataset construction; Factual inconsistency detection; GPT-4},
	keywords = {Contrastive Learning; Machine learning; Natural language processing systems; Article summary; BART; BERT; Dataset construction; Document summarization; Factual inconsistency detection; GPT-4; Inconsistency detection; Language processing; Natural languages; Adversarial machine learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037790-3},
	language = {English},
	abbrev_source_title = {Proc. - IIAI Int. Congr. Adv. Appl. Informatics, IIAI-AAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{El-Enen2024,
	author = {El-Enen, Mohamed Ahmed Abo and Tbaishat, Dina and AbdulRazek, Mustafa and Nazir, Amril and Muhammad, Reem and Sahlol, Ahmed T.},
	title = {Generative AI with Big Data for Better Detection of Fraud in Medical Claims},
	year = {2024},
	journal = {2024 IEEE International Conference on E-Health Networking, Application and Services, HealthCom 2024},
	doi = {10.1109/HEALTHCOM60970.2024.10880817},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219604589&doi=10.1109%2fHEALTHCOM60970.2024.10880817&partnerID=40&md5=14b81dbe275a108db9fa254f8fcbbd4f},
	affiliations = {TachyHealth, Inc., Dubai, United Arab Emirates; College of Technological Innovation, Zayed University, Dubai, United Arab Emirates},
	abstract = {Generative AI refers to a type of algorithms that can generate new content. This can be text, images, or any other form of data. While Large Language Models (LLMs) are a specific type of generative AI that focuses on language, they are basically trained on massive textual input to understand and generate human-like text. This paper addresses the critical challenge of fraud detection in medical insurance claims, a pervasive issue causing significant financial losses in healthcare. This work is focused on devising a robust, automated system for detecting fraudulent activities. Where an integration of Generative AI, specifically LLM is implemented with Big Data processing frameworks to enhancements in fraud detection in medical claims. Each LLM was used as an embedding layer that transforms textual features of a real-world insurance claim data into numerical representations. These claims data has been collected from countries belonging to the Mena region. The results show advantages towards LLMs that were trained on specialized medical contexts as they show better capability of understanding medical expressions which reflects model’s performance. Applying further sampling techniques such as class weight and up-sampling did not have a significant impact on the LLMs performance, with a little better performance for class weight. Gemini showed advantages over BERT medical language models on most experiments by achieving 90.44% of classification accuracy. © 2024 IEEE.},
	author_keywords = {Big Data; Fraud Detection; Generative AI; Large Language Models; Medical Claims},
	keywords = {Crime; Generative adversarial networks; Health insurance; Metadata; Modeling languages; Critical challenges; Fraud detection; Generative AI; Human like; Insurance claims; Language model; Large language model; Medical claims; Performance; Text images; Big data},
	correspondence_address = {D. Tbaishat; College of Technological Innovation, Zayed University, Dubai, United Arab Emirates; email: Dina.Tbaishat@zu.ac.ae},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035054-8},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. E-Health Netw., Appl. Serv., HealthCom},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kyriakou20241080,
	author = {Kyriakou, Theodora and Maslaris, Ioannis and Arampatzis, Avi},
	title = {DUTh at SemEval 2024 Task 8: Comparing classic Machine Learning Algorithms and LLM based methods for Multigenerator, Multidomain and Multilingual Machine-Generated Text Detection},
	year = {2024},
	journal = {SemEval 2024 - 18th International Workshop on Semantic Evaluation, Proceedings of the Workshop},
	pages = {1080 – 1086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215511502&partnerID=40&md5=bcf85fe82cbcbec7b2ffa9ea02833f55},
	affiliations = {Database & Information Retrieval Research Unit, Department of Electrical & Computer Engineering, Democritus University of Thrace, Greece},
	abstract = {Text-generative models evolve rapidly nowadays. Although, they are very useful tools for a lot of people, they have also raised concerns for different reasons. This paper presents our work for SemEval2024 Task-8 on 2 out of the 3 subtasks. This shared task aims at finding automatic models for making AI vs. human written text classification easier. Our team, after trying different preprocessing, several Machine Learning algorithms, and some LLMs, ended up with mBERT, XLM-RoBERTa, and BERT for the tasks we submitted. We present both positive and negative methods, so that future researchers are informed about what works and what doesn't. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Contrastive Learning; Learning algorithms; Automatic modeling; Generative model; Machine learning algorithms; Machine-generated texts; Multi-domains; Subtask; Text classification; Text detection; Written texts; Adversarial machine learning},
	editor = {Ojha A.K. and Dohruoz A.S. and Madabushi H.T. and Da San Martino G. and Rosenthal S. and Rosa A.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176107-0},
	language = {English},
	abbrev_source_title = {SemEval - Int. Workshop Semantic Eval., Proc. Workshop},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2024,
	author = {Li, Jianning and Dada, Amin and Puladi, Behrus and Kleesiek, Jens and Egger, Jan},
	title = {ChatGPT in healthcare: A taxonomy and systematic review},
	year = {2024},
	journal = {Computer Methods and Programs in Biomedicine},
	volume = {245},
	doi = {10.1016/j.cmpb.2024.108013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183173863&doi=10.1016%2fj.cmpb.2024.108013&partnerID=40&md5=1e0ec823297dd19c5125c234f2ec16a4},
	affiliations = {Institute for Artificial Intelligence in Medicine, University Hospital Essen (AöR), Girardetstraße 2, Essen, 45131, Germany; Institute of Medical Informatics, University Hospital RWTH Aachen, Pauwelsstraße 30, Aachen, 52074, Germany; Department of Oral and Maxillofacial Surgery, University Hospital RWTH Aachen, Pauwelsstraße 30, Aachen, 52074, Germany; Center for Virtual and Extended Reality in Medicine (ZvRM), University Hospital Essen, University Medicine Essen, Hufelandstraße 55, Essen, 45147, Germany; TU Dortmund University, Department of Physics, Otto-Hahn-Straße 4, Dortmund, 44227, Germany},
	abstract = {The recent release of ChatGPT, a chat bot research project/product of natural language processing (NLP) by OpenAI, stirs up a sensation among both the general public and medical professionals, amassing a phenomenally large user base in a short time. This is a typical example of the ‘productization’ of cutting-edge technologies, which allows the general public without a technical background to gain firsthand experience in artificial intelligence (AI), similar to the AI hype created by AlphaGo (DeepMind Technologies, UK) and self-driving cars (Google, Tesla, etc.). However, it is crucial, especially for healthcare researchers, to remain prudent amidst the hype. This work provides a systematic review of existing publications on the use of ChatGPT in healthcare, elucidating the ‘status quo’ of ChatGPT in medical applications, for general readers, healthcare professionals as well as NLP scientists. The large biomedical literature database PubMed is used to retrieve published works on this topic using the keyword ‘ChatGPT’. An inclusion criterion and a taxonomy are further proposed to filter the search results and categorize the selected publications, respectively. It is found through the review that the current release of ChatGPT has achieved only moderate or ‘passing’ performance in a variety of tests, and is unreliable for actual clinical deployment, since it is not intended for clinical applications by design. We conclude that specialized NLP models trained on (bio)medical datasets still represent the right direction to pursue for critical clinical applications. © 2024 The Author(s)},
	author_keywords = {Bard; BERT; ChatGPT; Healthcare; LLaMA; LLM; NLP; OpenAI; Taxonomy; Transformer},
	keywords = {Artificial Intelligence; Databases, Factual; Humans; Natural Language Processing; Physicians; PubMed; Binary alloys; Health care; Medical applications; Natural language processing systems; Potassium alloys; Uranium alloys; Bard; BERT; ChatGPT; Healthcare; Language processing; LLaMA; LLM; Natural language processing; Natural languages; Openai; Transformer; ChatGPT; classification; clinical decision making; consultation; health care personnel; large language model; long short term memory network; medical education; medical research; medicine; natural language processing; publication; recurrent neural network; Review; systematic review; taxonomy; workflow; artificial intelligence; factual database; human; Medline; physician; Taxonomies},
	correspondence_address = {J. Egger; Institute for Artificial Intelligence in Medicine, University Hospital Essen (AöR), Essen, Girardetstraße, 45131, Germany; email: jan.egger@uk-essen.de},
	publisher = {Elsevier Ireland Ltd},
	issn = {01692607},
	coden = {CMPBE},
	pmid = {38262126},
	language = {English},
	abbrev_source_title = {Comput. Methods Programs Biomed.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 137; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sinha2024,
	author = {Sinha, Himanshu},
	title = {A Sentiment Analysis of Product Review Data Through Large Language Models (LLMs)},
	year = {2024},
	journal = {2024 International Conference on Intelligent Computing and Sustainable Innovations in Technology, IC-SIT 2024},
	doi = {10.1109/IC-SIT63503.2024.10862104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218350495&doi=10.1109%2fIC-SIT63503.2024.10862104&partnerID=40&md5=a42ac4efef8ff70ceb6e5ba8e69b6335},
	affiliations = {Indiana University, Bloomington, Kelley School of Business, Naperville, IL, United States},
	abstract = {Opinion mining, which can be classified as process of extracting subjective information from text data, remains one of the most widely researched areas in NLP even today. Because of its ability to gauge thoughts and opinions of people it has garnered lot of interest from both scholars and practitioners. A Lot of advancement has been made in this area with the help of large language models (LLMs). This paper aims to compare the sentiment classification on Amazon product review dataset using the various types of LLMs, including BERT and TF-IDF models. Thus, the resultant dataset containing 59,794 total reviews was pre-processed and further split into the training and testing sets. When performing the Exploratory Data Analysis (EDA) it was determined there were three sentiments; Positive, Negative and Neutral. The measurements, namely F1-score, recall, accuracy, and precision, were used to compare the performances of the developed models. Analysis showed that an accuracy of TF-IDF model was enhanced by 15.59% as compared to the BERT model that yielded an accuracy of only 78. 91%. This study further embraces the use of TF-IDF and LLM for sentiment analysis and highlights directions for future studies to improve the model reliability and efficiency by eradicating false prediction gaps and integrating other complicated approaches such as ensemble learning.  © 2024 IEEE.},
	author_keywords = {Amazon Dataset; BERT; Deep Learning; Product Review; Sentiment Analysis; Tokenization},
	keywords = {Contrastive Learning; Reliability analysis; Sentiment analysis; Amazon dataset; BERT; Classifieds; Deep learning; Language model; Opinion mining; Product reviews; Sentiment analysis; Subjective information; Tokenization; Data accuracy},
	correspondence_address = {H. Sinha; Indiana University, Bloomington, Kelley School of Business, Naperville, United States; email: himanshusin@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036917-5},
	language = {English},
	abbrev_source_title = {Int. Conf. Intell. Comput. Sustain. Innov. Technol., IC-SIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gagan2024,
	author = {Gagan, N. and Sanand, Sasidharan},
	title = {Enhancing Oncology Care with Federated Learning and Foundation Models},
	year = {2024},
	journal = {2024 ITU Kaleidoscope: Innovation and Digital Transformation for a Sustainable World, ITU K 2024},
	doi = {10.23919/ITUK62727.2024.10772940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215284265&doi=10.23919%2fITUK62727.2024.10772940&partnerID=40&md5=1d28a89d186a6ba8bbcd102499d373b2},
	affiliations = {GE HealthCare, India},
	abstract = {Millions of people worldwide are battling cancer, and personalised care plans are essential for effective diagnosis, treatment, and monitoring of this disease. Recently, Large Language Models (LLMs) have proven valuable in cancer treatment, for instance, extracting key information from Electronic Medical Records (EMRs). This study presents a transformer encoder based LLM, that is domain adapted for Oncology, and outperforms generic models in recognising critical oncology related elements from clinical text. We observe that the development of such domain specific LLMs demands a huge amount of data and computational resources, which is a deterrent to the sustainability development goal of equitable health. To address this problem, we propose a federated learning approach for model development that will eliminate data sharing and centralised computational resource costs. Our evaluations show that the federated approach outperforms the generic base model, highlighting the advantages of collaborative learning in capturing domain specific knowledge and enhancing performance in oncology related NLP tasks. Our work is in line with the United Nations Sustainable Development Goals (SDGs) which are aimed at promoting equitable health and narrowing down the differences in access to advanced cancer treatment.  © 2024 ITU.},
	author_keywords = {BERT; Domain Adaptation; Embedding; Federated Learning; Fine-tuning; NER; Pre-tuning; SDG's},
	keywords = {Collaborative learning; Diagnosis; Diseases; Lung cancer; Oncology; BERT; Computational resources; Domain adaptation; Embeddings; Fine tuning; Foundation models; Language model; Learning models; NER; Pre-tuning; Electronic health record},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-926139091-4},
	language = {English},
	abbrev_source_title = {ITU Kaleidoscope: Innov. Digit. Transform. a Sustain. World, ITU K},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Da Silva202486,
	author = {Da Silva, Fabiano Tavares and De Araujo, Felipe Rocha and Bezerra, Erick Costa},
	title = {A Comparative Study of Bug Triage Representation and Classification Approaches from Canonical to Large Language Models},
	year = {2024},
	journal = {2024 5th International Conference on Artificial Intelligence and Computer Engineering, ICAICE 2024},
	pages = {86 – 93},
	doi = {10.1109/ICAICE63571.2024.10864116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218457971&doi=10.1109%2fICAICE63571.2024.10864116&partnerID=40&md5=6564d444746e86ee1fa35b9b2b8953dd},
	affiliations = {Sidia R&d Institute, Manaus, Brazil},
	abstract = {Bug triage is the task of assigning newly reported bugs to the proper developers or team for resolution. This is a critical point in software maintenance as it directly influences the time and correct allocation that impact the efficiency and effectiveness of the software process. In a global aspect, the number of teams/developers is extensive, which brings a challenge for bug triage. Traditional approaches to assign bugs struggle with the complexity of the problem. This paper proposes a comparative assessment for different text representation combined with text classification approaches for automated bug report triage by incorporating Large Language Models (LLMs) into the classification pipeline to surpass the limitations of canonical methods. Traditional classification methods were compared with LLM-enhanced models across accuracy metric. The results demonstrate an improvement in triage accuracy when utilizing the fine-tuned LLM, highlighting their potential to provide developer-appropriate bug assignments.  © 2024 IEEE.},
	author_keywords = {bug report triage; LLM; S-BERT},
	keywords = {Program debugging; Bug report triage; Bug reports; Classification approach; Comparatives studies; Global aspects; Language model; Large language model; S-BERT; Software process; Traditional approachs; Computer software maintenance},
	correspondence_address = {F.R. De Araujo; Sidia R&d Institute, Manaus, Brazil; email: felipe.araujo@sidia.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152891-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Artif. Intell. Comput. Eng., ICAICE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kim20248653,
	author = {Kim, Hongjin and Kim, Jai-Eun and Kim, Harksoo},
	title = {Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
	pages = {8653 – 8670},
	doi = {10.18653/v1/2024.emnlp-main.492},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217818873&doi=10.18653%2fv1%2f2024.emnlp-main.492&partnerID=40&md5=e17857136c51ab109eb63eaed152b666},
	affiliations = {Konkuk University, South Korea; Saltlux, South Korea},
	abstract = {Nested Named Entity Recognition (NER) poses a significant challenge in Natural Language Processing (NLP), demanding sophisticated techniques to identify entities within entities. This research investigates the application of Large Language Models (LLMs) to nested NER, exploring methodologies from prior work and introducing specific reasoning techniques and instructions to improve LLM efficacy. Through experiments conducted on the ACE 2004, ACE 2005, and GENIA datasets, we evaluate the impact of these approaches on nested NER performance. Results indicate that output format critically influences nested NER performance, methodologies from previous works are less effective, and our nested NER-tailored instructions significantly enhance performance. Additionally, we find that label information and descriptions of nested cases are crucial in eliciting the capabilities of LLMs for nested NER, especially in specific domains (i.e., the GENIA dataset). However, these methods still do not outperform BERT-based models, highlighting the ongoing need for innovative approaches in nested NER with LLMs. © 2024 Association for Computational Linguistics.},
	keywords = {Natural language processing systems; Label information; Language model; Language processing; Model method; Named entity recognition; Natural languages; Output formats; Performance; Performance methodology; Reasoning techniques; Computational linguistics},
	correspondence_address = {H. Kim; Konkuk University, South Korea; email: nlpdrkim@konkuk.ac.kr},
	editor = {Al-Onaizan Y. and Bansal M. and Chen Y.-N.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176164-3},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{O’brien2024,
	author = {O’brien, Kyle and Ng, Nathan and Puri, Isha and Mendez, Jorge and Palangi, Hamid and Kim, Yoon and Ghassemi, Marzyeh and Hartvigsen, Thomas},
	title = {Improving Black-box Robustness with In-Context Rewriting},
	year = {2024},
	journal = {Transactions on Machine Learning Research},
	volume = {2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219508290&partnerID=40&md5=88d79c6556b539f7d559b714235731e7},
	affiliations = {EleutherAI, United States; Google, United States; University of Toronto, Canada; Vector Institute, Canada; MIT CSAIL, United States; University of Virginia, United States},
	abstract = {Machine learning models for text classification often excel on in-distribution (ID) data but struggle with unseen out-of-distribution (OOD) inputs. Most techniques for improving OOD robustness are not applicable to settings where the model is effectively a black box, such as when the weights are frozen, retraining is costly, or the model is leveraged via an API. Test-time augmentation (TTA) is a simple post-hoc technique for improving robustness that sidesteps black-box constraints by aggregating predictions across multiple augmentations of the test input. TTA has seen limited use in NLP due to the challenge of generating effective natural language augmentations. In this work, we propose LLM-TTA, which uses LLM-generated augmentations as TTA’s augmentation function. LLM-TTA outperforms conven-tional augmentation functions across sentiment, toxicity, and news classification tasks for BERT and T5 models, with BERT’s OOD robustness improving by an average of 4.48 per-centage points without regressing average ID performance. We explore selectively augment-ing inputs based on prediction entropy to reduce the rate of expensive LLM augmentations, allowing us to maintain performance gains while reducing the average number of generated augmentations by 57.74%. LLM-TTA is agnostic to the task model architecture, does not require OOD labels, and is effective across low and high-resource settings. We share our data1, models2, and code3 for reproducibility. © 2024, Transactions on Machine Learning Research. All rights reserved.},
	publisher = {Transactions on Machine Learning Research},
	issn = {28358856},
	language = {English},
	abbrev_source_title = {Transact. mach. learn. res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dmonte20244869,
	author = {Dmonte, Alphaeus and Ko, Eunmi and Zampieri, Marcos},
	title = {An Evaluation of Large Language Models in Financial Sentiment Analysis},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Big Data, BigData 2024},
	pages = {4869 – 4874},
	doi = {10.1109/BigData62323.2024.10825272},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217988171&doi=10.1109%2fBigData62323.2024.10825272&partnerID=40&md5=6445630bf88493f3769fc94eca7379ed},
	affiliations = {George Mason University, Fairfax, VA, United States; Rochester Institute of Technology, Rochester, NY, United States},
	abstract = {Financial sentiment analysis can help in understanding market trends and help organizations and individuals make important business decisions. Several machine learning approaches have been used for financial sentiment analysis over the years ranging from lexicon-based approaches to the use of deep neural networks and transformer-based models. Recent advances in Large Language Models (LLM) have prompted the use of these models for various Natural Language Processing (NLP) tasks, however, these models have not yet been substantially explored in the financial domain. In this paper, we evaluate the performance of various LLMs and we introduce a small benchmark dataset consisting of excerpts extracted from the Federal Reserve chair's speeches. We use this dataset along with other existing datasets to evaluate LLMs using in-context learning approaches. We compare the F1 scores of these models with the state-of-the-art BERT-based models and analyze our results. © 2024 IEEE.},
	author_keywords = {Federal Reserve; Financial Sentiment Analysis; LLM; Sentiment Analysis},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep neural networks; Financial data processing; Financial markets; Large datasets; Natural language processing systems; Business decisions; Federal Reserve; Financial sentiment analyze; Language model; Large language model; Lexicon-based; Machine learning approaches; Market trends; Sentiment analysis; Decentralized finance},
	correspondence_address = {A. Dmonte; George Mason University, Fairfax, United States; email: admonte@gmu.edu},
	editor = {Ding W. and Lu C.-T. and Wang F. and Di L. and Wu K. and Huan J. and Nambiar R. and Li J. and Ilievski F. and Baeza-Yates R. and Hu X.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036248-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Kwon2024640,
	author = {Kwon, O. Hwang and Vu, Katie and Cooper, Jacob and Joynt, Veda and Radaideh, Majdi I.},
	title = {Using Large Language Models to Classify Public Sentiment Toward Nuclear Power},
	year = {2024},
	journal = {Pacific Basin Nuclear Conference, PBNC 2024},
	pages = {640 – 649},
	doi = {10.13182/PBNC24-44984},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211602349&doi=10.13182%2fPBNC24-44984&partnerID=40&md5=e078fb33dde759cef0f1b3a54ee4a627},
	affiliations = {Department of Nuclear Engineering and Radiological Sciences, University of Michigan, Ann Arbor, 48109, MI, United States},
	abstract = {Understanding public sentiment regarding nuclear power is a key component in achieving an equitable shift to clean energy, which encompasses the integration of nuclear energy. In this study, we navigate through social media to obtain data as an indicator of public sentiment related to nuclear power. We present sentiment analysis findings based on a dataset of 500,000 tweets collected from X (Twitter). A novel approach is utilized to label the data, employing seven different libraries to determine the sentiment label. This method highlighted the variability and bias among these libraries in labeling the same text. Consequently, the data was categorized into low and high confidence tweets depending on the level of agreement among the seven labeling tools. Then, the performance of various models, including Large Language Models (LLMs), neural networks (e.g., Long Short-Term Memory), and classical models (e.g., Random Forests), is evaluated in sentiment classification using these labeled data. Notably, LLMs like GPT and BERT showed superior performance when trained solely on high confidence data labels, as well as when dealing with both high and low confidence data. Their accuracy ranged from 81% for both low and high confidence data to 95% for high confidence data, surpassing all other models. Additionally, the analysis revealed a tendency toward neutral to negative sentiments regarding nuclear power within the dataset, with fewer instances of positive sentiment. Further investigation is needed to understand the underlying reasons behind these sentiments, such as potential political factors, an area that requires further investigation. © 2024 Pacific Basin Nuclear Conference, PBNC 2024. All rights reserved.},
	author_keywords = {BERT; GPT; Large Language Model (LLM); Nuclear Power; Sentiment Classification},
	keywords = {Decision trees; Economic and social effects; Labeled data; Long short-term memory; BERT; Clean energy; GPT; High confidence; Language model; Large language model; Performance; Power; Public sentiments; Sentiment classification; Tweets},
	publisher = {American Nuclear Society},
	isbn = {979-833130765-3},
	language = {English},
	abbrev_source_title = {Pac. Basin Nucl. Conf., PBNC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Creanga20242100,
	author = {Creanga, Claudiu and Dinu, Liviu P. and Gifu, Daniela},
	title = {Fine-Tuning Models for Biomedical Relation Extraction},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {2100 – 2109},
	doi = {10.1016/j.procs.2024.09.637},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213374637&doi=10.1016%2fj.procs.2024.09.637&partnerID=40&md5=4ec95f8424ab4fa40a30300273249076},
	affiliations = {Interdisciplinary School of Doctoral Studies, Romania; Faculty of Mathematics and Computer Science, University of Bucharest, Romania; HLT Research Center, Romania; Institute of Computer Science, Romanian Academy, Iasi Branch, Romania},
	abstract = {Next-Generation Sequencing has revolutionized the study of genetic mutations, enabling large-scale investigations into their roles in disease development. However, extracting meaningful insights from the vast amount of biomedical literature remains a complex challenge that cannot be addressed manually. In this paper, we present pre-trained models (PTMs) for the automatic extraction of relations from biomedical text, specifically targeting the variant-phenotype domain. Our evaluation on the SNPPhenA corpus demonstrates that fine-tuning small BERT-based models, particularly DeBERTa, yields strong performance, approaching the current state-of-the-art (SOTA). Additionally, our results indicate that carefully fine-tuning Google's Gemini Pro 1.0 outperforms the existing SOTA for both sentence-level tasks (where the model processes only the target sentence) and abstract-level tasks (where the model processes the entire abstract). © 2024 The Authors.},
	author_keywords = {biomedical text; genomics; LLM; MLM; relation extraction},
	keywords = {Biomedical text; Fine tuning; Genomics; LLM; MLM; Modeling process; Next-generation sequencing; Relation extraction; Sentence level; State of the art; Gene encoding},
	editor = {Flearmoy J.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Omar2024,
	author = {Omar, Marwan and Zangana, Hewa Majeed and Al-Karaki, Jamal N. and Mohammed, Derek},
	title = {Harnessing LLMs for IoT Malware Detection: A Comparative Analysis of BERT and GPT-2},
	year = {2024},
	journal = {ISMSIT 2024 - 8th International Symposium on Multidisciplinary Studies and Innovative Technologies, Proceedings},
	doi = {10.1109/ISMSIT63511.2024.10757249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213335239&doi=10.1109%2fISMSIT63511.2024.10757249&partnerID=40&md5=5c96ba7d8dd46a46591ef669e8751d2d},
	affiliations = {College of Computing, Illinois Institute of Technology, Chicago, United States; Duhok Technical College, Duhok Polytechnic University, It Department, Duhok, Iraq; College of Interdisciplinary Studies, Zayed University, Abu Dhabi, United Arab Emirates; College of Cards, Saint Leo University, FL, United States},
	abstract = {In recent years, the proliferation of Internet of Things (IoT) devices has introduced significant vulnerabilities in cybersecurity, particularly with the rise of sophisticated malware targeting these systems. Traditional detection methods, often based on static signatures, struggle to keep pace with evolving threats, such as zero-day attacks. This paper explores the application of Large Language Models (LLMs), specifically BERT and GPT-2, in detecting IoT malware by analyzing network traffic and identifying anomalies. Using the contextual understanding and adaptability of LLM, our approach significantly enhances detection accuracy compared to conventional methods. We evaluated the models using the ToN-IoT dataset, demonstrating their capability to detect complex malware patterns with higher precision. The results indicate that BERT outperforms GPT-2 across multiple metrics, highlighting its effectiveness in generalizing to various attack types. Despite promising advancements, challenges such as computational resource demands and model interpretability persist. Future research should focus on optimizing LLMs for real-time detection in resource-constrained environments and improving transparency to enhance trust among cybersecurity professionals. Our study underscores the potential of LLMs as powerful tools in the ongoing battle against IoT malware, offering a robust framework for enhancing cybersecurity defenses. © 2024 IEEE.},
	author_keywords = {AI Security; Cybersecurity; LLMs; Malware Detection; Risk Mitigation},
	keywords = {Cyber attacks; Malware; Risk assessment; AI security; Comparative analyzes; Cyber security; Detection methods; Language model; Large language model; Malware detection; Malwares; Risk mitigation; Static signatures; Zero-day attack},
	correspondence_address = {M. Omar; College of Computing, Illinois Institute of Technology, Chicago, United States; email: momar3@iit.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035442-3},
	language = {English},
	abbrev_source_title = {ISMSIT - Int. Symp. Multidiscip. Stud. Innov. Technol., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Zaleppa2024,
	author = {Zaleppa, Paige and Kaza, Siddharth and Taylor, Blair},
	title = {Generating an Instruction Dataset to Build Cyber Intelligent Large Language Models},
	year = {2024},
	journal = {2024 Cyber Awareness and Research Symposium, CARS 2024},
	doi = {10.1109/CARS61786.2024.10778717},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215302937&doi=10.1109%2fCARS61786.2024.10778717&partnerID=40&md5=dbdb756d7963271f6842211512af0d08},
	affiliations = {Towson University, Department of Computer and Information Sciences, Towson, MD, United States},
	abstract = {The rapid evolution of cybersecurity necessitates the commitment of professionals to continuously update their knowledge and skills. This challenges cybersecurity educators and trainers to update teaching materials to keep pace with vulnerabilities, technologies, and adversaries. Advancements in Artificial Intelligence (AI), especially within Large Language Models (LLMs) present opportunities to help build curriculum and training materials. However, many publicly available LLMs like BERT, GPT, and LLaMA lack deep knowledge in specific domains and require fine-tuning using specialized datasets. Due to its dynamic nature, the cybersecurity discipline faces a shortage of rich datasets, both general and specialized, necessary for effective fine-tuning. This paper presents the process and lessons learned from generating a cybersecurity instruction dataset using an LLM and cybersecurity learning modules created by humans. The aim is to create and publish for public use, a high-quality dataset that can be used to fine-tune pretrained LLMs (like BERT, LLaMA, and others) for NLP tasks in the cybersecurity domain with the larger goal of developing AI-generated curriculum.  © 2024 IEEE.},
	author_keywords = {AI; cybersecurity learning materials; fine-tuning LLMs; instruction datasets},
	keywords = {Adversarial machine learning; Federated learning; Cyber security; Cybersecurity learning material; Deep knowledge; Fine tuning; Fine-tuning large language model; Instruction dataset; Language model; Learning materials; Teaching materials; Training material},
	correspondence_address = {P. Zaleppa; Towson University, Department of Computer and Information Sciences, Towson, United States; email: pzaleppa@towson.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038641-7},
	language = {English},
	abbrev_source_title = {Cyber Aware. Res. Symp., CARS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang2024457,
	author = {Wang, Meng and Zhang, Zhixiong and Li, Hanyu and Zhang, Guangyin},
	title = {An Improved Meta-Knowledge Prompt Engineering Approach for Generating Research Questions in Scientific Literature},
	year = {2024},
	journal = {International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings},
	volume = {1},
	pages = {457 – 464},
	doi = {10.5220/0013060900003838},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215290786&doi=10.5220%2f0013060900003838&partnerID=40&md5=1435c06cbc2179ffc204381d2170bee9},
	affiliations = {National Science Library, Chinese Academy of Science, Beijing, China; University of Chinese Academy of Science, Beijing, China},
	abstract = {Research questions are crucial for the development of science, which are an important driving force for scientific evolution and progress. This study analyses the key meta knowledge required for generating research questions in scientific literature, including research objective and research method. To extract meta-knowledge, we obtained feature words of meta-knowledge from knowledge-enriched regions and embedded them into the DeBERTa (Decoding-enhanced BERT with disentangled attention) for training. Compared to existing models, our proposed approach demonstrates superior performance across all metrics, achieving improvements in F1 score of +9% over BERT (88% vs. 97%), +3% over BERT-CNN (94% vs. 97%), and +2% over DeBERTa (95% vs. 97%) for identifying meta-knowledge. And, we construct the prompts integrate meta-knowledge to fine tune LLMs. Compared to the baseline model, the LLMs fine-tuned using meta-knowledge prompt engineering achieves an average 88.6% F1 score in the research question generation task, with improvements of 8.4%. Overall, our approach can be applied to the research question generation in different domains. Additionally, by updating or replacing the meta-knowledge, the model can also serve as a theoretical foundation and model basis for the generation of different types of sentences. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Knowledge Extraction; Knowledge-Rich Regions; LLMs; Prompt Engineering; Research Question Generation},
	keywords = {Engineering research; Knowledge engineering; Driving forces; F1 scores; Knowledge extraction; Knowledge-rich region; LLM; Meta-knowledge; Prompt engineering; Research question generation; Research questions; Scientific literature; Domain Knowledge},
	editor = {Coenen F. and Fred A. and Bernardino J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21843228},
	isbn = {978-989758716-0},
	language = {English},
	abbrev_source_title = {International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {2024 11th International Conference on Advanced Informatics: Concept, Theory and Application, ICAICTA 2024},
	year = {2024},
	journal = {2024 11th International Conference on Advanced Informatics: Concept, Theory and Application, ICAICTA 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214646519&partnerID=40&md5=d0ed8a01141a8730e9e893cd775fbbe5},
	abstract = {The proceedings contain 41 papers. The topics discussed include: heterogeneous transfer learning optimization for greenhouse gas emissions prediction using quantum annealing; evaluating trustworthiness of twitter users: addressing data drift and domain relevance through novel dataset creation and feature analysis; BIOGAN-BERT: BioGPT-2 fine-tuned and GAN-BERT for extracting drug interaction based on biomedical texts; integrating BERTopic and large language models for thematic identification of Indonesian legal documents; enhancing speech de-identification with LLM-based data augmentation; automatic question-answer alignment for Japanese diverse local assembly minutes; sleep apnea identification based on multi-frequency band of EEG signal using slim UNETR; and card-based secure sorting protocols based on the sorting networks.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152031-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Informatics: Concept, Theory Appl., ICAICTA},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sufi2024,
	author = {Sufi, Fahim},
	title = {A Sustainable Way Forward: Systematic Review of Transformer Technology in Social-Media-Based Disaster Analytics},
	year = {2024},
	journal = {Sustainability (Switzerland) },
	volume = {16},
	number = {7},
	doi = {10.3390/su16072742},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190255355&doi=10.3390%2fsu16072742&partnerID=40&md5=1c617e86ed50bee53381806cf766412f},
	affiliations = {School of Public Health and Preventive Medicine, Monash University, Melbourne, 3004, VIC, Australia},
	abstract = {Transformer technologies, like generative pre-trained transformers (GPTs) and bidirectional encoder representations from transformers (BERT) are increasingly utilized for understanding diverse social media content. Despite their popularity, there is a notable absence of a systematic literature review on their application in disaster analytics. This study investigates the utilization of transformer-based technology in analyzing social media data for disaster and emergency crisis events. Leveraging a systematic review methodology, 114 related works were collated from popular databases like Web of Science and Scopus. After deduplication and following the exclusion criteria, 53 scholarly articles were analyzed, revealing insights into the geographical distribution of research efforts, trends in publication output over time, publication venues, primary research domains, and prevalently used technology. The results show a significant increase in publications since 2020, with a predominant focus on computer science, followed by engineering and decision sciences. The results emphasize that within the realm of social-media-based disaster analytics, BERT was utilized in 29 papers, BERT-based methods were employed in 28 papers, and GPT-based approaches were featured in 4 papers, indicating their predominant usage in the field. Additionally, this study presents a novel classification scheme consisting of 10 distinct categories that thoroughly categorize all existing scholarly works on disaster monitoring. However, the study acknowledges limitations related to sycophantic behavior and hallucinations in GPT-based systems and raises ethical considerations and privacy concerns associated with the use of social media data. To address these issues, it proposes strategies for enhancing model robustness, refining data validation techniques, and integrating human oversight mechanisms. © 2024 by the author.},
	author_keywords = {algorithms; BERT; GPTs in disaster analytics; language models; LLM for emergency situations; social media analytics; systematic literature review; transformer for crisis},
	keywords = {algorithm; analytical method; disaster management; geographical distribution; literature review; numerical model; social media; sustainability},
	correspondence_address = {F. Sufi; School of Public Health and Preventive Medicine, Monash University, Melbourne, 3004, Australia; email: fahim.sufi@monash.edu},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Reang2024,
	author = {Reang, Rujeena and Dehalwar, Vasudev and Pateriya, R.K.},
	title = {Automatically Generate Impression From Findings In Radiology Report Using BERT},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10724981},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211134659&doi=10.1109%2fICCCNT61001.2024.10724981&partnerID=40&md5=8f8ec5194c809eea50ee8fe56080d6da},
	affiliations = {Manit Bhopal, Department of Cse, Bhopal, India},
	abstract = {The vital work of summarizing medical reports so that the general public can easily access them can be considerably aided by the recent developments in deep learning and large language models (LLM). One medical specialty that can make use of it is radiology, where it's essential to summarize the most crucial information from the 'findings' part into the 'impression' part of a report to help radiologists and referring physicians communicate more easily. To automate the development of the 'impression' part in radiology reports, we propose a unique architecture for summarization. The workload for radiologists is greatly reduced by this method. Because of the specialized vocabulary employed in radiology, existing models and approaches for abstractive summarization-such as those that utilize recent advances in the field of natural language processing (NLP), such as BERT and its derivatives, are not immediately relevant. As such, our system is specially designed to tackle the particular difficulties presented by radiology reports. We create a pre-trained language model in radiology to address the issue of automatically summarizing reports on radiography. More specifically, In this research BERT Encoder is pre-trained on the MIMIC-CXR dataset. Next, an abstractive summarization model is built by combining a Transformer decoder and a pretrained BERT. In conclusion, for the abstractive summarization task, the model will be improved utilizing reports from chest X-rays. Furthermore, the publically available OPEN-I datasets is used for evaluation. © 2024 IEEE.},
	author_keywords = {Abstractive summarization; BERT; Decoder; LLM; Natural language processing (NLP); Pre-trained Language Model; Radiology Report},
	correspondence_address = {R. Reang; Manit Bhopal, Department of Cse, Bhopal, India; email: rujeenareang43@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037024-9},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Commun. Netw. Technol., ICCCNT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rajput2024,
	author = {Rajput, Gunjan and Mathur, Sanjiv},
	title = {Revolutionizing Workflow with AELU: Crafting a High-Precision, Time-Efficient Custom GPT Model},
	year = {2024},
	journal = {5th IEEE International Women in Technology Conference, WINTECHCON 2024},
	doi = {10.1109/WINTECHCON61988.2024.10837929},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217386086&doi=10.1109%2fWINTECHCON61988.2024.10837929&partnerID=40&md5=042e75687eeb0a07bd616346c46fcd48},
	affiliations = {Cadence Design Systems, India},
	abstract = {This paper introduces a groundbreaking method to enhance the accuracy and efficiency of Generative Pre-trained Transformer (GPT) models by integrating BERT and a customized activation function (AF). Through the fusion of BERT’s contextual understanding capabilities and the tailored non linear function ability to capture nuanced patterns in the data, our approach aims to surpass the limitations of traditional GPT models. Leveraging domain-specific knowledge and incorporating additional libraries and models. In extensive experiments, we evaluate the performance of our customized model against baseline BERT architectures and other state-of-the-art models, meticulously assessing accuracy, efficiency, and scalability across a spectrum of tasks and datasets. Our findings demonstrate a remarkable improvement in accuracy, with an average enhancement of 95.6 percent over baseline GPT architectures. Additionally, our customized model exhibits a notable reduction in loss. These results underscore the effectiveness of our approach in elevating both the accuracy and efficiency of LLM model. Through iterative refinement, our customized model aspires to set new benchmarks in language understanding and generation, paving the way for enhanced performance in real-world applications. This research not only contributes to the advancement of customized language model development but also lays the groundwork for future improvements in accuracy, robustness, and versatility. © 2024 IEEE.},
	author_keywords = {BERT; CNN; Generative Pre-trained Transformer; language understanding; model architecture; NLTK; spaCy; Transformers},
	keywords = {BERT; Generative pre-trained transformer; Language understanding; Modeling architecture; NLTK; Performance; Spacy; Transformer; Transformer modeling; Work-flows; Benchmarking},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037407-0},
	language = {English},
	abbrev_source_title = {IEEE Int. Women Technol. Conf., WINTECHCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schwarz2024173,
	author = {Schwarz, Pia},
	title = {Semiautomatic Data Generation for Academic Named Entity Recognition in German Text Corpora},
	year = {2024},
	journal = {20th Conference on Natural Language Processing, KONVENS 2024 - Proceedings of the Conference},
	pages = {173 – 181},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216756206&partnerID=40&md5=a9e6a0a4d26e16416b6dc36b05eb5471},
	affiliations = {Leibniz Institute for the German Language (IDS), R5 6-13, Mannheim, 68161, Germany},
	abstract = {An NER model is trained to recognize three types of entities in academic contexts: person, organization, and research area. Training data is generated semiautomatically from newspaper articles with the help of word lists for the individual entity types, an off-the-shelf NE recognizer, and an LLM. Experiments fine-tuning a BERT model with different strategies of post-processing the automatically generated data result in several NER models achieving overall F1 scores of up to 92.45%. ©2024 Association for Computational Linguistics.},
	keywords = {Data assimilation; Automatically generated; Data generation; Entity-types; Fine tuning; Named entity recognition; Post-processing; Research areas; Text corpora; Training data; Word lists; Computational linguistics},
	correspondence_address = {P. Schwarz; Leibniz Institute for the German Language (IDS), Mannheim, R5 6-13, 68161, Germany; email: schwarz@ids-mannheim.de},
	editor = {de Araujo P.H.L. and Baumann A. and Gromann D. and Krenn B. and Roth B. and Wiegand M. and Heinisch B.},
	publisher = {Association for Computational Linguistics (ACL)},
	language = {English},
	abbrev_source_title = {Conf. Nat. Lang. Process., KONVENS - Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Patil2024,
	author = {Patil, Ratna and Yeolekar, Suyash and Khade, Omkar and Kadam, Yash and Ingole, Prajwal and Patil, Suraj},
	title = {AyUR-bot: A Revolutionary Ayurvedic Chatbot Empowered by Generative AI},
	year = {2024},
	journal = {2024 8th International Conference on Computing, Communication, Control and Automation, ICCUBEA 2024},
	doi = {10.1109/ICCUBEA61740.2024.10774721},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215119982&doi=10.1109%2fICCUBEA61740.2024.10774721&partnerID=40&md5=0b0e4f596f9e9d2ac878dd1170972a05},
	affiliations = {Vishwakarma Institute of Information Technology, Department of Artificial Intelligence and Data Science, Maharashtra, Pune, India},
	abstract = {This study introduces AyUR-bot, a 24/7 Ayurvedic expert chatbot designed for prompt addressing of user queries on nutrition, remedies, and overall wellness. Project objectives include developing an Ayurvedic chatbot using NLP and deep learning, providing accurate responses, optimizing model efficiency, educating users about Ayurveda, and contributing to health and wellness through interactive conversations. The user-friendly chat interface allows effortless query submission. AyUR-bot leverages NLP tools, integrating the Llama 2 Large Language Model (LLM) and implementing Retrieval Augmented Generation (RAG) for question answering, optimizing Ayurvedic knowledge accessibility. The development process involves curating a specialized Ayurvedic document repository and utilizing the Llama 2 LLM model from Hugging Face. AyUR-bot ensures precise responses with unique stopping conditions. Components like the conversational retrieval chain, recursive character text splitter, and embeddings generator synergize for comprehensive responses. Evaluation with BERT Score validates AyUR-bot's effectiveness in delivering context-aware insights. The user-friendly interface enables interactive engagement, facilitating personalized Ayurvedic guidance. This research converges chatbot technology, NLP, and Ayurveda, aligned with project objectives, catering to the growing interest in traditional wellness, democratizing access to Ayurvedic wisdom. AyUR-bot results in a significant advancement in personalized Ayurvedic assistance. © 2024 IEEE.},
	author_keywords = {AyUR-bot; Ayurveda; Conversational Retrieval Chain; FAISS; Hugging Face; LangChain; Natural Language Processing; Retrieval Augmented Generation (RAG); Vector Database},
	keywords = {Bot (Internet); Medicinal chemistry; Nutrition; Query languages; AyUR-bot; Ayurveda; Conversational retrieval chain; FAISS; Hugging face; Langchain; Language processing; Natural language processing; Natural languages; Retrieval augmented generation; Vector database; Deep learning},
	correspondence_address = {R. Patil; Vishwakarma Institute of Information Technology, Department of Artificial Intelligence and Data Science, Pune, Maharashtra, India; email: ratna.nitin.patil@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039177-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput., Commun., Control Autom., ICCUBEA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Deineka2024182,
	author = {Deineka, Oleh and Harasymchuk, Oleh and Partyka, Andrii and Kozachok, Valerii},
	title = {Information classification framework according to SOC 2 Type II},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3826},
	pages = {182 – 189},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210256142&partnerID=40&md5=2b2b893adfd330ff1b3dd157297aaccb},
	affiliations = {Lviv Polytechnic National University, 12 Stepana Bandery str., Lviv, 79000, Ukraine; Borys Grinchenko Kyiv Metropolitan University, 18/2 Bulvarno-Kudryavska str., Kyiv, 04053, Ukraine},
	abstract = {Large Language Models (LLMs) like GPT-3 and BERT, trained on extensive text data, are transforming data management and governance, areas crucial for SOC 2 Type II compliance. LLMs respond to prompts, guiding their output generation, and can automate tasks like data cataloging, enhancing data quality, ensuring data privacy, and assisting in data integration. These capabilities can support a robust data classification policy, a key requirement for SOC 2 Type II. Vector search, another important method in data management, finds similar items to a given item by representing them as vectors in a high-dimensional space. It offers high accuracy, scalability, and flexibility, supporting efficient data classification. Embeddings, which convert categorical data into a form that can be input into a model, play a key role in vector search and LLMs. Prompt engineering, the crafting of effective prompts, is crucial for guiding LLMs’ output, and further enhancing data management and governance practices. © 2024 Copyright for this paper by its authors.},
	author_keywords = {data security; information classification; LLM; prompt; SOC 2 Type II; vector search},
	keywords = {Data accuracy; Data privacy; Data quality; Information management; Classification framework; Data classification; Information classification; Language model; Large language model; Prompt; SOC 2 type II; Text data; Type II; Vector search; Classification (of information)},
	correspondence_address = {V. Kozachok; Borys Grinchenko Kyiv Metropolitan University, Kyiv, 18/2 Bulvarno-Kudryavska str., 04053, Ukraine; email: v.kozachok@kubg.edu.ua},
	editor = {Sokolov V. and Ustimenko V. and Radivilova T. and Nazarkevych M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Martinelli20244853,
	author = {Martinelli, Fabio and Mercaldo, Francesco and Petrillo, Luca and Santone, Antonella},
	title = {A Method for AI-generated sentence detection through Large Language Models},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {4853 – 4862},
	doi = {10.1016/j.procs.2024.09.351},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213404601&doi=10.1016%2fj.procs.2024.09.351&partnerID=40&md5=019a4feb424f3ce9cd8a98cc90b6633e},
	affiliations = {IIT-CNR, Via Giuseppe Moruzzi, 1, PI, Pisa, 56124, Italy; University of Molise, Department of Medicine and Health Sciences Vincenzo Tiberio, CB, Campobasso, 86100, Italy; IMT School for Advanced Studies Lucca, S. Ponziano Square, 6, LU, Lucca, 55100, Italy},
	abstract = {In recent years, we have seen an impressive expansion of a family of artificial intelligence models, known as generative AI, that are capable of producing fresh, unique material, including text, images, audio, and even code. Large datasets of previously published information are used to train these models, enabling them to mimic the patterns and structures of the data and produce original output that is stylistically and qualitatively comparable to the training set. While these models have many promising applications, they also carry significant risks and potential dangers that must be carefully considered, such as misinformation, intellectual property violations, or biased information. For these reasons, in this work, we have proposed a method to detect whether a sentence is human-generated or AI-generated. To achieve this goal, we used a labeled dataset to train four different models from the BERT family, achieving an Accuracy of 96%. © 2024 The Authors.},
	author_keywords = {llm; sentence classification; sentence detection},
	keywords = {Biased information; Intelligence models; Language model; Large datasets; Llm; Property; Sentence classifications; Sentence detection; Text images; Training sets},
	editor = {Flearmoy J.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Gilbert2024265,
	author = {Gilbert and Beatricia, Sherleen and Reinaldo, Albert and Hasani, Muhammad Fikri},
	title = {Text Augmentation for Indonesian Intent Classification: Comparative Study},
	year = {2024},
	journal = {Proceedings - 11th International Conference on Information Technology, Computer and Electrical Engineering, ICITACEE 2024},
	pages = {265 – 270},
	doi = {10.1109/ICITACEE62763.2024.10762810},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214702660&doi=10.1109%2fICITACEE62763.2024.10762810&partnerID=40&md5=9756d17765327709a209a36ec1164920},
	affiliations = {School of Computer Science, Bina Nusantara University, Computer Science Department, Jakarta, 11480, Indonesia},
	abstract = {Several problems occur when doing intent classification, one of them is imbalanced data. Augmentation could be the solution to this problem. There are several methods of augmentation but there has not been any paper compared specific types of augmentation directly to know which method give the best result, especially when the data is in Indonesian language. Moreover, the Indonesian language used in the data is often non-formal. There has been no research that has compared augmentation techniques for Indonesian language. This article compares three types of augmentation: NLP augmentation, Large Language Models, and Easy Data Augmentation to determine whether augmentation affects the intent classification results or not in Indonesian language. This paper also uses a classifier known as Bidirectional Encoder Representations from Transformers (BERT). After several steps from data processing until implementing those 3 augmentation methods, the results show that there was an increase in the data before and after being augmented. LLM is the augmentation method with the best level of accuracy for agent intention with a value of 76.65% and NLPAUG is the best augmentation for visitor intention with a value of 72.26%. © 2024 IEEE.},
	author_keywords = {BERT; EDA; INDOBERT; Intent classification; LLM; NLPAug; Text augmentation},
	keywords = {Data assimilation; Data handling; Formal languages; Augmentation methods; Bidirectional encoder representation from transformer; Comparatives studies; EDA; INDOBERT; Indonesian languages; Intent classification; LLM; NLPAug; Text augmentation; Classification (of information)},
	editor = {Facta M. and Riyadi M.A. and Arfan M. and Soetrisno Y.A.A. and Wulandari A.P.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038928-9},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Inf. Technol., Comput. Electr. Eng., ICITACEE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Moar2024194,
	author = {Moar, Chakshu and Tahmasebi, Faraz and Pellauer, Michael and Kwon, Hyoukjun},
	title = {Characterizing the Accuracy-Efficiency Trade-off of Low-rank Decomposition in Language Models},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Symposium on Workload Characterization, IISWC 2024},
	pages = {194 – 209},
	doi = {10.1109/IISWC63097.2024.00026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214568308&doi=10.1109%2fIISWC63097.2024.00026&partnerID=40&md5=9431d53f003333d1212b976bedcbbdbb},
	affiliations = {University of California, Irvine, Electrical Engineering and Computer Science, Irvine, CA, United States; NVIDIA, Westford, MA, United States},
	abstract = {Recent large language models (LLMs) employ billions of parameters to enable broad problem-solving capabilities. Such language models also tend to be memory-bound because of the dominance of matrix-vector and matrix-matrix multiplications with low arithmetic intensity. Therefore, optimizing the memory footprint and traffic is an important optimization direction for LLMs today. Model compression methods such as quantization and parameter pruning have been actively explored to achieve memory footprint and traffic optimization. However, the accuracy-efficiency trade-off of rank pruning (i.e., low-rank decomposition) for LLMs is not well-understood yet. Therefore, in this work, we characterize the accuracy-efficiency trade-off of a low-rank decomposition method, specifically Tucker decomposition, on recent language models, including an open-source LLM, Llama 2.We formalize the low-rank decomposition design space and show that the decomposition design space is enormous (e.g., O(239) for Llama2-7B). To navigate such a vast design space, we formulate it and perform thorough case studies of accuracy-efficiency trade-offs using six widely used LLM benchmarks on BERT and Llama 2 models. Our results show that we can achieve a 9% model size reduction with minimal accuracy drops, which range from 4%p (%p refers to "percentage point,"which refers to the absolute difference between two percentage numbers; 74% -> 78% = 4%p increase) to 10%p, depending on the difficulty of the benchmark, without any retraining to recover accuracy after decomposition. The results show that low-rank decomposition can be a promising direction for LLM-based applications that require real-time service at scale (e.g., AI agent and real-time coding assistant), where the latency is as important as the model accuracy.  © 2024 IEEE.},
	keywords = {Benchmarking; Modeling languages; Problem oriented languages; Systems analysis; Design spaces; Language model; Low-rank decomposition; Matrix-matrix multiplications; Matrix-vector; Memory bounds; Memory footprint; Problem-solving; Trade off; Vector-matrix multiplications; Matrix algebra},
	correspondence_address = {C. Moar; University of California, Irvine, Electrical Engineering and Computer Science, Irvine, United States; email: cmoar@uci.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035603-8},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Symp. Workload Charact., IISWC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Kukreja2024133,
	author = {Kukreja, Sanjay and Kumar, Tarun and Purohit, Amit and Dasgupta, Abhijit and Guha, Debashis},
	title = {A Literature Survey on Open Source Large Language Models},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {133 – 143},
	doi = {10.1145/3647782.3647803},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197113921&doi=10.1145%2f3647782.3647803&partnerID=40&md5=030e1fc89599c3cc3aa63443d9f32004},
	affiliations = {SP Jain School of Global Management, India; EClerx Services Ltd., India},
	abstract = {Since the 1950s, post the Turing test, humans have been striving hard to make machines learn the art of mastering linguistic intelligence. Language being a complex and intricate tool of expression used by humans, poses a large number of challenges for AI enabled algorithms to grasp its understanding in entirety. Over the past few years, a chain of efforts have been made to make machines understand linguistic intricacies. Small scale models such as BERT and pre-trained language models (PLMs) have demonstrated strong capabilities in understanding and solving various language based tasks. Over the period of years, it is also observed that by increasing the parameters scale to larger size, large language models show a significant improvement in performance and showcase abilities to understand context. For the PLMs of a humongous size i.e in the tune of tens or hundreds of billions of parameters, and to understand the large parametric scales, the scientific community introduced the term LLMs - large language models. The whole world witnessed the launch and quick adoption of ChatGPT, an AI chatbot built on LLMs. As the usage of AI algorithms changes the way the scientific community, society and industry works, it is imperative to review the advances of LLMs. Since 2022, almost daily nearly a dozen LLMs are released. These LLMs are categorized as open and closed source. This paper aims to focus on major aspects of open source LLMs - pre-training covering data collection and pre-processing, model architecture and training. We will select open source models released in June, July and August 2023 with training parameters greater than 70 billion parameters and provide a comprehensive survey on the mentioned aspects. As new models are released on daily / weekly basis in the LLM space, in order to keep the survey concise and targeted to important models, we chose to select time-box of 3 months and a large parameter range of 70 billion in our literature survey. We will also cover historical evolution of LLMs and list open items for future directions.  © 2024 ACM.},
	author_keywords = {Generative AI; Large Language Models; Open Source LLMs},
	keywords = {Adversarial machine learning; Computational linguistics; Generative adversarial networks; List processing languages; Modeling languages; Natural language processing systems; Open source software; Turing machines; Generative AI; Human pose; Language model; Large language model; Learn+; Literature survey; Open source LLM; Open-source; Scientific community; Turing tests; Data acquisition},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071665-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@CONFERENCE{Lai2024196,
	author = {Lai, Jiang and Conghui, Zheng and Xiaohan, Zhang and Fuhui, Sun and Xiaoyan, Wang and Li, Pan},
	title = {Leveraging LLM based Retrieval-Augmented Generation for Legal Knowledge Graph Completion},
	year = {2024},
	journal = {Proceeding - 2024 IEEE 9th International Conference on Data Science in Cyberspace, DSC 2024},
	pages = {196 – 203},
	doi = {10.1109/DSC63484.2024.00033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218447959&doi=10.1109%2fDSC63484.2024.00033&partnerID=40&md5=4d09824edf9b01b6716df2cb9edcfbe7},
	affiliations = {Shanghai Jiao Tong University, Institute of Cyber Science and Technology, School of Electronic Information and Electrical Engineering, Shanghai, China; Information Technology Service Center of People's Court, Beijing, China},
	abstract = {Aiming at filling missing triple structures, Knowledge Graph Completion (KGC) is a crucial task in knowledge graph reasoning. Especially in the judicial domain, it plays a significant role not only in enhancing the completeness of legal knowledge graphs but also in improving the accuracy of legal supervisory inference. Due to extensive legal expertise, complex entity relationships, and strict requirements for interpretable reasoning, traditional methods, such as embedding-based methods and those that utilize pre-trained language models (e.g., BERT), often fail to delve into deep semantic information or overlook the interconnections among triples, which leads to significant shortcomings in generalizability and capabilities in practical applications. Motivated by the great generation power of Large Language Models (LLMs), we propose a legal knowledge graph completion model based on Retrieval Augmented Generation (RAG), which we have named RA-KG-LLM. This model effectively combines the generative capabilities of LLMs with retrieval-augmented technology to enhance the semantic information and interrelations mining within knowledge graphs. The retrieval framework within our model utilizes text embeddings and vector similarity matching to provide the LLM with relevant triples, while fine-tuning techniques are employed to infuse the semantic information from the knowledge graph into the LLM. Extensive experiments on five real datasets demonstrate the effectiveness and potentiality in the judicial field of the proposed model. Specifically, on the legal domain dataset Cail2022, it achieves better Hits@1 score in the relation prediction task than the state-of-the-art related works. © 2024 IEEE.},
	author_keywords = {Judicial Knowledge Graph; Knowledge Graph Completion; Large Language Models; Retrieval-Augmented Generation},
	keywords = {Content based retrieval; Domain Knowledge; Graph embeddings; Modeling languages; Semantics; Judicial knowledge graph; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Legal knowledge; Model-based OPC; Retrieval-augmented generation; Semantics Information; Knowledge graph},
	correspondence_address = {P. Li; Shanghai Jiao Tong University, Institute of Cyber Science and Technology, School of Electronic Information and Electrical Engineering, Shanghai, China; email: panli@sjtu.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039136-7},
	language = {English},
	abbrev_source_title = {Proceeding - IEEE Int. Conf. Data Sci. Cyberspace, DSC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang2024138,
	author = {Wang, Wenmin and Ma, Junpeng and Zhang, Peilin and Hu, Zhuolun and Jiang, Qi and Liu, Yafei},
	title = {Application of Multi-way Recall Fusion Reranking Based on Tensor and ColBERT in RAG},
	year = {2024},
	journal = {2024 IEEE 7th International Conference on Information Systems and Computer Aided Education, ICISCAE 2024},
	pages = {138 – 141},
	doi = {10.1109/ICISCAE62304.2024.10761558},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214673823&doi=10.1109%2fICISCAE62304.2024.10761558&partnerID=40&md5=36e8b52823b27e3ce4f160c978e67955},
	affiliations = {China Mobile Online Service Co., Ltd., Henan, Zhengzhou, 450000, China},
	abstract = {In recent years, Retrieval-Augmented Generation (RAG), as a framework to assist large model (LLM) retrieval enhancement and generation capabilities, has been widely used in the field of natural language processing. However, the recall algorithm, recall rate, precision and recommendation algorithm (Reciprocal Ranker) of different RAG frameworks largely determine the effectiveness of the final retrieval results of large models. This paper proposes a multi-way recall ranking method based on Tensor + ColBERT (Contextualized Late Interaction over BERT) to improve the retrieval part of the RAG system. This method uses the delayed interaction mechanism of ColBERT to improve the diversity and relevance of retrieval results through a multi-path retrieval strategy on the one hand, and uses Tensor to improve the multi-vector MaxSim similarity calculation of ColBERT on the other hand, achieving the efficiency of dual encoders and accurate fusion reranking. Experimental results show that the improved RAG system can significantly improve the recall and precision of retrieval in complex query and long document scenarios, while taking into account the balance of computing resources and processing speed. ©2024 IEEE.},
	author_keywords = {ColBERT; Fusion ReRanker; Multi-way recall; RAG; Tensor},
	keywords = {Modeling languages; Natural language processing systems; Query languages; Query processing; Search engines; Contextualized late interaction over BERT; Fusion reranke; Generation systems; Language processing; Large models; Multi-way recall; Natural languages; Re-ranking; Recall rate; Retrieval-augmented generation; Tensors},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035076-0},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Inf. Syst. Comput. Aided Educ., ICISCAE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Elchafei2024229,
	author = {Elchafei, Passant and Fashwan, Amany},
	title = {Arabic NER Evaluation: Pre-Trained Models via Contrastive Learning vs. LLM Few-Shot Prompting},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {244},
	pages = {229 – 237},
	doi = {10.1016/j.procs.2024.10.196},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211217191&doi=10.1016%2fj.procs.2024.10.196&partnerID=40&md5=0c07df0a7a6cbaed2b737a7252a4d888},
	affiliations = {Computer Science, Ulm University, Germany; Alexandria University, Faculty of Arts, Phonetics and Linguistics Department, Alexandria, Egypt},
	abstract = {Developing Natural Language Processing (NLP) tools for the Arabic language and its dialects is very challenging. Named Entity Recognition (NER) is one of these challenges, which serves as the core component in many NLP systems such as information extraction, question answering, machine translation and knowledge graph building. This paper sheds light on applying diferent approaches for Arabic NER (Flat and Nested) using a large and rich Arabic NER corpus, Wojood dataset, which consists of about 550K tokens annotated with 21 entity types. First, we apply the Wojood base model, AraBERTv2, along with various other Arabic BERT models such as MARBERTv2, CaMelBert, mBert,.etc. Next, we utilize the Bi-Encoder Contrastive Learning (CL) approach, a framework developed by Microsoft, which maps candidate text spans and entity types into the same vector representation space. The primary challenge in this approach is distinguishing non-entity spans from entity mentions. This approach could achieve F1 score 91.25% for Flat and 91.40% for Nested NER. Additionally, for evaluating the predicted NER, we employ Few-Shot prompting on LLaMA, and GPT-3.5 using refined prompt-based strategy. Our findings reveal that LLaMA outperforms GPT3.5. © 2024 Elsevier B.V.. All rights reserved.},
	author_keywords = {Arabic NER; BERT; Contrastive Learning; Few-Shot; GPT3.5; LLaMA; LLM; Named Entity Recognition; Prompt Engineering},
	keywords = {Adversarial machine learning; Knowledge graph; Natural language processing systems; Translation (languages); Vector spaces; Zero-shot learning; Arabic named entity recognition; BERT; Entity-types; Few-shot; Gpt3.5; LLaMA; LLM; Named entity recognition; Prompt engineering; Contrastive Learning},
	correspondence_address = {P. Elchafei; Computer Science, Ulm University, Germany; email: passant.elchafei@gmail.com},
	editor = {Shaalan K. and El-Beltagy S.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Bowen2024,
	author = {Bowen, Matthew and Smith, Logan and Carroll, Cody and Morkos, Beshoy},
	title = {LEVERAGING LATENT TEXTUAL TOPOLOGY FOR STANDARD IDENTIFICATION IN ENGINEERING DESIGN},
	year = {2024},
	journal = {Proceedings of the ASME Design Engineering Technical Conference},
	volume = {2B-2024},
	doi = {10.1115/DETC2024-146285},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210827602&doi=10.1115%2fDETC2024-146285&partnerID=40&md5=3fb1af24b46c2790030e854701653734},
	affiliations = {University of Georgia, Athens, GA, United States},
	abstract = {In engineering design, standards are instrumental in providing technical definitions and guidelines to designers, manufacturers, and users, reflecting best practices that are widely recognized. These standards, numbering in the hundreds of thousands, encapsulate the current state of technological expertise and aim to promote safety, reliability, productivity, and efficiency in both component and system design. Despite the clear value of standards, the vast quantity and diversity of these documents present significant challenges for designers in retrieving and implementing the appropriate standards for their projects. Moreover, the significant amount of time design engineers exhaust navigating through technical documentation highlights the necessity for more effective methods of engaging with the textual knowledge base represented by engineering standards, as the current manual process is inefficient and time-intensive. This presents an even greater challenge for small and medium-sized enterprises (SMEs) lacking the requisite personnel to adeptly navigate evolving standards. To bridge this gap, this research develops a fundamental understanding of language embeddings and large language models to assist in navigating engineering standards. This work examines the efficacy of three semantic-based approaches for engineering standard retrieval and further validates these approaches through an industry case study. Additionally, the Standards Augmented Requirements Generator (SARG) tool is presented, which provides a domain-specific approach to leveraging Retrieval Augmented Generation (RAG) in design contexts. Copyright © 2024 by ASME.},
	author_keywords = {BERT; Engineering Design; GPT-4; LLM; Requirements; Standards},
	keywords = {Bridge approaches; Integrated circuit design; Machine design; Requirements engineering; Thesauri; 'current; BERT; Best practices; Design standard; Engineering design; Engineering standards; GPT-4; LLM; Requirement; Time design; Semantics},
	correspondence_address = {B. Morkos; University of Georgia, Athens, United States; email: bmorkos@uga.edu},
	publisher = {American Society of Mechanical Engineers (ASME)},
	isbn = {978-079188835-3},
	language = {English},
	abbrev_source_title = {Proc. ASME Des. Eng. Tech. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jaganathan2024153,
	author = {Jaganathan, Vishnu and Gouda, Deepak and Arora, Kriti and Aggarwal, Mohit and Zhang, Chao},
	title = {Demo: On-Device Video Analysis with LLMs},
	year = {2024},
	journal = {HOTMOBILE 2024  - Proceedings of the 2024 25th International Workshop on Mobile Computing Systems and Applications},
	pages = {153},
	doi = {10.1145/3638550.3643052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187201621&doi=10.1145%2f3638550.3643052&partnerID=40&md5=e425e6c567e4599632663135b41659fa},
	affiliations = {Georgia Institute of Technology, Atlanta, GA, United States},
	abstract = {We present a new on-device pipeline that efficiently summarizes lecture videos and provides relevant answers directly from a smartphone. We utilize widely accessible tools like OCR and Vosk speech-to-text, coupled with powerful large language models (LLMs), to identify crucial sentences and generate summaries. By harnessing the capabilities of LLMs and the computational power of mobile devices, we fine-tune and quantize BERT and GPT-2 to achieve efficient lecture video summarization and question answering on consumer-grade smartphones like the Pixel 8 Pro. Notably, this approach eliminates the need for cloud APIs, ensuring enhanced user privacy and minimal mobile data usage. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {LLM; on-device ML; video understanding},
	keywords = {Natural language processing systems; Computational power; Language model; Large language model; Lecture video; On-device ML; Question Answering; Smart phones; Video analysis; Video summarization; Video understanding; Smartphones},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070497-0},
	language = {English},
	abbrev_source_title = {HOTMOBILE - Proc. Int. Workshop Mob. Comput. Syst. Appl.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}@CONFERENCE{Min20242985,
	author = {Min, Qingkai and Guo, Qipeng and Hu, Xiangkun and Huang, Songfang and Zhang, Zheng and Zhang, Yue},
	title = {Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {2985 – 3002},
	doi = {10.18653/v1/2024.acl-long.164},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202044332&doi=10.18653%2fv1%2f2024.acl-long.164&partnerID=40&md5=5e342c3d3c165d5d8b6b118aac667881},
	affiliations = {Zhejiang University, China; School of Engineering, Westlake University, China; Shanghai AI Laboratory, China; Fudan University, China; Alibaba DAMO Academy; New York University Shanghai, United States; Institute of Advanced Technology, Westlake Institute for Advanced Study, China},
	abstract = {Cross-document event coreference resolution (CDECR) involves clustering event mentions across multiple documents that refer to the same real-world events. Existing approaches utilize fine-tuning of small language models (SLMs) like BERT to address the compatibility among the contexts of event mentions. However, due to the complexity and diversity of contexts, these models are prone to learning simple co-occurrences. Recently, large language models (LLMs) like ChatGPT have demonstrated impressive contextual understanding, yet they encounter challenges in adapting to specific information extraction (IE) tasks. In this paper, we propose a collaborative approach for CDECR, leveraging the capabilities of both a universally capable LLM and a task-specific SLM. The collaborative strategy begins with the LLM accurately and comprehensively summarizing events through prompting. Then, the SLM refines its learning of event representations based on these insights during fine-tuning. Experimental results demonstrate that our approach surpasses the performance of both the large and small language models individually, forming a complementary advantage. Across various datasets, our approach achieves state-of-the-art performance, underscoring its effectiveness in diverse scenarios. © 2024 Association for Computational Linguistics.},
	keywords = {Data mining; Information retrieval; Clusterings; Collaborative approach; Coreference resolution; Cross documents; Fine tuning; Language model; Multiple documents; Real-world; Simple++; Synergetics; Computational linguistics},
	correspondence_address = {Y. Zhang; School of Engineering, Westlake University, China; email: zhangyue@westlake.edu.cn},
	editor = {Ku L.-W. and Martins A.F.T. and Srikumar V.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {979-889176094-3},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Alhamed20243250,
	author = {Alhamed, Falwah and Ive, Julia and Specia, Lucia},
	title = {Classifying Social Media Users Before and After Depression Diagnosis via their Language Usage: A Dataset and Study},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {3250 – 3260},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195941660&partnerID=40&md5=d4f084a7106867d0c5ec433d07b396b3},
	affiliations = {Department of Computing, Imperial College London, London, United Kingdom; King Abdulaziz City for Science and Technology(KACST), Riyadh, Saudi Arabia; Queen Mary University of London, London, United Kingdom},
	abstract = {Mental illness can significantly impact individuals' quality of life. Analysing social media data to uncover potential mental health issues in individuals via their posts is a popular research direction. However, most studies focus on the classification of users suffering from depression versus healthy users, or on the detection of suicidal thoughts. In this paper, we instead aim to understand and model linguistic changes that occur when users transition from a healthy to an unhealthy state. Addressing this gap could lead to better approaches for earlier depression detection when signs are not as obvious as in cases of severe depression or suicidal ideation. In order to achieve this goal, we have collected the first dataset of textual posts by the same users before and after reportedly being diagnosed with depression. We then use this data to build multiple predictive models (based on SVM, Random Forests, BERT, RoBERTa, MentalBERT, GPT-3, GPT-3.5, Bard, and Alpaca) for the task of classifying user posts. Transformer-based models achieved the best performance, while large language models used off-the-shelf proved less effective as they produced random guesses (GPT and Bard) or hallucinations (Alpaca). © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {BERT; Dataset; Depression classification; GPT; Lexicon; LLM; Mental Health; NLP; Social Media; Twitter; X},
	keywords = {Chemical detection; Diseases; Natural language processing systems; Social networking (online); Support vector machines; BERT; Dataset; Depression classification; GPT; Lexicon; LLM; Mental health; Social media; Twitter; X; Classification (of information)},
	editor = {Calzolari N. and Kan M.-Y. and Hoste V. and Lenci A. and Sakti S. and Xue N.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381410-4},
	language = {English},
	abbrev_source_title = {Jt. Int. Conf. Comput. Linguist., Lang. Resour. Eval., LREC-COLING - Main Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@BOOK{Dang2024173,
	author = {Dang, Nguyen Ngoc Hai and Thanh, Tho Quan and Nguyen-Duc, Anh},
	title = {BERTVRepair: On the Adoption of CodeBERT for Automated Vulnerability Code Repair},
	year = {2024},
	journal = {Generative AI for Effective Software Development},
	pages = {173 – 196},
	doi = {10.1007/978-3-031-55642-5_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205629497&doi=10.1007%2f978-3-031-55642-5_8&partnerID=40&md5=dcc1a4bc57be22d954c307201cca61df},
	affiliations = {Ho Chi Minh University of Technology, Ho Chi Minh City, Viet Nam; Vietnam National University, Ho Chi Minh City, Viet Nam; University of South Eastern, Notodden, Norway},
	abstract = {Vulnerable code continues to have a significant impact to software quality, leading to serious consequences such as economic loss, privacy breaches, and threats to national security. Traditional methods of detecting and addressing software security issues are often time-consuming and resource-intensive. This research aims to examine the effectiveness of generative-based methods, particu-larly those leveraging generative (DL) models like CodeBERT, in repairing code and addressing software vulnerabilities. Our research question (RQ) is: Can the adoption of CodeBERT extend the capabilities of vulnerability code repair, and, if so, to what extent? We proposed a new approach called BERTVRepair that adopts CodeBERT and state-of-the-art transfer learning and tokenization methods to generate vulnerable code patches. We performed an experiment to compare the performance of BERTVRepair with existing models. We showed a marginal improvement in accuracy and perplexity. We conclude that using generative-based methods like CodeBERT, with its code embedding extraction and transfer learning approaches, can potentially enhance the process of software vulnerability repair. This research contributes to adopting large programming language models into software engineering tasks, such as automated code repair. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {BERT; Code LLM; Code repair; Large language model; Vulnerability},
	correspondence_address = {N.N.H. Dang; Ho Chi Minh University of Technology, Ho Chi Minh City, Viet Nam; email: qttho@hcmut.edu.vn},
	publisher = {Springer Nature},
	isbn = {978-303155642-5; 978-303155641-8},
	language = {English},
	abbrev_source_title = {Generative AI for Effective Softw. Development},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Manir2024114670,
	author = {Manir, Shamiha Binta and Islam, K. M. Sajjadul and Madiraju, Praveen and Deshpande, Priya},
	title = {LLM-Based Text Prediction and Question Answer Models for Aphasia Speech},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {114670 – 114680},
	doi = {10.1109/ACCESS.2024.3443592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201260982&doi=10.1109%2fACCESS.2024.3443592&partnerID=40&md5=ceb25af166811dd701ee5872ca49b89c},
	affiliations = {Marquette University, Department of EECE, Milwaukee, 53233, WI, United States; Marquette University, Department of CS, Milwaukee, 53233, WI, United States},
	abstract = {Aphasia, a brain injury-related linguistic problem, hinders communication. Current techniques generally struggle to handle aphasic speech's intricacies. BERT, short for Bidirectional Encoder Representations from Transformers, is a pre-trained natural language model that utilizes contextual information from both preceding and succeeding words in a sentence to predict the target word. This study uses BERT models to predict and fill in sentences for people with aphasia, using the AphasiaBank dataset. The patients' transcripts were thoroughly preprocessed, with nonverbal clues and redundant phrases removed. Because of the lack of control data, the accuracy of BERT in predicting masked tokens in aphasic speech was evaluated using a manual rating system with four raters. In addition, BERT was used for question-answering to increase context comprehension, underlining its ability to aid communication for those with aphasia. The preprocessing pipeline used advanced text-cleaning algorithms to ensure input data quality. The evaluation of BERT performance yielded satisfactory results with strong inter-rater reliability. The inter-rater correlation was remarkably strong, overall coefficients ranging from 0.61 to 0.74, suggesting a substantial level of agreement (Fleiss' Kappa Score: 0.32). BERT's predictions demonstrated a significant degree of contextual relevance and grammatical accuracy, as proven by ratings that were primarily above 3.0. The box plots also suggested a minimal number of outliers. The goal of this method is to improve the accuracy of speech prediction, which is beneficial for caregivers and speech therapists. BERT shows its nuanced capability in Aphasia sentence completion tests by exhibiting exceptional performance in terms of contextual appropriateness and grammatical correctness, as confirmed by manual evaluation.  © 2013 IEEE.},
	author_keywords = {Aphasia; AphasiaBank; BERT models; communication aids; natural language processing (NLP); patient-spoken transcripts; sentence completion; speech prediction; speech therapy; text preprocessing; transformer models},
	keywords = {Electric transformer testing; Encoding (symbols); Hospital data processing; Job analysis; Linguistics; Patient treatment; Prediction models; Question answering; Speech analysis; Speech enhancement; Aphasia; Aphasiabank; BERT model; Communication aids; Encodings; Language processing; Natural language processing; Natural languages; Patient-spoken transcript; Predictive models; Sentence completions; Speech prediction; Speech therapy; Task analysis; Text preprocessing; Transformer modeling; Natural language processing systems},
	correspondence_address = {S.B. Manir; Marquette University, Department of EECE, Milwaukee, 53233, United States; email: shamihabinta.manir@marquette.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Chan202439,
	author = {Chan, Pak Yuen Patrick and Keung, Jacky},
	title = {A Symmetric Metamorphic Relations Approach Supporting LLM for Education Technology},
	year = {2024},
	journal = {Proceedings - 2024 International Symposium on Educational Technology, ISET 2024},
	pages = {39 – 43},
	doi = {10.1109/ISET61814.2024.00017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206563930&doi=10.1109%2fISET61814.2024.00017&partnerID=40&md5=2d9fb01e2f7da8736ce35f78c7cee417},
	affiliations = {City University of Hong Kong, Department of Computer Science, Kowloon, Hong Kong},
	abstract = {Question-Answering (Q&A) educational websites are widely used as self-learning platforms, and pre-trained large language models (LLMs) play a crucial role in maintaining content quality. Despite their usefulness, LLMs still fall short of human performance. To tackle this issue, we propose leveraging symmetric Metamorphic Relations (MRs) to enhance LLMs' performance by improving their machine common sense. The goal is to ensure that learners receive more relevant content. This work presents an empirical experiment using one specific symmetric MR, three LLMs, and a publicly available dataset of labelled Stack Overflow data. We employ the symmetric MR to generate training data that augments the machine common sense of LLMs. Additionally, we prepare a separate set of training data consisting of labelled Stack Overflow data for comparison purposes. By comparing the results of a common ability test and the predictions made by LLMs trained with different training datasets, we can assess the potential practicality of our proposed approach. Our experimental results demonstrate that a Bert-based LLM trained with MR-generated data outperforms a Bert-based LLM trained solely with regular labelled data. This outcome highlights the effectiveness of symmetric MRs in enhancing LLMs' performance by improving their machine common sense. Subsequent studies can extend our approach to other domains related to education technology and explore additional MRs to further enhance the study experience of students.  © 2024 IEEE.},
	author_keywords = {Content quality prediction; large language model; machine common sense; metamorphic relations; natural language processing data augmentation; question-answering (Q&A) website},
	keywords = {Contrastive Learning; Labeled data; Modeling languages; Natural language processing systems; Spatio-temporal data; Common sense; Content quality prediction; Contents qualities; Data augmentation; Language model; Language processing; Large language model; Machine common sense; Metamorphic relations; Natural language processing data augmentation; Natural languages; Quality prediction; Question Answering; Question-answering  website; Adversarial machine learning},
	correspondence_address = {P.Y.P. Chan; City University of Hong Kong, Department of Computer Science, Kowloon, Hong Kong; email: ppychan2-c@my.cityu.edu.hk},
	editor = {Chui K.T. and Hui Y.K. and Yang D. and Lee L.-K. and Wong L.-P. and Reynolds B.L.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036141-4},
	language = {English},
	abbrev_source_title = {Proc. - Int. Symp. Educ. Technol., ISET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bayazed2024,
	author = {Bayazed, Afnan and Almagrabi, Hana and Alahmadi, Dimah and Alghamdi, Hanan},
	title = {ACOM: Arabic Comparative Opinion Mining in Social Media Utilizing Word Embedding, Deep Learning Model & LLM-GPT},
	year = {2024},
	journal = {IEEE Access},
	doi = {10.1109/ACCESS.2024.3476336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207281435&doi=10.1109%2fACCESS.2024.3476336&partnerID=40&md5=4a03ea23487227483c004fb73a951783},
	affiliations = {King Abdulaziz University, Faculty of Computing and Information Technology, Information System Department, Jeddah, 21589, Saudi Arabia},
	abstract = {Reliance on social networks has become an integral part of modern daily activities. Social networks are crowded with vast numbers of comments, opinions, and beliefs about different aspects of people's daily lives. Opinions can directly express positive or negative perspectives toward a specific entity or its aspects, or they can be comparative opinions that present the differences or similarities between two or more entities, such as 'product A is better than product B.'' Comparative opinions have significant potential to offer new opportunities across various fields such as marketing, education, and e-commerce. Thus, analyzing comparative opinions is essential. Indeed, comparative opinion mining has been applied in several languages, including Arabic. Nevertheless, comparative opinion mining in Arabic is still in its early stages and requires more contributions and investigations. Therefore, this work introduces the ACOM approach for Arabic Comparative Opinion Mining. First, we collected the ACOM corpus in Arabic from the X platform, focusing on comparative opinions in the technology domain. This paper provides a benchmark comparison of several deep-learning models by employing different approaches, including Long Short-Term Memory (LSTM), Bidirectional LSTMs (BiLSTM), and Convolutional Neural Networks (CNN). In the deep learning model, the generated representation vector was used to construct the embedding layer as the first layer. To this end, we adopted two pretrained word embedding techniques to investigate their effectiveness on the ACOM corpus: Word2vec and Bidirectional Encoder Representations from Transformers (BERT). The main highlight of this paper is leveraging the most advanced innovation in AI, the GPT-3 model, as a classifier model. Our experimental results show that BERT and BiLSTM achieved impressive performance on the ACOM task with 91% accuracy and a 90% F1-score. Additionally, this paper discusses the impact of fine-tuning specific hyperparameters by providing a comprehensive examination.  © 2013 IEEE.},
	author_keywords = {comparative opinion mining; deep learning; GPT; LLM; Opinion mining; word embedding},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Labrak20242049,
	author = {Labrak, Yanis and Rouvier, Mickael and Dufour, Richard},
	title = {A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {2049 – 2066},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195928334&partnerID=40&md5=17deeeba912ffcd71dd487ce09487f60},
	affiliations = {LIA, Avignon Université, France; Zenidoc, France; Nantes Université, École Centrale Nantes, CNRS, LS2N, UMR 6004, Nantes, F-44000, France},
	abstract = {The recent emergence of Large Language Models (LLMs) has enabled significant advances in the field of Natural Language Processing (NLP). While these new models have demonstrated superior performance on various tasks, their application and potential are still underexplored, both in terms of the diversity of tasks they can handle and their domain of application. In this context, we evaluate four state-of-the-art instruction-tuned LLMs (ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca) on a set of 13 real-world clinical and biomedical NLP tasks in English, including named-entity recognition (NER), question-answering (QA), relation extraction (RE), and more. Our overall results show that these evaluated LLMs approach the performance of state-of-the-art models in zero- and few-shot scenarios for most tasks, particularly excelling in the QA task, even though they have never encountered examples from these tasks before. However, we also observe that the classification and RE tasks fall short of the performance achievable with specifically trained models designed for the medical field, such as PubMedBERT. Finally, we note that no single LLM outperforms all others across all studied tasks, with some models proving more suitable for certain tasks than others. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Benchmarking; BERT; Biomedical; Clinical; Large Language Models; Medical domain; NLP evaluation; Transformers},
	keywords = {Computational linguistics; Zero-shot learning; BERT; Biomedical; Clinical; Language model; Language processing; Large language model; Medical domains; Natural language processing evaluation; Natural languages; Transformer; Natural language processing systems},
	correspondence_address = {; ; },
	editor = {Calzolari N. and Kan M.-Y. and Hoste V. and Lenci A. and Sakti S. and Xue N.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381410-4},
	language = {English},
	abbrev_source_title = {Jt. Int. Conf. Comput. Linguist., Lang. Resour. Eval., LREC-COLING - Main Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Regneri20244697,
	author = {Regneri, Michaela and Abdelhalim, Alhassan and Laue, Sören},
	title = {Detecting Conceptual Abstraction in LLMs},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {4697 – 4704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195951631&partnerID=40&md5=6944a1cd90cc4cf10d5bd68af267be48},
	affiliations = {Universität Hamburg, Dept. of Computer Science, Machine Learning Research Group, Hamburg, Germany},
	abstract = {We present a novel approach to detecting noun abstraction within a large language model (LLM). Starting from a psychologically motivated set of noun pairs in taxonomic relationships, we instantiate surface patterns indicating hypernymy and analyze the attention matrices produced by BERT. We compare the results to two sets of counterfactuals and show that we can detect hypernymy in the abstraction mechanism, which cannot solely be related to the distributional similarity of noun pairs. Our findings are a first step towards the explainability of conceptual abstraction in LLMs. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {abstraction; attention; explainability; transformers},
	keywords = {Abstraction; Abstraction mechanism; Attention; Counterfactuals; Distributional similarities; Explainability; Language model; matrix; Surface pattern; Transformer},
	editor = {Calzolari N. and Kan M.-Y. and Hoste V. and Lenci A. and Sakti S. and Xue N.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381410-4},
	language = {English},
	abbrev_source_title = {Jt. Int. Conf. Comput. Linguist., Lang. Resour. Eval., LREC-COLING - Main Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{dos Santos2024531,
	author = {dos Santos, Vitor Gaboardi and Santos, Guto Leoni and Lynn, Theo and Benatallah, Boualem},
	title = {Identifying Citizen-Related Issues from Social Media Using LLM-Based Data Augmentation},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14663 LNCS},
	pages = {531 – 546},
	doi = {10.1007/978-3-031-61057-8_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196742027&doi=10.1007%2f978-3-031-61057-8_31&partnerID=40&md5=1cc5fd19a3cd8e4b3b3d2736bc1b65d5},
	affiliations = {Dublin City University, Dublin, Ireland},
	abstract = {Social media platforms, such as Twitter, offer an accessible way for people to share information and perspectives on a wide range of topics. Such citizen discourse can be a valuable source of information and offer policymakers and researchers insights into public sentiment, needs, and suggestions, guiding more informed and responsive planning and policy decisions. In this paper, we propose a novel approach using Large Language Models (LLMs) for data augmentation and multi-class classification to extract domain-specific data from tweets and identify issues raised by citizens thus providing policymakers and social science researchers with valuable data to formulate effective plans and policies for improving services. This approach involves initially collecting data from Twitter using specific keywords and manually labelling a subset of the acquired data. Then, we introduce a new data augmentation strategy employing a LLM that leverages the initial human-labelled data to enhance text diversity and address imbalances in the dataset. Finally, we use the manual-labelled and augmented data to fine-tune different LLMs to classify texts across multiple topics. We test our approach considering the identification of issues related to the cycling domain as case study, detecting tweets across eleven categories associated with infrastructure, safety, and accidents. Through fine-tuning BERT-based models and experimenting with zero- and few-shot prompts with GPT for tweet classification, we accomplished an accuracy of up to 90.9%. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {BERT; Cycling; GPT; LLM; Tweet classification},
	keywords = {Social networking (online); BERT; Cycling; Data augmentation; GPT; Language model; Large language model; Model-based OPC; Policy makers; Social media; Tweet classification; Classification (of information)},
	correspondence_address = {V.G. dos Santos; Dublin City University, Dublin, Ireland; email: vitorgaboardidos.santos@dcu.ie},
	editor = {Guizzardi G. and Santoro F. and Mouratidis H. and Soffer P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303161056-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Hu2024,
	author = {Hu, Xinghang},
	title = {Optimizing answer selection in community question answering through pre-trained and large language models},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13286},
	doi = {10.1117/12.3045190},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207052788&doi=10.1117%2f12.3045190&partnerID=40&md5=4dc5f6aa435dc5b79e34c7057c8dbcf3},
	affiliations = {Sichuan University, No.24 South Section 1, Yihuan Road, Sichuan, Chengdu, 610065, China},
	abstract = {Community Question Answering (CQA) has become increasingly prevalent in recent years. However, the large volume of answers poses a challenge for users in identifying the most pertinent ones, thereby making answer selection a vital subtask within CQA. In this paper, we introduce the Question-Answer cross attention networks (QAN) with pre-trained models for improved answer selection and leverage large language models (LLMs) for enhanced answer selection with knowledge augmentation. Specifically, we utilize the BERT model as the encoder layer to pre-train on question subjects, question bodies, and answers separately. The cross attention mechanism is then used to identify the most relevant answers for different questions. Our experimental results demonstrate that the QAN model attains state-of-the-art performance on the SemEval2015 and SemEval2017 datasets. Additionally, we use LLMs to generate external knowledge from questions and correct answers, enhancing the answer selection task. By optimizing the LLM prompts in various aspects, we found that incorporating external knowledge improves the correct answer selection rate on both the SemEval2015 and SemEval2017 datasets. Moreover, optimized prompts enable LLMs to select the correct answers for a greater number of questions. © 2024 SPIE.},
	author_keywords = {Cross attention; Knowledge augmentation; Large language model; Prompt optimization},
	keywords = {Photons; Community question answering; Cross attention; External knowledge; Knowledge augmentation; Language model; Large language model; Large volumes; Optimisations; Prompt optimization; Subtask; Modeling languages},
	correspondence_address = {X. Hu; Sichuan University, Chengdu, No.24 South Section 1, Yihuan Road, Sichuan, 610065, China; email: foolofatook@163.com},
	editor = {Yin F. and Zhan Z.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151068314-3},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schonle2024134,
	author = {Schonle, Daniel and Reich, Christoph and Abdeslam, Djaffar Ould},
	title = {Linguistic-Aware WordPiece Tokenization: Semantic Enrichment and OOV Mitigation},
	year = {2024},
	journal = {2024 6th International Conference on Natural Language Processing, ICNLP 2024},
	pages = {134 – 142},
	doi = {10.1109/ICNLP60986.2024.10692355},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207647796&doi=10.1109%2fICNLP60986.2024.10692355&partnerID=40&md5=f1e58bf0e07c5555065a11c58035a486},
	affiliations = {Furtwangen University, Idacus Insitute, Furtwangen, Germany; Université de Haute Alsace, Institut Irimas, Mulhouse, France},
	abstract = {The LinPair approach introduces an approach to tokenization, tackling challenges in processing textual data for machine learning applications. This method refines the Word-Piece Tokenization technique by incorporating linguistic insights into token-tag pairs, thereby enriching Large Language Models (LLMs) with syntactic information. LinPair Tokenization is articulated through two distinct strategies: CompleteLinPair Tokenization, which is tailored for smaller datasets and enriches each token with part-of-speech (POS) information, and SmartLinPair Tokenization, designed to mitigate the impact of out-of-vocabulary (OOV) occurrences. The experimental analysis indicates that SmartLinPair Tokenization improves text classification tasks with BERT, showing an increase in F1-Score of up to 13.9% compared to a WordPiece baseline. The CompleteLinPair Tokenization method results in a decrease in classification performance. It is important to note that these findings are experiment specific and may not be generalizable to other contexts. © 2024 IEEE.},
	author_keywords = {linguistic; llm; machine learning; nlp; tokenization},
	keywords = {Adversarial machine learning; Modeling languages; Language model; Llm; Machine learning applications; Machine-learning; Nlp; Semantic enrichment; Small data set; Syntactic information; Textual data; Tokenization; Semantics},
	correspondence_address = {D. Schonle; Furtwangen University, Idacus Insitute, Furtwangen, Germany; email: schonledanielhfu@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835034911-5},
	language = {English},
	abbrev_source_title = {Int. Conf. Nat. Lang. Process., ICNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Huang20241750,
	author = {Huang, Zien},
	title = {An Ensemble LLM Framework of Text Recognition Based on BERT and BPE Tokenization},
	year = {2024},
	journal = {2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2024},
	pages = {1750 – 1754},
	doi = {10.1109/AINIT61980.2024.10581466},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199135647&doi=10.1109%2fAINIT61980.2024.10581466&partnerID=40&md5=fdfea955af01366dd51fd47c8c464634},
	affiliations = {High School Attached To Beijing Normal University, The International Department of The Experimental, Beijing, China},
	abstract = {Given how quickly artificial intelligence is developing, Large Language Models (LLMs) such as GPT and BERT have achieved significant performance in text generation and language understanding. These models, trained on massive data sets, can now highly imitative human writing styles and the logic of human thinking, making the text they generate difficult to distinguish from human-written text in certain contexts. As the text generation capabilities of LLMs become increasingly powerful, the text automatically generated by machines may lead to misinformation and the spread of false content. The ability to discriminate between writing created by machines and text written by humans is becoming more and more crucial in both academics and industry. Developing effective identification methods for precise judgment of text has significant practical significance. Therefore, this study aims to explore a method to differentiate between human-written and LLM-generated texts. This paper discusses an integrated framework that uses the Byte-Pair Encoding (BPE) tokenization method to segment text, separately trains and constructs a deep learning model based on BERT fine-tuning, and a traditional machine learning model, combined with ensemble learning algorithms, to train an efficient classifier. The purpose of this classifier is to identify whether a piece of text is generated by a machine. The final model performs excellently on the test sets. This research is not only of great significance to academic research but also has practical application value in the authenticity identification of texts in news media, the publishing industry, and even at the legal level. © 2024 IEEE.},
	author_keywords = {BERT; BPE; Ensemble Model; LLM; Text Recognition},
	keywords = {Character recognition; Learning algorithms; BERT; Byte-pair encoding; Ensemble models; Language model; Large language model; Modelling framework; Performance; Text generations; Text recognition; Tokenization; Deep learning},
	correspondence_address = {Z. Huang; High School Attached To Beijing Normal University, The International Department of The Experimental, Beijing, China; email: keane_huangzien@163.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038555-7},
	language = {English},
	abbrev_source_title = {Int. Semin. Artif. Intell., Netw. Inf. Technol., AINIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Archanaa2024,
	author = {Archanaa, N. and Shivanesh, B. and Suwin Kumar, J.D.T. and Bharathi Mohan, G. and Doss, Srinath},
	title = {Comparative Analysis of News Articles Summarization using LLMs},
	year = {2024},
	journal = {2024 Asia Pacific Conference on Innovation in Technology, APCIT 2024},
	doi = {10.1109/APCIT62007.2024.10673458},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205590793&doi=10.1109%2fAPCIT62007.2024.10673458&partnerID=40&md5=117bca9ecf6dd52ce15d8749c3393448},
	affiliations = {Amrita Vishwa Vidyapeetham, Amrita School of Computing, Department of Computer Science and Engineering, Chennai, India; Botho University, Faculty of Engineering and Technology, Botswana},
	abstract = {In the rapidly evolving domain of Natural Language Processing (NLP), the efficiency of Large Language Models (LLMs) in generating abstractive text summaries plays a pivotal role in information synthesis. This study advances the understanding of LLM performance by conducting a comprehensive evaluation of seven cutting-edge models on four distinct datasets. The models selected for comparison include Distilbart-cnn-12-6, Led-base-16384, Google's Bigbird, Microsoft's ProphetNet, Facebook's BART, T5 fine-tuned, and Google's PEGASUS. Each model's summarization prowess is rigorously assessed using a battery of metrics: ROUGE, METEOR, BERTScore, Cosine Similarity, and BLEU. The goal is to discern the intricate relationship between dataset characteristics and model efficacy, delivering insights into the inherent advantages and limitations of each model in handling specific data contexts. The results contribute to a refined understanding of LLM applicability, offering empirical evidence to aid in the selection of the most suitable model for varied summarization needs. © 2024 IEEE.},
	author_keywords = {BART; BERT Score; Bigbird; BLEU Score; Cosine similarity; Distilbart-cnn-12-6; Led-base-16384; METEOR Score; PEGASUS; ProphetNet; ROUGE Metrics; T5 Model},
	keywords = {Large datasets; Metadata; Network security; BART; BERT score; Bigbird; BLEU score; Cosine similarity; Distilbart-cnn-12-6; Lead-base-16384; METEOR score; PEGASIS; Pegasus; Prophetnet; ROUGE metric; T5 model; Natural language processing systems},
	correspondence_address = {N. Archanaa; Amrita Vishwa Vidyapeetham, Amrita School of Computing, Department of Computer Science and Engineering, Chennai, India; email: nkanniga04@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036153-7},
	language = {English},
	abbrev_source_title = {Asia Pac. Conf. Innov. Technol., APCIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nowacki202435,
	author = {Nowacki, Arkadiusz and Sitek, Wojciech and Rybiński, Henryk},
	title = {LLMental: Classification of Mental Disorders with Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14670 LNAI},
	pages = {35 – 44},
	doi = {10.1007/978-3-031-62700-2_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197886996&doi=10.1007%2f978-3-031-62700-2_4&partnerID=40&md5=c79457413ff71e4723de5ac4bc2b2398},
	affiliations = {Institute of Computer Science, Warsaw University of Technology, Warsaw, Poland},
	abstract = {The increasing number of mental disorders is a severe problem in the modern world and can even lead to suicide if left untreated. In the age of digitalization, we move part of our lives to social media, where we share both the good and the bad moments. This allows for the early detection of mental disorders (such as depression, excessive stress, or social phobia) of which the user may even be unaware. We propose to modify large language models, such as PHI-2, Mistral, Flan-T5, or LLaMA 2, to classify mental disorders and to add appropriate layers. This gives a better prediction performance than zero-shot/few-shot for LLMs and classification by BERT-based models. Using such an architecture makes it possible to return a label rather than text, thus allowing the output of the LLM model to be freely modified. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {large language models; mental disorders classification; mental health analysis; social media},
	keywords = {Social networking (online); Zero-shot learning; Language model; Large language model; Mental disorder classification; Mental disorders; Mental health; Mental health analyse; Prediction performance; Social media; Social phobias; Computational linguistics},
	correspondence_address = {A. Nowacki; Institute of Computer Science, Warsaw University of Technology, Warsaw, Poland; email: arkadiusz.nowacki.stud@pw.edu.pl},
	editor = {Appice A. and Azzag H. and Hacid M.-S. and Hadjali A. and Ras Z.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303162699-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Xu2024175,
	author = {Xu, Hongling and Zhang, Delong and Zhang, Yice and Xu, Ruifeng},
	title = {HITSZ-HLT at SIGHAN-2024 dimABSA Task: Integrating BERT and LLM for Chinese Dimensional Aspect-Based Sentiment Analysis},
	year = {2024},
	journal = {SIGHAN 2024 - 10th SIGHAN Workshop on Chinese Language Processing, Proceedings of the Workshop},
	pages = {175 – 185},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204878735&partnerID=40&md5=0f561bfa7ded31e5090dae1c4958cc09},
	affiliations = {Harbin Institute of Technology, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies, China},
	abstract = {This paper presents the winning system participating in the ACL 2024 workshop SIGHAN-10 shared task: Chinese dimensional aspect-based sentiment analysis (dimABSA). This task aims to identify four sentiment elements in restaurant reviews: aspect, category, opinion, and sentiment intensity evaluated in valence-arousal dimensions, providing a concise yet fine-grained sentiment description for user opinions. To tackle this task, we introduce a system that integrates BERT and large language models (LLM) to leverage their strengths. First, we explore their performance in entity extraction, relation classification, and intensity prediction. Based on preliminary experiments, we develop an integrated approach to fully utilize their advantages in different scenarios. Our system achieves first place in all subtasks and obtains a 41.7% F1-score in quadruple extraction. © 2024 Association for Computational Linguistics},
	keywords = {Classification (of information); Modeling languages; Classification prediction; Entity extractions; Fine grained; Integrated approach; Intensity prediction; Language model; Performance; Relation classifications; Restaurant reviews; Sentiment analysis; Computational linguistics},
	correspondence_address = {R. Xu; Harbin Institute of Technology, Shenzhen, China; email: xuruifeng@hit.edu.cn},
	editor = {Wong K.-F. and Zhang M. and Xu R. and Li J. and Wei Z. and Gui L. and Liang B. and Zhao R.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176155-1},
	language = {English},
	abbrev_source_title = {SIGHAN - SIGHAN Workshop Chin. Language Processing, Proc. Workshop},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Sun2024274,
	author = {Sun, Lina and Aksyonov, Konstantin A.},
	title = {Fine-Tuning Bert on the Atis Dataset: Data Enhancement to Improve Intent Classification Accuracy},
	year = {2024},
	journal = {2024 9th International Symposium on Computer and Information Processing Technology, ISCIPT 2024},
	pages = {274 – 278},
	doi = {10.1109/ISCIPT61983.2024.10672674},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205542517&doi=10.1109%2fISCIPT61983.2024.10672674&partnerID=40&md5=90687eae203ea875e7bc4574454c12f5},
	affiliations = {Ural Federal University Named after the First President of Russia B.N.Yeltsin, Engineering School of Information Technologies, Telecommunications, and Control Systems, Yekaterinburg, Russian Federation},
	abstract = {Intent recognition is a pivotal task within the domain of Natural Language Understanding (NLU), specifically within the context of natural language classification. Accurate intent recognition is crucial for systems to more effectively comprehend user needs and intentions, thereby offering more precise and effective services and solutions. The dataset utilized in this project is the "ATIS Airline Travel Information System". It comprises questions sent by users through an airline service platform, which encapsulate the user's intent along with corresponding text labels for each question. The original document of this dataset contains 5,078 texts and is annotated with 11 types of labels. Upon the evaluation of the data, this project employed data augmentation techniques to fine-tune the BERT-BASE model for the construction of an intent recognition classification model specific to the aviation industry. Subsequently, the performance of the model in intent recognition was assessed using a test dataset. Additionally, a comparative analysis was conducted to benchmark the model's performance against similar research projects.The performance was subsequently compared with that of similar research projects. The project also included the plotting of a confusion matrix to analyze the model's accuracy in predicting intentions for specific intent labels. Additionally, directions for model improvement were identified. The classification model developed using BERT in this project achieved an intent recognition accuracy of 98.2%. © 2024 IEEE.},
	author_keywords = {Airline Travel Information System; BERT; Data Enhancement; LLMs; Multi - classified text},
	keywords = {Advanced traveler information systems; Classification (of information); Natural language processing systems; Airline travel information system; BERT; Classification models; Classifieds; Data enhancement; Intent recognition; LLM; Multi - classified text; Performance; Travel information system; Data accuracy},
	correspondence_address = {K.A. Aksyonov; Ural Federal University Named after the First President of Russia B.N.Yeltsin, Engineering School of Information Technologies, Telecommunications, and Control Systems, Yekaterinburg, Russian Federation; email: k.a.aksenov@urfu.ru},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038840-4},
	language = {English},
	abbrev_source_title = {Int. Symp. Comput. Inf. Process. Technol., ISCIPT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Nipu2024210,
	author = {Nipu, Ayesha Siddika and Islam, K M Sajjadul and Madiraju, Praveen},
	title = {How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Information Reuse and Integration for Data Science, IRI 2024},
	pages = {210 – 215},
	doi = {10.1109/IRI62200.2024.00052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207856655&doi=10.1109%2fIRI62200.2024.00052&partnerID=40&md5=6af3f8ce18b67ed9a23f56e83e50c9cf},
	affiliations = {University of Wisconsin-Platteville, Computer Science & Software Engineering, Platteville, WI, United States; Marquette University, Computer Science, Milwaukee, WI, United States},
	abstract = {Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs) are gaining traction in healthcare for their potential to automate patient interactions and aid clinical decision-making. This study examines the reliability of AI chatbots, specifically GPT 4.0, Claude 3 Opus, and Gemini Ultra 1.0, in predicting diseases from patient complaints in the emergency department. The methodology includes few-shot learning techniques to evaluate the chatbots' effectiveness in disease prediction. We also fine-tune the transformer-based model BERT and compare its performance with the AI chatbots. Results suggest that GPT 4.0 achieves high accuracy with increased fewshot data, while Gemini Ultra 1.0 performs well with fewer examples, and Claude 3 Opus maintains consistent performance. BERT's performance, however, is lower than all the chatbots, indicating limitations due to limited labeled data. Despite the chatbots' varying accuracy, none of them are sufficiently reliable for critical medical decision-making, underscoring the need for rigorous validation and human oversight. This study reflects that while AI chatbots have potential in healthcare, they should complement, not replace, human expertise to ensure patient safety. Further refinement and research are needed to improve AI-based healthcare applications' reliability for disease prediction. © 2024 IEEE.},
	author_keywords = {BERT; ChatGPT; Claude; electronic health record; few-shot learning; Gemini; LLM; patient complaint; prompt engineering},
	keywords = {Diseases; Zero-shot learning; BERT; ChatGPT; Claude; Electronic health; Few-shot learning; Geminus; Health records; Language model; Large language model; Patient complaint; Prompt engineering; Electronic health record},
	correspondence_address = {A.S. Nipu; University of Wisconsin-Platteville, Computer Science & Software Engineering, Platteville, United States; email: nipua@uwplatt.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035118-7},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Inf. Reuse Integr. Data Sci., IRI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {IberLEF 2024 - Proceedings of the Iberian Languages Evaluation Forum, co-located with the Conference of the Spanish Society for Natural Language Processing, SEPLN 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204372451&partnerID=40&md5=debf74b013ddd2c2e72e351f25475cb8},
	abstract = {The proceedings contain 85 papers. The topics discussed include: SINAI at IberAuTexTification in IberLEF 2024: perplexity metrics and text features for classifying automatically generated text; KaramiTeam at IberAuTexTification: soft voting ensemble for distinguishing AI generated texts; multidimensional text feature analysis: unveiling the veil of automatically generated text; human after all: using transformer based models to identify automatically generated text; telescope: discovering multilingual LLM generated texts with small specialized language models; automated text identification on languages of the Iberian Peninsula: LLM and BERT-based models aggregation; and the iimasNLP team at IberAuTexTification 2024: integrating graph neural networks, multilingual LLMs, and stylometry for automatic text identification.},
	editor = {Jimenez-Zafra S.M. and Chiruzzo L. and Rangel F. and Balouchzahi F. and Correa U.B. and Jover A.B. and Gomez-Adorno H. and Barba J.A.G. and Hernandez-Farias D.I. and Montejo-Raez A. and Moral P. and Abellan C.R. and Rodriguez M.E.V. and Taule M. and Valencia-Garcia R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Khan2024219,
	author = {Khan, Md. Nabil Rahman and Salsabil, Most. Sadia and Hasib, Khan Md. and Islam, Md Rafiqul and Alam, Mohammad Shafiul and Sanin, Cesar and Szczerbicki, Edward},
	title = {News that Moves the Market: DSEX-News Dataset for Forecasting DSE Using BERT},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2145 CCIS},
	pages = {219 – 235},
	doi = {10.1007/978-981-97-5934-7_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202205881&doi=10.1007%2f978-981-97-5934-7_19&partnerID=40&md5=980b3b62421e4e4a884d67e0fdecb1e2},
	affiliations = {Department of Computer Science and Engineering, Ahsanullah University of Science and Technology, Dhaka, Bangladesh; Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, 1216, Bangladesh; Business Information Systems, Australian Institute of Higher Education, Sydney, Australia; Faculty of Management and Economics, Gdansk University of Technology, Gdansk, Poland},
	abstract = {Stock market is a complex and dynamic industry that has always presented challenges for stakeholders and investors due to its unpredictable nature. This unpredictability motivates the need for more accurate prediction models. Traditional prediction models have limitations in handling the dynamic nature of the stock market. Additionally, previous methods have used less relevant data, leading to suboptimal performance. This study proposes the use of Bidirectional Encoder Representations from Transformers (BERT), a pre-trained Large Language Model (LLM), to predict Dhaka Stock Exchange (DSE) market movements. We also introduce a new dataset designed specifically for this problem, capturing important characteristics and patterns that were missing in other datasets. We test our new dataset of headlines and stock market indexes on various machine learning techniques, including Decision Tree (DT), Logistic Regression (LR), K-Nearest Neighbors (KNN), Random Forest (RF), Linear Support Vector Machine (LSVM), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), Bidirectional Long Short-Term Memory (Bi-LSTM), BERT, Financial Bidirectional Encoder Representations from Transformers (FinBERT), and RoBERTa, which are compared to assess their predictive capabilities. Our proposed model achieves 99.83% accuracy on the training set and 99.78% accuracy on the test set, outperforming previous methods. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Deep Learning; Large Language Model; Machine Learning; Natural Language Processing; Sentiment Analysis; Stock Exchange},
	keywords = {Commerce; Financial markets; Investments; k-nearest neighbors; Logistic regression; Marketplaces; Prediction models; Support vector machines; Deep learning; Language model; Language processing; Large language model; Machine-learning; Natural language processing; Natural languages; Prediction modelling; Sentiment analysis; Stock exchange; Long short-term memory},
	correspondence_address = {M.R. Islam; Business Information Systems, Australian Institute of Higher Education, Sydney, Australia; email: r.islam@aih.edu.au},
	editor = {Nguyen N.T. and Wojtkiewicz K. and Chbeir R. and Manolopoulos Y. and Fujita H. and Hong T.-P. and Nguyen L.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-981975933-0},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Colavito2024469,
	author = {Colavito, Giuseppe and Lanubile, Filippo and Novielli, Nicole and Quaranta, Luigi},
	title = {Leveraging GPT-like LLMs to Automate Issue Labeling},
	year = {2024},
	journal = {Proceedings - 2024 IEEE/ACM 21st International Conference on Mining Software Repositories, MSR 2024},
	pages = {469 – 480},
	doi = {10.1145/3643991.3644903},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197463687&doi=10.1145%2f3643991.3644903&partnerID=40&md5=2c66959db54a3e5c1093465a2ce81c8b},
	affiliations = {University of Bari, Italy},
	abstract = {Issue labeling is a crucial task for the effective management of software projects. To date, several approaches have been put forth for the automatic assignment of labels to issue reports. In particular, supervised approaches based on the fine-tuning of BERT-like language models have been proposed, achieving state-of-the-art performance. More recently, decoder-only models such as GPT have become prominent in SE research due to their surprising capabilities to achieve state-of-the-art performance even for tasks they have not been trained for. To the best of our knowledge, GPT-like models have not been applied yet to the problem of issue classification, despite the promising results achieved for many other software engineering tasks. In this paper, we investigate to what extent we can leverage GPT-like LLMs to automate the issue labeling task. Our results demonstrate the ability of GPT-like models to correctly classify issue reports in the absence of labeled data that would be required to fine-tune BERT-like LLMs.CCS CONCEPTS• Software and its engineering → Documentation; Software evolution; Maintaining software; • Information systems → Clustering and classification;  © 2024 ACM.},
	author_keywords = {GPT; Issue Labeling; Labeling Unstructured Data; LLM; Software Maintenance and Evolution},
	keywords = {Software engineering; Effective management; GPT; Issue labeling; Labeling unstructured data; Labelings; LLM; Software maintenance and evolution; State-of-the-art performance; Unstructured data; Classification (of information)},
	correspondence_address = {G. Colavito; University of Bari, Italy; email: giuseppe.colavito@uniba.it},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-840070587-8},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/ACM Int. Conf. Min. Softw. Repos., MSR},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Sindhu2024,
	author = {Sindhu, B. and Prathamesh, R.P. and Sameera, M.B. and KumaraSwamy, S.},
	title = {The Evolution of Large Language Model: Models, Applications and Challenges},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Current Trends in Advanced Computing, ICCTAC 2024},
	doi = {10.1109/ICCTAC61556.2024.10581180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199288115&doi=10.1109%2fICCTAC61556.2024.10581180&partnerID=40&md5=5bbec1d64f43c4e266edc8109d878b6a},
	affiliations = {Global Academy of Technology, Department of Computer Science and Engineering, Karnataka, Bangalore, India},
	abstract = {Large Language Models (LLMs) have attracted a lot of attention due to their success in natural language processing tasks. This paper provides a thorough overview by examining the architecture, applications, problems, assessment techniques, and future directions of LLM. With the constantly growing body of literature, a succinct yet comprehensive overview of recent developments is essential. Following the development of NLP, it highlights the move from rule-based systems to sophisticated transformer structures like as BERT and GPT. Important LLMs for text creation, translation, and summarization are mentioned, including T5, BART, and BioGPT. LLM performance is evaluated using metrics including as accuracy, perplexity, BLEU score, and ROUGE score. Research is still being done because of issues with bias, overfitting, and real-Time processing. Future directions include managing longer contexts, lowering bias, and increasing efficiency through methods like federated learning. Continuous learning and multimodal LLMs are promising fields, as well as interpretive AI. In conclusion, LLMs have transformed natural language processing (NLP) and brought up both technical and ethical issues about the future of AI.  © 2024 IEEE.},
	author_keywords = {Context length improvements; Fine-Tuning; Large Language Models (LLMs); Multi-modal LLMs; Natural Language Processing (NLP)},
	keywords = {Computational linguistics; Context length improvement; Fine tuning; Language model; Language processing; Large language model; Multi-modal; Multi-modal large language model; Natural language processing; Natural languages; Natural language processing systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039580-8},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Current Trends Adv. Comput., ICCTAC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Gao2024,
	author = {Gao, Zhen and Deng, Jie and Reviriego, Pedro and Liu, Shanshan and Lombardi, Fabrizio},
	title = {Reducing the Energy Dissipation of Large Language Models (LLMs) with Approximate Memories},
	year = {2024},
	journal = {Proceedings - IEEE International Symposium on Circuits and Systems},
	doi = {10.1109/ISCAS58744.2024.10558275},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198528798&doi=10.1109%2fISCAS58744.2024.10558275&partnerID=40&md5=4abbb8dcd398db9cfa2ca6843a3d1f5d},
	affiliations = {Tianjin University, School of Electrical And Information Engineering, Tianjin, China; Tianjin University, School of Future Technology, Tianjin, China; Universidad Politécnica De Madrid, Departamento De Ingeniería De Sistemas Telemáticos, Madrid, Spain; University of Electronic Science And Technology of China, School of Information And Communication Engineering, Chengdu, China; Northeastern University, Department of Electrical And Computer Engineering, Boston, MA, United States},
	abstract = {Large language models (LLMs) have shown impressive performance in a wide range of tasks such as answering questions or summarizing text. However, running LLMs on edge devices is challenging as they require large amounts of energy due to their memory and computation needs. In LLMs most of the memory is needed to store the model parameters which number keeps increasing from one LLM generation to the next. In the last several years, significant efforts have been made to compress and prune parameters, but this is not enough to reduce their memory needs as the number of parameters grows exponentially. In this work, to reduce energy dissipation, rather than trying to reduce the amount of memory used by LLMs, we study the use of approximate memories to store the LLM parameters. Approximate memories can significantly reduce the energy dissipation at the cost of introducing errors in some of the memory bits. Therefore, the impact of errors on LLMs must be understood. To that end, we have performed error injection on different compressed versions of a classic LLM: Bidirectional Encoder Representations from Transformers (BERT). The results show that in some cases compressed BERTs operate reliably at high bit error rates. This makes possible the use of approximate memories with a negligible impact on the LLM performance and a significant reduction in energy dissipation.  © 2024 IEEE.},
	author_keywords = {approximate computing; LLMs; memories},
	keywords = {Computational linguistics; Errors; Approximate computing; Energy; Error-injection; Language model; Large amounts; Large language model; Memory bits; Model generation; Modeling parameters; Performance; Energy dissipation},
	correspondence_address = {Z. Gao; Tianjin University, School of Electrical And Information Engineering, Tianjin, China; email: zgao@tju.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {02714310},
	isbn = {979-835033099-1},
	coden = {PICSD},
	language = {English},
	abbrev_source_title = {Proc IEEE Int Symp Circuits Syst},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Yao2024845,
	author = {Yao, Hongwei and Lou, Jian and Qin, Zhan and Ren, Kui},
	title = {PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification},
	year = {2024},
	journal = {Proceedings - IEEE Symposium on Security and Privacy},
	pages = {845 – 861},
	doi = {10.1109/SP54263.2024.00209},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197614104&doi=10.1109%2fSP54263.2024.00209&partnerID=40&md5=0785aa30d4ee1fa5e1b228d6a13cfe58},
	affiliations = {Zhejiang University, Hangzhou, China; ZJU-Hangzhou Global Scientific and Technological Innovation Center, Hangzhou, China},
	abstract = {Large language models (LLMs) have witnessed a meteoric rise in popularity among the general public users over the past few months, facilitating diverse downstream tasks with human-level accuracy and proficiency. Prompts play an essential role in this success, which efficiently adapt pre-trained LLMs to task-specific applications by simply prepending a sequence of tokens to the query texts. However, designing and selecting an optimal prompt can be both expensive and demanding, leading to the emergence of Prompt-as-a-Service providers who profit by providing well-designed prompts for authorized use. With the growing popularity of prompts and their indispensable role in LLM-based services, there is an urgent need to protect the copyright of prompts against unauthorized use.In this paper, we propose PromptCARE, the first framework for prompt copyright protection through watermark injection and verification. Prompt watermarking presents unique challenges that render existing watermarking techniques developed for model and dataset copyright verification ineffective. PromptCARE overcomes these hurdles by proposing watermark injection and verification schemes tailor-made for characteristics pertinent to prompts and the natural language domain. Extensive experiments on six well-known benchmark datasets, using three prevalent pre-trained LLMs (BERT, RoBERTa, and Facebook OPT-1.3b), demonstrate the effectiveness, harmlessness, robustness, and stealthiness of PromptCARE. © 2024 IEEE.},
	author_keywords = {Large Language Models; Prompt Learning; Prompt Watermarking},
	keywords = {Digital watermarking; Natural language processing systems; Problem oriented languages; Structured Query Language; Watermarking; Copyright protections; Down-stream; General publics; Human levels; Language model; Large language model; Prompt learning; Prompt watermarking; Watermark injections; Watermark verification; Query languages},
	correspondence_address = {Z. Qin; Zhejiang University, Hangzhou, China; email: qinzhan@zju.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {10816011},
	isbn = {979-835033130-1},
	language = {English},
	abbrev_source_title = {Proc. IEEE Symp. Secur. Privacy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Raja20243,
	author = {Raja, Sabarish Raja Ramesh and Antony Vigil, M.S. and Pattaiah, Muthukumar and Sudarson, B.},
	title = {Analyzing the Computational Efficiency of LLM Models for NLP Tweet Classification During Emergency-Crisis},
	year = {2024},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {717 IFIPAICT},
	pages = {3 – 15},
	doi = {10.1007/978-3-031-69982-5_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207645069&doi=10.1007%2f978-3-031-69982-5_1&partnerID=40&md5=4b1de8a4ef0e23a2b0c0fb2505aa6224},
	affiliations = {Department of Computer Science and Engineering, SRM Institute of Science and Technology, Ramapuram, Chennai, India},
	abstract = {Social media platforms which include Twitter, Reddit, Instagram, and YouTube have emerged as key information sources during emergencies or natural disasters. However, in the case of Twitter, it might be challenging to distinguish the tweets that are genuinely informative due to the overwhelming number of tweets that are sent during these occurrences. This study proposes a method for classifying the tweets as “informative” and “non-informative” using natural language processing. The technique considers the tweets’ subjects, hashtags segmentation, and locations for pre-processing. BERT, RoBERTa, LSTM, and DistilBERT are four different NLP models that have been trained and tested. The findings will indicate the highest classification accuracy for determining if a tweet is informative or not. Our findings reveal that DistilBERT achieved the highest accuracy of 92.0% in testing and 89% in precision of the Twitter dataset. © IFIP International Federation for Information Processing 2024.},
	author_keywords = {Bidirectional Encoder Representation from Transformers; Distilled BERT; Long Short Term Memory; Natural Language Processing; Robustly Optimized BERT Approach},
	keywords = {Classification (of information); Natural language processing systems; Public policy; Bidirectional encoder representation from transformer; Distilled BERT; Information sources; Language processing; Natural language processing; Natural languages; Robustly optimized BERT approach; Short term memory; Social media platforms; YouTube; Tweets},
	correspondence_address = {S.R.R. Raja; Department of Computer Science and Engineering, SRM Institute of Science and Technology, Chennai, Ramapuram, India; email: sabarishds03@gmail.com},
	editor = {Owoc M.L. and Rajaram K. and Sicily F.E.V. and Balasundaram P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303169981-8},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rhouma2024,
	author = {Rhouma, Rafik and McMahon, Christopher and Mcgillivray, Donald and Massood, Hassan and Kanwal, Safia and Khan, Meraj and Lo, Thomas and Lam, Jean-Paul and Smith, Christopher},
	title = {Leveraging mobile NER for real-time capture of symptoms, diagnoses, and treatments from clinical dialogues},
	year = {2024},
	journal = {Informatics in Medicine Unlocked},
	volume = {48},
	doi = {10.1016/j.imu.2024.101519},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196256020&doi=10.1016%2fj.imu.2024.101519&partnerID=40&md5=dd4a1462e793d6c6d08eb8a8ebd73758},
	affiliations = {Goodlabs Studio, Toronto, M5H 3E5, Canada; Department of Economics, University of Waterloo, Waterloo, N2L 3G1, Canada},
	abstract = {In the dynamic world of healthcare technology, efficiently and accurately extracting medical data from physician–patient conversations is vital. This paper presents a new approach in healthcare technology, employing Natural Language Processing (NLP) to identify and extract critical information from doctor–patient conversations on mobile devices. Unlike traditional methods that rely on Electronic Health Records, our novel application enables the extraction of symptoms, diagnoses, and treatments directly on a mobile device during medical consultations, significantly enhancing patient privacy. We managed to integrate both Bidirectional Encoder Representations from Transformers (BERT) models and optimized Large Language Models (LLMs) on a mobile device without compromising performance significantly. Our findings reveal that the BERT model attained an F1-score of 85.1%, while FLERT and its compressed variant DistilFLERT showed superior performance. The FLAN-T5 model outperformed all models we tested with scores up to 92.7%. These results highlight the efficacy of leveraging advanced NLP and LLM technologies in healthcare environments on a mobile device, offering a promising direction for accessible and efficient patient care. © 2024},
	author_keywords = {Distillation models for mobile; Electronic Health Records (EHR); Large Language Models; Medical data extraction; Named Entity Recognition (NER); Transformers},
	keywords = {Article; consultation; conversation; data extraction; electronic health record; health care access; human; information technology; large language model; natural language processing; patient care; privacy; symptomatology},
	correspondence_address = {J.-P. Lam; Goodlabs Studio, Toronto, M5H 3E5, Canada; email: jplam@uwaterloo.ca},
	publisher = {Elsevier Ltd},
	issn = {23529148},
	language = {English},
	abbrev_source_title = {Inform. Med. Unlocked},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Ram2024,
	author = {Ram, Gummuluri Venkata Ravi and Ashinee, Kesanam and Anand Kumar, M.},
	title = {End-to-End Space-Efficient Pipeline for Natural Language Query based Spacecraft Health Data Analytics using Large Language Model (LLM)},
	year = {2024},
	journal = {2024 5th International Conference on Innovative Trends in Information Technology, ICITIIT 2024},
	doi = {10.1109/ICITIIT61487.2024.10580129},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199205909&doi=10.1109%2fICITIIT61487.2024.10580129&partnerID=40&md5=446978f9571d2f52b948a082490ef420},
	affiliations = {National Institute of Technology Karnataka, Department of Information Technology, Karnataka, Surathkal, India},
	abstract = {There is a requirement of automated Space-craft Health monitoring and mission maintenance System which is able to process Natural-Language Query and revert back in required format for which size of space database is a hurdle. Hence, we propose an end-to-end customizable real-time pipeline for space mission health monitoring, utilizing LLM that addresses issue of very large databases by extracting only relevant columns in initial stages of pipeline itself leveraginf BERT for NER, LLM for fetching schema and PandasAI to execute these queries on large datasets efficiently, producing user-friendly outputs. The pipeline is robust, space-efficient, and customizable, offering features such as cross-table referencing and handling same feature names in multiple tables. We achieved 70% realtime accuracy. © 2024 IEEE.},
	author_keywords = {BERT; customizable; LLM; Natural-Language; PandasAI; space-craft; space-efficient; SQL; text-to-SQL},
	keywords = {Data Analytics; Natural language processing systems; Pipelines; Query processing; BERT; Customizable; Language model; Large language model; Natural languages; Pandasai; Space efficient; Space-craft; SQL; Text-to-SQL; Large datasets},
	correspondence_address = {G.V.R. Ram; National Institute of Technology Karnataka, Department of Information Technology, Surathkal, Karnataka, India; email: toraviram2003@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038681-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Innov. Trends Inf. Technol., ICITIIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shohan2024632,
	author = {Shohan, Symom Hossain and Hossain, Md Sajjad and Paran, Ashraful Islam and Hossain, Jawad and Ahsan, Shawly and Hoque, Mohammed Moshiul},
	title = {SemanticCuetSync at CheckThat! 2024: Pre-trained Transformer-based Approach to Detect Check-Worthy Tweets},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {632 – 640},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201587147&partnerID=40&md5=4fc8f916e43f75e963c2483e5f3b1371},
	affiliations = {Chittagong University of Engineering and Technology, Chattogram, 4349, Bangladesh},
	abstract = {This paper presents an intelligent technique for classifying English, Arabic, and Dutch texts as checkworthy, harnessing the power of the BERT-based model. The study explores ten baseline models, including LR, MNB, SVM, CNN+LSTM, CNN+BiLSTM, BERT-Base-Uncased, RoBERTa, AraBERTv2, Dutch-RoBERTa, and Dutch-BERT, to address the shared task. The study also investigates an LLM using few-shots, such as SetFit, to identify checkworthy tweets or texts. Evaluation results unequivocally demonstrate the superiority of transformer-based models, with RoBERTa achieving the highest F1 scores of 75.82% for English tweets, Dehate-BERT scoring 52.55% for Arabic texts, and Dutch-BERT obtaining a maximum score of 58.42% for Dutch texts. Our team ranked 6th overall for English, 5th for Arabic, and 16th for Dutch in the shared task challenge. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Check-Worthiness; Fact-checking; Natural Language Processing; Transformers; Tweet-Verification},
	keywords = {Natural language processing systems; Baseline models; Check-worthiness; Fact-checking; Intelligent techniques; Language processing; Natural language processing; Natural languages; Power; Transformer; Tweet-verification; Semantics},
	correspondence_address = {M.M. Hoque; Chittagong University of Engineering and Technology, Chattogram, 4349, Bangladesh; email: moshiul_240@cuet.ac.bd},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li202427515,
	author = {Li, Xuhong and Chen, Jiamin and Chai, Yekun and Xiong, Haoyi},
	title = {GILOT: Interpreting Generative Language Models via Optimal Transport},
	year = {2024},
	journal = {Proceedings of Machine Learning Research},
	volume = {235},
	pages = {27515 – 27530},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203805495&partnerID=40&md5=3fe23ab0e53af517ad25784e475ff35b},
	affiliations = {Baidu Inc., Beijing, China},
	abstract = {While large language models (LLMs) surge with the rise of generative AI, algorithms to explain LLMs highly desire. Existing feature attribution methods adequate for discriminative language models like BERT often fail to deliver faithful explanations for LLMs, primarily due to two issues: (1) For every specific prediction, the LLM outputs a probability distribution over the vocabulary-a large number of tokens with unequal semantic distance; (2) As an autoregressive language model, the LLM handles input tokens while generating a sequence of probability distributions of various tokens. To address above two challenges, this work proposes GILOT that leverages Optimal Transport approach to measure the distributional change of all possible generated sequences upon the absence of every input token, while taking into account the tokens' similarity, so as to faithfully estimate feature attribution for LLMs. We have carried out extensive experiments on top of Llama families and their fine-tuned derivatives across various scales to validate the effectiveness of GILOT for estimating the input attributions. The results show that GILOT outperforms existing solutions on a number of faithfulness metrics under fair comparison settings. Source code is publicly available at https://github.com/holyseven/GiLOT. Copyright 2024 by the author(s)},
	keywords = {Generative adversarial networks; AI algorithms; Auto-regressive; Discriminative language models; Language model; Model outputs; Optimal transport; Probability: distributions; Semantic distance; Source codes; Semantics},
	correspondence_address = {H. Xiong; Baidu Inc., Beijing, China; email: haoyi.xiong.fr@ieee.org},
	editor = {Salakhutdinov R. and Kolter Z. and Heller K. and Weller A. and Oliver N. and Scarlett J. and Berkenkamp F.},
	publisher = {ML Research Press},
	issn = {26403498},
	language = {English},
	abbrev_source_title = {Proc. Mach. Learn. Res.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu202414551,
	author = {Liu, Zhu and Kong, Cunliang and Liu, Ying and Sun, Maosong},
	title = {Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {14551 – 14558},
	doi = {10.18653/v1/2024.findings-acl.866},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205313101&doi=10.18653%2fv1%2f2024.findings-acl.866&partnerID=40&md5=3737cd8e164cc36c8d4488a6ea8f355f},
	affiliations = {School of Humanities, Tsinghua University, China; Department of Computer Science and Technology, Tsinghua University, China},
	abstract = {Large language models have achieved remarkable success in general language understanding tasks. However, as a family of generative methods with the objective of next token prediction, the semantic evolution with the depth of these models are not fully explored, unlike their predecessors, such as BERT-like architectures. In this paper, we specifically investigate the bottom-up evolution of lexical semantics for a popular LLM, namely Llama2, by probing its hidden states at the end of each layer using a contextualized word identification task. Our experiments show that the representations in lower layers encode lexical semantics, while the higher layers, with weaker semantic induction, are responsible for prediction. This is in contrast to models with discriminative objectives, such as mask language modeling, where the higher layers obtain better lexical semantics. The conclusion is further supported by the monotonic increase in performance via the hidden states for the last meaningless symbols, such as punctuation, in the prompting strategy. Our codes are available at https://github.com/RyanLiut/LLM_LexSem. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Digital elevation model; Generative adversarial networks; Modeling languages; Prediction models; Bottom up; Generative methods; Hidden state; Language model; Language understanding; Lexical semantics; Monotonics; Performance; Semantic evolution; Word identification; Semantics},
	correspondence_address = {Y. Liu; School of Humanities, Tsinghua University, China; email: yingliu@tsinghua.edu.cn},
	editor = {Ku L.-W. and Martins A. and Srikumar V.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {979-889176099-8},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Buder-Gröndahl2024327,
	author = {Buder-Gröndahl, Tommi},
	title = {What does Parameter-free Probing Really Uncover?},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {2},
	pages = {327 – 336},
	doi = {10.18653/v1/2024.acl-short.31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203798156&doi=10.18653%2fv1%2f2024.acl-short.31&partnerID=40&md5=fac87730548b61c694b01b6a03a30923},
	affiliations = {University of Helsinki, Yliopistonkatu 3, Helsinki, 00014, Finland},
	abstract = {Supervised approaches to probing large language models (LLMs) have been criticized of using pre-defined theory-laden target labels. As an alternative, parameter-free probing constructs structural representations bottom-up via information derived from the LLM alone. This has been suggested to capture a genuine “LLM-internal grammar”. However, its relation to familiar linguistic formalisms remains unclear. I extend prior work on a parameter-free probing technique called perturbed masking applied to BERT, by comparing its results to the Universal Dependencies (UD) formalism for English. The results highlight several major discrepancies between BERT and UD, which lack correlates in linguistic theory. This raises the question of whether human grammar is the correct analogy to interpret BERT in the first place. © 2024 Association for Computational Linguistics.},
	keywords = {Context free languages; Context sensitive grammars; Bottom up; Language model; Linguistic theory; Probing techniques; Structural representation; Target labels; Context free grammars},
	correspondence_address = {T. Buder-Gröndahl; University of Helsinki, Helsinki, Yliopistonkatu 3, 00014, Finland; email: tommi.grondahl@helsinki.fi},
	editor = {Ku L.-W. and Martins A.F.T. and Srikumar V.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {979-889176095-0},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhou202416655,
	author = {Zhou, Haotian and Lin, Yunhan and Yan, Longwu and Zhu, Jihong and Min, Huasong},
	title = {LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees},
	year = {2024},
	journal = {Proceedings - IEEE International Conference on Robotics and Automation},
	pages = {16655 – 16661},
	doi = {10.1109/ICRA57147.2024.10610183},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197618191&doi=10.1109%2fICRA57147.2024.10610183&partnerID=40&md5=c9f98be43d4830738a8deaf437a04f32},
	affiliations = {Institute of Robotics and Intelligent Systems, Wuhan University of Science and Technology, Wuhan, China; University of York, School of Physics, Engineering and Technology, United Kingdom},
	abstract = {Large Language Models (LLMs) have been widely utilized to perform complex robotic tasks. However, handling external disturbances during tasks is still an open challenge. This paper proposes a novel method to achieve robotic adaptive tasks based on LLMs and Behavior Trees (BTs). It utilizes ChatGPT to reason the descriptive steps of tasks. In order to enable ChatGPT to understand the environment, semantic maps are constructed by an object recognition algorithm. Then, we design a Parser module based on Bidirectional Encoder Representations from Transformers (BERT) to parse these steps into initial BTs. Subsequently, a BTs Update algorithm is proposed to expand the initial BTs dynamically to control robots to perform adaptive tasks. Different from other LLM-based methods for complex robotic tasks, our method outputs variable BTs that can add and execute new actions according to environmental changes, which is robust to external disturbances. Our method is validated with simulation in different practical scenarios. © 2024 IEEE.},
	keywords = {Modeling languages; Robots; Behaviour Trees; External disturbances; Language model; Model trees; Modeling behaviour; Novel methods; Object recognition algorithm; Robotic tasks; Semantic map; Task-based; Semantics},
	correspondence_address = {H. Min; Institute of Robotics and Intelligent Systems, Wuhan University of Science and Technology, Wuhan, China; email: jihong.zhu@york.ac.uk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {10504729},
	isbn = {979-835038457-4},
	coden = {PIIAE},
	language = {English},
	abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Feng202410642,
	author = {Feng, Xincan and Yoshimoto, Akifumi},
	title = {Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {10642 – 10656},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195962739&partnerID=40&md5=fc80dc543007c45f43302a803fb29edf},
	affiliations = {NARA Institute of Science and Technology, Japan; CyberAgent Inc., Japan},
	abstract = {Recent advancements in Natural Language Processing (NLP) have seen Large-scale Language Models (LLMs) excel at producing high-quality text for various purposes. Notably, in Text-To-Speech (TTS) systems, the integration of BERT for semantic token generation has underscored the importance of semantic content in producing coherent speech outputs. Despite this, the specific utility of LLMs in enhancing TTS synthesis remains considerably limited. This research introduces an innovative approach, Llama-VITS, which enhances TTS synthesis by enriching the semantic content of text using LLM. Llama-VITS integrates semantic embeddings from Llama2 with the VITS model, a leading end-to-end TTS framework. By leveraging Llama2 for the primary speech synthesis process, our experiments demonstrate that Llama-VITS matches the naturalness of the original VITS (ORI-VITS) and those incorporate BERT (BERT-VITS), on the LJSpeech dataset, a substantial collection of neutral, clear speech. Moreover, our method significantly enhances emotive expressiveness on the EmoV_DB_bea_sem dataset, a curated selection of emotionally consistent speech from the EmoV_DB dataset, highlighting its potential to generate emotive speech. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Emotive Speech; Large-scale Language Model; Semantic Embedding; Text-To-Speech},
	keywords = {Computational linguistics; Embeddings; Natural language processing systems; Semantics; Emotive speech; Excel; Language model; Language processing; Large-scale language model; Large-scales; Natural languages; Semantic content; Semantic embedding; Text to speech; Speech synthesis},
	editor = {Calzolari N. and Kan M.-Y. and Hoste V. and Lenci A. and Sakti S. and Xue N.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381410-4},
	language = {English},
	abbrev_source_title = {Jt. Int. Conf. Comput. Linguist., Lang. Resour. Eval., LREC-COLING - Main Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Huang2024138,
	author = {Huang, Bor-Woei},
	title = {Generative Large Language Models Augmented Hybrid Retrieval System for Biomedical Question Answering},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {138 – 149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201611134&partnerID=40&md5=cb23ec5e01f69e9308a77ef80ecb0725},
	affiliations = {University of Padova, Italy},
	abstract = {In our participation in the 12th BioASQ challenge document retrieval task B Phase A, our system hybridized advanced generative large language models (LLMs), traditional BM25 lexical retriever, and BERT-based cross-encoder re-ranker. Our approach aimed to improve recall and MAP scores by utilizing the pseudo-documents generated by GPT-3.5 and Gemini to augment a hybrid two-stage retrieval system. Our retrieval system is composed of two modules: the generator module and the extractor module. The generator module consists of LLMs GPT-3.5 and Gemini, which generate synthetic data on the seen questions and pseudo-documents on the unseen test questions. The extractor module has a two-stage retrieval framework consisting of BM25 lexical retriever and BiomedBERT cross-encoder re-ranker. By expanding the original queries with the biomedical entities extracted from the pseudo-documents, we observed improvements in recall in the first stage BM25 retrieval. We explored the effectiveness of a BiomedBERT cross-encoder re-ranker trained on the data that combines golden-standard data, synthetic data and LLM-generated pseudo-documents for the second stage re-ranking. This approach improves MAP scores by considering the contextual relationships between test questions and pseudo-documents. Finally, we used fusion methods to optimize the final output considering the question types. Our system demonstrated promising results in effectively retrieving relevant biomedical documents from PubMed. © 2024 Copyright for this paper by its authors.},
	author_keywords = {BioASQ; Generative large language models; Question Answering; Zero-shot},
	keywords = {Encoding (symbols); Generative adversarial networks; Metadata; Modeling languages; B phase; BioASQ; Biomedical question answering; Document Retrieval; Generative large language model; Language model; Question Answering; Retrieval systems; Synthetic data; Zero-shot; Question answering},
	correspondence_address = {B.-W. Huang; University of Padova, Italy; email: borwoei.huang@studenti.unipd.it},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Payumo2024,
	author = {Payumo, Kevin and Subramanian, Inimai and Lu, Thomas and Chow, Edward},
	title = {Intelligent Knowledge Base Search Tool using Large Language Model and Graph Neural Network},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13040},
	doi = {10.1117/12.3014075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197539004&doi=10.1117%2f12.3014075&partnerID=40&md5=ed518a4640a4277c8fcedb0f6bb6bbbc},
	affiliations = {University of Southern California, 3551 Trousdale Parkway, Los Angeles, CA, United States; Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA, United States; Jet Propulsion Laboratory, California Institute of Technology, 4800 Oak Grove Dr, Pasadena, CA, United States},
	abstract = {Within many organizations, a vast number of communications, memos, reports and documents have been accumulated in internal servers. Efficiently discovering relevant entries can reduce time spent addressing organizational needs such as personnel skills matching or anomaly resolution. However, per organization, information retrieval on these disparate data types can be challenging, as systems must be designed for their domain while accounting for unstructured and inconsistent datasets. Traditional querying via search terms often requires relevancy tuning by subject matter experts which makes it difficult to build retrieval systems. We argue that development of retrieval systems can be simplified and enhanced by embedding data with Large Language Models (LLMs), organizing information in a Knowledge Graph (KG) structure, and further encoding their relational features through a Graph Neural Network (GNN). One of the major challenges of using GNNs for information retrieval is optimizing negative edge selection. Training GNNs requires a balanced ratio between positive and negative edges however the space of negative edges is exponentially larger than positive edges. In this work, we extend the LLM-GNN hybrid architecture by applying ensemble voting on a set of trained LLM-GNNs. Preliminary results have shown modest improvement on our personnel-document matching tasks. This work contributes to a developmental effort that aims to help engineers and scientists find new research opportunities, learn from past mistakes, and quickly address future needs. © 2024 SPIE.},
	author_keywords = {BERT; GNN; GPT; graph neural network; Knowledge graph; Large Language Model; LLM; Neural document retrieval; Search tool},
	keywords = {Computational linguistics; Graph neural networks; Knowledge graph; Personnel; Search engines; BERT; Document Retrieval; GPT; Graph neural networks; Knowledge graphs; Language model; Large language model; Neural document retrieval; Search tools; Information retrieval},
	editor = {Alam M.S. and Asari V.K.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151067398-4},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Park202482,
	author = {Park, Haeju and Lee, Kyungjae and Park, Sunghyun and Lee, Moontae},
	title = {Enhancing Fusion-in-Decoder for Multi-Granularity Ranking},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3784},
	pages = {82 – 86},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207475624&partnerID=40&md5=1d77c490bf092e543d4887f675571945},
	affiliations = {LG AI Research, South Korea},
	abstract = {Large Language Models (LLMs) have demonstrated exceptional performance across various natural language tasks, leveraging extensive knowledge from massive datasets. However, their reliance solely on parametric knowledge often leads to the generation of inaccurate or outdated content, particularly in domain-specific tasks. Retrieval Augmented Generation (RAG) has emerged as a promising approach to address this limitation by incorporating external knowledge without necessitating re-training. While RAG enhances the accuracy of LLM-generated content, effectively retrieving external knowledge remains a challenge due to potential noise and computational costs. To address this, traditional information retrieval systems adopt two-stage approaches, utilizing efficient retrievers followed by reranking mechanisms. Recently, transformer-based architectures, including BERT and T5 models, have shown promise as effective rerankers. However, such models have limited context size and only perform single-granularity ranking at a time, hindering their effectiveness and efficiency. In this paper, we first explore the existing rerankers such as RankT5 and RFiD, highlighting challenges in multi-granularity ranking. Subsequently, we introduce PFiD (Passage Fusion-in-Decoder), a simple yet efficient approach aimed at effectively ranking both document and passage simultaneously. Through empirical evaluation, we demonstrate the efficacy of PFiD in improving effectiveness and efficiency, offering a promising direction for further research in this domain. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Information Systems; Large Language Model; Retrieval Augmented Generation},
	keywords = {Information retrieval; Large datasets; Natural language processing systems; Domain specific; Effectiveness and efficiencies; External knowledge; Language model; Large language model; Massive data sets; Multi-granularity; Natural languages; Performance; Retrieval augmented generation; Decoding},
	editor = {Petroni F. and Siciliano F. and Silvestri F. and Trappolini G.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Estevanell-Valladares202469,
	author = {Estevanell-Valladares, Ernesto Luis},
	title = {Improving AutoML for LLMs via Knowledge-Based Meta-Learning},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3797},
	pages = {69 – 77},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207938663&partnerID=40&md5=34349426cf0b4ca8e1fded7a18f2873e},
	affiliations = {Faculty of Mathematics and Computer Science, University of Havana, Cuba; Natural Language Processing and Information Systems Group, University of Alicante, Spain},
	abstract = {Recent advancements in Large Language Models (LLMs) such as BERT, GPT-4, and T5 have revolutionized the field of Natural Language Processing (NLP), unlocking numerous applications. However, finetuning these models for specific tasks remains a complex and resource-intensive process, often relying heavily on expert knowledge. This research proposes integrating meta-learning into Automatic Machine Learning (AutoML) systems to optimize LLM fine-tuning and pipeline construction. We hypothesize that knowledge-based meta-learning can overcome the inefficiencies of current AutoML approaches by embedding expert-derived heuristics into the optimization process. Our methodology involves compiling extensive LLM usage data, training meta-learning estimators, and integrating these into the AutoGOAL AutoML framework. By doing so, we aim to reduce computational costs and enhance the efficiency of LLM-based NLP applications. The proposed system will be evaluated against traditional AutoML methods and human experts on various text classification tasks to validate its effectiveness. This research can further democratize NLP by making advanced LLM capabilities more accessible and efficient. © 2024 Copyright for this paper by its authors.},
	author_keywords = {AutoML; Large Language Model; Meta-Learning; Natural Language Processing},
	keywords = {Adversarial machine learning; Contrastive Learning; Expert systems; Modeling languages; Pipeline processing systems; Automatic machine learning; Automatic machines; Knowledge based; Language model; Language processing; Large language model; Machine-learning; Metalearning; Natural language processing; Natural languages; Natural language processing systems},
	correspondence_address = {E.L. Estevanell-Valladares; Faculty of Mathematics and Computer Science, University of Havana, Cuba; email: elev1@alu.ua.es},
	editor = {Jover A.B. and Universidad de Alicante, University Institute for Computing Research, GPLSI Research Group, Carretera San Vicente s/n, Alicante and Calvo D.V. and Universidad de A Coruna, Computer Science and Information Technologies Department, LYS Research Group, Campus de Elvina s/n, A Coruna and Pastor E.L. and Universidad de Alicante, Department of Software and Computing Systems, GPLSI Research Group, Carretera San Vicente s/n, Alicante and Molina-Gonzalez M.D. and Universidad de Jaen, Computer Science Department, SINAI Research Group, Campus Las Lagunillas, Jaen and Jimenez-Zafra S.M. and Universidad de Jaen, Computer Science Department, SINAI Research Group, Campus Las Lagunillas, Jaen},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ma20242127,
	author = {Ma, Yongqiang and Qing, Lizhi and Liu, Jiawei and Kang, Yangyang and Zhang, Yue and Lu, Wei and Liu, Xiaozhong and Cheng, Qikai},
	title = {From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {2127 – 2137},
	doi = {10.18653/v1/2024.findings-acl.126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205284571&doi=10.18653%2fv1%2f2024.findings-acl.126&partnerID=40&md5=6e0efe6b862af25174d6ca7ef875c46c},
	affiliations = {School of Information Management, Wuhan University, China; Institute for Intelligent Computing, Alibaba Group, China; Worcester Polytechnic Institute, United States},
	abstract = {Evaluating large language models (LLMs) is fundamental, particularly in the context of practical applications. Conventional evaluation methods, typically designed primarily for LLM development, yield numerical scores that ignore the user experience. Therefore, our study shifts the focus from model-centered to human-centered evaluation in the context of AI-powered writing assistance applications. Our proposed metric, termed “Revision Distance,” utilizes LLMs to suggest revision edits that mimic the human writing process. It is determined by counting the revision edits generated by LLMs. Benefiting from the generated revision edit details, our metric can provide a self-explained text evaluation result in a human-understandable manner beyond the context-independent score. Our results show that for the easy-writing task, “Revision Distance” is consistent with established metrics (ROUGE, Bert-score, and GPT-score), but offers more insightful, detailed feedback and better distinguishes between texts. Moreover, in the context of challenging academic writing tasks, our metric still delivers reliable evaluations where other metrics tend to struggle. Furthermore, our metric also holds significant potential for scenarios lacking reference texts. © 2024 Association for Computational Linguistics.},
	keywords = {Human form models; Context independent; Evaluation methods; Evaluation results; Human-centered evaluation; Language model; Model development; Model-based OPC; Text evaluation; Users' experiences; Writing process; Computational linguistics},
	correspondence_address = {Y. Kang; Institute for Intelligent Computing, Alibaba Group, China; email: yangyang.kangyy@alibaba-inc.com; W. Lu; School of Information Management, Wuhan University, China; email: weilu@whu.edu.cn},
	editor = {Ku L.-W. and Martins A. and Srikumar V.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {979-889176099-8},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Javaji2024,
	author = {Javaji, Prashanth and Sreeya, Pulaparthi Satya and Rajesh, Sudha},
	title = {Detection of AI Generated Text With BERT Model},
	year = {2024},
	journal = {2024 2nd World Conference on Communication and Computing, WCONF 2024},
	doi = {10.1109/WCONF61366.2024.10692072},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207464523&doi=10.1109%2fWCONF61366.2024.10692072&partnerID=40&md5=4fff398a91bd9513f1450c2cd8cc9e46},
	affiliations = {Computational Intelligence (of Affiliation) SRMIST, Tamil Nadu, Chennai, India},
	abstract = {Identifying AI-generated material from human-crafted essays within a massive archive of over 28,000 compositions combining both sources is the central objective of the enormous effort. The heart of the project is a state-of-the-art machine learning model that has been painstakingly designed to distinguish between student-authored articles and those generated by LLMs. With its binary labeling system, where 0 denotes human-written pieces and 1 signifies AI-generated content, this dataset is mostly used for essay text classification tasks. This combined endeavor aims to defend written content against the growing demand for its authenticity by adding to the pool of models that can distinguish between human and AI-authored language on a subtle level. If such an innovative model is successfully put into use, it could have a huge effect on the fight against fake news by making written material more reliable in many areas, such as education and online content moderation. By actively engaging contributors in the exploration of this vast dataset, the program hopes to foster advances in text authenticity verification, accelerating the growth of sturdy systems for assessing content dependability to unparalleled heights. © 2024 IEEE.},
	author_keywords = {Accuracy; Artificial Intelligence; Augmenteed LLM; Authenticity; Machine learning},
	keywords = {Authentication; Contrastive Learning; Federated learning; Accuracy; Augmenteed LLM; Authenticity; Classification tasks; Growing demand; Labelling systems; Machine learning models; Machine-learning; State of the art; Text classification; Adversarial machine learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039532-7},
	language = {English},
	abbrev_source_title = {World Conf. Commun. Comput., WCONF},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jin2024,
	author = {Jin, Chen and Keren, Zhang and Ziqin, Zhu and Jiawei, Lin and Yilun, Zhang},
	title = {From Fiction to Forecast: Leveraging LLM-Enhanced Models and Science Fiction for Innovative Technology Predictions},
	year = {2024},
	journal = {PICMET 2024 - 2024 Portland International Conference on Management of Engineering and Technology: Technology Management in the Artificial Intelligence Era, Proceedings},
	doi = {10.23919/PICMET64035.2024.10653333},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204378286&doi=10.23919%2fPICMET64035.2024.10653333&partnerID=40&md5=960992893f23db322c762adf36a76943},
	affiliations = {School of Economics and Management, Tsinghua University, Beijing, 100084, China; Tsinghua University, Research Center for Technological Innovation, Beijing, 100084, China; Tianjin Institute of Industrial Biotechnology, Chinese Academy of Sciences, Tianjin, 300308, China; Shanghai Jiao Tong University, Department of Industrial Engineering and Management, Shanghai, 200240, China},
	abstract = {Science fiction has long stood as an abundant source of inspiration, often pre-empting technological breakthroughs before they occur. However, these predictions are usually constrained by the current level of understanding and analysis. Our research introduces a groundbreaking approach that skillfully integrates the visionary ideas of science fiction with the rigorous analysis of scientific principles to improve the accuracy of predicting technological trends. This method combines the imaginative scope of science fiction with concrete scientific progress, establishing an advanced strategy for predicting technological futures. By moving beyond mere theoretical speculation, our in-depth analysis and predicting model utilize a wide range of cutting-edge technological advancements. The integration of both comprehensive and specialized pre-trained language models is central to our approach. We employ the extensive capabilities of the Llama2 large language model to create context-aware prompts that adeptly encapsulate the technological visions found in science fiction. These visions are then complexly processed through sophisticated, more focused pre-trained models such as BERT, XLNet, and RoBERTa, transforming them into rich semantic vectors. This multi-layered analysis indicates the complex semantic and structural aspects in the fictional narratives. The result is a optimized supervised learning classification model, capable of accurately assessing the viability and practicality of the technologies depicted. Our study offers a fresh perspective on the analysis and prediction of technological trends, illustrating an integration of imaginative fiction and the systematic rigor of scientific research, thereby paving new avenues for understanding future technological innovations.  © 2024 PICMET.},
	keywords = {Technological forecasting; Current levels; Innovative technology; Language model; Rigorous analysis; Science fictions; Scientific principles; Scientific progress; Sources of inspirations; Technological breakthroughs; Technological trends; Prediction models},
	editor = {Kocaoglu D.F. and Anderson T.R. and Kozanoglu D.C. and Niwa K. and Steenhuis H.-J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-189084345-8},
	language = {English},
	abbrev_source_title = {PICMET - Portland Int. Conf. Manag. Eng. Technol.: Technol. Manag. Artif. Intell. Era, Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Assiri20244219,
	author = {Assiri, Adel and Gumaei, Abdu and Mehmood, Faisal and Abbas, Touqeer and Ullah, Sami},
	title = {DeBERTa-GRU: Sentiment Analysis for Large Language Model},
	year = {2024},
	journal = {Computers, Materials and Continua},
	volume = {79},
	number = {3},
	pages = {4219 – 4236},
	doi = {10.32604/cmc.2024.050781},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199170630&doi=10.32604%2fcmc.2024.050781&partnerID=40&md5=32bed00e8943018a3388e9314ca22ad4},
	affiliations = {Department of Informatics for Business, College of Business, King Khalid University, Abha, 61421, Saudi Arabia; Department of Computer Science, College of Computer Engineering and Sciences, Prince Sattam bin Abdulaziz University, Al-Kharj, 11942, Saudi Arabia; School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, 450001, China; Department of Computer Science and Technology, Beijing University of Chemical Technology, Beijing, 100029, China; Department of Computer Science, Government College University Faisalabad, Punjab, Faisalabad, 38000, Pakistan},
	abstract = {Modern technological advancements have made social media an essential component of daily life. Social media allow individuals to share thoughts, emotions, and ideas. Sentiment analysis plays the function of evaluating whether the sentiment of the text is positive, negative, neutral, or any other personal emotion to understand the sentiment context of the text. Sentiment analysis is essential in business and society because it impacts strategic decision-making. Sentiment analysis involves challenges due to lexical variation, an unlabeled dataset, and text distance correlations. The execution time increases due to the sequential processing of the sequence models. However, the calculation times for the Transformer models are reduced because of the parallel processing. This study uses a hybrid deep learning strategy to combine the strengths of the Transformer and Sequence models while ignoring their limitations. In particular, the proposed model integrates the Decoding-enhanced with Bidirectional Encoder Representations from Transformers (BERT) attention (DeBERTa) and the Gated Recurrent Unit (GRU) for sentiment analysis. Using the Decoding-enhanced BERT technique, the words are mapped into a compact, semantic word embedding space, and the Gated Recurrent Unit model can capture the distance contextual semantics correctly. The proposed hybrid model achieves F1-scores of 97% on the Twitter Large Language Model (LLM) dataset, which is much higher than the performance of new techniques. © 2024 Tech Science Press. All rights reserved.},
	author_keywords = {DeBERTa; GRU; large language model; LSTM; Naive Bayes; sentiment analysis},
	keywords = {Computational linguistics; Decision making; Decoding; Large datasets; Learning systems; Long short-term memory; Semantics; Social networking (online); DeBERTa; Gated recurrent unit; Language model; Large language model; LSTM; Naive bayes; Sentiment analysis; Sequence models; Social media; Transformer modeling; Sentiment analysis},
	correspondence_address = {A. Gumaei; Department of Computer Science, College of Computer Engineering and Sciences, Prince Sattam bin Abdulaziz University, Al-Kharj, 11942, Saudi Arabia; email: a.gumaei@psau.edu.sa; F. Mehmood; School of Electrical and Information Engineering, Zhengzhou University, Zhengzhou, 450001, China; email: faisalmehmood685@uaf.edu.pk},
	publisher = {Tech Science Press},
	issn = {15462218},
	language = {English},
	abbrev_source_title = {Comput. Mater. Continua},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{Gorgun2024,
	author = {Gorgun, Guher and Yildirim-Erbasli, Seyma N.},
	title = {Algorithmic Bias in BERT for Response Accuracy Prediction: A Case Study for Investigating Population Validity},
	year = {2024},
	journal = {Journal of Educational Measurement},
	doi = {10.1111/jedm.12420},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207353812&doi=10.1111%2fjedm.12420&partnerID=40&md5=c4891c73c3f36d73087502390d31053e},
	affiliations = {University of Alberta, Canada; Concordia University of Edmonton, United States},
	abstract = {Pretrained large language models (LLMs) have gained popularity in recent years due to their high performance in various educational tasks such as learner modeling, automated scoring, automatic item generation, and prediction. Nevertheless, LLMs are black box approaches where models are less interpretable, and they may carry human biases and prejudices because historical human data have been used for pretraining these large-scale models. For these reasons, the prediction tasks based on LLMs require scrutiny to ensure that the prediction models are fair and unbiased. In this study, we used BERT—a pretrained encoder-only LLM for predicting response accuracy using action sequences extracted from the 2012 PIAAC assessment. We selected three countries (i.e., Finland, Slovakia, and the United States) representing different performance levels in the overall PIAAC assessment. We found promising results for predicting response accuracy using the fine-tuned BERT model. Additionally, we examined algorithmic bias in the prediction models trained with different countries. We found differences in model performance, suggesting that some trained models are not free from bias, and thus the models are less generalizable across countries. Our results highlighted the importance of investigating algorithmic fairness in prediction models utilizing algorithmic systems to ensure models are bias-free. © 2024 The Author(s). Journal of Educational Measurement published by Wiley Periodicals LLC on behalf of National Council on Measurement in Education.},
	publisher = {John Wiley and Sons Inc},
	issn = {00220655},
	language = {English},
	abbrev_source_title = {J. Educ. Meas.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Wu2024415,
	author = {Wu, Jun-Wei and Lin, Lydia Hsiao-Mei and Tsai, Richard Tzong-Han},
	title = {Enhancing ESG Reporting Analysis: Leveraging GPT and Resampling Methods for Improved Multi-Label Classification},
	year = {2024},
	journal = {2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data, ICEIB 2024},
	pages = {415 – 418},
	doi = {10.1109/ICEIB61477.2024.10602711},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201212110&doi=10.1109%2fICEIB61477.2024.10602711&partnerID=40&md5=7892cb4dccb1cffa51560868f60c8645},
	affiliations = {National Central University, Department of Computer Science and Information Engineering, Taoyuan, Taiwan; National Taipei University of Technology, Department of Interaction Design, Taipei, Taiwan; Center for Gis, Research Center for Humanities and Social Sciences Academia Sinica, Taipei, Taiwan},
	abstract = {ESG reporting, covering environmental, social, and governance aspects, is a crucial resource for investors, companies, and governments to understand a company's value. However, the sheer volume of data and information in the reports makes it difficult to retrieve specific information on ESG. ESG-BERT models are developed to categorize the content of ESG reports based on the relevant field. However, the accurate prediction of multiple classifications is difficult due to unevenly distributed labels. To address this problem, we used a self-made assistant based on GPT to label the data and then resampling technology to adjust the balance of the data set. After the data set was balanced, we adjusted to ESG-BERT to improve its multi-label classification accuracy. We evaluated multiple resampling methods and determined the most suitable strategy for classifying ESG report content. Thus, the accuracy of ESG content analysis was improved through more refined model adjustment and preprocessing methods. The results indicated that balancing the data for improved classification ensures fairness and objectivity in distributing content for ESG reports with multiple labels.  © 2024 IEEE.},
	author_keywords = {ESG; imbalanced data; LLM; multi-label classification; resampling method},
	keywords = {Accurate prediction; Company values; Data and information; Data set; ESG; Imbalanced data; LLM; Multi-label classifications; Resampling method; Specific information; Classification (of information)},
	editor = {Meen T.-H.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036072-1},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Electron. Commun., Internet Things Big Data, ICEIB},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Singh2024537,
	author = {Singh, Aditya Pratap and Kohli, Anvi and Ali, Mohd Mohsin and Saiyyad, Aman and Pandey, Aditya and Pal, Aaryaman and Raj, Manish},
	title = {Innovative LegalTech Solutions: A Comprehensive Analysis of LegalEx in Enhancing Legal Work Efficiency},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1024 LNNS},
	pages = {537 – 549},
	doi = {10.1007/978-981-97-3817-5_38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202730469&doi=10.1007%2f978-981-97-3817-5_38&partnerID=40&md5=91c40c1da1ecefd6a07ac7ee0e740bf4},
	affiliations = {Bennett University, Gr. Noida, India},
	abstract = {LegalEx is an avant-garde legal technology platform which improves and then automates daily legal routines. Lawyers need to be equipped with the latest stuff in an instant, otherwise they could be left behind in the information age. It helps establish factors for success in legal disputes, for example by explaining difficult technical terms to understand or analyzing case outcomes thoroughly. Due to these factors, it increases the efficiency of a lawyer’s work and makes it more direct. In most cases legal professionals are inundated with large amounts of data. The specific nature of his work is to understand and analyze text carefully. This can often be difficult and time-consuming. LegalEx is a leading company in the LegalTech industry, focusing on innovation and integration. It has a strong edge in smoothing out the legal process, not just for legal professionals. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {BERT score; Law; Llama-CPP; LLM’s hugging face; Prompt engineering; Rogue score; Sentiment analysis},
	keywords = {BERT score; Comprehensive analysis; Law; Llama-CPP; LLM’s hugging face; Prompt engineering; Rogue score; Sentiment analysis; Technology platforms; Work efficiency; Laws and legislation},
	correspondence_address = {A. Kohli; Bennett University, Gr. Noida, India; email: anvikohli13@gmail.com},
	editor = {Hassanien A.E. and Anand S. and Jaiswal A. and Kumar P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-981973816-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gopali2024136451,
	author = {Gopali, Saroj and Abri, Faranak and Siami Namin, Akbar and Jones, Keith S.},
	title = {The Applicability of LLMs in Generating Textual Samples for Analysis of Imbalanced Datasets},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {136451 – 136465},
	doi = {10.1109/ACCESS.2024.3463400},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204575525&doi=10.1109%2fACCESS.2024.3463400&partnerID=40&md5=d9b0ed5f71916ef62ab310703f1b1273},
	affiliations = {Texas Tech University, Department of Computer Science, Lubbock, 79409, TX, United States; San Jose State University, Department of Computer Science, San Jose, 95192, CA, United States; Texas Tech University, Department of Psychological Sciences, Lubbock, 79409, TX, United States},
	abstract = {In machine learning class imbalance is a pressing issue, where the model is biased towards the majority classes and underperforms in the minority classes. In textual data, the natural language processing (NLP) model bias significantly reduces overall accuracy, along with poor performance in minority classes. This paper investigates and compares the performance of transformer-based models, such as Multi-head Attention with the data levels and algorithmic levels approaches and BERT (Bidirectional Encoder Representations from Transformers) with LLM-based data augmentation. The research utilized the approaches, such as Random Over Sampler, Synthetic Minority Over-sampling Technique (SMOTE), SMOTEENN, data augmentation at word level, class weights, L2 regularization and leveraging GPT-3.5-Turbo's for data augmentation to create additional data samples in imbalance dataset. The results from the experiment demonstrate that the LLM-based data augmentation with Multi-head Attention and BERT in the Myers-Briggs Type Indicator (MBTI) dataset (a highly skewed dataset) achieves the highest precision, recall and F1 score of 0.76 across terms. It indicates that the LLM-based data augmentation has significant improvements in dealing with class imbalance and improves the model's accuracy in minority class types in the MBTI dataset.  © 2013 IEEE.},
	author_keywords = {BERT; GPT 3.5-turbo; imbalance dataset; LLM; Multi-head attention; Myers-Briggs type indicators},
	keywords = {Data assimilation; Bidirectional encoder representation from transformer; Class imbalance; Data augmentation; GPT 3.5-turbo; Imbalance dataset; Imbalanced dataset; LLM; Machine-learning; Mult-head attention; Myers-Briggs Type Indicators; Natural language processing systems},
	correspondence_address = {S. Gopali; Texas Tech University, Department of Computer Science, Lubbock, 79409, United States; email: saroj.gopali@ttu.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Maged2024135,
	author = {Maged, Samaa and Elmaghraby, Asmaa and Marzban, Ali and Essawey, Mohamed and Ahmed, Amira and Negm, Esraa and Gomaa, Wael H.},
	title = {HistoryQuest: Arabic Question Answering in Egyptian History with LLM Fine-Tuning and Transformer Models},
	year = {2024},
	journal = {2nd International Conference of Intelligent Methods, Systems and Applications, IMSA 2024},
	pages = {135 – 140},
	doi = {10.1109/IMSA61967.2024.10652824},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204365140&doi=10.1109%2fIMSA61967.2024.10652824&partnerID=40&md5=47624099ddc6fbfdca685e795edc3c39},
	affiliations = {School of Information Technology and Computer Science (ITCS), Nile University, Artificial Intelligence Program, Giza, Egypt; Beni-Suef University, Faculty of Computers and Artificial Intelligence, Egypt},
	abstract = {Question answering (QA) in Egyptian history presents a unique and complex challenge for Arabic natural language processing (NLP). This study aims to explore and assess how large language models (LLMs) can enhance the accuracy and performance of Arabic question answering (QA), specifically in this domain. To conduct this investigation, we utilize two comprehensive datasets: the Arabic History-QA dataset and the Contextual Articles Dataset, which cover pivotal historical periods. We evaluate transformer-based models, including AraBERTv2, BERT-large-Arabic with Retrieval-Augmented Generation (RAG), fine-tuned LLaMa-2, and zero-shot LLaMa-3 with Retrieval-Augmented Generation (RAG). Through a rigorous and detailed evaluation process, we analyze how these models address various questions related to Egyptian history. This research contributes valuable insights into advancing the capabilities of Arabic NLP in specialized domains such as historical question answering. Our best results, summarized as the superiority of LLMs, beat those with transformers; additionally, the RAG significantly raised the performance level overall.  © 2024 IEEE.},
	author_keywords = {Arabic Question Answering(AQA); Large Language Models(LLMs); Natural Language Processing(NLP); Question Answering(QA); Retrieval Augmented Generation (RAG)},
	keywords = {Large datasets; Natural language processing systems; Arabic question answering; Egyptians; Language model; Language processing; Large language model; Natural language processing; Natural languages; Question Answering; Retrieval augmented generation; Question answering},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036263-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Intell. Methods, Syst. Appl., IMSA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mohan2024164,
	author = {Mohan, Apoorve and Ye, Mengmei and Franke, Hubertus and Srivatsa, Mudhakar and Liu, Zhuoran and Gonzalez, Nelson Mimura},
	title = {Securing AI Inference in the Cloud: Is CPU-GPU Confidential Computing Ready?},
	year = {2024},
	journal = {IEEE International Conference on Cloud Computing, CLOUD},
	pages = {164 – 175},
	doi = {10.1109/CLOUD62652.2024.00028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203256755&doi=10.1109%2fCLOUD62652.2024.00028&partnerID=40&md5=9ca57d77e8624c9becbb553ff43d0058},
	affiliations = {Ibm T.J. Watson Research Center, Yorktown Heights, NY, United States},
	abstract = {Many applications have been offloaded onto cloud environments to achieve higher agility, access to more powerful computational resources, and obtain better infrastructure management. Although cloud environments provide solid security solutions, users with highly sensitive data or regulatory compliance requirements, such as HIPAA (Health Insurance Portability and Accountability Act) and GDPR (General Data Protection Regulation), still hesitate to move such application domains to the cloud. To address these concerns, cloud service providers have started to offer solutions to protect data confidentiality and integrity through trusted execution environments (TEEs). While so far these were limited to CPU TEEs only, NVIDIA's Hopper architecture has shifted the landscape by enabling confidential computing features essential to protecting confidentiality and integrity for real-world applications offloaded to GPUs, such as large language models (LLMs). However, there lacks a sufficient study on how much performance overhead confidential computing introduces in a TEE comprised of a CPU-GPU configuration. In this paper we evaluate a confidential computing environment comprised of an Intel TDX system and NVIDIA H100 GPUs through various micro benchmarks and real workloads including BERT, LLaMA, and Granite large language models and provide discussions on the overhead incurred by confidential computing when GPUs are utilized. We show that while LLMs are sensitive to the model types and batch sizes, when larger models with pipelined processing are deployed, the performance of LLM inference in CPU-GPU TEEs can be close to par with their non-confidential setups.  © 2024 IEEE.},
	author_keywords = {cloud computing; cloud security; confidential computing; foundation models; high performance computing; large language models},
	keywords = {Cloud platforms; Cloud security; Computer graphics equipment; Data integrity; Data privacy; Pipeline processing systems; Problem oriented languages; Cloud environments; Cloud securities; Cloud-computing; Confidential computing; Foundation models; High performance computing; Language model; Large language model; Performance computing; Trusted execution environments; Health insurance},
	editor = {Chang R.N. and Chang C.K. and Yang J. and Atukorala N. and Jin Z. and Sheng M. and Fan J. and Fletcher K. and He Q. and Kosar T. and Sarkar S. and Venkateswaran S. and Wang S. and Liu X. and Seelam S. and Narayanaswami C. and Zong Z.},
	publisher = {IEEE Computer Society},
	issn = {21596182},
	isbn = {979-835036853-6},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Cloud Comput., CLOUD},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Ho202423,
	author = {Ho, Clara Wan Ching and Weber, Tobias and Fritze, Thorsten and Risse, Thomas},
	title = {Towards Multilingual LLM-Based Approaches for Automatic Dewey Decimal Classification},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15178 LNCS},
	pages = {23 – 33},
	doi = {10.1007/978-3-031-72440-4_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206217824&doi=10.1007%2f978-3-031-72440-4_3&partnerID=40&md5=ab803cefb5fdeb006e28958096356674},
	affiliations = {Goethe University Frankfurt, University Library, Frankfurt am Main, Frankfurt am Main, Germany},
	abstract = {The usage of classification systems is a standard method in libraries to organize all kind of materials. The Dewey Decimal Classification System (DDC) is widely used for this task. Even though approaches exist since the 1970s to automate this classification task, it is most often still a time consuming manual process. With the constantly increasing number of publications the need for automation support is growing. Current approaches have certain limitations e.g. only mono- or bi-lingual support, limited accuracy for research domains, limited to higher levels in the DDC hierarchies. The usage of Large Language Models (LLMs) opens new possibilities to support librarians in their work. In this paper we present preliminarily a study to evaluate the usage of BERT to handle a DDC classification task in the linguistic domain. In addition, we analyze the effect of a more condensed representation of full text on the performance of LLMs for this task. Results on multilingual texts are comparable to recent performances on monolingual inputs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Classification; DDC; Large Language Models; linguistics},
	keywords = {Classification (of information); Modeling languages; 'current; Classification system; Classification tasks; Dewey decimal classification system; Dewey decimal classifications; Language model; Large language model; Manual process; Model based approach; Research domains; Linguistics},
	correspondence_address = {C.W.C. Ho; Goethe University Frankfurt, University Library, Frankfurt am Main, Frankfurt am Main, Germany; email: c.ho@ub.uni-frankfurt.de},
	editor = {Antonacopoulos A. and Hinze A. and Vanderschantz N. and Piwowarski B. and Coustaty M. and Di Nunzio G.M. and Gelati F.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303172439-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Verma202412672,
	author = {Verma, Gaurav and Grover, Rynaa and Zhou, Jiawei and Mathew, Binny and Kraemer, Jordan and De Choudhury, Munmun and Kumar, Srijan},
	title = {A Community-Centric Perspective for Characterizing and Detecting Anti-Asian Violence-Provoking Speech},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {12672 – 12684},
	doi = {10.18653/v1/2024.acl-long.684},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204463579&doi=10.18653%2fv1%2f2024.acl-long.684&partnerID=40&md5=8235d73e55dc254271c0414a42187f7b},
	affiliations = {Georgia Institute of Technology, United States; Anti-Defamation League, United States},
	abstract = {Violence-provoking speech - speech that implicitly or explicitly promotes violence against the members of the targeted community, contributed to a massive surge in anti-Asian crimes during the COVID-19 pandemic. While previous works have characterized and built tools for detecting other forms of harmful speech, like fear speech and hate speech, our work takes a community-centric approach to studying anti-Asian violence-provoking speech. Using data from ~ 420k Twitter posts spanning a 3-year duration (January 1, 2020 to February 1, 2023), we develop a codebook to characterize anti-Asian violence-provoking speech and collect a community-crowdsourced dataset to facilitate its large-scale detection using state-of-the-art classifiers. We contrast the capabilities of natural language processing classifiers, ranging from BERT-based to LLM-based classifiers, in detecting violence-provoking speech with their capabilities to detect anti-Asian hateful speech. In contrast to prior work that has demonstrated the effectiveness of such classifiers in detecting hateful speech (F1 = 0.89), our work shows that accurate and reliable detection of violence-provoking speech is a challenging task (F1 = 0.69). We discuss the implications of our findings, particularly the need for proactive interventions to support Asian communities during public health crises. © 2024 Association for Computational Linguistics.},
	keywords = {Natural language processing systems; Codebooks; Health crisis; Language processing; Large-scales; Natural languages; Reliable detection; State of the art; Twitter posts; Speech recognition},
	editor = {Ku L.-W. and Martins A.F.T. and Srikumar V.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {979-889176094-3},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Lin2024442,
	author = {Lin, Lydia Hsiao-Mei and Ting, Fang-Kai and Chang, Ting-Jui and Wu, Jun-Wei and Tsai, Richard Tzong-Han},
	title = {GPT4ESG: Streamlining Environment, Society, and Governance Analysis with Custom AI Models},
	year = {2024},
	journal = {2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data, ICEIB 2024},
	pages = {442 – 446},
	doi = {10.1109/ICEIB61477.2024.10602567},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201232516&doi=10.1109%2fICEIB61477.2024.10602567&partnerID=40&md5=cda608a6eb7a5cd62f97e5f111a1107b},
	affiliations = {National Taipei University of Technology, Department of Interaction Design, Taipei City, Taiwan; National Central University, Department of Computer Science and Information Engineering, Taoyuan City, Taiwan; Center for Gis, Research Center for Humanities and Social Sciences Academia Sinica, Taipei City, Taiwan},
	abstract = {Many companies now prioritize Environment, Society, and Governance (ESG) and financial performance due to concerns about climate change. We created GPT4ESG, a quick method to analyze a company's ESG investment and influence. GPT4ESG is a model system architecture based on BERT and GPT with five parts:(1) Data cleaning: The data is cleaned and preprocessed to ensure it is in a suitable format for the model. (2) Tokenizer adaptation: A customized GPT assistant is used to assist in scoring, and results are given after expert review. (3) Model adjustment: A classification layer is added to the output. (4) Fine-tuning: The pre-trained model is fine-tuned according to the ESG field know-how. (5) Evaluation and Testing: The model was tested on a validation set during training and then on a testing set. We collected ESG reports of well-known listed companies in the technology industries in the United States as a data set. The experimental results showed that the customized GPT4ESG model was more effective than ESG-BERT in classifying ESG data. This model simplifies ESG reporting for stakeholders to make responsible decisions.  © 2024 IEEE.},
	author_keywords = {BERT; ESG; GPT; LLM; sustainable investing},
	keywords = {Classification (of information); Technology transfer; Architecture-based; BERT; Data cleaning; Environment, society, and governance; Financial performance; GPT; LLM; Modelling systems; Sustainable investing; Systems architecture; Climate change},
	correspondence_address = {L.H.-M. Lin; National Taipei University of Technology, Department of Interaction Design, Taipei City, Taiwan; email: lydia@mail.ntut.edu.tw},
	editor = {Meen T.-H.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036072-1},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Electron. Commun., Internet Things Big Data, ICEIB},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Jiang2024577,
	author = {Jiang, Yizhuo},
	title = {Enhancing Recommender Systems Through Multimodal Large Language Models and Neural Matrix Factorization},
	year = {2024},
	journal = {2024 5th International Conference on Electronic Communication and Artificial Intelligence, ICECAI 2024},
	pages = {577 – 580},
	doi = {10.1109/ICECAI62591.2024.10675129},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206102811&doi=10.1109%2fICECAI62591.2024.10675129&partnerID=40&md5=212a97f43d3c1e07fa5384b532fcd983},
	affiliations = {School of Management, Shanghai University, Shanghai, China},
	abstract = {This This study proposes a new recommendation system model that integrates multimodal data, large language models (LLM), and neural matrix factorization techniques. By using Vision Transformer (ViT) and the BERT model, we deeply mine the image and text information of users and products, and combine unstructured data with neural network technology for evaluation prediction and recommendation, showing excellent prediction performance. This study also verified the performance advantages of this method compared with traditional recommendation system methods through various ablation experiments. The results highlight the importance of text data in capturing user preferences and improving recommendation accuracy. In addition, the study found that in practical applications, more detailed segmentation processing of visual data is needed to accurately evaluate the specific contribution of visual data to multi-modal recommendation systems. These findings provide important theoretical and practical guidance for further optimizing recommendation systems. © 2024 IEEE.},
	author_keywords = {component; large language model; multimodal; neural matrix factorization; recommended system},
	keywords = {Matrix algebra; Matrix factorization; Prediction models; Recommender systems; Component; Factorization techniques; Language model; Large language model; Matrix factorizations; Multi-modal; Neural matrix factorization; Recommended systems; System models; Visual data; Neural network models},
	correspondence_address = {Y. Jiang; School of Management, Shanghai University, Shanghai, China; email: Jiangyz1002@126.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038694-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Electron. Commun. Artif. Intell., ICECAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Salmi2024,
	author = {Salmi, Salim and Mérelle, Saskia and Gilissen, Renske and Mei, Rob van der and Bhulai, Sandjai},
	title = {The Most Effective Interventions for Classification Model Development to Predict Chat Outcomes Based on the Conversation Content in Online Suicide Prevention Chats: Machine Learning Approach},
	year = {2024},
	journal = {JMIR Mental Health},
	volume = {11},
	doi = {10.2196/57362},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206646229&doi=10.2196%2f57362&partnerID=40&md5=9ec0cd9e51ccba3ce3973a27caac5d96},
	affiliations = {Research Department, Suicide Prevention, Amsterdam, 113, Netherlands; Department of Stochastics, Centrum Wiskunde & Informatica, Amsterdam, Netherlands; Department of Mathematics, Vrije Universiteit Amsterdam, Amsterdam, Netherlands},
	abstract = {Background: For the provision of optimal care in a suicide prevention helpline, it is important to know what contributes to positive or negative effects on help seekers. Helplines can often be contacted through text-based chat services, which produce large amounts of text data for use in large-scale analysis. Objective: We trained a machine learning classification model to predict chat outcomes based on the content of the chat conversations in suicide helplines and identified the counsellor utterances that had the most impact on its outputs. Methods: From August 2021 until January 2023, help seekers (N=6903) scored themselves on factors known to be associated with suicidality (eg, hopelessness, feeling entrapped, will to live) before and after a chat conversation with the suicide prevention helpline in the Netherlands (113 Suicide Prevention). Machine learning text analysis was used to predict help seeker scores on these factors. Using 2 approaches for interpreting machine learning models, we identified text messages from helpers in a chat that contributed the most to the prediction of the model. Results: According to the machine learning model, helpers’ positive affirmations and expressing involvement contributed to improved scores of the help seekers. Use of macros and ending the chat prematurely due to the help seeker being in an unsafe situation had negative effects on help seekers. Conclusions: This study reveals insights for improving helpline chats, emphasizing the value of an evocative style with questions, positive affirmations, and practical advice. It also underscores the potential of machine learning in helpline chat analysis. ©Salim Salmi, Saskia Mérelle, Renske Gilissen, Rob van der Mei, Sandjai Bhulai.},
	author_keywords = {artificial intelligence; BERT; bidirectional encoder representations from transformers; classification; conversations; explainable AI; helpline; interpretable AI; large language models; LLM; machine learning; natural language processing; suicidality; suicide; suicide helpline; suicide prevention},
	keywords = {Article; binary classification; clinical effectiveness; controlled study; conversation; data accuracy; deep learning; embedding; help seeking behavior; hopelessness; human; large language model; large scale production; major clinical study; motivational interviewing; Netherlands; online system; positive reinforcement; risk factor; suicide; suicide prevention; support vector machine; text messaging},
	correspondence_address = {S. Salmi; Research Department, Amsterdam, 113 Suicide Prevention Paasheuvelweg 25, 1105 BP, Netherlands; email: s.salmi@113.nl},
	publisher = {JMIR Publications Inc.},
	issn = {23687959},
	language = {English},
	abbrev_source_title = {JMIR Ment. Heal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sar2024605,
	author = {Sar, Soumyadeep and Roy, Dwaipayan},
	title = {Indigo at CheckThat! 2024: Using Setfit: A Resource Efficient Technique for Subjectivity Detection in News Article},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {605 – 612},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201617504&partnerID=40&md5=44a4b6006d3f7052ecf0c63a31367973},
	affiliations = {Indian Institute of Science Education and Research, Kolkata, India},
	abstract = {The spread of misinformation and biased news across various reliable news outlets has led to serious consequences in our society. It has become crucial to understand the patterns in such misleading news articles, identify key evidence, and learn how to recognize false information. Subjectivity can play a pivotal role in identifying misleading news. In this work, we employed a resource-efficient method called SetFit on the English sub-task for Task-2 (subjectivity detection) at CheckThat!. This technique uses a few shot examples from training data and aims to produce results comparable to those of fully fine-tuned models like BERT on the entire dataset. For the selected sample data, we filter out conflict-resolved instances from the dataset and combine them with some other chosen data-points, then train our desired models on this dataset. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Few shot text classification; Fine-tuning; LLMs; Natural Language processing; Sentence Transformers; SetFit},
	keywords = {Classification (of information); Deep learning; Natural language processing systems; Deep learning; Few shot text classification; Fine tuning; Language processing; LLM; Natural language processing; Natural languages; Sentence transformer; Setfit; Text classification; Zero-shot learning},
	correspondence_address = {S. Sar; Indian Institute of Science Education and Research, Kolkata, India; email: soumyadeepsar26@gmail.com},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Seth20241,
	author = {Seth, Taniya and Muhuri, Pranab K.},
	title = {MARSHAL: Multiple-Attribute Regret Theory and Semantically Aware Probabilistic Weights based Hesitant Linguistic Decision-Making},
	year = {2024},
	journal = {IEEE Transactions on Fuzzy Systems},
	pages = {1–15},
	doi = {10.1109/TFUZZ.2024.3429240},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201761080&doi=10.1109%2fTFUZZ.2024.3429240&partnerID=40&md5=f9eaf9263ce755a201a2017dab353319},
	affiliations = {Department of Computer Science, South Asian University, Maidan Garhi, New Delhi, India},
	abstract = {With ever-increasing abundance of text data, decisionmaking problems are becoming more complex. Such complexity is often a consequence of the nuanced input linguistic information which are already highly uncertain and subjective. In this paper, a novel multi-attribute decision making (MADM) model named MARSHAL is introduced in order to capture the aforesaid nuanced characteristics from raw input linguistic data. It is for the first time in the literature of fuzzy-based linguistic MADM models that MARSHAL treats inputs as rich linguistic features from a pretrained deep learning based large language model (LLM) in addition to being uncertain and hesitant, while also presenting vector arithmetic-based information elicitation from corresponding hesitant fuzzy linguistic term sets. The idea is to introduce semantically-aware probabilistic attribute weights based on high-dimensional linguistic features learnt by an enhanced variant of BERT, utilized to solve MADM problems alongside risk and regret-aversive behaviours of experts. The proposed model is tested for applicability on a real case-study of employee flight risk detection. Additionally, extensive quantitative and qualitative experiments are performed to prove the proposed model&#x0027;s gained interpretability and adaptability amongst several other properties which existing congeneric models do not possess IEEE},
	author_keywords = {Adaptation models; Computational modeling; Decision making; Hesitant fuzzy linguistic term sets; Linguistics; multi attributes decision making; natural language models; Probabilistic logic; regret theory; semantic textual similarity; semantically aware weights; Semantics; Vectors},
	keywords = {Contrastive Learning; Deep learning; Fuzzy logic; Fuzzy sets; Probabilistic logics; Problem solving; Adaptation models; Computational modelling; Decisions makings; Hesitant fuzzy linguistic term sets; Multi attribute decision making; Natural language model; Probabilistics; Regret theory; Semantic textual similarity; Semantically aware weight; Textual similarities; Semantics},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {10636706},
	coden = {IEFSE},
	language = {English},
	abbrev_source_title = {IEEE Trans Fuzzy Syst},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Yu2024,
	author = {Yu, Hong Qing and McGuinness, Stephen},
	title = {An experimental study of integrating fine-tuned large language models and prompts for enhancing mental health support chatbot system},
	year = {2024},
	journal = {Journal of Medical Artificial Intelligence},
	volume = {7},
	number = {June},
	doi = {10.21037/jmai-23-136},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199639787&doi=10.21037%2fjmai-23-136&partnerID=40&md5=26bb68ee39ebb51af9de71b2af17eed6},
	affiliations = {School of Computing, University of Derby, Derby, United Kingdom},
	abstract = {Background: Conversational mental healthcare support plays a crucial role in aiding individuals with mental health concerns. Large language models (LLMs) like GPT and BERT show potential in enhancing chatbot-based therapy responses. Despite their potential, there are recognised limitations in directly deploying these LLMs for therapeutic interactions as they are trained in general context and knowledge data. The overarching aim of this study is to integrate the capabilities of both GPT and BERT with the use of specialised mental health dataset methodologies. Its goal is to enhance mental health conversations, limiting the risk and increasing quality. Methods: To achieve these aims, we will review existing chatbot methodologies from rule-based systems to advanced approaches based on cognitive behavioural therapy (CBT) principles. The study introduces a unique method which integrates a fine-tuned DialoGPT model along with the real-time capabilities of the ChatGPT 3.5 application programming interface (API). This blended combination aims to leverage the contextual awareness of LLMs and the precision of mental health-focused training. The evaluation involves a case study whereby our hybrid model is compared to traditional and standalone LLM-based chatbots. The performance is assessed using metrics such as perplexity and BLEU (Bilingual Evaluation Understudy) scores, along with subjective evaluations from end-users and mental health carers. Results: Our combined model outperforms others in conversational quality and relevance in mental healthcare. The positive feedback from patients and mental healthcare professionals is evidence of this. However, vital limitations highlight the need for further development in next-generation mental health support systems. Addressing these challenges is crucial for such technologies’ practical application and effectiveness. Conclusions: With the rise of digital mental health tools, integrating models such as LLMs transforms conversational support. The study presents a promising approach combining state-of-the-art LLMs with domain-specific fine-tuned model principles. Results suggest our combined model offers affordable and better everyday support, validated by positive feedback from patients and professionals. Our research emphasises the potential of LLMs and points towards shaping responsible and effective policies for chatbot deployment in mental healthcare. These findings will contribute to future mental healthcare chatbot development and policy guidelines, emphasising the need for balanced and effective integration of advanced models and traditional therapeutic principles. © Journal of Medical Artificial Intelligence. All rights reserved.},
	author_keywords = {artificiaintelligence (AI); ChatGPT prompt engineering; large language model (LLM); Mental health chatbot},
	correspondence_address = {H.Q. Yu; School of Computing, University of Derby, Derby, Markeaton St, DE223AW, United Kingdom; email: h.yu@derby.ac.uk},
	publisher = {AME Publishing Company},
	issn = {26172496},
	language = {English},
	abbrev_source_title = {J. Med. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@ARTICLE{Susanto2024202,
	author = {Susanto, Hansel and Santoso Gunawan, Alexander Agung and Fikri Hasani, Muhammad},
	title = {Development of Automated Essay Scoring System Using DeBERTa as a Transformer-Based Language Model},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {935 LNNS},
	pages = {202 – 215},
	doi = {10.1007/978-3-031-54820-8_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197363250&doi=10.1007%2f978-3-031-54820-8_17&partnerID=40&md5=c50fe61958b0418eea85ac419fac5077},
	affiliations = {School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia},
	abstract = {Giving an essay assignment is an important task every educational institution holds for measuring students’ understanding and ability. Teachers have a significant role in this task because they are the one who assesses the assignment. Over time, the number of students will increase too. This makes doing a manual correction become more complicated. Some downsides are taking too much time, being less objective, and many more. In the past few years, the problem of automated essay scoring has become popular. But this problem still has a big problem which makes automated essay scoring still not as good as human assessment, especially in detecting the main idea of an essay, cohesion, and coherence. The large language model (LLM) has become popular in the past few years. Some examples are transformer-based models such as BERT, RoBERTa, and DeBERTa. In this research, we implement those three models as our base layer, in which we compare the value of Quadratic Weighted Kappa (QWK) as the metric of accuracy. In conclusion, the DeBERTa-based model has the best value of QWK compared to the other two. We also implement a system using Python, that can retrieve an essay and will run the model to do the scoring automatically. We also suggest fur- ther research references that can use different datasets other than the ASAP-AES dataset for the research or try to use the GPT-based language model as the base layer model. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Automated Essay Scoring; BERT; Correction; DeBERTa; Essay; Large Language Model; Python; Quadratic Weighted Kappa; RoBERTa},
	keywords = {Automation; Computational linguistics; E-learning; High level languages; Students; Automated essay scoring; Base layers; BERT; Correction; DeBERTa; Essay; Language model; Large language model; Quadratic weighted kappa; RoBERTa; Python},
	correspondence_address = {H. Susanto; School of Computer Science, Bina Nusantara University, Jakarta, 11480, Indonesia; email: hansel.susanto001@binus.ac.id},
	editor = {Silhavy R. and Silhavy P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303154819-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Garcia202425,
	author = {Garcia, Adriano Marques and Malenza, Giulio and Birke, Robert and Aldinucci, Marco},
	title = {Assessing Large Language Models Inference Performance on a 64-core RISC-V CPU with Silicon-Enabled Vectors},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3785},
	pages = {25 – 33},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207519040&partnerID=40&md5=f836fb157adee1fd419e0e23e2bb29b5},
	affiliations = {Computer Science Department, University of Torino, Corso Svizzera 185, Torino, 10149, Italy},
	abstract = {The rising usage of compute-intensive AI applications with fast response time requirements, such as text generation using large language models, underscores the need for more efficient and versatile hardware solutions. This drives the exploration of emerging architectures like RISC-V, which has the potential to deliver strong performance within tight power constraints. The recent commercial release of processors with RISC-V Vector (RVV) silicon-enabled extensions further amplifies the significance of RISC-V architectures, offering enhanced capabilities for parallel processing and accelerating tasks critical to large language models and other AI applications. This work aims to evaluate the BERT and GPT-2 language models inference performance on the SOPHON SG2042 64-core RISC-V architecture with silicon-enabled RVV v0.7.1. We benchmarked the models with and without RVV, using OpenBLAS and BLIS as BLAS backends for PyTorch to enable vectorization. Enabling RVV in OpenBLAS improved the inference performance by up to 40% in some cases. © 2024 Copyright for this paper by its authors.},
	author_keywords = {BLIS; LLM; OpenBLAS; PyTorch; RISC-V; RVV; SOPHON SG2042; XuanTie C920},
	keywords = {Benchmarking; C (programming language); Computer system recovery; Fast response computer systems; Memory architecture; Problem oriented languages; System-on-chip; BLIS; Language model; LLM; OpenBLAS; Performance; Pytorch; RISC-V; RISC-V vector; SOPHON sg2042; Xuantie c920; Parallel architectures},
	correspondence_address = {A.M. Garcia; Computer Science Department, University of Torino, Torino, Corso Svizzera 185, 10149, Italy; email: adriano.marquesgarcia@unito.it},
	editor = {Antelmi A. and Carlini E. and Dazzi P.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Panagoulias2024,
	author = {Panagoulias, Dimitrios P. and Virvou, Maria and Tsihrintzis, George A.},
	title = {Large Language Models as a Service: Optimisation Strategies via Knowledge Space Reduction},
	year = {2024},
	journal = {2024 IEEE International Conference on Omni-Layer Intelligent Systems, COINS 2024},
	doi = {10.1109/COINS61597.2024.10622117},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202569985&doi=10.1109%2fCOINS61597.2024.10622117&partnerID=40&md5=9d197c7a4a0b3691a2380e03a5bfb363},
	affiliations = {University of Piraeus, Department of Informatics, Piraeus, 18534, Greece},
	abstract = {In Large Language Models (LLMs), 'reducing the domain space' for text generation refers to limiting the range of content to be utilized for generating responses. This work explores Sequential Language Model Integration (SLMI), which mirrors the organization and distribution of knowledge across different fields of expertise. SLMI is the technique of linking multiple LLMs in a systematic manner and creating LLM-chains. In this paper, we refer to a process of choosing, linking and connecting LLMs with other services (invoke external machine learning processes or rule based applications) as 'Large Language Models as a Service' to describe a complete system with specific agency. We outline the development and evaluation process of an SLMI methodology to refine response accuracy and we evaluate the methodology in the domain of dermatology using medical knowledge paths, where gains were found regarding diagnostic accuracy.  © 2024 IEEE.},
	author_keywords = {AI-empowered software engineering; BERT; GPT; Large Language Models},
	keywords = {Application programs; Artificial intelligence; Computer software selection and evaluation; Program debugging; Program processors; Systems analysis; AI-empowered software engineering; BERT; GPT; Language model; Large language model; Modeling as a services; Models integration; Optimization strategy; Sequential languages; Service optimization},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835034959-7},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Omni-Layer Intell. Syst., COINS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Deng2024,
	author = {Deng, Yu and Xing, Yunzhao and Quach, Jason and Chen, Xiaotian and Wu, Xiaoqiang and Zhang, Yafei and Moureaud, Charlotte and Yu, Mengjia and Zhao, Yujie and Wang, Li and Zhong, Sheng},
	title = {Developing large language models to detect adverse drug events in posts on x},
	year = {2024},
	journal = {Journal of Biopharmaceutical Statistics},
	doi = {10.1080/10543406.2024.2403442},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204625316&doi=10.1080%2f10543406.2024.2403442&partnerID=40&md5=847a06d5b64995cea2b0128e22057f29},
	affiliations = {Data & Statistical Sciences, AbbVie Inc, North Chicago, IL, United States; Computer Science & Engineering, University of California San Diego, La Jolla, CA, United States; Clinical Development Oncology, AbbVie Inc, North Chicago, IL, United States},
	abstract = {Adverse drug events (ADEs) are one of the major causes of hospital admissions and are associated with increased morbidity and mortality. Post-marketing ADE identification is one of the most important phases of drug safety surveillance. Traditionally, data sources for post-marketing surveillance mainly come from spontaneous reporting system such as the Food and Drug Administration Adverse Event Reporting System (FAERS). Social media data such as posts on X (formerly Twitter) contain rich patient and medication information and could potentially accelerate drug surveillance research. However, ADE information in social media data is usually locked in the text, making it difficult to be employed by traditional statistical approaches. In recent years, large language models (LLMs) have shown promise in many natural language processing tasks. In this study, we developed several LLMs to perform ADE classification on X data. We fine-tuned various LLMs including BERT-base, Bio_ClinicalBERT, RoBERTa, and RoBERTa-large. We also experimented ChatGPT few-shot prompting and ChatGPT fine-tuned on the whole training data. We then evaluated the model performance based on sensitivity, specificity, negative predictive value, positive predictive value, accuracy, F1-measure, and area under the ROC curve. Our results showed that RoBERTa-large achieved the best F1-measure (0.8) among all models followed by ChatGPT fine-tuned model with F1-measure of 0.75. Our feature importance analysis based on 1200 random samples and RoBERTa-Large showed the most important features are as follows: “withdrawals”/”withdrawal”, “dry”, “dealing”, “mouth”, and “paralysis”. The good model performance and clinically relevant features show the potential of LLMs in augmenting ADE detection for post-marketing drug safety surveillance. © 2024 Taylor & Francis Group, LLC.},
	author_keywords = {adverse drug event; BERT; ChatGPT; few-shot prompting; LLM; Machine learning; natural language processing; RoBERTa; RoBERTa-large; Twitter/X},
	correspondence_address = {L. Wang; Data & Statistical Sciences, AbbVie Inc, North Chicago, United States; email: li.wang1@abbvie.com; S. Zhong; Data & Statistical Sciences, AbbVie Inc, North Chicago, 1 N. Waukegan Road, 60064, United States; email: sheng.zhong@abbvie.com},
	publisher = {Taylor and Francis Ltd.},
	issn = {10543406},
	coden = {JBSTE},
	pmid = {39300965},
	language = {English},
	abbrev_source_title = {J. Biopharm. Stat.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Madake20249,
	author = {Madake, Jyoti and Sondur, Mrunal and Morey, Sumit and Naik, Atharva and Bhatlawande, Shripad},
	title = {Comparative study of different LLM's for Captioning Images to Help Blind People},
	year = {2024},
	journal = {Proceedings of the 2024 International Conference on Emerging Techniques in Computational Intelligence, ICETCI 2024},
	pages = {9 – 15},
	doi = {10.1109/ICETCI62771.2024.10704129},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207819170&doi=10.1109%2fICETCI62771.2024.10704129&partnerID=40&md5=8ceaaa278a21ad85274367baaea2e022},
	affiliations = {Vishwakarma Institute of Technology, Department of Electronics and Commmunications, Pune, India},
	abstract = {The proposed system leverages LLMs, including GPT2, DistillGPT2, BERT, and RoBERTa, to provide detailed scene descriptions for the visually impaired. It employs an Encoder-Decoder architecture, with the Vision Transformer as the encoder and a distilled GPT-2 model as the decoder, facilitating the generation of comprehensive image captions. Training used a diverse dataset of around a hundred thousand samples on hardware equipped with an Nvidia Tesla V100 PCIE card and two Intel Xeon Silver CPUs. The model achieved a ROUGE score of 21.69%, signifying its potential to generate captions closely resembling human descriptions after training on suitable LLMs in the near future. This research has profound implications for enhancing the independence, education, and employment prospects of the visually impaired.  © 2024 IEEE.},
	author_keywords = {GPT2; LLM; Self-attention; Tokens; ViT},
	keywords = {Image coding; Personnel training; Blind people; Comparatives studies; Encoder-decoder architecture; GPT2; LLM; Scene description; Self-attention; Token; Visually impaired; ViT; Signal encoding},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038706-3},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Emerg. Techniques Comput. Intell., ICETCI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yokoyama2024328,
	author = {Yokoyama, Daiki and Nishiura, Kinari and Monden, Akito},
	title = {Identifying Security Bugs in Issue Reports: Comparison of BERT, N-gram IDF and ChatGPT},
	year = {2024},
	journal = {2024 IEEE/ACIS 22nd International Conference on Software Engineering Research, Management and Applications, SERA 2024 - Proceedings},
	pages = {328 – 333},
	doi = {10.1109/SERA61261.2024.10685583},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207067435&doi=10.1109%2fSERA61261.2024.10685583&partnerID=40&md5=62586c90d5e514162ad3677d7cc488fe},
	affiliations = {Graduate School of Environmental, Life, Natural Science and Technology, Okayama University, Okayama, Japan; Kyoto Institute of Technology, Faculty of Information and Human Sciences, Kyoto, Japan; Okayama University, Faculty of Environmental, Life, Natural Science and Technology, Okayama, Japan},
	abstract = {In recent software development, which has become increasingly large and complex, a huge number of issues including bugs, improvements, new feature requests are reported on a daily basis, and there is a risk of missing urgent bugs. Security bugs are particularly urgent because they can cause serious problems such as mal ware infections, and must be resolved quickly. Therefore, it is important to develop a technique to automatically identify security bugs in a large number of issue reports. The goal of this study is to empirically evaluate recent machine learning methods to identify security bugs using issue report text written in natural language as input. Specifically, this paper focuses on the two-class classification model using BERT, a language model based on the Transformer architecture. The model is constructed by fine-tuning a pre-trained model of BERT with the text of issue reports. In our experiment, we performed classification of issue reports obtained from four open source software projects. As a comparison method, we employ a classification model using features obtained by N -gram IDF, which is an extension of the conventional Bag-of- Words approach. We also employ ChatGPT, which is a general-purpose chatbot that utilizes a large-scale language model (LLM). As a result of our experiment, the BERT-based model showed the best classification performance in terms of F1 score. ChatGPT was better than the N-gram IDF based model, but far behind the BERT.  © 2024 IEEE.},
	author_keywords = {bug report; bug triage; issue classification; large language model},
	keywords = {Open source software; Bug reports; Bug triage; Classification models; Feature requests; Issue classification; Language model; Large language model; Machine learning methods; N-grams; Security bugs; Software design},
	editor = {Hochin T. and Ma J. and Mizuno O.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039134-3},
	language = {English},
	abbrev_source_title = {IEEE/ACIS Int. Conf. Softw. Eng. Res., Manag. Appl., SERA - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Ali20243174,
	author = {Ali, Syed Muhammad and Sajid, Hammad and Aijaz, Owais and Waheed, Owais and Alvi, Faisal and Samad, Abdul},
	title = {Team Sharingans at SimpleText: Fine-Tuned LLM based approach to Scientific Text Simplification},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {3174 – 3181},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201580617&partnerID=40&md5=b18063d1161065eb741f84f18ebe1faa},
	affiliations = {Computer Science Program, Dhanani School of Science and Engineering, Habib University, Karachi, 75290, Pakistan},
	abstract = {This paper reports Habib University's Team Sharingans' participation in the CLEF 2024 SimpleText track, which aims to simplify scientific texts for improved readability and comprehension for non-experts. Our goal is to use state-of-the-art language models for simple yet accurate explanations of scientific texts for the general public. Our solution is based on a multi-step approach utilizing the GPT-3.5 model to solve Tasks 1, 2, and 3 i.e. passage extraction, identification and explanation of difficult concepts, and summarization. Our approach for Task 1 involved sentence embedding-based vector database for narrowing the corpus, MS-Marco for document ranking, and GPT-3.5 for selecting informative passages. For Task 2, we fine-tuned the GPT-3.5 model to identify and explain difficult terms and generate explanations. For Task 3 also, we fine-tuned the GPT-3.5 model with a specific prompt to simplify given scientific abstracts and sentences. The effectiveness of our approach was assessed based on the quality of results, demonstrating the potential of advanced language models in making scientific education more accessible to the general public. Our solution proposes using fine-tuned large language models as a reliable source for scientific education. © 2024 Copyright for this paper by its authors.},
	author_keywords = {BERT; Elastic Search; GPT-3.5 Turbo; Large Language Models; SimpleText; Text simplification},
	keywords = {BERT; Elastic search; General publics; GPT-3.5 turbo; Language model; Large language model; Scientific education; Scientific texts; Simpletext; Text simplification},
	correspondence_address = {S.M. Ali; Computer Science Program, Dhanani School of Science and Engineering, Habib University, Karachi, 75290, Pakistan; email: sn07590@st.habib.edu.pk},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Mohammed20241503,
	author = {Mohammed, Sabah and Fiaidhi, Jinan},
	title = {Generative AI for Evidence-Based Medicine: A PICO GenAI for Synthesizing Clinical Case Reports},
	year = {2024},
	journal = {IEEE International Conference on Communications},
	pages = {1503 – 1508},
	doi = {10.1109/ICC51166.2024.10622271},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202825825&doi=10.1109%2fICC51166.2024.10622271&partnerID=40&md5=ac24f3d9e4fb639724e1eec37ad5b013},
	affiliations = {Lakehead University, Department of Computer Science, Thunder Bay, Canada},
	abstract = {Clinical research and practice are generating important new findings at exponential rate which need to be readily available to clinicians. However, clinicians are confronted with serious challenges when they try to seek such information for their evidence-based decision making or to generate new clinical case report. One important challenge is the long time needed to browse, filter, summarize and compile information from different resources. The other important challenge is to identify relevant important evidence-based information resources required to answer clinical questions or support a clinical finding. Artificial intelligence can help in solving both challenges based on the automatic question answering (Q&A) and generative technologies. However, Q&A and generative techniques are not trained to answer clinical queries that can be used for evidence-based practice nor it can respond to structured clinical questioning protocol like PICO (Patient/Problem, Intervention, Comparison and Outcome). This article describes the use of deep learning techniques for Q&A that is based on generative models like BERT and GPT to answer PICO clinical questions that can be used for evidence-based practice extracted from sound medical research resources like PubMed. We are reporting acceptable clinical answers that are supported by findings from PubMed. Our generative methods are reaching state of the art performance based on two staged bootstrapping process involving filtering relevant articles followed by identifying articles that support the requested outcome expressed by the PICO question. © 2024 IEEE.},
	author_keywords = {Automatic Question Answering; Bootstrapping; Clinical Case Report; Evidence-Based Medicine; Fine Tuning; Generative Models; LLM Transformers; PICO questions},
	keywords = {Case based reasoning; Clinical research; Deep learning; Automatic question answering; Bootstrapping; Case reports; Clinical case report; Evidence-based medicine; Fine tuning; Generative model; LLM transformer; Patient/problem, intervention, comparison and outcome question; Question Answering; Generative adversarial networks},
	editor = {Valenti M. and Reed D. and Torres M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15503607},
	isbn = {978-172819054-9},
	language = {English},
	abbrev_source_title = {IEEE Int Conf Commun},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gritsai2024,
	author = {Gritsai, German and Grabovoy, Andrey},
	title = {Automated Text Identification on Languages of the Iberian Peninsula: LLM and BERT-based Models Aggregation},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204394796&partnerID=40&md5=0fdce5ccaa0b6b3074fe6f2a0f4b28ae},
	affiliations = {Advacheck, Tallinn, Estonia; Université Grenoble Alpes (UGA), Grenoble, France},
	abstract = {This paper describes our solution approach for the IberAuTexTification (Automated Text Identification on Languages of the Iberian Peninsula) competition held as part of the IberLEF 2024 conference. Machine-generated text fragments can be spotted in almost various domains nowadays. The rapid progress of language models and the booming distribution of such texts sometimes confuses human beings. In this article, we present a model for detecting machine-generated fragments based on the aggregation of responses from a large language model BLOOM and two BERT-like encoders Multilingual E5 and XLM-RoBERTa. Given the specificity of the task, namely the presence of the different languages of the Iberian Peninsula, we fine-tuned the distinct models for different subgroups of languages. The method described in the paper helped our team to achieve about 67% for the binary classification dataset with 6 languages in the final competition result. © 2024 Copyright for this paper by its authors.},
	author_keywords = {adapters; fine-tuning; large language models; machine-generated text; multilungual approach; text classification; transformer-based models},
	keywords = {Modeling languages; Text processing; Adapter; Fine tuning; Iberian Peninsula; Language model; Large language model; Machine-generated texts; Multilungual approach; Text classification; Text identification; Transformer-based model; Classification (of information)},
	correspondence_address = {G. Gritsai; Advacheck, Tallinn, Estonia; email: gritsai@advacheck.com},
	editor = {Jimenez-Zafra S.M. and Chiruzzo L. and Rangel F. and Balouchzahi F. and Correa U.B. and Jover A.B. and Gomez-Adorno H. and Barba J.A.G. and Hernandez-Farias D.I. and Montejo-Raez A. and Moral P. and Abellan C.R. and Rodriguez M.E.V. and Taule M. and Valencia-Garcia R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nair2024134379,
	author = {Nair, Priyanka C. and Gupta, Deepa and Devi, Bhagavatula Indira and Kanjirangat, Vani and Deepak, P.},
	title = {Predicting Tumor Type and Residual Status of Suprasellar Lesions Using Indian Discharge Summaries},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {134379 – 134410},
	doi = {10.1109/ACCESS.2024.3460976},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204537537&doi=10.1109%2fACCESS.2024.3460976&partnerID=40&md5=672bbdf5cce97d9603f57046f416f072},
	affiliations = {Amrita Vishwa Vidyapeetham, Amrita School of Computing, Department of Computer Science and Engineering, Bengaluru, 560035, India; National Institute of Mental Health and Neurosciences, Department of Neurosurgery, Bengaluru, 560029, India; Istituto Dalle Molle di Studi sull'Intelligenza Artificiale USI/SUPSI, Lugano, 6962, Switzerland; Queen's University Belfast, School of Electronics, Electrical Engineering and Computer Science, Belfast, BT7 1NN, United Kingdom},
	abstract = {A suprasellar lesion is an unusual mass in the suprasellar region in the brain. Some common suprasellar lesions include Pituitary Adenoma, Craniopharyngioma and Meningioma. Patients may present with significant visual and other symptoms like headache, and hormonal imbalances. The proposed study utilizes 553 discharge summaries of suprasellar patients admitted during 2013-2019 at NIMHANS hospitals, Bangalore. Classification of discharge summary was conducted using 11 different word embedding techniques, including word2vec, FastText, Glove, and transformer-based embeddings. Tumor type is predicted using advanced ML classifiers like AdaBoost, Random Forest, and XGBoost. The highest F-score of 0.91 was reported for XGBoost when implemented along with SMOTE based data balancing and PCA based feature reduction. To enhance the classification performance of the best performing model, ClinicalBioBERT, a pre-trained BERT model that demonstrated superior results, was finetuned with domain-specific clinical data and resulted in an improvement of the F-score to 0.93. Classification of presence/absence of residual tumor post surgery is also carried out using transformer models and achieved a macro F1-score of maximum 1, after handling the class imbalance using SMOTE. Different combinations of experiments with PCA and SMOTE were carried out in both classification problems. Two Large Language Models: FlanT5 and Bloom, are also investigated in this work for both classification problems Initially, the LLM is employed with a zero-shot classification pipeline, resulting in poor performance. Consequently, fine-tuning of the LLM models are attempted using the discharge summary text, resulting in performance improvements.  © 2013 IEEE.},
	author_keywords = {BioBERT; bloom; Brain tumor; discharge summaries; fine-tuning; Flan-T5; large language model; residual tumor; suprasellar lesions; word embedding; zero-shot classification},
	keywords = {Adaptive boosting; Blooms (metal); Problem oriented languages; BioBERT; Bloom; Brain tumors; Discharge summary; Embeddings; Fine tuning; Flan-t5; Language model; Large language model; Residual tumors; Shot classification; Suprasellar lesion; Word embedding; Zero-shot classification; Embeddings},
	correspondence_address = {D. Gupta; Amrita Vishwa Vidyapeetham, Amrita School of Computing, Department of Computer Science and Engineering, Bengaluru, 560035, India; email: g_deepa@blr.amrita.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Lewoniewski2024506,
	author = {Lewoniewski, Włodzimierz and Stolarski, Piotr and Stróżyna, Milena and Lewańska, Elzbieta and Wojewoda, Aleksandra and Księżniak, Ewelina and Sawiński, Marcin},
	title = {OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {506 – 519},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201628048&partnerID=40&md5=e9e46cdc82234367ee354928e5fe035b},
	affiliations = {Department of Information Systems, Poznań University of Economics and Business, Al. Niepodległości 10, Poznań, 61-875, Poland},
	abstract = {This paper presents the experiments and results for the CheckThat! Lab at CLEF 2024 Task 6: Robustness of Credibility Assessment with Adversarial Examples (InCrediblAE). The primary objective of this task was to generate adversarial examples in five problem domains in order to evaluate the robustness of widely used text classification methods (fine-tuned BERT, BiLSTM, and RoBERTa) when applied to credibility assessment issues. This study explores the application of ensemble learning to enhance adversarial attacks on natural language processing (NLP) models. We systematically tested and refined several adversarial attack methods, including BERT-Attack, Genetic algorithms, TextFooler, and CLARE, on five datasets across various misinformation tasks. By developing modified versions of BERT-Attack and hybrid methods, we achieved significant improvements in attack effectiveness. Our results demonstrate the potential of modification and combining multiple methods to create more sophisticated and effective adversarial attack strategies, contributing to the development of more robust and secure systems. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Adversarial examples; BERT; fact-checking; LLM},
	keywords = {Generative adversarial networks; Attack methods; BERT; Credibility assessment; Ensemble learning; Fact-checking; LLM; Primary objective; Problem domain; Text classification methods; Text generations; Adversarial machine learning},
	correspondence_address = {M. Stróżyna; Department of Information Systems, Poznań University of Economics and Business, Poznań, Al. Niepodległości 10, 61-875, Poland; email: milena.strozyna@ue.poznan.pl},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sallah2024118250,
	author = {Sallah, Amine and Arbi Abdellaoui Alaoui, El and Agoujil, Said and Ahmad Wani, Mudasir and Hammad, Mohamed and Maleh, Yassine and Abd El-Latif, Ahmed A.},
	title = {Fine-Tuned Understanding: Enhancing Social Bot Detection with Transformer-Based Classification},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {118250 – 118269},
	doi = {10.1109/ACCESS.2024.3440657},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200814228&doi=10.1109%2fACCESS.2024.3440657&partnerID=40&md5=bdf14a3d9efe0606aae4a9f82e7f16ce},
	affiliations = {Moulay Ismail University of Meknes, Faculty of Sciences and Techniques, Department of Computer Science, Errachidia, 52000, Morocco; Moulay Ismail University of Meknes, Department of Sciences, Ecole Normale Supérieure, Errachidia, 50000, Morocco; Moulay Ismail University of Meknes, École Nationale de Commerce et de Gestion, El Hajeb, 23000, Morocco; Prince Sultan University, EIAS Data Science Laboratory, College of Computer and Information Sciences, Riyadh, 11586, Saudi Arabia; Menoufia University, Faculty of Computers and Information, Department of Information Technology, Shibin El Kom, 32511, Egypt; Sultan Moulay Slimane University (USMS), Laboratory LaSTI, ENSAK, Beni Mellal, 23000, Morocco; Prince Sultan University, Center of Excellence in Quantum and Intelligent Computing, Riyadh, 11586, Saudi Arabia; Menoufia University, Faculty of Science, Department of Mathematics and Computer Science, Shebin El-Koom, 32511, Egypt},
	abstract = {In recent years, the proliferation of online communication platforms and social media has given rise to a new wave of challenges, including the rapid spread of malicious bots. These bots, often programmed to impersonate human users, can infiltrate online communities, disseminate misinformation, and engage in various activities detrimental to the integrity of digital discourse. It is becoming more and more difficult to discern a text produced by deep neural networks from that created by humans. Transformer-based Pre-trained Language Models (PLMs) have recently shown excellent results in challenges involving natural language understanding (NLU). The suggested method is to employ an approach to detect bots at the tweet level by utilizing content and fine-tuning PLMs, to reduce the current threat. Building on the recent developments of the BERT (Bidirectional Encoder Representations from Transformers) and GPT-3, the suggested model employs a text embedding approach. This method offers a high-quality representation that can enhance the efficacy of detection. In addition, a Feedforward Neural Network (FNN) was used on top of the PLMs for final classification. The model was experimentally evaluated using the Twitter bot dataset. The strategy was tested using test data that came from the same distribution as their training set. The methodology in this paper involves preprocessing Twitter data, generating contextual embeddings using PLMs, and designing a classification model that learns to differentiate between human users and bots. Experiments were carried out adopting advanced Language Models to construct an encoding of the tweet to create a potential input vector on top of BERT and their variants. By employing Transformer-based models, we achieve significant improvements in bot detection F1-score (93%) compared to traditional methods such as Word2Vec and Global Vectors for Word Representation (Glove). Accuracy improvements ranging from 3% to 24% compared to baselines were achieved. The capability of GPT-4, an advanced Large Language Model (LLM), in interpreting bot-generated content is examined in this research. Additionally, explainable artificial intelligence (XAI) was utilized alongside transformer-based models for detecting bots on social media, enhancing the transparency and reliability of these models.  © 2013 IEEE.},
	author_keywords = {BERT; bot classification; explainability; LLM-based prompting; NLP; online social networks; pre-trained language models; transfer learning; transformers},
	keywords = {Blogs; Botnet; Computational linguistics; Deep neural networks; Encoding (symbols); Feedforward neural networks; Job analysis; Natural language processing systems; Network coding; Bidirectional control; Bidirectional encoder representation from transformer; Bot classification; Chatbots; Encodings; Explainability; Language model; Large language model-based prompting; Model-based OPC; Pre-trained language model; Social networking (online); Task analysis; Transfer learning; Transformer; Social networking (online)},
	correspondence_address = {Y. Maleh; Sultan Moulay Slimane University (USMS), Laboratory LaSTI, ENSAK, Beni Mellal, 23000, Morocco; email: yassine.maleh@ieee.org},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Assayed2024165,
	author = {Assayed, Suha Khalil and Alkhatib, Manar and Shaalan, Khaled},
	title = {A Transformer-Based Generative AI Model in Education: Fine-Tuning BERT for Domain-Specific in Student Advising},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2162 CCIS},
	pages = {165 – 174},
	doi = {10.1007/978-3-031-65996-6_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200759927&doi=10.1007%2f978-3-031-65996-6_14&partnerID=40&md5=4d844ac6027c161e3d0aa394148c457e},
	affiliations = {Faculty of Engineering and Information Technology, The British University in Dubai, Dubai, United Arab Emirates},
	abstract = {The Transformer model has inspired state-of-the-art generative NLP models such as the Bidirectional Encoder Representations from Transformers (BERT), Generative Pre-trained Transformer (GPT) and their variations models. Despite the fact that these training methods are responsible to have an effective language model, but the computational cost will be very expensive for performing any NLP tasks. Accordingly, the fine-tuning plays an essential role in improving the performance during the training process and reducing the computational cost. In this study we applied one of the pre-trained model from HuggingFace platform called a BERT-base-uncased model, which it’s variant of BERT and we utilized a specific purpose dataset for high school advising. However, the data is collected from high school and universities websites as well as from educational experts. The data includes enquiries and answers about advising high school students toward their future. This transformer, takes the input as a pair from the context and the question, and the output defined with the start and end positions of the answer in the context. Accordingly, the collected dataset is converted into json file, and then we applied the PyTorch libraries for building both, training and inference models. The ROUGE metrics revealed that the model achieves a good performance in answering to the students’ questions. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {BERT; Conversational AI; Domain-Specific; Fine-Tuning; Generative; GPT; LLM; NLP; Pre-trained; Transformer},
	keywords = {Artificial intelligence; Education computing; Students; Bidirectional encoder representation from transformer; Computational costs; Conversational AI; Domain specific; Fine tuning; Generative; Generative pre-trained transformer; LLM; Pre-trained; Transformer; Natural language processing systems},
	correspondence_address = {S.K. Assayed; Faculty of Engineering and Information Technology, The British University in Dubai, Dubai, United Arab Emirates; email: sassayed@gmail.com},
	editor = {Basiouni A. and Frasson C.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303165995-9},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vazquez2024,
	author = {Vazquez, Omar Garcia and Cardoso-Moreno, Marco and Torres-León, José Alberto and Jiménez, Diana},
	title = {HomoCIC at HOMO-MEX 2024: Deep Learning Approaches for Classifying Homophobic Content in Tweets and Songs: Leveraging LLM and NL},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204369515&partnerID=40&md5=b7f74ef0f5da34335ee952c4789c93b8},
	affiliations = {Instituto Politécnico Nacional, Center for Computing Research, Computational Cognitive Science Laboratory, City, Mexico, 07700, Mexico},
	abstract = {The increase of use of social media platforms has led to an increase in hate speech expressions in these platforms, including homophobic content targeting the LGBT+ community. Since LGBT+ people presents a particular susceptibility to various forms of discrimination and mental health issues, the wide spread of hate speech expressions poses a significant societal risk, particularly in the context of Mexican society, where drug abuse presents a pervasive social challenge. The HOMO-MEX task, par of the IberLEF (Iberian Languages Evaluation Forum), aims to tackle this issue by developing Natural Language Processing systems to detect hate speech directed to the LGBT+ community. The 2024 edition introduced three tracks: a multi-class hate speech detection, a multilabel one and, for the first time, a track focusing on identifying homophobic hate speech content in song lyrics. Our proposal consists on the use of different Large Language Models, namely: BERT, DistillBERT and RoBERTa, for tracks one and three, achieving 0.8219 and 0.4896 of macro F1-score, respectively. Our findings demonstrate the effectiveness of these advanced computational techniques in identifying subtle expressions of hate speech, contributing to the broader effort of mitigating the spread of harmful content and fostering a safer online and cultural environment for LGBT+ communities. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Classification; Hate Speech; Homophobia; LLM; NLP},
	keywords = {Deep learning; Natural language processing systems; Speech recognition; Tweets; Drug abuse; Hate speech; Health issues; Homophobia; Learning approach; LLM; Mental health; Social media platforms; Societal risks; Wide spreads; Health risks},
	correspondence_address = {M. Cardoso-Moreno; Instituto Politécnico Nacional, Center for Computing Research, Computational Cognitive Science Laboratory, Mexico, City, 07700, Mexico; email: mcardosom2021@cic.ipn.mx},
	editor = {Jimenez-Zafra S.M. and Chiruzzo L. and Rangel F. and Balouchzahi F. and Correa U.B. and Jover A.B. and Gomez-Adorno H. and Barba J.A.G. and Hernandez-Farias D.I. and Montejo-Raez A. and Moral P. and Abellan C.R. and Rodriguez M.E.V. and Taule M. and Valencia-Garcia R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pasquadibisceglie20241,
	author = {Pasquadibisceglie, Vincenzo and Appice, Annalisa and Malerba, Donato},
	title = {LUPIN: A LLM Approach for Activity Suffix Prediction in Business Process Event Logs},
	year = {2024},
	journal = {Proceedings - 2024 6th International Conference on Process Mining, ICPM 2024},
	pages = {1 – 8},
	doi = {10.1109/ICPM63005.2024.10680620},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205555906&doi=10.1109%2fICPM63005.2024.10680620&partnerID=40&md5=76016ed680f513b80f4ab035af422704},
	affiliations = {University of Bari Aldo Moro, Department of Computer Science, Bari, Italy},
	abstract = {Forecasting future states of running process instances is one of the main challenges of Predictive Process Monitoring (PPM). Several deep learning approaches have recently achieved a valuable accuracy performance by addressing this task. On the other hand, with the recent boom of Large Language Models (LLMs) in multiple fields, LLMs have started attracting attention in PPM research also. In this study, we leverage the rich context of textual data to transform information recorded in event logs in smart textual data ready for boosting accurate PPM learning. In detail, we propose LUPIN, a LLM approach to predict the activity suffix of a running process instance. First it encodes historical running process instances in semantic text stories formulated according to narrative templates that account for information recorded in the event log. Then it fine tunes a pre-trained LLM model - medium BERT - on the text stories of historic running instances of a business process, to predict the activity suffix of any future running instance of the same business process. Finally, LUPIN integrates the XAI Integrated Gradient (IG) algorithm to explain how each part of the textual description of a running process instance has an effect on the prediction of its activity completion. The experimental evaluation explores the accuracy performance of LUPIN compared to that of several related methods and draws insights from the explanation retrieved through the IG algorithm. © 2024 IEEE.},
	author_keywords = {Activity Suffix Prediction; BERT; Fine Tuning; LLMs; PPM; XAI},
	keywords = {Adaptive boosting; Data accuracy; Modeling languages; Prediction models; Activity suffix prediction; BERT; Fine tuning; Language model; Large language model; Predictive process; Predictive process monitoring; Process instances; Running process; XAI; Semantics},
	correspondence_address = {V. Pasquadibisceglie; University of Bari Aldo Moro, Department of Computer Science, Bari, Italy; email: vincenzo.pasquadibisceglie@uniba.it},
	editor = {Lu X. and Pufahl L. and Song M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036503-0},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Process Min., ICPM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Jafari20241458,
	author = {Jafari, Amir Reza and Heidary, Behnam and Farahbakhsh, Reza and Salehi, Mostafa and Crespi, Noel},
	title = {Language Models for Multi-Lingual Tasks - A Survey},
	year = {2024},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {15},
	number = {6},
	pages = {1458 – 1472},
	doi = {10.14569/IJACSA.2024.01506146},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199711458&doi=10.14569%2fIJACSA.2024.01506146&partnerID=40&md5=13d2d54daad882159f28be57c36b73c5},
	affiliations = {Samovar, Telecom SudParis, Institut Polytechnique de Paris, Palaiseau, 91120, France; New Sciences and Technologies, University of Tehran, Tehran, Iran},
	abstract = {These days different online media platforms such as social media provide their users the possibility to exchange and engage in different languages. It is not surprising anymore to see comments from different languages in posts published by international celebrities and figures. In this era, understanding cross-language content and multilingualism in natural language processing (NLP) are crucial, and huge amount of efforts have been dedicated on leverage existing technologies in NLP to tackle this challenging research problem, specially with advances in language analysis and the introduction of large language models. In this survey, we provide a comprehensive overview of the existing literature focusing on the evolution of language models with a focus on multilingual tasks and then we identify potential opportunities for further research in this domain. © (2024), (Science and Information Organization). All Rights Reserved.},
	author_keywords = {BERT; Language models; LLMs; low resource languages; multilingual task; NLP; transfer learning},
	keywords = {Natural language processing systems; Social networking (online); Transfer learning; BERT; Language model; Language processing; LLM; Low resource languages; Multi-lingual tasks; Natural language processing; Natural languages; Online medium; Transfer learning; Computational linguistics},
	publisher = {Science and Information Organization},
	issn = {2158107X},
	language = {English},
	abbrev_source_title = {Intl. J. Adv.  Comput. Sci. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Allen2024,
	author = {Allen, Janerra D. and Xia, Luke and Hong, L. Elliot and Choa, Fow-Sen},
	title = {Exploring Connections Between Auditory Hallucinations and Language Model Structures and Functions},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13059},
	doi = {10.1117/12.3013964},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196554052&doi=10.1117%2f12.3013964&partnerID=40&md5=91af2a83f5ab62041c59480487b60462},
	affiliations = {Department of Computer Science and Electrical Engineering, University of Maryland Baltimore County, Baltimore, MD, United States; Department of Psychology, Department of Biology, University of Maryland Baltimore County, Baltimore, MD, United States; Department of Psychiatry, The University of Texas Health Science Center, Houston, TX, United States},
	abstract = {Auditory hallucinations are a hallmark symptom of mental disorders such as schizophrenia, psychosis, and bipolar disorder. The biological basis for auditory perceptions and hallucinations, however, is not well understood. Understanding hallucinations may broadly reflect how our brains work - namely, by making predictions about stimuli and the environments that we navigate. In this work, we would like to use a recently developed language model to help the understanding of auditory hallucinations. Bio-inspired large language models (LLMs) such as Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-trained Transformer (GPT) can generate next words based on previously generated words from the embedded space and their pre-trained library with or without inputs. The generative nature of neural networks in GPT (like self-attention) can be analogously associated with the neurophysiological sources of hallucinations. Functional imaging studies have revealed that the hyperactivity of the auditory cortex and the disruption between auditory and verbal network activity may underlie auditory hallucinations' etiology. Key areas involved in auditory processing suggest that regions involved in verbal working memory and language processing are also associated with hallucinations. Auditory hallucinations reflect decreased activity in verbal working memory and language processing regions, including the superior temporal and inferior parietal regions. Parallels between auditory processing and LLM transformer architecture may help to decode brain functions on meaning assignment, contextual embedding, and hallucination mechanisms. Furthermore, an improved understanding of neurophysiological functions and brain architecture would bring us one step closer to creating human-like intelligence. © 2024 SPIE.},
	author_keywords = {auditory verbal hallucinations; BERT; generative neural network; GPT; large language models},
	keywords = {Biomimetics; Brain; Computational linguistics; Memory architecture; Model structures; Network architecture; Auditory hallucinations; Auditory processing; Auditory verbal hallucination; Bidirectional encoder representation from transformer; Generative neural network; Generative pre-trained transformer; Language model; Large language model; Neural-networks; Verbal working memory; Neurophysiology},
	editor = {Cullum B.M. and Kiehl D. and McLamore E.S.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151067436-3},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Liu20242735,
	author = {Liu, Biao and Han, Zhongyuan and Cao, HaoJie},
	title = {Team nlpln at PAN 2024: An Approach to Classifying Conspiratorial and Critical Public Health Narratives With Zero-shot and Sequence Labeling},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {2735 – 2743},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201591211&partnerID=40&md5=dcfba4d621fb14caada4ff7b265524a3},
	affiliations = {Foshan University, Foshan, China},
	abstract = {The growing prevalence of conspiracy theories poses significant challenges to content moderation on digital platforms. In our team nlpln, we employ a two-pronged approach to tackle distinct classification tasks related to public health narratives. For the first binary classification task, we utilize a Zero-Shot Learning approach with prompt engineering and Large Language Model (LLM). This method enables the model to differentiate between critical and conspiratorial narratives without extensive labeled data. For the second token-level classification task, we fine-tune a pretrained BERT-based model to identify and classify key elements in the narratives with the sliding windows technique and sequence Labeling. Our experiments demonstrate results; in subtask1, DeepSeek V2 and Baseline models outperform others in classification tasks across both languages, with notably high MCC values; in subtask2, our model demonstrates higher precision in detecting oppositional narrative elements across both languages, but the baseline model achieves better overall performance with higher Span-F1 scores, indicating a superior balance between precision and recall. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Conspiracy Theories; Fine-tune; LLM; Prompt engineering; Sequence Labeling},
	keywords = {Baseline models; Binary classification; Classification tasks; Conspiracy theory; Digital platforms; Fine-tune; Language model; Large language model; Prompt engineering; Sequence Labeling; Zero-shot learning},
	correspondence_address = {B. Liu; Foshan University, Foshan, China; email: hyticen@gmail.com},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jeong2024619,
	author = {Jeong, Ongee and Martin, Antoinette Deborah and Ahamadzadeh, Ezat and Moon, Inkyu},
	title = {Robust Cryptosystem Identification Under Various Operation Modes Using Deep Recurrent Neural Networks},
	year = {2024},
	journal = {2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data, ICEIB 2024},
	pages = {619 – 623},
	doi = {10.1109/ICEIB61477.2024.10602570},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201206230&doi=10.1109%2fICEIB61477.2024.10602570&partnerID=40&md5=521b3b277a060bfb3a58daa1d023369d},
	affiliations = {Daegu Gyeongbuk Institute of Science and Technology (DGIST), Department of Robotics and Mechatronics Engineering, Daegu, South Korea; Keimyung University Dongsan Hospital, Daegu, South Korea},
	abstract = {In the Ciphertext Only Attack (COA), an attacker can access and use only ciphertexts, identifying the type of cryptosystem is critical for further attack. The attacker can analyze patterns in the ciphertexts that have different forms according to the cryptosystem and recognize the type of cryptosystem. We propose deep learning-based cryptosystem identification by investigating eight cryptosystems, DES, S-DES, AES, S-AES, Blowfish, RC2, SPECK, and RSA. The Recurrent Neural Network (RNN)-based deep learning model with Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) is utilized to identify cryptosystems. The proposed method is used to classify ciphertext in each operation mode such as CBC, CFB, OFB, and CTR, into the corresponding cipher system. The performance of the proposed method was evaluated with recall, precision, classification accuracy, and F1 score. To verify effectiveness and superiority, we compared the proposed method with different machine learning-based and deep learning-based classifiers such as Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and BERT, a Large Language Model (LLM). Moreover, the previous methods in cryptosystem identification were also compared with the proposed method, and the results showed that eight cryptosystems were successfully recognized under various operation modes. The proposed method outperformed the other machine learning-based, and its deep learning-based classifiers were superior in cryptosystem identification. Furthermore, the proposed method showed a classification accuracy of 97.3 and 96.2 % in CBC and CFB, respectively, while the highest accuracy in the previous methods was 20% in CBC and 85.5% in CFB.  © 2024 IEEE.},
	author_keywords = {cryptosystems; deep learning; deep recurrent neural networks; operation modes prediction},
	keywords = {Deep neural networks; Learning systems; Long short-term memory; Nearest neighbor search; Security of data; Support vector machines; Ciphertext-only attacks; Ciphertexts; Classification accuracy; Deep learning; Deep recurrent neural network; Learning models; Machine-learning; Network-based; Operation mode; Operation mode prediction; Cryptography},
	editor = {Meen T.-H.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036072-1},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Electron. Commun., Internet Things Big Data, ICEIB},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu20248211,
	author = {Liu, Bo and Zhan, Li-Ming and Lu, Zexin and Feng, Yujie and Xue, Lei and Wu, Xiao-Ming},
	title = {How Good Are LLMs at Out-of-Distribution Detection?},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {8211 – 8222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195939658&partnerID=40&md5=45545b81d031adb2b83ee0ee544e4fb3},
	affiliations = {Department of Computing, The Hong Kong Polytechnic University, Hong Kong; School of Cyber Science and Technology, Sun Yat-Sen University, Shenzhen, China},
	abstract = {Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning models. As large language models (LLMs) become more prevalent, the applicability of prior research on OOD detection that utilized smaller-scale Transformers such as BERT, RoBERTa, and GPT-2 may be challenged, due to the significant differences in the scale of these models, their pre-training objectives, and the paradigms used for inference. This paper initiates a pioneering empirical investigation into the OOD detection capabilities of LLMs, focusing on the LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly used OOD detectors, examining their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLMs with downstream tasks. Our findings unveil that a simple cosine distance OOD detector demonstrates superior efficacy, outperforming other OOD detectors. We provide an intriguing explanation for this phenomenon by highlighting the isotropic nature of the embedding spaces of LLMs, which distinctly contrasts with the anisotropic property observed in smaller BERT family models. The new insight enhances our understanding of how LLMs detect OOD data, thereby enhancing their adaptability and reliability in dynamic environments. We have released the source code at https://github.com/Awenbocc/LLM-OOD for other researchers to reproduce our results. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {large language models; Out-of-distribution detection; performance evaluation},
	keywords = {Detection capability; Empirical investigation; Fine tuning; Language model; Large language model; Machine learning models; Out-of-distribution detection; Performances evaluation; Pre-training; Small scale; Computational linguistics},
	correspondence_address = {X.-M. Wu; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; email: xiao-ming.wu@polyu.edu.hk},
	editor = {Calzolari N. and Kan M.-Y. and Hoste V. and Lenci A. and Sakti S. and Xue N.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381410-4},
	language = {English},
	abbrev_source_title = {Jt. Int. Conf. Comput. Linguist., Lang. Resour. Eval., LREC-COLING - Main Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Tai202414673,
	author = {Tai, Yintao and Liao, Xiyang and Suglia, Alessandro and Vergari, Antonio},
	title = {PIXAR: Auto-Regressive Language Modeling in Pixel Space},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {14673 – 14695},
	doi = {10.18653/v1/2024.findings-acl.874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205311452&doi=10.18653%2fv1%2f2024.findings-acl.874&partnerID=40&md5=a93e060cae69108294aeba89d529b6f3},
	affiliations = {University of Edinburgh, United Kingdom; Heriot-Watt University, United Kingdom},
	abstract = {Recent work showed the possibility of building open-vocabulary large language models (LLMs) that directly operate on pixel representations. These models are implemented as autoencoders that reconstruct masked patches of rendered text. However, these pixel-based LLMs are limited to discriminative tasks (e.g., classification) and, similar to BERT, cannot be used to generate text. Therefore, they cannot be used for generative tasks such as free-form question answering. In this work, we introduce PIXAR, the first pixel-based autoregressive LLM that performs text generation. Consisting of only a decoder, PIXAR can perform free-form generative tasks while keeping the number of parameters on par with previous encoder-decoder models. Furthermore, we highlight the challenges of generating text as non-noisy images and show this is due to using a maximum likelihood objective. To overcome this problem, we propose an adversarial pretraining stage that improves the readability and accuracy of PIXAR by 8.1 on LAMBADA and 8.5 on bAbI- making it comparable to GPT-2 on text generation tasks. This paves the way to build open-vocabulary LLMs that operate on perceptual input only and calls into question the necessity of the usual symbolic input representation, i.e., text as (sub)tokens. Code is available at https://github.com/april-tools/pixar. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Generative adversarial networks; Image coding; Maximum likelihood estimation; Modeling languages; Pixels; Auto encoders; Auto-regressive; Encoder-decoder; Freeforms; Language model; Maximum-likelihood; Noisy image; Pixel representation; Question Answering; Text generations; Decoding},
	correspondence_address = {A. Suglia; Heriot-Watt University, United Kingdom; email: a.suglia@hw.ac.uk; A. Vergari; University of Edinburgh, United Kingdom; email: avergari@ed.ac.uk},
	editor = {Ku L.-W. and Martins A. and Srikumar V.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {979-889176099-8},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Yamaguchi2024291,
	author = {Yamaguchi, Saneyasu and Hirabayashi, Fuma and Tamekuri, Atsuki},
	title = {Improvement of Deep Learning Models by Excluding Inappropriate Data Based on Interpretability},
	year = {2024},
	journal = {Proceedings - 2024 IEEE 48th Annual Computers, Software, and Applications Conference, COMPSAC 2024},
	pages = {291 – 296},
	doi = {10.1109/COMPSAC61105.2024.00048},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204056651&doi=10.1109%2fCOMPSAC61105.2024.00048&partnerID=40&md5=4d42b4c40f13a2f3c4404b9fa9c63c34},
	affiliations = {Kogakuin University, Department of Information and Communications Engineering, Tokyo, Japan; Kogakuin University Graduate School, Electrical Engineering and Electronics, Tokyo, Japan},
	abstract = {Deep learning and large scale language models have significantly advanced data engineering, particularly in natural language processing. However, it has been pointed out that deep learning is a black box, raising concerns about its interpretability. To address this, methods for extracting decision bases and training data that influence the decision have been proposed. This paper focuses on a method for extracting training data that have a large impact on the decision, and proposes a method for improving training data by identifying and excluding training data that lead to incorrect decisions. The method divides the training data into subsets-the training data in the training data, the verification data in the training data, and the test data in the training data-and uses them to train and test the task. It then identifies and excludes training data that cause incorrect classifications. We evaluate this approach on document classification tasks using BERT, which is a large scale language model, demonstrating its effectiveness. We also evaluate our method on popular corpora, highlighting both its strengths and limitations.  © 2024 IEEE.},
	author_keywords = {BERT; decision basis; deep learning; documents classification; influence of a training example; LLM},
	keywords = {Adversarial machine learning; Data assimilation; Federated learning; BERT; Decision base; Deep learning; Document Classification; Influence of a training example; Interpretability; Large-scales; LLM; Training data; Training example; Contrastive Learning},
	editor = {Shahriar H. and Ohsaki H. and Sharmin M. and Towey D. and Majumder AKM.J.A. and Hori Y. and Yang J.-J. and Takemoto M. and Sakib N. and Banno R. and Ahamed S.I.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037696-8},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Annu. Comput., Softw., Appl. Conf., COMPSAC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {3rd International Conference on Modeling and Simulation of Social-Behavioral Phenomena in Creative Socities, MSBC 2024},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2211 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205092186&partnerID=40&md5=ef2d1facec45191ed04740a744efdbf2},
	abstract = {The proceedings contain 16 papers. The special focus in this conference is on Modeling and Simulation of Social-Behavioral Phenomena in Creative Socities. The topics include: A Signed Network Model of the Interaction Between Religious Movements and Authority in Judea; digital Society and Social Conflicts: A Science Map of the Field; on Strong Solutions in Linear Programming Problems with a Fuzzy Goal; sustainable Cooperation in a Bicriteria Game of Renewable Resource Extraction; Using the RoBERTa and T5 Models for Analyzing Texts in Uzbek: NER Tasks and Punctuation Prediction; algorithmic Strategies for stemming Complex Word from Uzbek to English in Machine Translation; research on the Impact of Social Networks on the Development of Bilingualism in Kazakhstan; A Comparative Analysis of LSTM and BERT Models for Named Entity Recognition in Kazakh Language: A Multi-classification Approach; Collection and Preprocessing of Data for LLM in the Kazakh Language in the Field of Legislation; model of Innovation-Based Economy Within the New Paradigm During the Relevant Economic Transformation; optimization of an Enterprise System Structure Based on the Concept of Multipolar Management; ethnic Nation Index; quantifying of Governance and Sectoral Policy History: Assessing General Education Efficiency in Lithuania in 1990–2020; investment Strategies and Private Interests in the Hierarchical Management Systems.},
	editor = {Agarwal N. and Sakalauskas L. and Tukeyev U.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303172259-2},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mohamed2024121251,
	author = {Mohamed, Toka A. and Khafgy, Mohamed H. and Elsedawy, Ahmed B. and Ismail, Ahmed S.},
	title = {A Proposed Model for Distinguishing between Human-Based and ChatGPT Content in Scientific Articles},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {121251 – 121260},
	doi = {10.1109/ACCESS.2024.3448315},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201746158&doi=10.1109%2fACCESS.2024.3448315&partnerID=40&md5=30d3858c3785e5f7b1cde6c01cf38d0c},
	affiliations = {Fayoum University, Faculty of Computers and Artificial Intelligence, Faiyum, 63514, Egypt; National Egyptian E-learning University, Faculty of Computers and Information Technology, Giza, 12611, Egypt; AASTMT, Educational Affairs Information System Department, Cairo, 4471344, Egypt},
	abstract = {This study introduces an innovative approach to address the growing challenge of detecting and distinguishing ChatGPT-generated content within scientific articles, particularly in the context of Learning Management Systems (LMS). Leveraging state-of-the-art large language models, including Robustly Optimized BERT Pretraining (RoBERTa), Text-to-Text Transfer Transformer (T5), and Generative Pre-trained Transformers (EleutherAI GPT-Neo-125M), our methodology focuses on the incorporation of the LMS concept into the research framework. To construct a comprehensive dataset representative of the diverse landscape of scientific abstracts, samples of the dataset are gathered from articles produced by human authors and those generated by ChatGPT within the LMS framework. The models (RoBERTa, T5, and EleutherAI GPT-Neo-125M) were subsequently trained on this unique dataset, showcasing their adaptability to the distinct characteristics of both human-generated and AI-generated content within the LMS context. The efficacy of our approach was rigorously evaluated using a range of metrics, resulting in an outstanding accuracy exceeding 99%. This achievement underscores the robustness of our methodology in successfully discerning content generated by ChatGPT within the LMS and that authored by human contributors, thereby advancing the field of content differentiation in scientific discourse.  © 2024 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.},
	author_keywords = {AI content; ChatGPT; EleutherAI GPT-Neo-125M; GPT-3.5; LLM; LMS; RoBERTa; T5},
	keywords = {Distribution transformers; Accuracy; AI content; Chatbots; ChatGPT; Eleutherai GPT-neo-125m; GPT-3.5; Language model; Large language model; Learning management system; LLM; Pre-training; Robustly optimized BERT pretraining; T5; Task analysis; Transformer; Data accuracy},
	correspondence_address = {T.A. Mohamed; Fayoum University, Faculty of Computers and Artificial Intelligence, Faiyum, 63514, Egypt; email: ta1231@fayoum.edu.eg},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Fahim Siddiqui2024266,
	author = {Fahim Siddiqui, Muhammad Hammad and Inkpen, Diana and Gelbukh, Alexander},
	title = {Towards Interpretable Emotion Classification: Evaluating LIME, SHAP, and Generative AI for Decision Explanations},
	year = {2024},
	journal = {Proceedings of the International Conference on Information Visualisation},
	pages = {266 – 271},
	doi = {10.1109/IV64223.2024.00053},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207848160&doi=10.1109%2fIV64223.2024.00053&partnerID=40&md5=a1f27dfb3617f69a65da68ba1bb265ad},
	affiliations = {University of Ottawa, Ottawa, ON, Canada; Instituto Politecnico Nacional, Mexico City, Mexico},
	abstract = {This paper explores the classification of multi-label emotions utilizing fine-tuned RoBERTa base and zero-shot GPT4 models, with experiments conducted on the SemEval 2018 E-c dataset encompassing 11 emotions, where more than one label is allowed for a text. Employing SHAP and LIME for RoBERTa explanations and generative AI for GPT4, we assess the sufficiency of explanations using the BERT score metric. We show the explanations generated by LIME and SHAP visually using different plots. The BERT score indicates that generative AI produces better explanations than the statistical models, providing deeper insights into emotion selection, with a BERT score of 59.66% compared to SHAP-RoBERTa's 54.17% and LIME-RoBERTa's 53.22%. This shows the potential of generative AI in revealing the reasoning behind decisions within complex emotional contexts. Though the performance is superior, we also discuss the limitations of these models that hinder wide-scale adoption. © 2024 IEEE.},
	author_keywords = {Emotion Classification; Explainable AI; LIME; LLM; Multi-label Classification; SHAP; XAI},
	keywords = {Generative adversarial networks; Emotion classification; Explainable AI; LLM; Multi-label classifications; Multi-labels; Performance; SHAP; Statistic modeling; XAI; Classification (of information)},
	editor = {Banissi E. and Datia N. and Pires J.M. and Ursyn A. and Nazemi K. and Kovalerchuk B. and Andonie R. and Gavrilova M. and Nakayama M. and Nguyen Q.V. and Mabakane M.S. and Rusu A. and Sciarrone F. and Temperini M. and Bouali F. and Venturini G. and Huang T.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {10939547},
	isbn = {979-835038016-3},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Inf. Visual.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Saxena2024,
	author = {Saxena, Yash and Chopra, Sarthak and Tripathi, Arunendra Mani},
	title = {Evaluating Consistency and Reasoning Capabilities of Large Language Models},
	year = {2024},
	journal = {2nd IEEE International Conference on Data Science and Information System, ICDSIS 2024},
	doi = {10.1109/ICDSIS61070.2024.10594233},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200126417&doi=10.1109%2fICDSIS61070.2024.10594233&partnerID=40&md5=8737a7f541f4e3d52c71a88c797fd9ef},
	affiliations = {Galgotias University, School Of Computing Science And Engineering, Greater Noida, India},
	abstract = {Large Language Models (LLMs) are extensively used today across various sectors, including academia, research, business, and finance, for tasks such as text generation, summarization, and translation. Despite their widespread adoption, these models often produce incorrect and misleading information, exhibiting a tendency to hallucinate. This behavior can be attributed to several factors, with consistency and reasoning capabilities being significant contributors. LLMs frequently lack the ability to generate explanations and engage in coherent reasoning, leading to inaccurate responses. Moreover, they exhibit inconsistencies in their outputs. This paper aims to evaluate and compare the consistency and reasoning capabilities of both public and proprietary LLMs. The experiments utilize the Boolq dataset as the ground truth, comprising questions, answers, and corresponding explanations. Queries from the dataset are presented as prompts to the LLMs, and the generated responses are evaluated against the ground truth answers. Additionally, explanations are generated to assess the models' reasoning abilities. Consistency is evaluated by repeatedly presenting the same query to the models and observing for variations in their responses. For measuring reasoning capabilities, the generated explanations are compared to the ground truth explanations using metrics such as BERT, BLEU, and F-1 scores. The findings reveal that proprietary models generally outperform public models in terms of both consistency and reasoning capabilities. However, even when presented with basic general knowledge questions, none of the models achieved a score of 90% in both consistency and reasoning. This study underscores the direct correlation between consistency and reasoning abilities in LLMs and highlights the inherent reasoning challenges present in current language models.  © 2024 IEEE.},
	author_keywords = {Consistency; Explanability; LLM; Prompting; Reasoning},
	keywords = {Consistency; Explanability; Ground truth; Language model; Large language model; Prompting; Reasoning; Reasoning ability; Reasoning capabilities; Text generations; Computational linguistics},
	correspondence_address = {Y. Saxena; Galgotias University, School Of Computing Science And Engineering, Greater Noida, India; email: yashsaxena2111@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038166-5},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Data Sci. Inf. Syst., ICDSIS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Song2024168,
	author = {Song, Jinwang and Zan, Hongying and Zhang, Kunli},
	title = {Enhanced Discriminative Fine-Tuning of Large Language Models for Chinese Text Classification},
	year = {2024},
	journal = {Proceedings of 2024 International Conference on Asian Language Processing, IALP 2024},
	pages = {168 – 174},
	doi = {10.1109/IALP63756.2024.10661135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204802230&doi=10.1109%2fIALP63756.2024.10661135&partnerID=40&md5=53c5f3662fb33baf81202ad9ccdd7835},
	affiliations = {Zhengzhou University, School of Computer and Artificial Intelligence, Zhengzhou, China},
	abstract = {In the field of natural language processing, the era of Large Language Models (LLMs) has arrived. Text classification, being a classic and widely applied task, can greatly benefit from the advancements brought by LLMs to enhance its performance. We introduce an Enhanced Discriminative Fine-Tuning (ED-FT) approach aimed at enhancing discriminative text classification with LLMs, which we experimentally validate on the open-source Chinese LLM, Yi series. ED-FT utilizes a prompt encoder to search for the soft prompts in a continuous parameter space for downstream text classification tasks, combined with efficient fine-Tuning techniques for LLMs. Additionally, we modify the attention mask of the Yi-6B model to incorporate bidirectional attention, enabling it to generate bidirectional representations of the input text sequences, which are then fed into an additional classification layer for non-generative text classification. We evaluate our method on three publicly available Chinese datasets: Tnews, ChnSentiCorp, and SMP2020-EWECT-Usual, achieving accuracy rates of 64.88%, 96.83%, and 83.35%, respectively. These results significantly surpass those of Bert-like models, achieving state-of-The-Art performance. Additionally, it markedly improved inference speed. Furthermore, we explore the effectiveness of utilizing LLM intermediate layer hidden states for text classification, and the impact of LLM sizes. © 2024 IEEE.},
	author_keywords = {Large Language Models; Natural Language Processing; Text Classification},
	keywords = {Classification (of information); Open systems; Chinese text classification; Fine tuning; Language model; Language processing; Large language model; Natural language processing; Natural languages; Open-source; Performance; Text classification; Natural language processing systems},
	correspondence_address = {H. Zan; Zhengzhou University, School of Computer and Artificial Intelligence, Zhengzhou, China; email: iehyzan@zzu.edu.cn},
	editor = {Liu R. and Wang L. and Bao F. and Lu Y. and Fan C. and Dong M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833154085-2},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Asian Lang. Process., IALP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Nazyrova2024,
	author = {Nazyrova, Nodira and Chahed, Salma and Chausalet, Thierry and Dwek, Miriam},
	title = {Leveraging large language models for medical text classification: a hospital readmission prediction case},
	year = {2024},
	journal = {2024 14th International Conference on Pattern Recognition Systems, ICPRS 2024},
	doi = {10.1109/ICPRS62101.2024.10677826},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206472619&doi=10.1109%2fICPRS62101.2024.10677826&partnerID=40&md5=57d814e5d4235e5e5f4c820a3601d903},
	affiliations = {School of Computer Science & Engineering, University of Westminster, London, United Kingdom; School of Life Scinces, University of Westminster, London, United Kingdom},
	abstract = {In recent years, the intersection of natural language processing (NLP) and healthcare informatics has witnessed a revolutionary transformation. One of the most groundbreaking developments in this realm is the advent of large language models (LLM), which have demonstrated remarkable capabilities in analysing clinical data. This paper aims to explore the potential of large language models in medical text classification, shedding light on their ability to discern subtle patterns, grasp domain-specific terminology, and adapt to the dynamic nature of medical information. This research focuses on the application of transformer-based models, such as Bidirectional Encoder Representations from Transformers (BERT), on hospital discharge summaries to predict 30-day readmissions among older adults. In particular, we explore the role of transfer learning in medical text classification and compare domain-specific transformer models, such as SciBERT, BioBERT and ClinicalBERT. We also analyse how data preprocessing techniques affect the performance of language models. Our comparative analysis shows that removing parts of text with a large proportion of out-of-vocabulary words improves the classification results. We also investigate how the input sequence length affects the model performance, varying sequence length from 128 to 512 for BERT-based models and 4096 sequence length for the Longformers. The results of the investigation showed that among compared models SciBERT yields the best performance when applied in the medical domain, improving current hospital readmission predictions using clinical notes on MIMIC data from 0.714 to 0.735 AUROC. Our next step is pretraining a model with a large corpus of clinical notes to potentially improve the adaptability of a language model in the medical domain and achieve better results in downstream tasks. ©2024 IEEE.},
	author_keywords = {BERT; BioBERT; ClinicalBERT; domain-specific transformer models; hospital readmission prediction; large language models; SciBERT},
	keywords = {Hospital data processing; Prediction models; Bidirectional encoder representation from transformer; BioBERT; Clinicalbert; Domain specific; Domain-specific transformer model; Hospital readmission prediction; Language model; Large language model; SciBERT; Transformer modeling; Natural language processing systems},
	correspondence_address = {N. Nazyrova; School of Computer Science & Engineering, University of Westminster, London, United Kingdom; email: N.Nazyrova@westminster.ac.uk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037565-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Pattern Recognit. Syst., ICPRS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Kilhoffer202479,
	author = {Kilhoffer, Zachary and Bashir, Masooda},
	title = {Cloud Privacy Beyond Legal Compliance: An NLP Analysis of Certifiable Privacy and Security Standards},
	year = {2024},
	journal = {Proceeding - 2024 IEEE Cloud Summit, Cloud Summit 2024},
	pages = {79 – 86},
	doi = {10.1109/Cloud-Summit61220.2024.00020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202430372&doi=10.1109%2fCloud-Summit61220.2024.00020&partnerID=40&md5=5d436674d476867840ff7c60765e7eb0},
	affiliations = {University of Illinois at Urbana-Champaign, School of Information Sciences, United States},
	abstract = {By implementing standards and becoming certified, organizations can demonstrate good practices and trustworthiness. However, privacy standards are relatively immature, and the pri-vacy research community rarely examines the individual controls of organizational standards (e.g., ISO 27017, SOC-2), which are what concretely implements privacy principles. It is also very time-consuming to monitor evolving standards, assess relevance and usefulness in a given context, and whether the effort and expense of becoming certified makes sense. In this paper, we propose an exploratory method leveraging a large language model (LLM) to analyze privacy documents. We created a dataset of controls (n = 1,511) from all nine standards identified as certifiable, cloud relevant, and privacy relevant. We fine-tuned BERT, a popular baseline LLM, to optimize performance on privacy standards. Finally, we performed topic modeling to better understand how the standards address privacy challenges and compare to one another. We demonstrate that controls can be grouped into 11 topics (e.g., "PII Management", "Continuous Monitoring and Auditing in Cloud"). Most standards seem to strongly emphasize the security and risk angles of privacy rather than rights and control over data. The results suggest efforts to standardize privacy practices are still nascent - more time, practice, and theoretical agreement is required before privacy standards approach the rigor of their security counterparts. By providing our fine-tuned model, coding pipeline, and method, we demonstrate the utility of this approach to better compare and understand privacy standards and other documen-tation for assessment and refining.  © 2024 IEEE.},
	author_keywords = {certification; controls; privacy; security; standards},
	keywords = {Anonymity; Data privacy; Pipeline codes; Certification; Good practices; Individual control; Language model; Legal compliance; Privacy; Privacy and security; Research communities; Security; Security standards; Differential privacy},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037006-5},
	language = {English},
	abbrev_source_title = {Proceeding - IEEE Cloud Summit, Cloud Summit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Zhang2024899,
	author = {Zhang, Xiaocai and Lim, Hur and Fu, Xiuju and Wang, Ke and Xiao, Zhe and Qin, Zheng},
	title = {Maritime-Context Text Identification for Connecting Artificial Intelligence (AI) Models},
	year = {2024},
	journal = {Proceedings - 2024 IEEE Conference on Artificial Intelligence, CAI 2024},
	pages = {899 – 904},
	doi = {10.1109/CAI59869.2024.00165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201204381&doi=10.1109%2fCAI59869.2024.00165&partnerID=40&md5=72e2ae174bc0eda4a41db0946b2ba51b},
	affiliations = {Agency for Science, Technology and Research (A∗STAR), Institute of High Performance Computing (IHPC), 1 Fusionopolis Way, #16-16 Connexis, Singapore, 138632, Singapore; Singapore Polytechnic, School of Computing, 500 Dover Road, Singapore, 139651, Singapore},
	abstract = {This study focuses on identifying texts related to maritime contexts using an advanced Large Language Model (LLM) and cost-sensitive approach for handling data imbalances. Firstly, a comprehensive dataset specifically for maritime-context queries is collected and augmented. Secondly, the dynamic contextual representations of input query considering the context of each word are obtained by a pre-trained LLM which incorporates Bidirectional Encoder Representations from Transformers (BERT) and Convolutional Neural Network (CNN). Thirdly, a Multi-Layer Perceptron (MLP) is constructed as the classifier to fine-tune the whole network on the newly collected dataset. Finally, the Focal loss is introduced for more effective parameter optimization to tackle the challenge of data imbalance between positive and negative samples, Extensive experiments have been conducted and the following promising results have been obtained: 1) The proposed approach achieves an impressive 99.97% F1 score in recognizing maritime-context texts; 2) The ConvBERT model, an enhancement over the original BERT, demonstrates superior performance in text representation while being more computationally efficient; 3) The Focal loss method outperforms other cost-sensitive learning strategies like class weighting and oversampling techniques; and 4) the proposed method surpasses other deep learning and BERT-based methods in text classification tasks. © 2024 IEEE.},
	author_keywords = {ConvBERT; imbalanced; Large Language Model (LLM); Maritime; text classification},
	keywords = {Classification (of information); Computational linguistics; Convolutional neural networks; Data handling; Learning systems; Query processing; Text processing; ConvBERT; Data imbalance; Imbalanced; Intelligence models; Language model; Large language model; Maritime; Model-sensitive; Text classification; Text identification; Deep learning},
	correspondence_address = {K. Wang; Agency for Science, Technology and Research (A∗STAR), Institute of High Performance Computing (IHPC), Singapore, 1 Fusionopolis Way, #16-16 Connexis, 138632, Singapore; email: wang_ke@ihpc.a-star.edu.sg},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035409-6},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Conf. Artif. Intell., CAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lin2024,
	author = {Lin, Jianzhe and Diesendruck, Maurice and Du, Liang and Abraham, Robin},
	title = {BATCHPROMPT: ACCOMPLISH MORE WITH LESS},
	year = {2024},
	journal = {12th International Conference on Learning Representations, ICLR 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200554286&partnerID=40&md5=dc7825cd075e4719645bb5059c6c83d7},
	affiliations = {Microsoft, United States},
	abstract = {The ever-increasing token limits of large language models (LLMs) have enabled long context as input. Many LLMs are trained and fine-tuned to perform zero/few-shot inference using instruction-based prompts. Prompts typically include a detailed task instruction, several examples, and a single data point for inference. This baseline is referred to as “SinglePrompt” in this paper. In terms of token count, when the data input is small compared to instructions and examples, this results in lower token utilization, compared with encoder-based models like fine-tuned BERT. This cost inefficiency, affecting inference speed and compute budget, counteracts many of the benefits that LLMs offer. This paper aims to alleviate this problem by batching multiple data points in each prompt, a strategy we refer to as “BatchPrompt”. We improve token utilization by increasing the “density” of data points, however, this cannot be done naively. Simple batching can degrade performance, especially as batch size increases, and data points can yield different answers depending on their position within a prompt. To address the quality issue while retaining high token utilization, we introduce Batch Permutation and Ensembling (BPE) for BatchPrompt - a simple majority vote over repeated permutations of data, that recovers label quality at the cost of more token usage. To counterbalance this cost, we further propose Self-reflection-guided EArly Stopping (SEAS), which can terminate the voting process early for data points that the LLM handles confidently. Our comprehensive experimental evaluation demonstrates that BPE + SEAS can boost the performance of BatchPrompt by a striking margin on a range of popular NLP tasks, including question answering (Boolq), textual entailment (RTE), and duplicate questions identification (QQP). This performance is even competitive with/higher than single-data prompting (SinglePrompt), while using far fewer LLM calls and input tokens. At batch size 32, our BatchPrompt + BPE + SEAS uses 15.7% the number of LLM calls, and achieves: Boolq accuracy 90.6% → 90.9% with 27.4% tokens, QQP accuracy 87.2% → 88.4% with 18.6% tokens, RTE accuracy 91.5% → 91.1% with 30.8% tokens. We hope our simple yet effective approach will shed light on the future research of large language models. Code: github.com/microsoft/BatchPrompt. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.},
	keywords = {Budget control; Batch sizes; Cost inefficiencies; Data input; Datapoints; Early stopping; Language model; Multiple data; Performance; Self reflection; Simple++; Natural language processing systems},
	publisher = {International Conference on Learning Representations, ICLR},
	language = {English},
	abbrev_source_title = {Int. Conf. Learn. Represent., ICLR},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dong20247372,
	author = {Dong, Ming and Chen, Yujing and Zhang, Miao and Sun, Hao and He, Tingting},
	title = {Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {7372 – 7383},
	doi = {10.18653/v1/2024.findings-acl.439},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205288052&doi=10.18653%2fv1%2f2024.findings-acl.439&partnerID=40&md5=c9dea29188242002c628cfae1fae89ab},
	affiliations = {Hubei Provincial Key Laboratory of Artificial Intelligence and Smart Learning, Wuhan, China; National Language Resources Monitoring and Research Center for Network Media, Wuhan, China; School of Computer, Central China Normal University, Wuhan, China; School of Computer Science and Information Engineering, Hubei University, Wuhan, China},
	abstract = {Chinese Spell Checking (CSC) is a widely used technology, which plays a vital role in speech to text (STT) and optical character recognition (OCR). Most of the existing CSC approaches relying on BERT architecture achieve excellent performance. However, limited by the scale of the foundation model, BERT-based method does not work well in few-shot scenarios, showing certain limitations in practical applications. In this paper, we explore using an in-context learning method named RS-LLM (Rich Semantic based LLMs) to introduce large language models (LLMs) as the foundation model. Besides, we study the impact of introducing various Chinese rich semantic information in our framework. We found that by introducing a small number of specific Chinese rich semantic structures, LLMs achieve better performance than most of the BERT-based model on few-shot CSC task. Furthermore, we conduct experiments on multiple datasets, and the experimental results verified the superiority of our proposed framework. © 2024 Association for Computational Linguistics.},
	keywords = {Optical character recognition; Semantics; Zero-shot learning; Context learning; Foundation models; In contexts; Language model; Learning methods; Optical-; Performance; Semantics Information; Semantics knowledge; Spell-checking; Computational linguistics},
	correspondence_address = {T. He; Hubei Provincial Key Laboratory of Artificial Intelligence and Smart Learning, Wuhan, China; email: tthe@ccnu.edu.cn},
	editor = {Ku L.-W. and Martins A. and Srikumar V.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {979-889176099-8},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Hashimoto2024,
	author = {Hashimoto, Masayuki},
	title = {Reducing response delays in dialogue systems using the predictive performance of large language models},
	year = {2024},
	journal = {Proceedings of the World Congress on Electrical Engineering and Computer Systems and Science},
	doi = {10.11159/mhci24.104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205531541&doi=10.11159%2fmhci24.104&partnerID=40&md5=ed1068236a73dd08dd81ebf6bb96666e},
	affiliations = {Toyo University, 2100 Kujirai, Kawagoe-shi, Saitama, Japan},
	abstract = {1. Objectives Current speech dialogue systems struggle to provide smooth, human-like responses to user utterances, often resulting in response delays. In this study, we propose an approach to reduce these delays by utilizing the predictive capabilities of Large Language Models (LLMs)[1] within speech dialogue systems. We conducted an analysis to estimate the potential reduction in response times that can be expected from this proposed approach. Furthermore, we propose methodologies to implement this approach in actual speech dialogue systems. 2. Approach In typical LLM-based speech dialogue systems, the system waits for the user to complete their utterance before feeding it into the LLM to generate a response and process the speech. This causes a delay equal to the time taken by the LLM to generate the response text after the user has finished speaking. To reduce this delay, we propose an approach where the LLM generates response text for an incomplete utterance without waiting for the user to finish speaking. This allows for earlier initiation of LLM response generation, potentially reducing response delays. Additionally, the system verifies that the user has finished speaking before responding. 3. Scope This study focuses on text sentences gained after speech recognition in speech conversation systems. While there are some deviations from actual spoken dialogues, a text chat corpus[2] was employed for its clear content when the proposed approach was evaluated in this study. Additionally, a corpus derived from transcriptions of real conversations[3] was also examined. 4. Issues However, two significant issues arise with the proposed approach described in Section 2. First, despite LLMs' ability to predict the continuation of unfinished sentences, they may not always produce appropriate responses when generating replies to incomplete utterances. As part of a feasibility study, this research estimated the expected reduction in response time using gpt-3.5-turbo, as shown in Section 5. Second, in practical dialogue systems, it is unclear at which point during a user's ongoing utterance it would be appropriate to stop voice data acquisition and initiate dialogue response generation. This study proposes a metric to determine the timing for response generation that minimizes response failures, as shown in Section 6, and will quantitatively evaluate how much this proposed algorithm can reduce failure rates. 5. Anticipated Effects and Analysis Results/Expected Reduction in Response Time To determine the predictive performance, we assessed gpt-3.5-turbo's ability to generate coherent responses from incomplete user utterances, even when part of the utterance was missing. Results showed that failure rates increase with the number of omitted characters. Specifically, in an evaluation with a text chat corpus where 15 characters were omitted, denoted as N = 15, the failure rate was under 20%. Translating 15 characters to about 2.5 seconds of spoken Japanese suggests that it may be possible to reduce response times by up to 2.5 seconds with an 80% success rate. In contrast, a spoken dialogue corpus showed a 47% failure rate at N = 15. For this issue, a re-evaluation is planned using a more exemplary daily conversation corpus. 6. Proposed Method Based on Experimental Results As a criterion for deciding when to stop voice data acquisition and initiate dialogue response generation, we focus on the embedding representations of dialogue content using Sentence-BERT[4]. This approach is inspired by the fact that LLMs typically use the embedding representation of an input sentence to generate subsequent words. We investigated changes in the similarity measure, St(X0,Xt), between the embedding representation X0 (the embedding at the start of the user's utterance) and Xt (the embedding at midpoint t during the user's utterance). Our analysis aimed to determine whether LLMs can produce coherent responses based solely on the dialogue history up to t. We discovered that when St sharply declines and then rises, gpt-3.5-turbo is capable of returning a coherent response based solely on the dialogue history up to that point. Consequently, our proposed method involves continuously transcribing the user's speech in real-time, calculating St from the entire dialogue history up to that point, and initiating dialogue response generation when the characteristic temporal change in St —a sharp decline followed by a rise—is detected. Further analysis and quantitative evaluation of this timing detection method are planned. © 2024, Avestia Publishing. All rights reserved.},
	correspondence_address = {M. Hashimoto; Toyo University, Kawagoe-shi, Saitama, 2100 Kujirai, Japan; email: hashimoto065@toyo.jp},
	editor = {Benedicenti L.},
	publisher = {Avestia Publishing},
	issn = {2369811X},
	isbn = {978-199080043-6},
	language = {English},
	abbrev_source_title = {Proc. World. Congr. Electr. Eng. Comput. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Balakrishna2024,
	author = {Balakrishna, Chinnala and Yadav, Ankit and Singh, Jagendra and Saba, Masarath and Shashikant and Shrivastava, Vineet},
	title = {Smart Drug Delivery Systems using Large Language Models for Real-Time Treatment Personalization},
	year = {2024},
	journal = {2024 2nd World Conference on Communication and Computing, WCONF 2024},
	doi = {10.1109/WCONF61366.2024.10692060},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207468483&doi=10.1109%2fWCONF61366.2024.10692060&partnerID=40&md5=b1476603553f8a4ae66630ecdcbde02e},
	affiliations = {Department of CSE(AIML & Cyber Security), Guru Nanak Institute of Technology(Autonomous), Hyderabad, India; School of Computer Science Engineering & Technology, Bennett University, Greater Noida, India; Department of CSE (AI&ML), CVR College of Engineering, JNTUH, Hyderabad, India; Electrical Engineering Department, School of Engineering, Babu Banarasi Das University, Lucknow, India; Department of Computer Science and Engineering, Raj Kumar Goel Institute of Technology, Ghaziabad, India},
	abstract = {This research explores the use of large language models, such as BERT and GPT, in developing a smart drug delivery system utilizing real-time personalized treatments. The research aims to utilize large datasets with advanced natural language processing to recommend the appropriate drug for a patient based on their health record with enhanced accuracy and efficiency. The research, which evaluates and compares BERT and GPT, achieves the goal of predicting a drug with high accuracy, and GPT delivers the best results compared to BERT. Specifically, GPT achieved an accuracy of 97.95%, while BERT's accuracy was 95.50%. Additionally, the research emphasizes the essential aspect of a model's time response since these are real-time clinical decision systems. GPT took 110 milliseconds to predict the drug while the BERT took 120 milliseconds. It is clear from the results of this work that LLM has the potential of changing personalized medicine's approach by recommending drugs in real-time and according to the patient's health record within no time. The proposed system for smart drug delivery is promising to improve healthcare services, patient outcomes, and reduce drug administration errors. Apart from predicting the drug, these research findings can be simulated to the health sectors and integrated with AI technologies to improve decision support systems. © 2024 IEEE.},
	author_keywords = {BERT; GPT; large language models; personalized medicine; real-time treatment; Smart drug delivery},
	keywords = {Clinical research; Electronic health record; Personalized medicine; Records management; Targeted drug delivery; BERT; GPT; Health records; Language model; Large language model; Personalized medicines; Real- time; Real-time treatment; Smart drug deliveries; Smart drug delivery systems; Drug discovery},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039532-7},
	language = {English},
	abbrev_source_title = {World Conf. Commun. Comput., WCONF},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Chuor2024161,
	author = {Chuor, Porchourng and Ittoo, Ashwin and Heng, Samedi},
	title = {User Story Classification with Machine Learning and LLMs},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14884 LNAI},
	pages = {161 – 175},
	doi = {10.1007/978-981-97-5492-2_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200718178&doi=10.1007%2f978-981-97-5492-2_13&partnerID=40&md5=c51b63d0ec4eed1b5c0b2bf0ae3e1cec},
	affiliations = {HEC ULiege, Université de Liège, Liège, Belgium; LouRIM, UCLouvain, Louvain-la-Neuve, Belgium},
	abstract = {We address the problem of classifying Capability, Task, Hard-goal, and Soft-goal in user stories. Such a classification is essential for generating Rationale Tree. Several articles have attempted to classify different aspects of user stories in the past. However, classifying the Capability, Task, Hard-goal, and Soft-goal class has been largely overlooked. To this aim, we present three pipelines. The first two pipelines rely on standard machine learning methods. They differ in how they represent features, i.e. bag-of-word vs. embedding from deep learning methods. Our third pipeline explores a recent NLP development, viz. few-shot classification with two LLMs, Mistral and Llama. Our experiments reveal that using deep learning embedding as a feature of classical machine learning methods significantly improves performance, even for minority classes. Thus, such features could help alleviate class imbalance and data sparsity issues. We also found out that Mistral outperformed Llama. However, its performance was still far below that achieved by classical machine learning methods. We believe that our is novel as we are the first to study the problem of classifying Capability, Task, Hard-goal, and Soft-goal, and as we investigate how LLMs perform in this problem. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {BERT; Llama2; LLMs; Mistral; Neural Networks; Random forest; SVM; Text classification; User story},
	keywords = {Classification (of information); Deep learning; Embeddings; Support vector machines; Text processing; BERT; Llama2; LLM; Mistral; Neural-networks; Random forests; Soft goals; SVM; Text classification; User stories; Pipelines},
	correspondence_address = {P. Chuor; HEC ULiege, Université de Liège, Liège, Belgium; email: porchourng.chuor@uliege.be},
	editor = {Cao C. and Chen H. and Zhao L. and Arshad J. and Wang Y. and Asyhari T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981975491-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liao202414798,
	author = {Liao, Zihan and Yu, Hang and Li, Jianguo and Wang, Jun and Zhang, Wei},
	title = {D2LLM: Decomposed and Distilled Large Language Models for Semantic Search},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {14798 – 14814},
	doi = {10.18653/v1/2024.acl-long.791},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204432134&doi=10.18653%2fv1%2f2024.acl-long.791&partnerID=40&md5=3d5134c03f815c8f6c14675478762174},
	affiliations = {East China Normal University, China; Ant Group, China},
	abstract = {The key challenge in semantic search is to create models that are both accurate and efficient in pinpointing relevant sentences for queries. While BERT-style bi-encoders excel in efficiency with pre-computed embeddings, they often miss subtle nuances in search tasks. Conversely, GPT-style LLMs with cross-encoder designs capture these nuances but are computationally intensive, hindering real-time applications. In this paper, we present D2LLMs-Decomposed and Distilled LLMs for semantic search-that combines the best of both worlds. We decompose a cross-encoder into an efficient bi-encoder integrated with Pooling by Multihead Attention and an Interaction Emulation Module, achieving nuanced understanding and pre-computability. Knowledge from the LLM is distilled into this model using contrastive, rank, and feature imitation techniques. Our experiments show that D2LLM surpasses five leading baselines in terms of all metrics across three tasks, particularly improving NLI task performance by at least 6.45%. The source code is available at https://github.com/codefuse-ai/D2LLM. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Encoding (symbols); Latent semantic analysis; Design captures; Embeddings; Encoder design; Excel; Imitation techniques; Language model; Multihead; Real-time application; Search tasks; Semantic search; Semantics},
	correspondence_address = {J. Li; Ant Group, China; email: lijg.zero@antgroup.com; J. Wang; East China Normal University, China; email: wongjun@gmail.com; W. Zhang; East China Normal University, China; email: zhangwei.thu2011@gmail.com},
	editor = {Ku L.-W. and Martins A.F.T. and Srikumar V.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {979-889176094-3},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Esfahani202477,
	author = {Esfahani, Seyed Hamed Noktehdan and Adda, Mehdi},
	title = {Classical Machine Learning and Large Models for Text-Based Emotion Recognition},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {241},
	pages = {77 – 84},
	doi = {10.1016/j.procs.2024.08.013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204281448&doi=10.1016%2fj.procs.2024.08.013&partnerID=40&md5=18be750f7b670274e5df82e7fb87db20},
	affiliations = {Department of Mathematics and Computer Science, University of Quebec, Rimouski, QC, Canada},
	abstract = {In the era of digital communication, detecting emotions has become crucial for applications ranging from customer service to mental health assessment. This study examines emotion recognition in text through various machine learning techniques, from traditional machine learning techniques, to advanced large language models (LLMs) such as BERT, Falcon 7B, and Mistral 7B. The results reveal that the fine-tuned Mistral 7B model is the most precise, achieving an accuracy of 76%. Furthermore, Support Vector Machine attained an accuracy of 64%. © 2024 The Authors. Published by Elsevier B.V.},
	author_keywords = {Emotion Recognition; Fine-tuning; Large Language Models; LLM; Machine Learning; NLP; One-shot learning},
	keywords = {Contrastive Learning; Emotion Recognition; Support vector machines; Zero-shot learning; Emotion recognition; Fine tuning; Language model; Large language model; Machine learning models; Machine learning techniques; Machine-learning; One-shot learning; Adversarial machine learning},
	correspondence_address = {M. Adda; Department of Mathematics and Computer Science, University of Quebec, Rimouski, Canada; email: mehdi_adda@uqar.ca},
	editor = {Shakshuki E.E.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Qiang Wang2024160396,
	author = {Qiang Wang, Zhi and Wang, Haopeng and El Saddik, Abdulmotaleb},
	title = {FedITD: A Federated Parameter-Efficient Tuning With Pre-Trained Large Language Models and Transfer Learning Framework for Insider Threat Detection},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {160396 – 160417},
	doi = {10.1109/ACCESS.2024.3482988},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207781039&doi=10.1109%2fACCESS.2024.3482988&partnerID=40&md5=7c84cc0e9dadb20725147413b40692c5},
	affiliations = {University of Ottawa, Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, Ottawa, K1N 6N5, ON, Canada; MBZUAI, Department of Computer Vision, Abu Dhabi, United Arab Emirates},
	abstract = {Insider threats cause greater losses than external attacks, prompting organizations to invest in detection systems. However, there exist challenges: 1) Security and privacy concerns prevent data sharing, making it difficult to train robust models and identify new attacks. 2) The diversity and uniqueness of organizations require localized models, as a universal solution could be more effective. 3) High resource costs, delays, and data security concerns complicate building effective detection systems. This paper introduces FedITD, a flexible, hierarchy, and federated framework with local real-time detection systems, combining Large Language Models (LLM), Federated Learning (FL), Parameter Efficient Tuning (PETuning), and Transfer Learning (TF) for insider threat detection. FedITD uses FL to protect privacy while indirect integrating client information and employs PETuning methods (Adapter, BitFit, LoRA) with LLMs (BERT, RoBERTa, XLNet, DistilBERT) to reduce resource use and time delay. FedITD customizes client models and optimizes performance via transfer learning without central data transfer, further enhancing the detection of new attacks. FedITD outperforms other federated learning methods and its performance is very close to the best centrally trained method. Extensive experiment results show FedITD's superior performance, adaptability to varied data, and reduction of resource costs, achieving an optimal balance in detection capabilities across source data, unlabeled local data, and global data. Alternative PETuning implementations are also explored in this paper.  © 2024 The Authors.},
	author_keywords = {adapter; artificial intelligence; BERT; BitFit; Cybersecurity; data augmentation; deep learning; DistilBERT; GPT; insider threat; LLM; LoRA; machine learning; NLP; PETuning; pre-trained LLM; RoBERTa; transformer; XLNet},
	keywords = {Adversarial machine learning; Data privacy; Deep learning; Medium access control; Network security; Steganography; Taxonomies; Transfer learning; Adapter; BERT; Bitfit; Cyber security; Data augmentation; Deep learning; Distilbert; GPT; Insider Threat; Language model; Large language model; LoRA; Machine-learning; Parameter-efficient tuning; Pre-trained large language model; RoBERTa; Transformer; XLNet; Federated learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Roosan202415,
	author = {Roosan, Don and Wu, Yanting and Chok, Jay and Sanine, Christopher P. and Khou, Tiffany and Li, Yawen and Khan, Hasiba M.},
	title = {Artificial Intelligence-Powered Large Language Transformer Models for Opioid Abuse and Social Determinants of Health Detection for the Underserved Population},
	year = {2024},
	journal = {Proceedings of the 13th International Conference on Data Science, Technology and Applications, DATA 2024},
	pages = {15 – 26},
	doi = {10.5220/0012717200003756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203069318&doi=10.5220%2f0012717200003756&partnerID=40&md5=8407344ad549a40af7ca1564508cb162},
	affiliations = {Western University of Health Sciences, College of Pharmacy, 309 E 2nd Street, Pomona, CA, United States; Indiana University School of Medicine, Division of Clinical Pharmacology, 340 W 10th Street, Indianapolis, IN, United States; Westcliff University, 17877 Von Karman Ave 4th floor, Irvine, 92614, CA, United States; Emanate Health Inter-Community Hospital, 210 W San Bernardino Road, Covina, CA, United States; School of Social Work, California State University, San Bernardino, CA, United States; Tekurai Inc., 2000 NW Military Highway #10, San Antonio, TX, United States},
	abstract = {The rise of big data in healthcare, particularly within electronic health records (EHRs), presents both challenges and opportunities for addressing complex public health issues such as opioid use disorder (OUD) and social determinants of health (SDoH). Traditional data analysis methods are often limited by their reliance on structured data, overlooking the wealth of valuable insights embedded within unstructured clinical narratives. Leveraging advancements in artificial intelligence (AI), Large Language Models (LLM) and natural language processing (NLP), this study proposes a novel approach to detect OUD by analyzing unstructured data within EHRs. Specifically, a Bidirectional Encoder Representations from Transformers (BERT)-based NLP method is developed and applied to clinical progress notes extracted from the EHR system of Emanate Health System. The study created a data analytics platform utilizing user-centered design for improving clinical decisions. This study contributes to the ongoing effort to combat the opioid crisis by bridging the gap between technology-driven analytics and clinical practice, ultimately striving for improved patient wellbeing and equitable healthcare delivery. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Artificial Intelligence; Cognitive Task Analysis; Data Visualization; Electronic Health Record; Opioid Use Disorder},
	keywords = {Cognitive task analysis; Electronic health; Health records; Language processing; Natural languages; Opioid use disorder; Opioids; Public health issues; Social determinants of healths; Transformer modeling; Electronic health record},
	editor = {Benkhelifa E. and Cuzzocrea A. and Gusikhin O. and Hammoudi S.},
	publisher = {SciTePress},
	isbn = {978-989758707-8},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Data Sci., Technol. Appl., DATA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Alsagri2024,
	author = {Alsagri, Hatoon S. and Sohail, Shahab Saquib},
	title = {FRACTAL-INSPIRED SENTIMENT ANALYSIS: EVALUATION OF LARGE LANGUAGE MODELS AND DEEP LEARNING METHODS},
	year = {2024},
	journal = {Fractals},
	doi = {10.1142/S0218348X24400565},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204493685&doi=10.1142%2fS0218348X24400565&partnerID=40&md5=8dcf8c93af8bfbdef0e02d8235e64466},
	affiliations = {Information Systems Department, College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, 11432, Saudi Arabia; School of Computing Science and Engineering, VIT Bhopal University, Kothrikalan, MP, Sehore, 466114, India},
	abstract = {Sentiment analysis is a vital task in natural language processing (NLP) that aims to identify and extract the emotional states and opinions of text. In this study, we conduct a comprehensive comparison of large language models (LLMs), such as ChatGPT and Google Bard, with conventional methods in sentiment analysis. We employ a rigorous evaluation framework that covers four essential metrics: accuracy, precision, recall, and the F1-score. Our results reveal that TextBlob outperforms other methods, achieving an impressive accuracy of 69% and precision of 83%. On the other hand, Bard shows a relatively poor performance, with only 39% accuracy and 46% precision. This study offers valuable insights into the diverse capabilities of AI models in sentiment analysis. A key finding of this study is the importance of model selection according to the specific requirements of the task. Each model has its own strengths and weaknesses, which are reflected in their performance profiles. Moreover, the context in which these models operate is crucial. For instance, ChatGPT generates varied responses, Bard struggles with multiple sentences, and Robustly Optimized BERT Pretraining Approach (RoBERTa) balances precision and recall. This study also reveals the performance gap between LLMs and state-of-the-art deep learning methods. We believe this work will inspire future research and applications of ChatGPT and similar AI models in sentiment analysis and related tasks. © 2024 The Author(s).},
	author_keywords = {ChatGPT; Deep Learning; Fractal AI; Google Bard; Large Language Model (LLM); Sentiment Classification},
	keywords = {Adversarial machine learning; Deep learning; Deep reinforcement learning; Natural language processing systems; ChatGPT; Deep learning; Fractal AI; Google bard; Google+; Language model; Large language model; Learning methods; Sentiment analysis; Sentiment classification; Contrastive Learning},
	correspondence_address = {S.S. Sohail; School of Computing Science and Engineering, VIT Bhopal University, Sehore, Kothrikalan, MP, 466114, India; email: shahabsaquibsohail@vitbhopal.ac.in},
	publisher = {World Scientific},
	issn = {0218348X},
	language = {English},
	abbrev_source_title = {Fractals},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{del-Hoyo-Gabaldon2024,
	author = {del-Hoyo-Gabaldon, Jesus-Angel and Garcia-Lopez, Eva and Garcia-Cabot, Antonio and de-Fitero-Dominguez, David and Wiltrout, Mary-Ellen and Sandland, Jessica and Bell, Ana},
	title = {Large Language Models for Learner Assistance in Massive Open Online Courses: Challenges, Tools, and Approaches},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3772},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207085375&partnerID=40&md5=f3d3e17022a82d7e969666e64eb10fbd},
	affiliations = {Universidad de Alcalá, Ctra. Madrid-Barcelona km 33.6, Alcala de Henares, 28805, Spain; Massachusetts Institute of Technology, Massachusetts Avenue 77, Cambridge, 02139, MA, United States},
	abstract = {Artificial Intelligence has undergone a significant revolution in recent years. The emergence and subsequent development of the Transformers architecture led to extensive research resulting in large language models (LLMs). These systems power widely used applications, such as ChatGPT, which is based on LLMs fine-tuned with human instructions to enhance their performance. Evidence shows that they surpass the results of previous models (BERT/GPT/T5 families) in terms of outcomes, even when they have less complex configurations. In addition, online courses and Massive Open Online Courses (MOOCs) experience a well-known issue: high dropout rates. Scholars aim to tackle this problem by introducing innovative systems and alternatives to enhance students' learning experiences and prevent course abandonment. One option is to complement these courses with LLMs, which can incorporate chatbots or comparable systems to facilitate learning and engagement. The present proposal focuses on developing an automated system wherein a chatbot automatically produces questions related to course content. Then, learners will receive feedback on their answers through semantic similarity mechanisms, indicating the specific content they need to review. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Large Language Models; LLM; Massive Open Online Course; MOOC; Multiple Choice Question Generation; Transformers; Visual Question Generation},
	keywords = {Adversarial machine learning; Contrastive Learning; Curricula; Deep learning; Distribution transformers; Teaching; Deep learning; Language model; Large language model; Massive open online course; Multiple choice question generation; Multiple-choice questions; Transformer; Visual question generation; Semantics},
	correspondence_address = {A. Garcia-Cabot; Universidad de Alcalá, Alcala de Henares, Ctra. Madrid-Barcelona km 33.6, 28805, Spain; email: a.garciac@uah.es},
	editor = {Benedetto L. and Caines A. and Duenas G. and Galvan-Sosa D. and Loukina A. and Taslimipoor S. and Zesch T.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee2024159,
	author = {Lee, Chaeeun and Simpson, T. Ian and Posma, Joram M. and Lain, Antoine D.},
	title = {Comparative Analyses of Multilingual Drug Entity Recognition Systems for Clinical Case Reports In Cardiology},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {159 – 167},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201634026&partnerID=40&md5=b5fba93333249d0ff853bc3c13962ee7},
	affiliations = {School of Informatics, University of Edinburgh, 10 Crichton Street, Edinburgh, EH8 9AB, United Kingdom; Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London, London, W12 0NN, United Kingdom},
	abstract = {Performance disparities exist in Named Entity Recognition (NER) systems across languages due to variations in available human-annotated data. We participated in the MultiDrug subtask of MultiCardioNER, a shared task focusing on multilingual NER for cardiology, to compare the effectiveness of fine-tuning BERT-based monolingual and multilingual language models, and prompting Large Language Models (LLMs) for drug entity recognition across multiple languages. Our findings demonstrate that monolingual BERT models pretrained on biomedical corpora generally outperform their multilingual counterparts. However, for languages lacking access to a broader range of pretrained models, combining the translation capability of LLM [1, 2, 3, 4] with the best-performing pretrained monolingual BERT model yielded superior results. This approach effectively reduces the resource disparity while leveraging domain-specific knowledge captured by the monolingual BERT model. Our best systems in the MultiCardioNER track yielded F1-scores of 0.9277 for Spanish, 0.9107 for English, and 0.8776 for Italian. We highlight the comparative advantages of domain-specific fine-tuning and LLM-powered language translation for multilingual drug NER. © 2024 Copyright for this paper by its authors.},
	author_keywords = {BERT; Cardiology; Multilingual; Named Entity Recognition; Natural Language Processing},
	keywords = {Metadata; Modeling languages; Translation (languages); BERT; Entity recognition; Fine tuning; Language model; Language processing; Multilingual; Named entity recognition; Natural language processing; Natural languages; Recognition systems; Natural language processing systems},
	correspondence_address = {A.D. Lain; Section of Bioinformatics, Division of Systems Medicine, Department of Metabolism, Digestion, and Reproduction, Faculty of Medicine, Imperial College London, London, W12 0NN, United Kingdom; email: a.lain@imperial.ac.uk},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Usmani20241274,
	author = {Usmani, Maha and Siddiqui, Rania and Rizwan, Samin and Khan, Faryal and Alvi, Faisal and Samad, Abdul},
	title = {Sexism Identification in Tweets using BERT and XLM - Roberta},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {1274 – 1279},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201616612&partnerID=40&md5=fd56ae1a7582799b2998d89dda37d7aa},
	affiliations = {Computer Science Program, Dhanani School of Science and Engineering, Habib University, Karachi, Pakistan},
	abstract = {The rapid growth of social media platforms has led to an increase in offensive content, often targeting specific demographic groups. This paper focuses on identifying and categorizing sexism in tweets collected from various social media platforms. We address three tasks from the EXIST 2024 lab, involving the classification of tweets in English and Spanish. These tasks include binary classification for sexism identification, source intention categorization of sexist tweets, and multi-label classification for different facets of sexism. Our approach employs BERT multilingual and XLM-RoBERTa models, along with an ensemble technique to enhance prediction accuracy. We evaluate the models using both hard labels, determined by majority vote, and soft labels, based on class probabilities. © 2022 Copyright for this paper by its authors.},
	author_keywords = {BERT; ensemble; LLM; Roberta; Sexism; Tweets},
	keywords = {BERT; Binary classification; Demographic groups; Ensemble; LLM; Multi-label classifications; Rapid growth; Robertum; Sexism; Social media platforms; Tweets},
	correspondence_address = {M. Usmani; Computer Science Program, Dhanani School of Science and Engineering, Habib University, Karachi, Pakistan; email: mahausmani71@gmail.com; R. Siddiqui; Computer Science Program, Dhanani School of Science and Engineering, Habib University, Karachi, Pakistan; email: rs07494@st.habib.edu.pk; A. Samad; Computer Science Program, Dhanani School of Science and Engineering, Habib University, Karachi, Pakistan; email: abdul.samad@sse.habib.edu.pk},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {CLEF 2024 - Working Notes of the Conference and Labs of the Evaluation Forum},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201594389&partnerID=40&md5=9a90cca38596b7391cd3bbcd62ef658e},
	abstract = {The proceedings contain 339 papers. The topics discussed include: overview of MultiCardioNER task at BioASQ 2024 on medical specialty and language adaptation of clinical NER systems for Spanish, English and Italian; transformer-based disease and drug named entity recognition in multilingual clinical texts: MultiCardioNER challenge; LLM fine-tuning with biomedical open-source data; can open-source LLMs compete with commercial models? exploring the few-shot performance of current GPT models in biomedical tasks; multilingual clinical NER for diseases and medications recognition in cardiology texts using BERT embeddings; enhancing biomedical question answering with parameter-efficient fine-tuning and hierarchical retrieval augmented generation; generative large language models augmented hybrid retrieval system for biomedical question answering; comparative analyses of multilingual drug entity recognition systems for clinical case reports in cardiology; and enhancing biomedical document ranking with domain knowledge incorporation in a multi-stage retrieval approach.},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Huertas-García20242665,
	author = {Huertas-García, Álvaro and Martí-González, Carlos and Muñoz, Javier and De Miguel Ambite, Enrique},
	title = {Small Language Models and Large Language Models in Oppositional Thinking Analysis: Capabilities, Biases and Challenges},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {2665 – 2675},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201643653&partnerID=40&md5=36e47f95b2984c3452beb4540e13d212},
	affiliations = {Department of Computer System Engineering, Polytechnic University of Madrid, Calle de Alan Turing, Madrid, 28031, Spain; Fundación Tecnológica Advantx - Funditec, Paseo de la Castellana, Madrid, 28046, Spain},
	abstract = {The proliferation of misinformation and conspiracy theories needs robust methods to differentiate legitimate critical discourse from harmful conspiratorial narratives. This study investigates discerning critical messages from conspiracy theories within COVID-19 discussions on Telegram. Preserving information integrity on social media impacts vital public discourse on health, politics, and science. The research employs two distinct approaches: linguistic style classification and contextual knowledge classification. The former leverages a diverse ensemble of Small Language Models (SLMs), Large Language Models (LLMs), and State-Space Models (SSMs), while the latter harnesses the capabilities of the Claude 2.0 Opus model for contextual analysis. Empirical evaluations demonstrate that the SLM models using Matryoshka embedding and Mamba (SSM) models exhibit superior performance for the English language dataset, achieving a Matthews Correlation Coefficient (MCC) of 0.793. For the Spanish dataset, the Spanish BERT baseline (SLM) attains an MCC of 0.699. Notably, a multilingual model trained on a balanced combination of English and Spanish data outperforms its monolingual counterparts, with the multilingual-e5-large model (LLM) achieving an MCC of 0.768 for English and 0.725 for Spanish. This finding underscores the potential of multilingual models to mitigate the”curse of multilinguality,” where performance often degrades on low-resource languages. However, the suboptimal performance of the Claude 2.0 Opus model, exhibiting a tendency to classify texts as conspiracy-related, highlights inherent biases that require further investigation. Overall, this study contributes to the development of advanced models that can effectively differentiate critical thinking from conspiratorial narratives in various linguistic contexts. Future research should prioritize identifying and addressing biases in large language models to ensure fair treatment of diverse perspectives, as well as to preserve freedom of expression and ensure fair representation of narratives. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Bias; Claude; LLM; Mamba; Oppositional Thinking Analysis; PAN 2024; Transformers},
	keywords = {Linguistics; Bias; Claude; Correlation coefficient; Language model; Large language model; Mamba; Oppositional thinking analyze; PAN 2024; State-space models; Transformer; Economic and social effects},
	correspondence_address = {Á. Huertas-García; Department of Computer System Engineering, Polytechnic University of Madrid, Madrid, Calle de Alan Turing, 28031, Spain; email: ahuertas@funditec.es},
	editor = {Faggioli G. and Ferro N. and Galuscakova P. and de Herrera A.G.S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Latif2024166,
	author = {Latif, Ehsan and Fang, Luyang and Ma, Ping and Zhai, Xiaoming},
	title = {Knowledge Distillation of LLMs for Automatic Scoring of Science Assessments},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2151 CCIS},
	pages = {166 – 174},
	doi = {10.1007/978-3-031-64312-5_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199786183&doi=10.1007%2f978-3-031-64312-5_20&partnerID=40&md5=3132189e8b4300e72fbfa081bbb81ddf},
	affiliations = {AI4STEM Education Center, Athens, GA, United States; Department of Mathematics, Science, and Social Studies Education, University of Georgia, Athens, GA, United States; Department of Statistics, University of Georgia, Athens, GA, United States},
	abstract = {This study proposes a method for knowledge distillation (KD) of fine-tuned Large Language Models (LLMs) into smaller, more efficient, and accurate neural networks. We specifically target the challenge of deploying these models on resource-constrained devices. Our methodology involves training the smaller student model (Neural Network) using the prediction probabilities (as soft labels) of the LLM, which serves as a teacher model. This is achieved through a specialized loss function tailored to learn from the LLM’s output probabilities, ensuring that the student model closely mimics the teacher’s performance. To validate the performance of the KD approach, we utilized a large dataset, 7T, containing 6,684 student-written responses to science questions and three mathematical reasoning datasets with student-written responses graded by human experts. We compared accuracy with state-of-the-art (SOTA) distilled models, TinyBERT, and artificial neural network (ANN) models. Results have shown that the KD approach has 3% and 2% higher scoring accuracy than ANN and TinyBERT, respectively, and comparable accuracy to the teacher model. Furthermore, the student model size is 0.03M, 4,000 times smaller in parameters and x10 faster in inferencing than the teacher model and TinyBERT, respectively. The significance of this research lies in its potential to make advanced AI technologies accessible in typical educational settings, particularly for automatic scoring. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {automatic scoring; BERT; education technology; knowledge distillation; large language model (LLM)},
	keywords = {Computational linguistics; Education computing; Large datasets; Neural networks; Personnel training; Students; Automatic scoring; BERT; Education technology; Knowledge distillation; Language model; Large language model; Performance; Science assessments; Student Modeling; Teacher models; Distillation},
	correspondence_address = {X. Zhai; AI4STEM Education Center, Athens, United States; email: xiaoming.zhai@uga.edu; P. Ma; Department of Statistics, University of Georgia, Athens, United States; email: pingma@uga.edu},
	editor = {Olney A.M. and Chounta I.-A. and Liu Z. and Santos O.C. and Bittencourt I.I.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303164311-8},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Imtiaz2024,
	author = {Imtiaz, Sakib and Hashi, Emrana Kabir},
	title = {Analyzing the Performance of Sentiment Analysis Using BERT, DistilBERT, RoBERTa and GPT-2},
	year = {2024},
	journal = {2024 6th International Conference on Sustainable Technologies for Industry 5.0, STI 2024},
	doi = {10.1109/STI64222.2024.10951049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003398971&doi=10.1109%2fSTI64222.2024.10951049&partnerID=40&md5=76fd16a5c20cda8698084b9df236ab8e},
	affiliations = {Rajshahi University of Engineering & Technology, Department of Computer Science & Engineering, Bangladesh},
	abstract = {Sentiment analysis, also known as opinion mining, employs natural language processing (NLP) techniques to determine, extract, and measure the emotional undertones within a text. This approach is valuable for measuring public sentiment and interests across various domains, including social media discussions, product and movie reviews, among others. Techniques like Linear Regression, Support Vector Machines, Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and Long Short-Term Memory (LSTM) are utilized in analyzing sentiments. However, these are no comparison to the capabilities of the pre-trained transformer models such as BERT, DistilBERT, RoBERTa, and the recent large language model (LLM) GPT-2, which offer significantly enhanced performance and flexibility. This study employs the Sentiment140 dataset to evaluate sentiments expressed in tweets, utilizing four advanced transformer-based models: BERT, DistilBERT, RoBERTa, and GPT-2. The sentiment analysis conducted within this research framework focuses on accuracy as the primary performance metric. The findings of the analysis indicate that the GPT-2 model outperforms its counterparts by achieving an impressive accuracy of 94.13%, thereby demonstrating its superior capability in handling sentiment analysis tasks. This study not only reinforces the efficacy of transformer-based models in processing complex language data but also highlights the cutting-edge potential of GPT-2 to revolutionize sentiment analysis in social media contexts. Furthermore, the integration of these technologies aligns with the principles of Industry 5.0 by enhancing human-machine collaboration, thus driving more personalized, efficient, and sustainable technological advancements. By leveraging such sophisticated models, businesses can harness real-time sentiment analysis to foster a more responsive and sustainable operational framework, ultimately contributing to smarter and more sustainable technology deployments. © 2024 IEEE.},
	author_keywords = {BERT; DistilBERT; GPT-2; Natural Language Processing; RoBERTa; Sentiment Analysis},
	keywords = {Economic and social effects; Economic geology; Economics; Linear regression; Long short-term memory; Natural language processing systems; Support vector regression; BERT; Distilbert; GPT-2; Language processing; Natural language processing; Natural languages; Performance; RoBERTa; Sentiment analysis; Social media; Convolutional neural networks},
	correspondence_address = {S. Imtiaz; Rajshahi University of Engineering & Technology, Department of Computer Science & Engineering, Bangladesh; email: sakibimtiaz1998@gmail.com; E.K. Hashi; Rajshahi University of Engineering & Technology, Department of Computer Science & Engineering, Bangladesh; email: emranakabir@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833153197-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Sustain. Technol. Ind. 5.0, STI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yang20232793,
	author = {Yang, Jingchao and Wei, Fusheng and Huber-Fliflet, Nathaniel and Dabrowski, Adam and Mao, Qiang and Qin, Han},
	title = {An Empirical Analysis of Text Segmentation for BERT Classification in Extended Documents},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {2793 – 2797},
	doi = {10.1109/BigData59044.2023.10386783},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184984611&doi=10.1109%2fBigData59044.2023.10386783&partnerID=40&md5=c5340940ad9cfb34f7383ba1bf06549e},
	affiliations = {Ankura Consulting Group, LLC, Data & Technology, Washington, DC, United States},
	abstract = {In the domain of natural language processing and text analysis, the Bidirectional Encoder Representations from Transformers (BERT) has emerged as a powerful tool for discerning the intricate nuances of textual data. Nonetheless, BERT's inherent token limit of 512 tokens presents a noteworthy challenge when confronted with exceedingly long documents. Lengthy documents are commonly encountered during legal document review and often exceed the 512-token constraint. In response to this challenge, this study empirically compares two distinct applications of BERT, leveraging real-world, construction industry legal data. The approach compares applications of BERT to the entire document and on segmented text portions from each document. In the latter approach, the highest-scoring text segment from each document represents the document's score. This research offers practical insights for effectively utilizing BERT in scenarios where document length exceeds the token limit. Our results allow practitioners and researchers to make informed choices when confronted with documents of significant length, thus contributing to a more effective and insightful application of BERT for text analysis.  © 2023 IEEE.},
	author_keywords = {Construction; E-Discovery; legal document review; LLM; predictive coding; Text classification},
	keywords = {Authentication; Classification (of information); Information retrieval systems; Natural language processing systems; Text processing; Document review; E discoveries; Empirical analysis; Legal document review; Legal documents; LLM; Predictive coding; Text analysis; Text classification; Text segmentation; Construction industry},
	editor = {He J. and Palpanas T. and Hu X. and Cuzzocrea A. and Dou D. and Slezak D. and Wang W. and Gruca A. and Lin J.C.-W. and Agrawal R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032445-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Tikayat Ray2023,
	author = {Tikayat Ray, Archana and Cole, Bjorn F. and Pinon Fischer, Olivia J. and Bhat, Anirudh Prabhakara and White, Ryan T. and Mavris, Dimitri N.},
	title = {Agile Methodology for the Standardization of Engineering Requirements Using Large Language Models},
	year = {2023},
	journal = {Systems},
	volume = {11},
	number = {7},
	doi = {10.3390/systems11070352},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172161216&doi=10.3390%2fsystems11070352&partnerID=40&md5=7a71030038c82ba86ed09218764fae75},
	affiliations = {Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States; Lockheed Martin Space, Littleton, 80127, CO, United States; Amazon, Toronto, M5H 4A9, ON, Canada; Neural Transmissions Laboratory, Department of Mathematical Sciences, Florida Institute of Technology, Melbourne, 32901, FL, United States},
	abstract = {The increased complexity of modern systems is calling for an integrated and comprehensive approach to system design and development and, in particular, a shift toward Model-Based Systems Engineering (MBSE) approaches for system design. The requirements that serve as the foundation for these intricate systems are still primarily expressed in Natural Language (NL), which can contain ambiguities and inconsistencies and suffer from a lack of structure that hinders their direct translation into models. The colossal developments in the field of Natural Language Processing (NLP), in general, and Large Language Models (LLMs), in particular, can serve as an enabler for the conversion of NL requirements into machine-readable requirements. Doing so is expected to facilitate their standardization and use in a model-based environment. This paper discusses a two-fold strategy for converting NL requirements into machine-readable requirements using language models. The first approach involves creating a requirements table by extracting information from free-form NL requirements. The second approach consists of an agile methodology that facilitates the identification of boilerplate templates for different types of requirements based on observed linguistic patterns. For this study, three different LLMs are utilized. Two of these models are fine-tuned versions of Bidirectional Encoder Representations from Transformers (BERTs), specifically, aeroBERT-NER and aeroBERT-Classifier, which are trained on annotated aerospace corpora. Another LLM, called flair/chunk-english, is utilized to identify sentence chunks present in NL requirements. All three language models are utilized together to achieve the standardization of requirements. The effectiveness of the methodologies is demonstrated through the semi-automated creation of boilerplates for requirements from Parts 23 and 25 of Title 14 Code of Federal Regulations (CFRs). © 2023 by the authors.},
	author_keywords = {BERT; Large Language Models (LLMs); model-based systems engineering; Natural Language Processing (NLP); requirement boilerplates; requirement tables; requirements engineering; transformer-based language models},
	correspondence_address = {A. Tikayat Ray; Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, United States; email: atr@gatech.edu; O.J. Pinon Fischer; Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, United States; email: olivia.pinon@asdl.gatech.edu},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20798954},
	language = {English},
	abbrev_source_title = {Systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sindhwad2024,
	author = {Sindhwad, Parul V. and Ranka, Prateek and Muni, Siddhi and Kazi, Faruk},
	title = {VulnArmor: mitigating software vulnerabilities with code resolution and detection techniques},
	year = {2024},
	journal = {International Journal of Information Technology (Singapore)},
	doi = {10.1007/s41870-024-01775-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187927029&doi=10.1007%2fs41870-024-01775-4&partnerID=40&md5=137cd4daac6a13313dee904a895b4d9a},
	affiliations = {Department of Electrical Engineering, Veermata Jijabai Technological Institute, Mumbai, 400019, India; D.J. Sanghvi College of Engineering, Mumbai, India},
	abstract = {In today’s swiftly evolving digital environment, the security and dependability of software applications are crucial. In light of industries’ increasing reliance on software, identifying and mitigating vulnerabilities is essential for protecting data, systems, and user trust. With data-driven methodologies, there is increased interest in using Artificial Intelligence (AI) and Machine Learning (ML) for software assurance to construct trustworthy software systems. This research addresses the urgent need for an automated and comprehensive approach to code resolution and vulnerability detection, providing a robust solution to improve software security and reduce potential risks. Code resolution is implemented by fine-tuning Large Language Models (LLM) like Generative Pre-Trained Transformers (GPT)-2, Text-to-Text Transfer Transformers (T5), Bidirectional Encoder Representations from Transformers (BERT), and Large Language Model Meta AI (LLaMA). Secondly, vulnerable code detection plays a crucial role in evaluating the correctness of resolved code and identifying any remaining vulnerabilities. This essential step not only validates the efficacy of code resolution but also identifies areas where additional mitigation efforts are required. Utilizing Deep Learning (DL) models, the top performer of the study, Convolutional Neural Network (CNN), achieved a remarkable 93% accuracy rate, demonstrating its prowess in protecting software applications against potential attacks. © The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management 2024.},
	author_keywords = {Code resolution; Convolutional neural network (CNN); Large language models (LLMs); Software security; Vulnerability detection},
	correspondence_address = {P.V. Sindhwad; Department of Electrical Engineering, Veermata Jijabai Technological Institute, Mumbai, 400019, India; email: pvsindhwad_p21@el.vjti.ac.in},
	publisher = {Springer Science and Business Media B.V.},
	issn = {25112104},
	language = {English},
	abbrev_source_title = {Int. J. Inf. Technol.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Veeramani202466,
	author = {Veeramani, Hariram and Thapa, Surendrabikram and Naseem, Usman},
	title = {MLInitiative@WILDRE7: Hybrid Approaches with Large Language Models for Enhanced Sentiment Analysis in Code-Switched and Code-Mixed Texts},
	year = {2024},
	journal = {Proceedings - International Conference on Computational Linguistics, COLING},
	pages = {66 – 72},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001336747&partnerID=40&md5=a3f79867c22fd8c713b319a30908b4ec},
	affiliations = {UCLA, United States; Virginia Tech, United States; Macquarie University, Australia},
	abstract = {Code-switched and code-mixed languages are prevalent in multilingual societies, reflecting the complex interplay of cultures and languages in daily communication. Understanding the sentiment embedded in such texts is crucial for a range of applications, from improving social media analytics to enhancing customer feedback systems. Despite their significance, research in code-mixed and code-switched languages remains limited, particularly in less-resourced languages. This scarcity of research creates a gap in natural language processing (NLP) technologies, hindering their ability to accurately interpret the rich linguistic diversity of global communications. To bridge this gap, this paper presents a novel methodology for sentiment analysis in code-mixed and code-switched texts. Our approach combines the power of large language models (LLMs) and the versatility of the multilingual BERT (mBERT) framework to effectively process and analyze sentiments in multilingual data. By decomposing code-mixed texts into their constituent languages, employing mBERT for named entity recognition (NER) and sentiment label prediction, and integrating these insights into a decision-making LLM, we provide a comprehensive framework for understanding sentiment in complex linguistic contexts. Our system achieves competitive rank on all subtasks in the Code-mixed Less-Resourced Sentiment analysis (Code-mixed) shared task at WILDRE-7 (LREC-COLING). © 2024 ELRA Language Resource Association.},
	author_keywords = {Code-switched language; Code-switched language; Large language models (LLMs); Named entity recognition (NER); Sentiment analysis},
	keywords = {Economic and social effects; Linguistics; Metadata; Modeling languages; Natural language processing systems; Problem oriented languages; Code-switched language; Customer feedback; Hybrid approach; Language model; Large language model; Named entity recognition; Sentiment analysis; Social media analytics; Decision making},
	editor = {Jha G.N. and Devi S.L. and Bali K. and Ojha A.Kr. and Ojha A.Kr.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {29512093},
	isbn = {978-249381437-1},
	language = {English},
	abbrev_source_title = {Proc. Main Conf. Int. Conf. Comput. Linguist., COLING},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Mughal202460943,
	author = {Mughal, Nimra and Mujtaba, Ghulam and Shaikh, Sarang and Kumar, Aveenash and Daudpota, Sher Muhammad},
	title = {Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {60943 – 60959},
	doi = {10.1109/ACCESS.2024.3386969},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190737817&doi=10.1109%2fACCESS.2024.3386969&partnerID=40&md5=d084304d2c21a296eee630fcba810765},
	affiliations = {Sukkur IBA University, Center of Excellence for Robotics, Artificial Intelligence, and Block Chain, Department of Computer Science, Sukkur, Sindh, 65200, Pakistan; Norwegian University of Science and Technology (NTNU), Department of Information Security and Communication Technology (IIK), Trondheim, Gjovik, 7034, Norway; Learners.ai, Toronto, M5C 2B5, ON, Canada; Sukkur IBA University, Department of Computer Science, Sukkur, Sindh, 65200, Pakistan},
	abstract = {Sentiment analysis is essential for comprehending public opinion, particularly when considering e-commerce and the expansion of online businesses. Early approaches treated sentiment analysis as a document or sentence-level classification problem, lacking the ability to capture nuanced opinions about specific aspects. This limitation was addressed by the development of aspect-based sentiment analysis (ABSA), which links sentiment to specific aspects that are mentioned explicitly or implicitly in the review. ABSA is relatively a recent field of sentiment analysis and the existing models for ABSA face three main challenges, including domain-specificity, reliance on labeled data, and a lack of exploration into the potential of newer large language models (LLMs) such as GPT, PaLM, and T5. Leveraging a diverse set of datasets, including DOTSA, MAMS, and SemEval16, we evaluate the performance of prominent models such as ATAE-LSTM, flan-t5-large-absa, DeBERTa, PaLM, and GPT-3.5-Turbo. Our findings reveal nuanced strengths and weaknesses of these models across different domains, with DeBERTa emerging as consistently high-performing and PaLM demonstrating remarkable competitiveness for aspect term sentiment analysis (ATSA) tasks. In addition, the PaLM demonstrates competitive performance for all the domains that were used in the experiments including the restaurant, hotel, books, clothing, and laptop reviews. Notably, the analysis underscores the models' domain sensitivity, shedding light on their varying efficacy for both ATSA and ACSA tasks. These insights contribute to a deeper understanding of model applicability and highlight potential areas for improvement in ABSA research and development.  © 2013 IEEE.},
	author_keywords = {Aspect-based sentiment analysis (ABSA); BERT; GPT; large language model (LLM); PaLM},
	keywords = {Computational linguistics; Data mining; Information retrieval systems; Job analysis; Modeling languages; Sentiment analysis; Social aspects; Aspect-based sentiment analyse; BERT; Biological system modeling; Computational modelling; GPT; Language model; Large language model; PaLM; Sentiment analysis; Task analysis; Transformer; Reviews},
	correspondence_address = {N. Mughal; Sukkur IBA University, Center of Excellence for Robotics, Artificial Intelligence, and Block Chain, Department of Computer Science, Sindh, Sukkur, 65200, Pakistan; email: nimra.cs16@gmail.com; S. Shaikh; Norwegian University of Science and Technology (NTNU), Department of Information Security and Communication Technology (IIK), Gjovik, Trondheim, 7034, Norway; email: sarang.shaikh@ntnu.no},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access}
}

@CONFERENCE{Lee2024,
	author = {Lee, Chang-Shing and Wang, Mei-Hui and Chiang, Jun-Kui and Kubota, Naoyuki and Sato-Shimokawara, Eri and Nojima, Yusuke and Acampora, Giovanni and Wu, Pei-Yu and Chiu, Szu-Chi and Yang, Sheng-Chi and Siow, Chyan-Zheng},
	title = {Quantum Computational Intelligence with Generative AI Image for Human-Machine Interaction},
	year = {2024},
	journal = {IEEE International Conference on Fuzzy Systems},
	doi = {10.1109/FUZZ-IEEE60900.2024.10611970},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191275657&doi=10.1109%2fFUZZ-IEEE60900.2024.10611970&partnerID=40&md5=ade4540c643c56b940fff9c96cd8e88b},
	affiliations = {National University of Tainan, Tainan, Taiwan; Tokyo Metropolitan University, Tokyo, Japan; Osaka Metropolitan University, Japan; University of Naples Federico II, Italy},
	abstract = {This paper introduces a Quantum Computational Intelligence (QCI) agent equipped with a content attention ontology model, specifically designed to enhance human-machine interaction based on a Generative Artificial Intelligence (GAI) image generation agent for Taiwanese/English learning and experience. Its diverse primary applications include social media analysis on Facebook groups and YouTube learning videos related to the 2023 IEEE CIS Education Portal (EP) Subcommittee, as well as in the areas of Taiwanese/English language learning and dialogue experience with GAI image generation. To establish the knowledge and inference models for the QCI agent, we initially developed a Taiwanese/English learning and experience ontology, including a content attention ontology, and an image attention ontology. The QCI agent utilizes metrics such as the number of views, posts, and comments to predict the fuzzy number of reactions. In addition, the GAI image agent generates Taiwanese speech-based/English text-based images and evaluates the fuzzy similarity score between Taiwanese/English and the attention ontology together with the Sentence BERT (SBERT) agent. This Taiwanese/English fuzzy similarity score is further validated through human assessments, with these evaluations subsequently serving as an additional metric for comparative analysis of Human-Machine Interaction (HMI). Furthermore, the GAI image agent is designed to create images and Chinese/English texts from text/speech translated by the Meta AI Universal Speech Translator (UST) Taiwanese/English agent. A Particle Swarm Optimization (PSO)-based machine learning mechanism is employed to train the QCI model for assessing learners' performance and predicting the performance of others. The National University of Tainan (NUTN) Taiwan-Large Language Model (NUTN.TW-LLM) agent has been further enhanced to support interactive learning experiences for HMI. An SBERT-based assessment agent is used to calculate fuzzy similarities between questions and answers in Taiwanese/English experiences and dialogues. Experimental results demonstrate the feasibility and efficacy of the proposed QCI model, equipped with QCI&AI-FML (Artificial Intelligence-Fuzzy Markup Language) and machine learning capabilities, for social media and language learning applications on HMI. In the future, we will extend the QCI model to various HMI applications for student learning around the world. © 2024 IEEE.},
	author_keywords = {ChatGPT; Content Attention Ontology; Fuzzy Markup Language; Generative AI Image Agent; IEEE CIS Education Portal; NUTN.TW-LLM; Quantum CI Agent; Sentence BERT},
	keywords = {Computational linguistics; Computer aided language translation; Curricula; Fuzzy inference; Fuzzy rules; Gene transfer; Intelligent systems; Machine learning; Motion estimation; Neural networks; Personnel training; Problem oriented languages; Semantics; SGML; Students; Swarm intelligence; Syntactics; ChatGPT; CI-Agent; Content attention ontology; Education portals; Fuzzy markup languages; Generative AI image agent; IEEE CIS education portal; National university of tainan.; Ontology's; Quantum CI agent; Sentence BERT; TW-LLM; Speech enhancement},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {10987584},
	isbn = {979-835031954-5},
	coden = {PIFSF},
	language = {English},
	abbrev_source_title = {IEEE Int Conf Fuzzy Syst},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Suthanthiradevi2024,
	author = {Suthanthiradevi, P. and Revathy, G. and Rejini, K. and Muthu Lakshmi, V.},
	title = {Leveraging Deep Learning Models for Machine-Generated Text Detection Using Transformer-Based Models},
	year = {2024},
	journal = {Proceedings of the 2024 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems, ICSES 2024},
	doi = {10.1109/ICSES63760.2024.10910837},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001400942&doi=10.1109%2fICSES63760.2024.10910837&partnerID=40&md5=305611ad3e2bd94db8b6f3ee688ca97b},
	affiliations = {School of Computing, Srm institute of Science and Technology, Department of Data Science and Business Systems, Kattankulathur, Chennai, India; Vels Institute of science Technology and Advanced studies, Department of Computer science and engineering, Chennai, 117, India; Amrita college of Engineering and Technology, Department of Computer Science Engineering, Nagercoil, India; St. Joseph's College of Engineering, Department of Computer Science and Engineering, OMR, Chennai, India},
	abstract = {GPT is a large language model (LLM) derived from natural language processing that can generate a human-like text using machine learning. However, these models raise questions about authenticity and reliability of material, particularly in fields such as journalism, social media, and academia, despite their usefulness for automating text-based tasks. Detecting machine-generated text is thus an important difficulty in ensuring content integrity. This study investigates the use of huge language models as a technique for recognizing machine-generated material. The author proposes a comprehensive detection model by evaluating the language patterns, syntactic structures, and stylistic traits that separate AI-generated literature from human writing. In addition, this research investigate the possibilities of fine-tuning models designed expressly for text identification tasks and evaluate their performance using LLM - Detect AI Generated Text datasets. In digital ecosystems, LLMs are effective at detecting AI-generated text, providing a novel approach for content moderation, academic integrity checks, and synthetic media detection. An increasingly AI-powered future will require a model that can discriminate between human and machine-generated writing in real-time. According to experimental findings, the CNN architecture's design combined with the use of DistilBERT embeddings allows for the effective and efficient classification of AI generated text data, achieving an exceptional 98% accuracy rate. © 2024 IEEE.},
	author_keywords = {Deep learning; Large Language models; Machine generated text; Transformers and BERT},
	keywords = {Contrastive Learning; Deep learning; Natural language processing systems; Deep learning; Human like; Language model; Language processing; Large language model; Learning models; Machine-generated texts; Natural languages; Text detection; Transformer and BERT; Adversarial machine learning},
	correspondence_address = {G. Revathy; Vels Institute of science Technology and Advanced studies, Department of Computer science and engineering, Chennai, 117, India; email: grevathy19@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833154361-7},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Innov. Comput., Intell. Commun. Smart Electr. Syst., ICSES},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{De202399,
	author = {De, Somsubhra and Vats, Shaurya},
	title = {Decoding Concerns: Multi-label Classification of Vaccine Sentiments in Social Media},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3681},
	pages = {99 – 111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193979989&partnerID=40&md5=b7c190ad4bbdeec4db7ea9968c4c6a57},
	affiliations = {Indian Institute of Technology, Tamil Nadu, Madras, India; Indian Institute of Technology, West Bengal, Kharagpur, India},
	abstract = {In the realm of public health, vaccination stands as the cornerstone for mitigating disease risks and controlling their proliferation. The recent COVID-19 pandemic has highlighted how vaccines play a crucial role in keeping us safe. However the situation involves a mix of perspectives, with skepticism towards vaccines prevailing for various reasons such as political dynamics, apprehensions about side effects, and more. The paper addresses the challenge of comprehensively understanding and categorizing these diverse concerns expressed in the context of vaccination. Our focus is on developing a robust multi-label classifier capable of assigning specific concern labels to tweets based on the articulated apprehensions towards vaccines. To achieve this, we delve into the application of a diverse set of advanced natural language processing techniques and machine learning algorithms including transformer models like BERT, state of the art GPT 3.5, Classifier Chains & traditional methods like SVM, Random Forest, Naive Bayes. We see that the cutting-edge large language model outperforms all other methods in this context. © 2023 Copyright for this paper by its authors.},
	author_keywords = {AI; Concerns; COVID-19; LLM; Machine Learning; Multi label classifier; Prompt engineering; Sentiment; Transformer models; Tweet classification; Vaccine skepticism},
	keywords = {Classification (of information); Health risks; Learning algorithms; Natural language processing systems; Social networking (online); Support vector machines; Vaccines; Concern; LLM; Machine-learning; Multi label classifier; Multi-labels; Prompt engineering; Sentiment; Transformer modeling; Tweet classification; Vaccine skepticism; COVID-19},
	correspondence_address = {S. De; Indian Institute of Technology, Madras, Tamil Nadu, India; email: somsubhra@outlook.in},
	editor = {Ghosh K. and Mandl T. and Majumder P. and Mitra M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sadot2023,
	author = {Sadot, Arefin Abu Isha Md. and Maliha Mehjabin, Mitu and Mahafuz, Aziz},
	title = {A Novel Approach to Efficient Multilabel Text Classification: BERT-Federated Learning Fusion},
	year = {2023},
	journal = {2023 26th International Conference on Computer and Information Technology, ICCIT 2023},
	doi = {10.1109/ICCIT60459.2023.10441264},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187388964&doi=10.1109%2fICCIT60459.2023.10441264&partnerID=40&md5=5cf3711c863fa21ea7c3ead69bac0ee9},
	affiliations = {United International University, Dept. of CSE, Madani Ave, Dhaka, Bangladesh; BRAC University, Dept. of CSE, 66 Mohakhali, Dhaka, Bangladesh},
	abstract = {Large Language Model (LLM)-based transformers, such as Bidirectional Encoder Representations from Transformers (BERT), are currently gaining significant attention for various Natural Language Processing (NLP) tasks, such as machine translation, classification, and auto-completion. These transformer models demonstrate substantial performance improvements for text classification tasks. Multi-label classification problems often require more computation than binary and multi-class classification problems. Also, the computation requirements become more aggressive if large datasets are considered. Federated Learning (FL) offers a solution to train models in a distributed manner while preserving data privacy. This paper proposes a novel approach for building a machine learning model, which deals with a sizeable textual dataset for multi-label classification leveraging FL. FL has been used to train a compound model constructed by extending Bidirectional Encoder Representations from Transformers (BERT) with a "One-dimensional Convolutional Neural Network (1D CNN)". At first, The experiment was conducted in a single machine (Central) with the entire dataset. Then, the dataset was split into two groups, and the same experiment was performed in a Federated Learning fashion (BERT-FL Fusion). The FL setup considerably reduced the required computing power to derive an equivalent global model while increasing accuracy, precision, and F1 Score and minimizing Hamming Loss.  © 2023 IEEE.},
	author_keywords = {BERT; federated learning; large language model; multi-label; text classification; transfer learning},
	keywords = {Classification (of information); Computational linguistics; Computing power; Convolutional neural networks; Data privacy; Learning algorithms; Learning systems; Natural language processing systems; Signal encoding; Text processing; Transfer learning; Bidirectional encoder representation from transformer; Federated learning; Language model; Large language model; Model-based OPC; Multi-label classifications; Multi-label text classification; Multi-labels; Text classification; Transfer learning; Large datasets},
	correspondence_address = {A.A.I.M. Sadot; United International University, Dept. of CSE, Dhaka, Madani Ave, Bangladesh; email: sadot.arefin@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035901-5},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Inf. Technol., ICCIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ding2024298,
	author = {Ding, Shiyao and Ito, Takayuki},
	title = {Self-agreement: A Framework for Fine-Tuning Language Models to Find Agreement Among Diverse Opinions},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14326 LNAI},
	pages = {298 – 309},
	doi = {10.1007/978-981-99-7022-3_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177449428&doi=10.1007%2f978-981-99-7022-3_26&partnerID=40&md5=d997fbb0776f9c0e0c54f27f54eb6140},
	affiliations = {Kyoto University, Kyoto-shi, Kyoto, 606-8501, Japan},
	abstract = {Finding an agreement among diverse opinions is a challenging topic in social intelligence. Recently, large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human-like text. However, they typically rely on extensive human-annotated data. In this paper, we propose Self-Agreement, a novel framework for fine-tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically, our approach employs the generative pre-trained transformer-3 (GPT-3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then, a bidirectional encoder representations from transformers (BERT)-based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question-opinion-agreements, which we use to fine-tune a pre-trained LLM for discovering agreements among diverse opinions. Remarkably, a pre-trained LLM fine-tuned by our Self-Agreement framework achieves comparable performance to GPT-3 with only 1/25 of its parameters, showcasing its ability to identify agreement among various opinions without the need for human-annotated data. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2024.},
	author_keywords = {Consensus building; Large language models; Opinion summarization; Social intelligence},
	keywords = {Economic and social effects; Consensus buildings; Fine tuning; Human like; Language model; Large language model; Opinion summarization; Performance; Process yield; Social intelligence; Computational linguistics},
	correspondence_address = {S. Ding; Kyoto University, Kyoto, Kyoto-shi, 606-8501, Japan; email: ding@i.kyoto-u.ac.jp},
	editor = {Liu F. and Sadanandan A.A. and Pham D.N. and Mursanto P. and Lukose D.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981997021-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Wang202373,
	author = {Wang, Shuai and Scells, Harrisen and Koopman, Bevan and Potthast, Martin and Zuccon, Guido},
	title = {Generating Natural Language Queries for More Effective Systematic Review Screening Prioritisation},
	year = {2023},
	journal = {SIGIR-AP 2023 - Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
	pages = {73 – 83},
	doi = {10.1145/3624918.3625322},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180127416&doi=10.1145%2f3624918.3625322&partnerID=40&md5=e6e8370976e66a506bcc590e7d87448f},
	affiliations = {Eecs, The University of Queensland, Australia; Leipzig University, Germany; Leipzig University, ScaDS.AI, Germany; Csiro, The University of Queensland, Australia},
	abstract = {Screening prioritisation in medical systematic reviews aims to rank the set of documents retrieved by complex Boolean queries. Prioritising the most important documents ensures that subsequent review steps can be carried out more efficiently and effectively. The current state of the art uses the final title of the review as a query to rank the documents using BERT-based neural rankers. However, the final title is only formulated at the end of the review process, which makes this approach impractical as it relies on ex post facto information. At the time of screening, only a rough working title is available, with which the BERT-based ranker performs significantly worse than with the final title. In this paper, we explore alternative sources of queries for prioritising screening, such as the Boolean query used to retrieve the documents to be screened and queries generated by instruction-based generative large-scale language models such as ChatGPT and Alpaca. Our best approach is not only viable based on the information available at the time of screening, but also has similar effectiveness to the final title.  © 2023 ACM.},
	author_keywords = {LLM; Query variations; Screening prioritisation; Systematic review},
	keywords = {Natural language processing systems; 'current; Boolean queries; LLM; Natural language queries; Prioritization; Query variation; Review process; Screening prioritization; State of the art; Systematic Review; Diagnosis},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070408-6},
	language = {English},
	abbrev_source_title = {SIGIR-AP - Annu. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr. Asia Pac. Reg.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Park202461,
	author = {Park, Yunsoo and Hong, Younkyung},
	title = {Sentiment Analysis of Preservice Teachers' Reflections Using a Large Language Model},
	year = {2024},
	journal = {Proceedings - 2024 6th International Workshop on Artificial Intelligence and Education, WAIE 2024},
	pages = {61 – 65},
	doi = {10.1109/WAIE63876.2024.00018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000647677&doi=10.1109%2fWAIE63876.2024.00018&partnerID=40&md5=1c0bea85f5ca0247db4d86bc2eb84b8c},
	affiliations = {Iowa State University, Department of Electrical and Computer Engineering, Ames, IA, United States; Ball State University, Department of Elementary Education, Muncie, IN, United States},
	abstract = {In this study, the emotion and tone of preservice teachers' reflections were analyzed using sentiment analysis with LLMs: GPT-4, Gemini, and BERT. We compared the results to understand how each tool categorizes and describes individual reflections and multiple reflections as a whole. This study aims to explore ways to bridge the gaps between qualitative, quantitative, and computational analyses of reflective practices in teacher education. This study finds that to effectively integrate LLM analysis into teacher education, developing an analysis method and result format that are both comprehensive and relevant for preservice teachers and teacher educators is crucial.  © 2024 IEEE.},
	author_keywords = {AI in education; Large Language Model; reflection analysis; Sentiment Analysis; teacher education},
	keywords = {Teaching; AI in education; Computational analysis; Language model; Large language model; Multiple reflections; Preservice teachers; Qualitative analysis; Reflection analysis; Sentiment analysis; Teacher education; Contrastive Learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037889-4},
	language = {English},
	abbrev_source_title = {Proc. - Int. Workshop Artif. Intell. Educ., WAIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Kauf2023,
	author = {Kauf, Carina and Ivanova, Anna A. and Rambelli, Giulia and Chersoni, Emmanuele and She, Jingyuan Selena and Chowdhury, Zawad and Fedorenko, Evelina and Lenci, Alessandro},
	title = {Event Knowledge in Large Language Models: The Gap Between the Impossible and the Unlikely},
	year = {2023},
	journal = {Cognitive Science},
	volume = {47},
	number = {11},
	doi = {10.1111/cogs.13386},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177808989&doi=10.1111%2fcogs.13386&partnerID=40&md5=abe8179ac23f5338864289e2980c1666},
	affiliations = {Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, United States; McGovern Institute for Brain Research, Massachusetts Institute of Technology, United States; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology, United States; Department of Modern Languages, Literatures and Cultures, University of Bologna, Italy; Department of Chinese and Bilingual Studies, Hong Kong Polytechnic University, Hong Kong; Department of Mathematics, University of Washington, United States; Department of Philology, Literature, and Linguistics, University of Pisa, Italy},
	abstract = {Word co-occurrence patterns in language corpora contain a surprising amount of conceptual knowledge. Large language models (LLMs), trained to predict words in context, leverage these patterns to achieve impressive performance on diverse semantic tasks requiring world knowledge. An important but understudied question about LLMs’ semantic abilities is whether they acquire generalized knowledge of common events. Here, we test whether five pretrained LLMs (from 2018's BERT to 2023's MPT) assign a higher likelihood to plausible descriptions of agent−patient interactions than to minimally different implausible versions of the same event. Using three curated sets of minimal sentence pairs (total n = 1215), we found that pretrained LLMs possess substantial event knowledge, outperforming other distributional language models. In particular, they almost always assign a higher likelihood to possible versus impossible events (The teacher bought the laptop vs. The laptop bought the teacher). However, LLMs show less consistent preferences for likely versus unlikely events (The nanny tutored the boy vs. The boy tutored the nanny). In follow-up analyses, we show that (i) LLM scores are driven by both plausibility and surface-level sentence features, (ii) LLM scores generalize well across syntactic variants (active vs. passive constructions) but less well across semantic variants (synonymous sentences), (iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence plausibility serves as an organizing dimension in internal LLM representations. Overall, our results show that important aspects of event knowledge naturally emerge from distributional linguistic patterns, but also highlight a gap between representations of possible/impossible and likely/unlikely events. © 2023 The Authors. Cognitive Science published by Wiley Periodicals LLC on behalf of Cognitive Science Society (CSS).},
	author_keywords = {Artificial neural networks; Generalized event knowledge; Language models; Plausibility; Semantics; Syntax; Typicality; World knowledge},
	keywords = {Humans; Judgment; Knowledge; Language; Male; Reading; Semantics; decision making; human; knowledge; language; male; reading; semantics},
	correspondence_address = {C. Kauf; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, 43 Vassar St., 02139, United States; email: ckauf@mit.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {03640213},
	coden = {COGSD},
	pmid = {38009752},
	language = {English},
	abbrev_source_title = {Cogn. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Giudice202371,
	author = {Giudice, Oliver and Maggi, Alessandro and Nardelli, Matteo},
	title = {Exploring Naive Approaches to Tell Apart LLMs Productions from Human-written Text},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {71 – 76},
	doi = {10.1145/3639233.3639354},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187551734&doi=10.1145%2f3639233.3639354&partnerID=40&md5=a3e77a6dc1b87d5029b24d0f033ca72e},
	affiliations = {Bank of Italy, RM, Rome, Italy},
	abstract = {Powerful Large Language Models (large LMs or LLMs) such as BERT and GPT are making the task of detecting machine-generated text more and more prominent and crucial to minimize threats posed by text generation models misuse. Nonetheless, only a limited number of efforts exist so far, which can be classified into simple classifiers, zero-shot approaches, and fine-Tuned LMs. These approaches usually rely on LMs whose discrimination accuracy decreases as the size difference in favor of the generator model increases (hence, a detector should always employ a LM with at least the same number of parameters of the source LM). Also, most of these approaches do not explicitly investigate whether the sentence syntactic structure can provide additional information that helps to build better detectors. All these considerations make the generalizing ability of detection methods into question. While generation techniques become more and more capable of producing human-like text, are the detection techniques capable of keeping up if not properly trained? In this paper, we evaluate the most effective (and reproducible) detection method available in the state of the art in order to figure out the limits in its robustness. We complement this analysis by discussing results obtained using a novel naive approach that demonstrably achieves comparable results in terms of robustness with respect to much more advanced and sophisticated state-of-The-Art methods. Code with details on experiments are available at: https://github.com/bancaditalia/gen-Text-detect. © 2023 ACM.},
	author_keywords = {classification; detection; human-written; LLM; machine-generated; NLP},
	keywords = {Computational linguistics; HTTP; Natural language processing systems; Text processing; Zero-shot learning; Classifieds; Detection; Detection methods; Human-written; Language model; LLM; Machine-generated; Machine-generated texts; Text generations; Written texts; Syntactics},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070922-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Alaswad20232097,
	author = {Alaswad, S. and Kalganova, T. and Awad, W.S.},
	title = {Using ChatGPT and other LLMs in Professional Environments},
	year = {2023},
	journal = {Information Sciences Letters},
	volume = {12},
	number = {9},
	pages = {2097 – 2108},
	doi = {10.18576/isl/120916},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172336382&doi=10.18576%2fisl%2f120916&partnerID=40&md5=ff10faa3ab119006bb20f1cc511ed37a},
	affiliations = {Department of Multimedia Science, College of Information Technology, Ahlia University, Manama, Bahrain; Department of Electronic and Electrical Engineering, Brunel University London, Uxbridge, UB8 3PH, United Kingdom; Department of Information Technology, College of Information Technology, Ahlia University, Manama, Bahrain},
	abstract = {Large language models like ChatGPT, Google’s Bard, and Microsoft’s new Bing, to name a few, are developing rapidly in recent years, becoming very popular in different environments, and supporting a wide range of tasks. A deep look into their outcomes reveals several limitations and challenges that can be further improved. The main challenge of these models is the possibility of generating biased or inaccurate results, since these models rely on large amounts of data with no access to unpublic information. Moreover, these language models need to be properly monitored and trained to prevent generating inappropriate or offensive content and to ensure that they are used ethically and safely. This study investigates the use of ChatGPT and other large language models such as Blender, and BERT in professional environments. It has been found that none of the large language models, including ChatGPT, have been used in unstructured dialogues. Moreover, involving the models in professional environments requires extensive training and monitoring by domain professionals or fine-tuning through API. © 2023 NSP Natural Sciences Publishing Cor.},
	author_keywords = {Artificial Intelligence; Chatbot; ChatGPT; LLM},
	correspondence_address = {S. Alaswad; Department of Multimedia Science, College of Information Technology, Ahlia University, Manama, Bahrain; email: salaswad@ahlia.edu.bh},
	publisher = {Natural Sciences Publishing},
	issn = {20909551},
	language = {English},
	abbrev_source_title = {Inf. Sci. Lett.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Khabarov2024444,
	author = {Khabarov, Dmitry and Samsonovich, Alexei V.},
	title = {Registrar: A Social Conversational Agent Based on Cognitive and Statistical Models for a Limited Paradigm},
	year = {2024},
	journal = {Studies in Computational Intelligence},
	volume = {1130 LNCS},
	pages = {444 – 452},
	doi = {10.1007/978-3-031-50381-8_46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186637129&doi=10.1007%2f978-3-031-50381-8_46&partnerID=40&md5=a5922bdee2588dff7607b71821873fa7},
	affiliations = {National Research Nuclear University MEPhI, Kashirskoe Shosse 31, Moscow, 115409, Russian Federation},
	abstract = {A virtual conversational agent is designed based on a cognitive model integrated with neural network model named BERT and large language model ChatGPT. The system was tested in a Turing-test-like experiment with human participants, using a limited paradigm of registration of a guest in a hotel. Performance of the agent on several scales matches human performance, while in empathy it showed a significantly higher score compared to humans. The narrowly designed prototype proves the concept and suggest future applications to general open-ended paradigms. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Cognitive model; Intentionalities; LLM; Social intelligent agents},
	correspondence_address = {A.V. Samsonovich; National Research Nuclear University MEPhI, Moscow, Kashirskoe Shosse 31, 115409, Russian Federation; email: avsamsonovich@mephi.ru},
	editor = {Samsonovich A.V. and Liu T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {1860949X},
	isbn = {978-303150380-1},
	language = {English},
	abbrev_source_title = {Stud. Comput. Intell.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{García-Barragán2024,
	author = {García-Barragán, Álvaro and González Calatayud, Alberto and Solarte-Pabón, Oswaldo and Provencio, Mariano and Menasalvas, Ernestina and Robles, Víctor},
	title = {GPT for medical entity recognition in Spanish},
	year = {2024},
	journal = {Multimedia Tools and Applications},
	doi = {10.1007/s11042-024-19209-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191098262&doi=10.1007%2fs11042-024-19209-5&partnerID=40&md5=ff4502258e8daa8f5a2cea6983c77e61},
	affiliations = {Center of Biomedical Technology, Universidad Politécnica de Madrid, Campus Montegancedo, Madrid, Pozuelo de Alarcón, 28223, Spain; Escuela de Ingeniería de Sistemas y Computación, Universidad del Valle, Cali, Colombia; Hospital Universitario Puerta de Hierro, Madrid, Spain},
	abstract = {In recent years, there has been a remarkable surge in the development of Natural Language Processing (NLP) models, particularly in the realm of Named Entity Recognition (NER). Models such as BERT have demonstrated exceptional performance, leveraging annotated corpora for accurate entity identification. However, the question arises: Can newer Large Language Models (LLMs) like GPT be utilized without the need for extensive annotation, thereby enabling direct entity extraction? In this study, we explore this issue, comparing the efficacy of fine-tuning techniques with prompting methods to elucidate the potential of GPT in the identification of medical entities within Spanish electronic health records (EHR). This study utilized a dataset of Spanish EHRs related to breast cancer and implemented both a traditional NER method using BERT, and a contemporary approach that combines few shot learning and integration of external knowledge, driven by LLMs using GPT, to structure the data. The analysis involved a comprehensive pipeline that included these methods. Key performance metrics, such as precision, recall, and F-score, were used to evaluate the effectiveness of each method. This comparative approach aimed to highlight the strengths and limitations of each method in the context of structuring Spanish EHRs efficiently and accurately.The comparative analysis undertaken in this article demonstrates that both the traditional BERT-based NER method and the few-shot LLM-driven approach, augmented with external knowledge, provide comparable levels of precision in metrics such as precision, recall, and F score when applied to Spanish EHR. Contrary to expectations, the LLM-driven approach, which necessitates minimal data annotation, performs on par with BERT’s capability to discern complex medical terminologies and contextual nuances within the EHRs. The results of this study highlight a notable advance in the field of NER for Spanish EHRs, with the few shot approach driven by LLM, enhanced by external knowledge, slightly edging out the traditional BERT-based method in overall effectiveness. GPT’s superiority in F-score and its minimal reliance on extensive data annotation underscore its potential in medical data processing. © The Author(s) 2024.},
	author_keywords = {BERT; Breast cancer; EHR; GPT; Information extraction; LLM; NER},
	keywords = {Data handling; Data mining; Natural language processing systems; Terminology; BERT; Breast Cancer; Electronic health; Electronic health record; GPT; Health records; Information extraction; Language model; Large language model; Named entity recognition; Diseases},
	correspondence_address = {Á. García-Barragán; Center of Biomedical Technology, Universidad Politécnica de Madrid, Pozuelo de Alarcón, Campus Montegancedo, Madrid, 28223, Spain; email: alvaro.gbarragan@upm.es},
	publisher = {Springer},
	issn = {13807501},
	coden = {MTAPF},
	language = {English},
	abbrev_source_title = {Multimedia Tools Appl},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Varalakshmi2024,
	author = {Varalakshmi, P. and Bugatha, N. Meena Kumari},
	title = {AI-Powered Resume Based QA Tailoring for Success in Interviews},
	year = {2024},
	journal = {2024 IEEE International Conference on Intelligent Techniques in Control, Optimization and Signal Processing, INCOS 2024 - Proceedings},
	doi = {10.1109/INCOS59338.2024.10527664},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194100122&doi=10.1109%2fINCOS59338.2024.10527664&partnerID=40&md5=2838cea03269dad7539536029c807e7e},
	affiliations = {Anna University, Department of Information Science and Technology, India},
	abstract = {In today's competitive job market, individuals encounter the challenge of aligning their skills with suitable job opportunities that match their interests. To tackle this, the system utilizes Natural Language Processing (NLP), leveraging Large Language Models (LLM) such as BERT, T5, ROBERTA, and XLNET. Through the analysis of resumes and job descriptions, it extracts keywords and generates Q&A, significantly increasing the likelihood of finding a role that aligns with their skills and aspirations. Achieving semantic accuracy, it delivers meaningful question and answer generation with an impressive 97% accuracy compared to previous works. This support empowers students and job seekers to confidently showcase their strengths, facilitating a more impactful journey towards securing meaningful employment. Additionally, the system provides a comprehensive analysis of the performance of each model.  © 2024 IEEE.},
	author_keywords = {BERT; Contextually linked; GPT-2; NER; ROBERTA; Semantic Accuracy; T5; Text Summarization; Web Scarping; XLNET},
	keywords = {Job analysis; Natural language processing systems; Semantic Web; Semantics; BERT; Contextually linked; GPT-2; NER; ROBERTA; Semantic accuracy; T5; Text Summarisation; Web scarping; XLNET; Employment},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036118-6},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Intell. Techniques Control, Optim. Signal Process., INCOS - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Zhang20241245,
	author = {Zhang, Micah and Ahmed, Shafiuddin Rehan and Martin, James H.},
	title = {FtG-CoT at SemEval-2024 Task 9: Solving Sentence Puzzles Using Fine-Tuned Language Models and Zero-Shot CoT Prompting},
	year = {2024},
	journal = {SemEval 2024 - 18th International Workshop on Semantic Evaluation, Proceedings of the Workshop},
	pages = {1245 – 1251},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192541230&partnerID=40&md5=1f1be977f52f2bd116105638273f7448},
	affiliations = {University of Colorado, Boulder, CO, United States},
	abstract = {Recent large language models (LLMs) can solve puzzles that require creativity and lateral thinking. To advance this front of research, we tackle SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense. We approach this task by introducing a technique that we call Fine-tuned Generated Chain-of-Thought (FtG-CoT). It is a novel few-shot prompting method that combines a fine-tuned BERT classifier encoder with zero-shot chain-of-thought generation and a fine-tuned LLM. The fine-tuned BERT classifier provides a context-rich encoding of each example question and choice list. Zero-shot chain-of-thought generation leverages the benefits of chain-of-thought prompting without requiring manual creation of the reasoning chains. We fine-tune the LLM on the generated chains-of-thought and include a set of generated reasoning chains in the final few-shot LLM prompt to maximize the relevance and correctness of the final generated response. In this paper, we show that FtG-CoT outperforms the zero-shot prompting baseline presented in the task paper and is highly effective at solving challenging sentence puzzles achieving a perfect score on the practice set and a 0.9 score on the evaluation set. © 2024 Association for Computational Linguistics.},
	keywords = {Chains; Zero-shot learning; Common sense; Encodings; Language model; Lateral thinking; Novel task; Computational linguistics},
	editor = {Ojha A.K. and Dohruoz A.S. and Madabushi H.T. and Da San Martino G. and Rosenthal S. and Rosa A.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176107-0},
	language = {English},
	abbrev_source_title = {SemEval - Int. Workshop Semantic Eval., Proc. Workshop},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Veeramani202466,
	author = {Veeramani, Hariram and Thapa, Surendrabikram and Naseem, Usman},
	title = {MLInitiative@WILDRE7: Hybrid Approaches with Large Language Models for Enhanced Sentiment Analysis in Code-Switched and Code-Mixed Texts},
	year = {2024},
	journal = {7th Workshop on Indian Language Data Resource and Evaluation, WILDRE 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {66 – 72},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195187333&partnerID=40&md5=b50d36371af3b58e17a24b66010afd6f},
	affiliations = {UCLA, United States; Virginia Tech, United States; Macquarie University, Australia},
	abstract = {Code-switched and code-mixed languages are prevalent in multilingual societies, reflecting the complex interplay of cultures and languages in daily communication. Understanding the sentiment embedded in such texts is crucial for a range of applications, from improving social media analytics to enhancing customer feedback systems. Despite their significance, research in code-mixed and code-switched languages remains limited, particularly in less-resourced languages. This scarcity of research creates a gap in natural language processing (NLP) technologies, hindering their ability to accurately interpret the rich linguistic diversity of global communications. To bridge this gap, this paper presents a novel methodology for sentiment analysis in code-mixed and code-switched texts. Our approach combines the power of large language models (LLMs) and the versatility of the multilingual BERT (mBERT) framework to effectively process and analyze sentiments in multilingual data. By decomposing code-mixed texts into their constituent languages, employing mBERT for named entity recognition (NER) and sentiment label prediction, and integrating these insights into a decision-making LLM, we provide a comprehensive framework for understanding sentiment in complex linguistic contexts. Our system achieves competitive rank on all subtasks in the Code-mixed Less-Resourced Sentiment analysis (Code-mixed) shared task at WILDRE-7 (LREC-COLING). © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Code-switched language; Code-switched language; Large language models (LLMs); Named entity recognition (NER); Sentiment analysis},
	keywords = {Computational linguistics; Decision making; Embedded systems; Code-switched language; Customer feedback; Hybrid approach; Language model; Large language model; Named entity recognition; Sentiment analysis; Social media analytics; Sentiment analysis},
	editor = {Jha G.N. and Devi S.L. and Bali K. and Ojha A.Kr.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381437-1},
	language = {English},
	abbrev_source_title = {Workshop Indian Lang. Data Resour. Eval., WILDRE LREC-COLING - Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Wang2024649,
	author = {Wang, Yun and Hu, Min and Ta, Na and Sun, Haitao and Guo, Yifeng and Zhou, Wuai and Guo, Yu and Zhang, Wanzhe and Feng, Jianhua},
	title = {Large language models and their application in government affairs; [大语言模型及其在政务领域的应用]},
	year = {2024},
	journal = {Qinghua Daxue Xuebao/Journal of Tsinghua University},
	volume = {64},
	number = {4},
	pages = {649 – 658},
	doi = {10.16511/j.cnki.qhdxxb.2023.26.042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192893271&doi=10.16511%2fj.cnki.qhdxxb.2023.26.042&partnerID=40&md5=2024013adbe43dfecd0fcb85675fdb4a},
	affiliations = {Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China; China Mobile Information System Integration Co., Ltd., Beijing, 100032, China; School of Journalism and Communication, Renmin University of China, Beijing, 100872, China},
	abstract = {[Significance] Since the turn of the 21st century, artificial intelligence (AI) has advanced considerably in many domains, including government affairs. Furthermore, the emergence of deep learning has taken the development of many AI fields, including natural language processing (NLP), to a new level. Language models (LMs) are key research directions of NLP. Referred to as statistical models, LMs were initially used to calculate the probability of a sentence; however, in recent years, there have been substantial developments in large language models (LLMs). Notably, LLM products, such as the generative pretrained transformer (GPT) series, have driven the rapid revolution of large language research. Domestic enterprises have also researched LLMs, for example, Huawei's Pangu and Baidu's enhanced language representation with informative entities (ERNIE) bot. These models have been widely used in language translation, abstract construction, named-entity recognition, text classification, and relationship extraction, among other applications, and in government affairs, finance, biomedicine, and other domains. [Progress] In this study, we observe that improving the efficiency of governance has become one of the core tasks of the government in the era of big data. With the continuous accumulation of government data, traditional statistical models relying on expert experience and local features gradually suffer limitations during application. However, LLMs, which offer the advantages of high flexibility, strong representation ability, and effective results, can rapidly enhance the intelligence level of government services. First, we review the research progress on early LMs, such as statistical LMs and neural network LMs. Subsequently, we focus on the research progress on LLMs, namely the Transformers series, GPT series, and bidirectional encoder representations from transformers (BERT) series. Finally, we introduce the application of LLMs in government affairs, including government text classification, relationship extraction, public opinion risk identification, named-entity recognition, and government question answering. Moreover, we propose that research on LLMs for government affairs must focus on multimodality, correctly benefit from the trend of "model as a service," focus on high data security, and clarify government responsibility boundaries. Additionally, a technical path for studying LLMs for government affairs has been proposed. [Conclusions and Prospects] The application of LLMs in government affairs mainly focuses on small-scale models, lacking examples of application in large-scale models. Compared with smaller models, large models offer many advantages, including high efficiency, broader application scenarios, and more convenience. These advantages can be understood as follows. In terms of efficiency, large models are usually trained on a large amount of heterogeneous data, thus delivering better performance. In terms of application scenarios, large models gradually support multimodal data, resulting in more diverse application scenarios. In terms of convenience, we emphasize the "pretraining + fine-tuning" mode and the invocation method of interfaces, making LLMs more convenient for research and practical applications. This study also analyzes the issues suffered by LLMs, specifically from the technological and ethical perspectives, which have resulted in a panic to a certain extent. For example, ChatGPT has generated many controversies, including whether the generated files are novel, whether using ChatGPT will lead to plagiarism and ambiguity as to who are property rights owners for the generated files. Overall, it can be said that LLMs are in the stage of vigorous development. As the country promotes research on AI and its application in government affairs, LLMs will play an increasingly crucial role in the field. © 2024 Tsinghua University. All rights reserved.},
	author_keywords = {artificial intelligence; digital government; language model; natural language processing; transfer learning},
	keywords = {Abstracting; Classification (of information); Computational linguistics; E-learning; Extraction; Natural language processing systems; Social aspects; Text processing; Transfer learning; Application scenario; Digital government; Government affairs; Language model; Language processing; Large models; Natural language processing; Natural languages; Statistic modeling; Transfer learning; Deep learning},
	correspondence_address = {N. Ta; School of Journalism and Communication, Renmin University of China, Beijing, 100872, China; email: tanayun@ruc.edu.cn},
	publisher = {Tsinghua University},
	issn = {10000054},
	coden = {QDXKE},
	language = {Chinese},
	abbrev_source_title = {Qinghua Daxue Xuebao},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Mellon2024,
	author = {Mellon, Jonathan and Bailey, Jack and Scott, Ralph and Breckwoldt, James and Miori, Marta and Schmedeman, Phillip},
	title = {Do AIs know what the most important issue is? Using language models to code open-text social survey responses at scale},
	year = {2024},
	journal = {Research and Politics},
	volume = {11},
	number = {1},
	doi = {10.1177/20531680241231468},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184687565&doi=10.1177%2f20531680241231468&partnerID=40&md5=57f23aa7ea315cd88a85d288e7e9479b},
	affiliations = {Department of Systems Engineering, West Point, West Point, NY, United States; Department of Politics, University of Manchester, Manchester, United Kingdom; School of Sociology, Politics and International Studies, University of Bristol, Bristol, United Kingdom},
	abstract = {Can artificial intelligence accurately label open-text survey responses? We compare the accuracy of six large language models (LLMs) using a few-shot approach, three supervised learning algorithms (SVM, DistilRoBERTa, and a neural network trained on BERT embeddings), and a second human coder on the task of categorizing “most important issue” responses from the British Election Study Internet Panel into 50 categories. For the scenario where a researcher lacks existing training data, the accuracy of the highest-performing LLM (Claude-1.3: 93.9%) neared human performance (94.7%) and exceeded the highest-performing supervised approach trained on 1000 randomly sampled cases (neural network: 93.5%). In a scenario where previous data has been labeled but a researcher wants to label novel text, the best LLM’s (Claude-1.3: 80.9%) few-shot performance is only slightly behind the human (88.6%) and exceeds the best supervised model trained on 576,000 cases (DistilRoBERTa: 77.8%). PaLM-2, Llama-2, and the SVM all performed substantially worse than the best LLMs and supervised models across all metrics and scenarios. Our results suggest that LLMs may allow for greater use of open-ended survey questions in the future. © The Author(s) 2024.},
	author_keywords = {ChatGPT; GPT-4; Large language models; most important issue; open-text survey questions; public opinion; text as data},
	correspondence_address = {J. Mellon; Department of Systems Engineering, West Point, West Point, United States; email: jonathan.mellon@westpoint.edu},
	publisher = {SAGE Publications Ltd},
	issn = {20531680},
	language = {English},
	abbrev_source_title = {Res. Polit.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access}
}

@ARTICLE{Cardillo2024100,
	author = {Cardillo, Elena and Portaro, Alessio and Taverniti, Maria and Lanza, Claudia and Guarasci, Raffaele},
	title = {Towards the Automated Population of Thesauri Using BERT: A Use Case on the Cybersecurity Domain},
	year = {2024},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {193},
	pages = {100 – 109},
	doi = {10.1007/978-3-031-53555-0_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186487152&doi=10.1007%2f978-3-031-53555-0_10&partnerID=40&md5=5356803f37d48124669c5ccb1d6767e5},
	affiliations = {Institute of Informatics and Telematics, National Research Council, Rende, Italy; University of Calabria (UNICAL), Rende, Italy; Institute for High Performance Computing and Networking, National Research Council of Italy (CNR), Rende, Italy},
	abstract = {The present work delves into innovative methodologies leveraging the widely used BERT model to enhance the population and enrichment of domain-oriented controlled vocabularies as Thesauri. Starting from BERT’s embeddings, we extracted information from a sample corpus of Cybersecurity related documents and presented a novel Natural Language Processing-inspired pipeline that combines Neural language models, knowledge graph extraction, and natural language inference for identifying implicit relations (adaptable to thesaural relationships) and domain concepts to populate a domain thesaurus. Preliminary results are promising, showing the effectiveness of using the proposed methodology, and thus the applicability of LLMs, BERT in particular, to enrich specialized controlled vocabularies with new knowledge. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Domain-specific language modeling; Knowledge Extraction; LLMs; Semantic analysis; Thesauri},
	keywords = {Computational linguistics; Domain Knowledge; Extraction; Knowledge graph; Modeling languages; Natural language processing systems; Pipeline processing systems; Problem oriented languages; Semantics; Vocabulary control; Cyber security; Domain-oriented; Domain-specific language modeling; Domains specific languages; Innovative methodologies; Knowledge extraction; Language model; LLM; Natural languages; Semantic analysis; Thesauri},
	correspondence_address = {E. Cardillo; Institute of Informatics and Telematics, National Research Council, Rende, Italy; email: elena.cardillo@iit.cnr.it},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23674512},
	language = {English},
	abbrev_source_title = {Lecture. Notes. Data Eng. Commun. Tech.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Chari2023,
	author = {Chari, Shruthi and Acharya, Prasant and Gruen, Daniel M. and Zhang, Olivia and Eyigoz, Elif K. and Ghalwash, Mohamed and Seneviratne, Oshani and Saiz, Fernando Suarez and Meyer, Pablo and Chakraborty, Prithwish and McGuinness, Deborah L.},
	title = {Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes},
	year = {2023},
	journal = {Artificial Intelligence in Medicine},
	volume = {137},
	doi = {10.1016/j.artmed.2023.102498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147794628&doi=10.1016%2fj.artmed.2023.102498&partnerID=40&md5=6c5cc1b57f4fd01e972d0ca1c16ae219},
	affiliations = {Rensselaer Polytechnic Institute, 110 8th St, Troy, 12180, NY, United States; Center for Computational Health, IBM Research, 1101 Kitchawan Rd, Yorktown Heights, 10598, NY, United States; IBM Watson Health, 75 Binney St, Cambridge, 02142, MA, United States},
	abstract = {Medical experts may use Artificial Intelligence (AI) systems with greater trust if these are supported by ‘contextual explanations’ that let the practitioner connect system inferences to their context of use. However, their importance in improving model usage and understanding has not been extensively studied. Hence, we consider a comorbidity risk prediction scenario and focus on contexts regarding the patients’ clinical state, AI predictions about their risk of complications, and algorithmic explanations supporting the predictions. We explore how relevant information for such dimensions can be extracted from Medical guidelines to answer typical questions from clinical practitioners. We identify this as a question answering (QA) task and employ several state-of-the-art Large Language Models (LLM) to present contexts around risk prediction model inferences and evaluate their acceptability. Finally, we study the benefits of contextual explanations by building an end-to-end AI pipeline including data cohorting, AI risk modeling, post-hoc model explanations, and prototyped a visual dashboard to present the combined insights from different context dimensions and data sources, while predicting and identifying the drivers of risk of Chronic Kidney Disease (CKD) - a common type-2 diabetes (T2DM) comorbidity. All of these steps were performed in deep engagement with medical experts, including a final evaluation of the dashboard results by an expert medical panel. We show that LLMs, in particular BERT and SciBERT, can be readily deployed to extract some relevant explanations to support clinical usage. To understand the value-add of the contextual explanations, the expert panel evaluated these regarding actionable insights in the relevant clinical setting. Overall, our paper is one of the first end-to-end analyses identifying the feasibility and benefits of contextual explanations in a real-world clinical use case. Our findings can help improve clinicians’ usage of AI models. © 2023},
	author_keywords = {Clinical explainability; Contextual explanations; Question-answering approach; Type-2 diabetes comorbidity risk prediction; User-driven},
	keywords = {Artificial Intelligence; Diabetes Mellitus, Type 2; Humans; Trust; Epidemiology; Forecasting; Modeling languages; Risk perception; Clinical explainability; Comorbidities; Contextual explanation; Question Answering; Question-answering approach; Risk prediction models; Risk predictions; Type-2 diabetes; Type-2 diabetes comorbidity risk prediction; User driven; adult; Article; artificial intelligence; chronic kidney failure; clinical assessment; clinical indicator; clinician; comorbidity; disease simulation; female; human; male; non insulin dependent diabetes mellitus; post hoc analysis; practice guideline; predictive model; qualitative analysis; quantitative analysis; risk assessment; artificial intelligence; trust; Risk assessment},
	correspondence_address = {S. Chari; Rensselaer Polytechnic Institute, Troy, 110 8th St, 12180, United States; email: charis@rpi.edu},
	publisher = {Elsevier B.V.},
	issn = {09333657},
	coden = {AIMEE},
	pmid = {36868690},
	language = {English},
	abbrev_source_title = {Artif. Intell. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@ARTICLE{Alcántara2024106,
	author = {Alcántara, Tania and García-Vázquez, Omar and Calvo, Hiram and Torres-León, José A.},
	title = {Disaster Tweets: Analysis from the Metaphor Perspective and Classification Using LLM’s},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14392 LNAI},
	pages = {106 – 117},
	doi = {10.1007/978-3-031-47640-2_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177436446&doi=10.1007%2f978-3-031-47640-2_9&partnerID=40&md5=2f6a5263d3a227ec9503948e2309436a},
	affiliations = {Laboratorio de Ciencias Cognitivas Computacionales, Centro de Investigación en Computación, Instituto Politécnico Nacional, Mexico City, Mexico},
	abstract = {Nowadays, social networks, specially Twitter (now X), allow the spread of information about all topics; since this platform is completely open, there is little to none restriction on what a user can post, hence, creating a lack of confidence and trust on the information available. However, the information on Twitter sometimes have hidden meanings, as the users use metaphors to define their ideas. This paper analyzes and classifies a set of texts labeled as disaster and non-disaster, where those labeled as non-disaster include metaphorical context, focusing on the metaphorical tweets and their interaction with large language models such as BERT, RoBERTa and DistilBERT. These experiments showed an improvement compared with the state-of-the-art approaches, demonstrating that these models capture proper metaphorical text representations. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {BERT; Classification; DistilBERT; LLM; Metaphors; Natural Language Processing; RoBERTa},
	keywords = {Natural language processing systems; Social networking (online); BERT; Distilbert; Lack of confidences; Language processing; LLM; Metaphor; Natural language processing; Natural languages; RoBERTa; Spread of informations; Disasters},
	correspondence_address = {T. Alcántara; Laboratorio de Ciencias Cognitivas Computacionales, Centro de Investigación en Computación, Instituto Politécnico Nacional, Mexico City, Mexico; email: talcantaram2020@cic.ipn.mx},
	editor = {Calvo H. and Martínez-Villaseñor L. and Ponce H.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303147639-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Sarafrazi20241,
	author = {Sarafrazi, Soodabeh and Wheeler, Darwin and Garcia, David and Henrikson, Shane and Sharif, Naveed and Wu, Hui},
	title = {Enhancing Search Engine Optimization in Healthcare and Clinical Domains with Natural Language Processing and Graph Techniques},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2019 CCIS},
	pages = {1 – 13},
	doi = {10.1007/978-3-031-52216-1_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184798739&doi=10.1007%2f978-3-031-52216-1_1&partnerID=40&md5=51ff8203c00b7f9f2b8e4e5069929469},
	affiliations = {Oakland, 94612, United States; Kaiser Permanente, Oakland, 94612, United States},
	abstract = {Search Engine Optimization (SEO) is the art of refining a website to enhance its visibility in search engine results, capturing the attention of both potential and existing customers. At Kaiser Permanente Digital, our unwavering commitment is to provide individuals with pertinent and precise health-related information. In this study, our primary objective is to elevate the rankings of KP.org webpages. To attain this goal, we leverage data from a third-party platform and harness cutting-edge Natural Language Processing (NLP) techniques, including the powerful large language model BERT. Our NLP arsenal encompasses diverse techniques, such as clustering and topic modeling, designed to extract invaluable insights from our data. Moreover, we complement our findings with practical examples and compelling visualizations tailored to the clinical and healthcare domain. Additionally, we conduct thorough graph analysis, employing methods like node2vec, to identify pages with closely related content within our domain, addressing the issue of keyword cannibalization and content competition for ranking. In this paper, we present our innovative solutions in a visually intuitive manner, showcasing how these approaches not only optimize our content effectively but also ensure strategic and non-redundant keyword utilization across our website. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Graph Analysis; Large Language Model (LLM); Natural Language Processing (NLP); Search Engine Optimization (SEO)},
	keywords = {Arsenals; Computational linguistics; Health care; Modeling languages; Natural language processing systems; Search engines; Graph analysis; Graph technique; Language model; Language processing; Language processing techniques; Large language model; Natural language processing; Natural languages; Search engine optimization; Search engine optimizations; Websites},
	correspondence_address = {H. Wu; Kaiser Permanente, Oakland, 94612, United States; email: jason.x2.wu@kp.org},
	editor = {Qi J. and Yang P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303152215-4},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hashimoto202313,
	author = {Hashimoto, Wakana and Yasui, Masahito and Takeuchi, Kazuhiro},
	title = {Basic Investigation of Code Edit Distance Measurement by CodeBERT},
	year = {2023},
	journal = {Proceedings - 2023 15th International Congress on Advanced Applied Informatics Winter, IIAI-AAI-Winter 2023},
	pages = {13 – 18},
	doi = {10.1109/IIAI-AAI-Winter61682.2023.00012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191496013&doi=10.1109%2fIIAI-AAI-Winter61682.2023.00012&partnerID=40&md5=e25e11acb77c61fbebdd34804b42f08a},
	affiliations = {Graduate School of Engineering, Osaka Electro-Communication University, Osaka, Japan; Osaka Electro-Communication University, Faculty of Information and Communication Engineering, Osaka, Japan},
	abstract = {This paper investigates the use of CodeBERT, a well-known large-scale language model (LLM) for program code, in computing code edit distance, an important aspect of software development. We perform two experiments to evaluate CodeBERT's ability to discriminate between code changes, detect deletions of functional parts, and understand structural and grammatical aspects of code. In the first experiment, we aim to detect the deletion of specific functional parts in abstract syntax trees (ASTs). The experimental results show that CodeBERT exhibits high accuracy in identifying the presence or absence of arbitrary subtrees in the AST, indicating its potential for understanding the structural aspects of code. In the second experiment, we use CodeBERT to train code similarity computation using Sentence-BERT, demonstrating its ability to capture both semantic and grammatical aspects of code. These results are valuable for the further development of comprehensive LLMs for program code.  © 2023 IEEE.},
	author_keywords = {knowledge management; large-scale language model; software analysis},
	keywords = {Computational linguistics; Semantics; Software design; Trees (mathematics); Abstract Syntax Trees; Code changes; Computing codes; Edit distance; Functional parts; Language model; Large-scale language model; Large-scales; Program code; Software analysis; Knowledge management},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038382-9},
	language = {English},
	abbrev_source_title = {Proc. - Int. Congr. Adv. Appl. Informatics Winter, IIAI-AAI-Winter},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {1st International Artificial Intelligence Conference, IAIC 2023},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2060 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190640953&partnerID=40&md5=1ed2312657e519343e147d033caaa2f9},
	abstract = {The proceedings contain 86 papers. The special focus in this conference is on Artificial Intelligence. The topics include: A Paper Citation Link Prediction Method Using Graph Attention Network; research on Emotional Analysis of Tibetan Short Text Based on Fusion Sentiment Lexicon; A Review of Solving Non-IID Data in Federated Learning: Current Status and Future Directions; a Review of Relationship Extraction Based on Deep Learning; BERT and LLM-Based Multivariate Hate Speech Detection on Twitter: Comparative Analysis and Superior Performance; Deep Learning for Protein-Protein Contact Prediction Using Evolutionary Scale Modeling (ESM) Feature; fedTag: Towards Automated Attack Investigation Using Federated Learning; Deep Learning Based SQL Injection Attack Detection; RSCC: Robust Semi-supervised Learning with Contrastive Learning and Augmentation Consistency Regularization; enhanced Prototypical Network for Few-Shot Named Entity Recognition; Regularized DNN Based Adaptive Compensation Algorithm for Gateway Power Meter in Ultra-High Voltage Substations; Dynamic Occlusion Expression Recognition Based on Improved GAN; Contrastive Learning Based on AMR Graph for Logic Reasoning; automated Detection and Recognition of Wild Dolphin Behaviors Using Deep Learning; M-GFCC: Audio Copy-Move Forgery Detection Algorithm Based on Fused Features of MFCC and GFCC; a Survey of Homogeneous and Heterogeneous Multi-source Information Fusion Based on Rough Set Theory; formula Maintenance of Single Material Tobacco Compatibility Based on Co-formulation Analysis Method; multi-physical Field Collaborative Simulation Optimization Technology and Reliability Analysis of Power Amplifiers; research and Design of Hydrological Data Visualization Based on Digital Twin; Design of Constraint FH-LFM DFRC Waveform; a Construction of IoT Malicious Traffic Dataset and Its Applications; meta-learning Based on Multi-objective Optimization; research and Implementation of Cooperative Utilization of Network Security Devices for Typical Security Events.},
	editor = {Jin H. and Pan Y. and Lu J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-981971331-8},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Edwards202320,
	author = {Edwards, Chris},
	title = {LEARNING WITH ERRORS},
	year = {2023},
	journal = {New Electronics},
	volume = {56},
	number = {9},
	pages = {20 – 21},
	doi = {10.12968/s0047-9624(24)60046-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182433192&doi=10.12968%2fs0047-9624%2824%2960046-5&partnerID=40&md5=0dd13d3021b2c0179206ccfcf773ffd8},
	abstract = {The large-language model (LLM) has seen a remarkable rise from obscurity to, apparently, forming as big a threat to skilled jobs as electricity formed to the Edwardian army of gas-lamp lighters. The neural-network layout that formed the basis of (BERT) technology appeared just five years ago in a model that demanded more than 300 million parameters to store the training data of some three billion words taken from publicdomain books and Wikipedia,},
	keywords = {Language model; Learning with Errors; Network layout; Neural-networks; Public domains; Training data; Wikipedia},
	publisher = {Findlay Publications Ltd},
	issn = {00479624},
	coden = {NWELA},
	language = {English},
	abbrev_source_title = {New Electron.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bețianu2024277,
	author = {Bețianu, Miruna and Mălan, Abele and Aldinucci, Marco and Birke, Robert and Chen, Lydia},
	title = {DALLMi: Domain Adaption for LLM-Based Multi-label Classifier},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14647 LNAI},
	pages = {277 – 289},
	doi = {10.1007/978-981-97-2259-4_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192795538&doi=10.1007%2f978-981-97-2259-4_21&partnerID=40&md5=fc8089adf6202a5aa7f2bd278ee5b79a},
	affiliations = {Delft University of Technology, Delft, Netherlands; University of Neuchâtel, Neuchâtel, Switzerland; University of Turin, Torino, Italy},
	abstract = {Large language models (LLMs) increasingly serve as the backbone for classifying text associated with distinct domains and simultaneously several labels (classes). When encountering domain shifts, e.g., classifier of movie reviews from IMDb to Rotten Tomatoes, adapting such an LLM-based multi-label classifier is challenging due to incomplete label sets at the target domain and daunting training overhead. The existing domain adaptation methods address either image multi-label classifiers or text binary classifiers. In this paper, we design DALLMi, Domain Adaptation Large Language Model interpolator, a first-of-its-kind semi-supervised domain adaptation method for text data models based on LLMs, specifically BERT. The core of DALLMi is the novel variation loss and MixUp regularization, which jointly leverage the limited positively labeled and large quantity of unlabeled text and, importantly, their interpolation from the BERT word embeddings. DALLMi also introduces a label-balanced sampling strategy to overcome the imbalance between labeled and unlabeled data. We evaluate DALLMi against the partial-supervised and unsupervised approach on three datasets under different scenarios of label availability for the target domain. Our results show that DALLMi achieves higher mAP than unsupervised and partially-supervised approaches by 19.9% and 52.2%, respectively. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Domain adaptation; Large language models; Multi-label classification; Semi-supervised learning},
	keywords = {Classification (of information); Computational linguistics; Learning algorithms; Supervised learning; Adaptation methods; Domain adaptation; Domain adaptions; Language model; Large language model; Model-based OPC; Multi-label classifications; Multi-labels; Semi-supervised learning; Target domain; Interpolation},
	correspondence_address = {A. Mălan; Delft University of Technology, Delft, Netherlands; email: abele.malan@unine.ch},
	editor = {Yang D.-N. and Xie X. and Tseng V.S. and Pei J. and Huang J.-W. and Lin J.C.-W.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981972261-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Kumari2023118,
	author = {Kumari, Tripti and Das, Ayan},
	title = {Towards development of an effective AI-based system for relevant comment generation},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {118 – 120},
	doi = {10.1145/3632754.3632770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185397641&doi=10.1145%2f3632754.3632770&partnerID=40&md5=47b437ce6f913ca6087330c6eebf9eb4},
	affiliations = {Indian Institute of Technology, Indian School of Mines, Dhanbad, Jharkhand, India},
	abstract = {The comments are essential to understand the functionality of the source code. The comments are crucial to enhancing code readability, maintainability, and collaboration among developers. However, writing elaborate comments for codes is sometimes time-consuming and the comments written for codes do not clearly bring out the meaning of the latter. Furthermore, given the availability of AI-based text generators in the form of ChatGPT, developers are using them to automatically generate comments for their programs to save time and effort. However, the quality of the comments generated by these AI-based systems and the ability of these systems to generate comments for complex programs is not well-studied in the literature. In this research work, we wish to explore the efficacy of AI-based systems in generating comments and compare the quality of such synthetically generated comments with human-written comments.  © 2023 Owner/Author.},
	author_keywords = {and Comment generator.; Bidirectional Encoder Representations from Transformer (BERT); ChatGPT; Code-comment pairs; Data augmentation; Distinguisher; Embeddings from Language Models (ELMo); Large Language Model (LLM); Usefulness prediction},
	keywords = {Codes (symbols); Computational linguistics; And comment generator.; Bidirectional encoder representation from transformer; ChatGPT; Code-comment pair; Data augmentation; Distinguishers; Embedding from language model; Embeddings; Language model; Large language model; Usefulness prediction; Signal encoding},
	editor = {Ganguly D. and Majumdar S. and Mitra B. and Gupta P. and Gangopadhyay S. and Majumder P. and Majumder P.},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071632-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yang2024,
	author = {Yang, Zi and Liu, Ziyue and Choudhary, Samridhi and Xie, Xinfeng and Gao, Cao and Kunzmann, Siegfried and Zhang, Zheng},
	title = {CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization},
	year = {2024},
	journal = {Advances in Neural Information Processing Systems},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000535274&partnerID=40&md5=ecebacc37c5bcbfe84b249f077b257ad},
	affiliations = {University at Albany, SUNY, United States; University of California, Santa Barbara, United States; Amazon Alexa AI, United States; Meta, United States},
	abstract = {Training large AI models such as LLMs and DLRMs costs massive GPUs and computing time. The high training cost has become only affordable to big tech companies, meanwhile also causing increasing concerns about the environmental impact. This paper presents CoMERA, a Computing- and Memory-Efficient training method via Rank-Adaptive tensor optimization. CoMERA achieves rank-adaptive tensor-compressed (pre)-training via a multi-objective optimization formulation and improves the training to provide both a high compression ratio and excellent accuracy in the training process. Our optimized numerical computation (e.g., optimized tensorized embedding and tensor-network contractions) and GPU implementation eliminate part of the run-time overhead in the tensorized training on GPU. This leads to, for the first time, 2 − 3× speedup per training epoch compared with standard training. CoMERA also outperforms the recent GaLore in terms of both memory and computing efficiency. Specifically, CoMERA is 2× faster per training epoch and 9× more memory-efficient than GaLore on a tested six-encoder transformer with single-batch training. Our method also shows ∼ 2× speedup than standard pre-training on a BERT-like code-generation LLM while achieving 4.23× compression ratio in pre-training. With further HPC optimization, CoMERA may reduce the pre-training cost of many other LLMs. An implementation of CoMERA is available at https://github.com/ziyangjoy/CoMERA. © 2024 Neural information processing systems foundation. All rights reserved.},
	correspondence_address = {Z. Yang; University at Albany, SUNY, United States; email: zyang8@albany.edu},
	editor = {Globerson A. and Mackey L. and Belgrave D. and Fan A. and Paquet U. and Tomczak J. and Zhang C.},
	publisher = {Neural information processing systems foundation},
	issn = {10495258},
	language = {English},
	abbrev_source_title = {Adv. neural inf. proces. syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rahravi2024205,
	author = {Rahravi, Mahdi and Khouri, Masoud and Ghasemzadeh, Mohammad},
	title = {Mathematic Problems Categorization Using Synthetic- LLM Models},
	year = {2024},
	journal = {2024 10th International Conference on Signal Processing and Intelligent Systems, ICSPIS 2024},
	pages = {205 – 208},
	doi = {10.1109/ICSPIS65223.2024.10931108},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002253506&doi=10.1109%2fICSPIS65223.2024.10931108&partnerID=40&md5=22d58985bf7a0b0a3fc6c190c6e99bdb},
	affiliations = {Yazd University, Computer Engineering Department, Yazd, Iran},
	abstract = {Accurate identification and understanding of mathematical problems are essential for effective problem-solving. This study addresses challenges in classifying and tagging mathematical questions for educational purposes, such as ambiguous phrasing, varied structures, and the complexity of different mathematical concepts. To tackle these issues, the proposed method consists of two main steps: utilizing the BERT language model for classifying questions related to derivatives and integrals, and employing the T5 model for precise tagging of problems. The process involves tokenization and thorough training of both models on a custom dataset that includes four categories of mathematical topics, focusing on integral and derivative problems. Evaluation is conducted using five metrics: Accuracy, precision, recall, F1-score, and confusion matrix. Results indicate a high level of accuracy in classifying question types and tagging, highlighting the effectiveness of the proposed approach in enhancing educational tools for mathematics through advanced language processing techniques.  © 2024 IEEE.},
	author_keywords = {BERT Model; Mathematical Problem Classification; Problem Tagging; T5 Model;},
	keywords = {Choquet integral; Human computer interaction; Modeling languages; Problem oriented languages; BERT model; Language model; Mathematical concepts; Mathematical problem classification; Mathematical problems; Problem classification; Problem tagging; Problem-solving; T5 model;; Tokenization; Problem solving},
	correspondence_address = {M. Rahravi; Yazd University, Computer Engineering Department, Yazd, Iran; email: myazdani374@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833153254-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Signal Process. Intell. Syst., ICSPIS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Linzbach20231145,
	author = {Linzbach, Stephan and Tressel, Tim and Kallmeyer, Laura and Dietze, Stefan and Jabeen, Hajira},
	title = {Decoding Prompt Syntax: Analysing its Impact on Knowledge Retrieval in Large Language Models},
	year = {2023},
	journal = {ACM Web Conference 2023 - Companion of the World Wide Web Conference, WWW 2023},
	pages = {1145 – 1149},
	doi = {10.1145/3543873.3587655},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159599405&doi=10.1145%2f3543873.3587655&partnerID=40&md5=afff6d9a0e85a8e4e258c14a2eeff344},
	affiliations = {GESIS Leibniz Institute for Social Sciences, Germany; Heinrich Heine University, Düsseldorf, Germany},
	abstract = {Large Language Models (LLMs), with their advanced architectures and training on massive language datasets, contain unexplored knowledge. One method to infer this knowledge is through the use of cloze-style prompts. Typically, these prompts are manually designed because the phrasing of these prompts impacts the knowledge retrieval performance, even if the LLM encodes the desired information. In this paper, we study the impact of prompt syntax on the knowledge retrieval capacity of LLMs. We use a template-based approach to paraphrase simple prompts into prompts with a more complex grammatical structure. We then analyse the LLM performance for these structurally different but semantically equivalent prompts. Our study reveals that simple prompts work better than complex forms of sentences. The performance across the syntactical variations for simple relations (1:1) remains best, with a marginal decrease across different typologies. These results reinforce that simple prompt structures are more effective for knowledge retrieval in LLMs and motivate future research into the impact of prompt syntax on various tasks.  © 2023 ACM.},
	author_keywords = {BERT; Knowledge retrieval; Large Language models; Syntax aware prompt},
	keywords = {Computational linguistics; Large dataset; Advanced architecture; BERT; Grammatical structure; Knowledge retrieval; Language model; Large language model; Retrieval performance; Simple++; Syntax aware prompt; Template-based approaches; Syntactics},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039416-1},
	language = {English},
	abbrev_source_title = {ACM Web Conf. - Companion World Wide Web Conf., WWW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Simonds202475,
	author = {Simonds, Toby and Kurniawan, Kemal and Lau, Jey Han},
	title = {MoDEM: Mixture of Domain Expert Models},
	year = {2024},
	journal = {Proceedings of the Australasian Language Technology Workshop},
	volume = {22},
	pages = {75 – 88},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003283293&partnerID=40&md5=17509f38a82e8dd0b8f8366ed52fbb31},
	affiliations = {The University of Melbourne, Australia},
	abstract = {We propose a novel approach to enhancing the performance and efficiency of large language models (LLMs) by combining domain prompt routing with domain-specialized models. We introduce a system that utilizes a BERT-based router to direct incoming prompts to the most appropriate domain expert model. These expert models are specifically tuned for domains such as health, mathematics and science. Our research demonstrates that this approach can significantly outperform general-purpose models of comparable size, leading to a superior performance-to-cost ratio across various benchmarks. The implications of this study suggest a potential shift in LLM development and deployment. Rather than focusing solely on creating increasingly large, general-purpose models, the future of AI may lie in developing ecosystems of smaller, highly specialized models coupled with sophisticated routing systems. This approach could lead to more efficient resource utilization, reduced computational costs, and superior overall performance. ©2024 Association for Computational Linguistics.},
	editor = {Baldwin T. and Rodríguez Méndez S.J. and Kuo N.I-H.},
	publisher = {Australasian Language Technology Association},
	issn = {18347037},
	language = {English},
	abbrev_source_title = {Proc. Australas. Lang. Technol. Workshop.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hachmeier202437,
	author = {Hachmeier, Simon and Jäschke, Robert},
	title = {Information Extraction of Music Entities in Conversational Music Queries},
	year = {2024},
	journal = {Proceedings of the 3rd Workshop on NLP for Music and Audio, NLP4MusA 2024},
	pages = {37 – 42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000192449&partnerID=40&md5=a36150663449311f536fdfc41dfc9ab2},
	affiliations = {School of Library and Information Science, Humboldt-Universität zu Berlin, Germany},
	abstract = {The detection of music entities such as songs or performing artists in natural language queries is an important task when designing conversational music recommendation agents. Previous research has observed the applicability of named entity recognition approaches for this task based on pre-trained encoders like BERT. In recent years, large language models (LLMs) have surpassed these encoders in a variety of downstream tasks. In this paper, we validate the use of LLMs for information extraction of music entities in conversational queries by few-shot prompting. We test different numbers of examples and compare two sampling methods to obtain few-shot examples. Our results indicate that LLM performance can achieve state-of-the-art performance in the task. © 2024 NLP4MusA. All Rights Reserved.},
	keywords = {Chatbots; Computer music; Encoding (symbols); Modeling languages; Natural language processing systems; Query languages; Down-stream; Language model; Modeling performance; Music recommendation; Named entity recognition; Natural language queries; Recommendation agents; Sampling method; State-of-the-art performance; Task-based; Information retrieval},
	editor = {Kruspe A. and Oramas S. and Epure E.V. and Sordo M. and Weck B. and Doh S. and Won M. and Manco I. and Meseguer-Brocal G.},
	publisher = {Association for Computational Linguistics (ACL)},
	language = {English},
	abbrev_source_title = {Proc. Workshop NLP  Music Audio, NLP4MusA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Shi202485,
	author = {Shi, Xiaohou and Liu, Jiahao and Song, Yaqi},
	title = {BERT and LLM-Based Multivariate Hate Speech Detection on Twitter: Comparative Analysis and Superior Performance},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2058 CCIS},
	pages = {85 – 97},
	doi = {10.1007/978-981-97-1277-9_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190436047&doi=10.1007%2f978-981-97-1277-9_7&partnerID=40&md5=f4c2fbb33c3d525c19669dddb3cb6f7d},
	affiliations = {China Telecom Corporation Limited Research Institute, Beijing, China; Johns-Hopkins University, Baltimore, 21218, MD, United States},
	abstract = {The detection of toxic and hate speech in online social media is becoming increasingly necessary due to its prevalence and the potentially harmful consequences it can cause. Previous research has demonstrated the vital role that machine learning and natural language processing models have in identifying inappropriate language. In this study, the aim is to assess the viability of BERT for accurately predicting multivariate classifications related to hate speech on Twitter. The analysis will be conducted using the Twitter hate speech dataset. BERT has demonstrated exceptional performance in numerous areas of NLP, making it a potentially superior alternative to traditional machine learning approaches. Experiments were performed on the same dataset using 1-layer BERT, 2-layers BERT, and logistic regression models for both training and prediction purposes. The results demonstrate that the 2-layer BERT produces an accuracy of 85%. Additionally, we incorporated transfer learning techniques by leveraging a Large Language model GPT-3 and data augmentation strategies to further enhance model performance. This experiment reached a higher accuracy of 88%. As this is a multivariate classification problem with an asymmetrical dataset, we anticipate BERT and GPT-3 will achieve greater accuracy for the binary classification problem of identifying hate speech. These findings enhance the comprehension of hate speech detection in online material and the implications of various modeling approaches. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {BERT; data augmentation; Fine-tuning; GPT-3; Hate Speech Detection; Large Language modeling; Nature Language Process; Social media; Transfer learning},
	keywords = {Classification (of information); Computational linguistics; Learning algorithms; Learning systems; Logistic regression; Modeling languages; Social networking (online); Speech recognition; Transfer learning; BERT; Data augmentation; Fine tuning; GPT-3; Hate speech detection; Language model; Large language modeling; Nature language process; Social media; Speech detection; Transfer learning; Natural language processing systems},
	correspondence_address = {J. Liu; Johns-Hopkins University, Baltimore, 21218, United States; email: jliu306@jh.com},
	editor = {Jin H. and Pan Y. and Lu J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-981971276-2},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Aygün2023652,
	author = {Aygün, İrfan and Kaya, Mehmet},
	title = {Use of Large Language Models for Medical Synthetic Data Generation in Mental Illness},
	year = {2023},
	journal = {IET Conference Proceedings},
	volume = {2023},
	number = {44},
	pages = {652 – 656},
	doi = {10.1049/icp.2024.1033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194232069&doi=10.1049%2ficp.2024.1033&partnerID=40&md5=c85063d45d7d81e152760821dfbbd97c},
	affiliations = {Department of Software Engineering, Celal Bayar University, Manisa, Turkey; Department of Computer Engineering, Fırat University, Elazığ, Turkey},
	abstract = {Data quantity and quality are very important for the development of medical artificial intelligence research. Nowadays, thanks to easier access to data, studies in this field produce very successful results. However, many factors such as protection of patient rights in medical data and confidentiality of personal data prevent researchers from directly accessing the data. For this reason, synthetic data creation studies are often needed both to expand the training and test sets and to create sample cases to be used in the relevant field. In this study, various synthetic patient data are created to be presented to a language model that enables the detection of psychological disorders through patient text. Synthetic data sets were produced with 200 artificial patient data created with popular LLM examples ChatGPT and Google Bard. The quality of synthetic data was measured with the help of a pre-trained BERT model using these datasets. In the experiments, it was observed that chatbots that generate instant data, such as ChatGPT and Google Bard, produced successful results at rates of 89% and 86% with the language representation model. With the experimental results, it appears that LLM studies can provide more successful results than advanced language models in various medical text production tasks. © The Institution of Engineering & Technology 2023.},
	author_keywords = {ChatGPT; Deep Learning; Google Bard; Large Language Models; Mental Illness},
	keywords = {Computational linguistics; Deep learning; Diseases; ChatGPT; Deep learning; Google bard; Google+; Language model; Large language model; Mental illness; Patient data; Synthetic data; Synthetic data generations; Hospital data processing},
	correspondence_address = {İ. Aygün; Department of Software Engineering, Celal Bayar University, Manisa, Turkey; email: irfan.aygun@cbu.edu.tr},
	publisher = {Institution of Engineering and Technology},
	issn = {27324494},
	language = {English},
	abbrev_source_title = {IET. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Alghamdi2024534,
	author = {Alghamdi, Abdulaziz and Mohaisen, David},
	title = {Through the Looking Glass: LLM-Based Analysis of AR/VR Android Applications Privacy Policies},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Machine Learning and Applications, ICMLA 2024},
	pages = {534 – 539},
	doi = {10.1109/ICMLA61862.2024.00078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001037517&doi=10.1109%2fICMLA61862.2024.00078&partnerID=40&md5=2c74556202beb545a48218961e5b4163},
	affiliations = {University of Central Florida, United States},
	abstract = {This paper comprehensively analyzes privacy policies in AR/VR applications, leveraging BERT, a state-of-the-art text classification model, to evaluate the clarity and thoroughness of these policies. By comparing the privacy policies of AR/VR applications with those of free and premium websites, this study provides a broad perspective on the current state of privacy practices within the AR/VR industry. Our findings indicate that AR/VR applications generally offer a higher percentage of positive segments than free content but lower than premium websites. The analysis of highlighted segments and words revealed that AR/VR applications strategically emphasize critical privacy practices and key terms. This enhances privacy policies' clarity and effectiveness.  © 2024 IEEE.},
	author_keywords = {AR; BERT; Machine Learning; Privacy Policy; VR},
	keywords = {Android applications; AR; BERT; Machine-learning; Privacy policies; Privacy practices; State of the art; Text classification models; VR; VR applications; Differential privacy},
	editor = {Wani M.A. and Angelov P. and Luo F. and Ogihara M. and Wu X. and Precup R.-E. and Ramezani R. and Gu X.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037488-9},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Mach. Learn. Appl., ICMLA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Ouyang202459,
	author = {Ouyang, Kun and Liu, Yi and Li, Shicheng and Bao, Ruihan and Harimoto, Keiko and Sun, Xu},
	title = {Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from Monetary Policy Conference Calls with LLM},
	year = {2024},
	journal = {Joint Workshop of the 7th Financial Technology and Natural Language Processing, the 5th Knowledge Discovery from Unstructured Data in Financial Services and the 4th Economics and Natural Language Processing, FinNLP-KDF-ECONLP 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {59 – 69},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195171155&partnerID=40&md5=610632a69ec50934629c3a1b20fd748c},
	affiliations = {National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University, China; Mizuho Securities Co., Ltd., Japan},
	abstract = {Financial prediction from Monetary Policy Conference (MPC) calls is a new yet challenging task, which targets at predicting the price movement and volatility for specific financial assets by analyzing multimodal information including text, video, and audio. Although the existing work has achieved great success using cross-modal transformer blocks, it overlooks the potential external financial knowledge, the varying contributions of different modalities to financial prediction, as well as the innate relations among different financial assets. To tackle these limitations, we propose a novel Modal-Adaptive kNowledge-enhAnced Graph-basEd financial pRediction scheme, named MANAGER. Specifically, MANAGER resorts to FinDKG to obtain the external related knowledge for the input text. Meanwhile, MANAGER adopts BEiT-3 and Hidden-unit BERT (HuBERT) to extract the video and audio features, respectively. Thereafter, MANAGER introduces a novel knowledge-enhanced cross-modal graph that fully characterizes the semantic relations among text, external knowledge, video and audio, to adaptively utilize the information in different modalities, with ChatGLM2 as the backbone. Extensive experiments on a publicly available dataset Monopoly verify the superiority of our model over cutting-edge methods. © 2024 ELRA Language Resource Association.},
	author_keywords = {Financial Prediction; LLM; Multimodal Learning},
	keywords = {Finance; Forecasting; Graphic methods; Semantics; Cross-modal; Financial assets; Financial prediction; Graph-based; LLM; Monetary policies; Multi-modal information; Multi-modal learning; Price movement; Price volatility; Teleconferencing},
	correspondence_address = {R. Bao; Mizuho Securities Co., Ltd., Japan; email: ruihan.bao@mizuho-sc.com; X. Sun; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University, China; email: xusun@pku.edu.cn},
	editor = {Chen C.-C. and Ma Z. and Hahn U.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381419-7},
	language = {English},
	abbrev_source_title = {Jt. Workshop Financ. Technol. Nat. Lang. Process., Knowl. Discov.  from Unstructured Data Financ. Serv. Econ. Nat. Lang. Process., FinNLP-KDF-ECONLP LREC-COLING - Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hillebrand2023,
	author = {Hillebrand, Lars and Berger, Armin and Deußer, Tobias and Dilmaghani, Tim and Khaled, Mohamed and Kliem, Bernd and Loitz, Rüdiger and Pielka, Maren and Leonhard, David and Bauckhage, Christian and Sifa, Rafet},
	title = {Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models},
	year = {2023},
	journal = {DocEng 2023 - Proceedings of the 2023 ACM Symposium on Document Engineering},
	doi = {10.1145/3573128.3609344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173560745&doi=10.1145%2f3573128.3609344&partnerID=40&md5=a28a51e40f7582a448e015c8dcf64c0a},
	affiliations = {Fraunhofer Iais, Sankt Augustin, Germany; PricewaterhouseCoopers GmbH, Düsseldorf, Germany},
	abstract = {Auditing financial documents is a very tedious and time-consuming process. As of today, it can already be simplified by employing AI-based solutions to recommend relevant text passages from a report for each legal requirement of rigorous accounting standards. However, these methods need to be fine-tuned regularly, and they require abundant annotated data, which is often lacking in industrial environments. Hence, we present ZeroShotALI, a novel recommender system that leverages a state-of-the-art large language model (LLM) in conjunction with a domain-specifically optimized transformer-based text-matching solution. We find that a two-step approach of first retrieving a number of best matching document sections per legal requirement with a custom BERT-based model and second filtering these selections using an LLM yields significant performance improvements over existing approaches.  © 2023 Owner/Author.},
	author_keywords = {Large Language Models; Recommender System; Text Matching},
	keywords = {Computational linguistics; Information retrieval systems; Zero-shot learning; Accounting standards; Best matching; Industrial environments; Language model; Large language model; Legal requirements; Model yields; State of the art; Text-matching; Two-step approach; Recommender systems},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070027-9},
	language = {English},
	abbrev_source_title = {DocEng - Proc. ACM Symp. Doc. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Amato2024,
	author = {Amato, Natale and De Carolis, Berardina and de Gioia, Francesco and Venezia, Mario Nicola and Palestra, Giuseppe and Loglisci, Corrado},
	title = {Can an AI-driven VTuber engage People? The KawAIi Case Study},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3660},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190754935&partnerID=40&md5=bd76d56b13e328027aa1b458849cf73f},
	affiliations = {Department of Computer Science, University of Bari "A. Moro", Bari, Italy},
	abstract = {Live streaming has become increasingly popular, with most streamers presenting their real-life appearance. However, Virtual YouTubers (VTubers), virtual 2D or 3D avatars that are voiced by humans, are emerging as live streamers and attracting a growing viewership. This paper presents the development of a conversational agent, named KawAIi, embodied in a 2D character that, while accurately and promptly responding to user requests, provides an entertaining experience in streaming chat platforms such as YouTube while providing adequate real-time support. The agent relies on the Vicuna 7B GPTQ 4-bit Large Language Model (LLM). In addition, KawAIi uses a BERT-based model for analyzing the sentence generated by the model in terms of conveyed emotion and shows self-emotion awareness through facial expressions. Tested with users, the system has demonstrated a good ability to handle the interaction with the user while maintaining a pleasant user experience. In particular, KawAIi has been evaluated positively in terms of engagement and competence on various topics. The results show the potential of this technology to enrich interactivity in streaming platforms and offer a promising model for future online assistance contexts. © 2024 Copyright for this paper by its authors.},
	author_keywords = {live streaming; LLMs; virtual agent},
	keywords = {Virtual reality; 3D Avatars; Case-studies; Conversational agents; Facial Expressions; Language model; Live streaming; LLM; Real- time; Virtual agent; YouTube; Three dimensional computer graphics},
	correspondence_address = {B. De Carolis; Department of Computer Science, University of Bari "A. Moro", Bari, Italy; email: berardina.decarolis@uniba.it},
	editor = {Soto A. and Zangerle E.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Mboma2024,
	author = {Mboma, Jean Gilbert Mbula and Lusala, Kuti and Matalatala, Michel and Tshipata, Obed Tshimanga and Nzakuna, Pierre Sedi and Kazumba, Dave Tshimbalanga},
	title = {Integrating LLM with Blockchain and IPFS to Enhance Academic Diploma Integrity},
	year = {2024},
	journal = {International Conference on Artificial Intelligence, Computer, Data Sciences, and Applications, ACDSA 2024},
	doi = {10.1109/ACDSA59508.2024.10467706},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189930162&doi=10.1109%2fACDSA59508.2024.10467706&partnerID=40&md5=f5272f352e5d8f411d836ed336e01125},
	affiliations = {Université de Kinshasa (UNIKIN), Génie Electrique et Informatique, Kinshasa, Democratic Republic Congo},
	abstract = {This paper presents an innovative solution to counter academic document fraud. It consists in combining a Large Language Model (LLM), specifically the Bidirectional Encoder Representations from Transformers (BERT), with blockchain and Interplanetary File System (IPFS) to pre-validate academic documents before their certification. This approach addresses the vulnerabilities inherent in current systems, particularly the over-reliance on the trustworthiness of system users issuing documents. The results demonstrate that our approach outperforms simple IPFS-blockchain-based solutions in detecting document alterations. We achieved an accuracy of 99.3% with a slight increase of 1 second in latency per document. Although the study has been carried out with high school diplomas delivered in the Democratic Republic of the Congo (DRC), the proposed solution has broad applicability. It can be globally adapted for various academic document verification purposes. © 2024 IEEE.},
	author_keywords = {Artificial Intelligence; Blockchain; Documents authentication; Fraud Detection; Large Language models},
	keywords = {Computational linguistics; Crime; Block-chain; Current system; Document authentication; Filesystem; Fraud detection; Innovative solutions; Language model; Large language model; Over reliance; Simple++; Blockchain},
	correspondence_address = {J.G.M. Mboma; Université de Kinshasa (UNIKIN), Génie Electrique et Informatique, Kinshasa, Democratic Republic Congo; email: mbula.gilberto01@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039452-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Artif. Intell., Comput., Data Sci., Appl., ACDSA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Verma2024,
	author = {Verma, Amitasha Anand and Kurupudi, Deshik and Sathyalakshmi, S.},
	title = {BlogGen- A Blog Generation Application Using Llama-2},
	year = {2024},
	journal = {2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems, ADICS 2024},
	doi = {10.1109/ADICS58448.2024.10533489},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195180800&doi=10.1109%2fADICS58448.2024.10533489&partnerID=40&md5=baabe02555302dc5695912f2460a3e48},
	affiliations = {Hindustan Institute Of Technology And Science, Dept.of Computer Science And Engineering, Chennai, India},
	abstract = {In recent years, Large Language Models (LLMs) have emerged as transformative tools in natural language processing (NLP) and artificial intelligence (AI) research.LLMs excel in generating coherent and contextually relevant text across a wide range of applications one such segment focusing on content generation for websites, blogs and creative writing platforms. In such cases,with an open-source LLM like Llama-2, any person or business can use it for their means without having to pay licensing fees. This includes deploying the LLM to their own infrastructure and fine-tuning it to fit their own needs eliminating the exposure of data to third party interfaces, also making it task specific. This paper introduces a unique model to generate customised blogs by fine-tuning Llama-2 model and perform a comparison with GPT-3.5 and BERT.  © 2024 IEEE.},
	author_keywords = {Artificial Intelligence; BERT; fine-tuning; GPT; Large language model; LlaMa; Natural Language Processing; Open source},
	keywords = {Artificial intelligence; Computational linguistics; Natural language processing systems; BERT; Fine tuning; GPT; Language model; Language processing; Large language model; Llama; Natural language processing; Natural languages; Open-source; Blogs},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036482-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Data Eng. Intell. Comput. Syst., ADICS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Simonds202475,
	author = {Simonds, Toby and Kurniawan, Kemal and Lau, Jey Han},
	title = {MoDEM: Mixture of Domain Expert Models},
	year = {2024},
	journal = {ALTA 2024 - Proceedings of the 22nd Annual Workshop of the Australasian Language Technology Association},
	pages = {75 – 88},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000151884&partnerID=40&md5=4dcc7df1f93e70ec4d22353b89d09076},
	affiliations = {The University of Melbourne, Australia},
	abstract = {We propose a novel approach to enhancing the performance and efficiency of large language models (LLMs) by combining domain prompt routing with domain-specialized models. We introduce a system that utilizes a BERT-based router to direct incoming prompts to the most appropriate domain expert model. These expert models are specifically tuned for domains such as health, mathematics and science. Our research demonstrates that this approach can significantly outperform general-purpose models of comparable size, leading to a superior performance-to-cost ratio across various benchmarks. The implications of this study suggest a potential shift in LLM development and deployment. Rather than focusing solely on creating increasingly large, general-purpose models, the future of AI may lie in developing ecosystems of smaller, highly specialized models coupled with sophisticated routing systems. This approach could lead to more efficient resource utilization, reduced computational costs, and superior overall performance. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Domain Knowledge; Expert systems; Cost ratio; Domain experts; Expert modeling; Language model; Model development; Performance; Potential shift; Resources utilizations; Routing system; Routings; Computational linguistics},
	editor = {Baldwin T. and Baldwin T. and Mendez S.J.R. and Kuo N.},
	publisher = {Association for Computational Linguistics (ACL)},
	language = {English},
	abbrev_source_title = {ALTA - Proc. Annu. Workshop Australas. Lang. Technol. Assoc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tikayat Ray2023,
	author = {Tikayat Ray, Archana and Bhat, Anirudh Prabhakara and White, Ryan T. and Nguyen, Van Minh and Pinon Fischer, Olivia J. and Mavris, Dimitri N.},
	title = {Examining the Potential of Generative Language Models for Aviation Safety Analysis: Case Study and Insights Using the Aviation Safety Reporting System (ASRS)},
	year = {2023},
	journal = {Aerospace},
	volume = {10},
	number = {9},
	doi = {10.3390/aerospace10090770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172146359&doi=10.3390%2faerospace10090770&partnerID=40&md5=26f4d35cbdc8683c3552fe4d1a514ba4},
	affiliations = {Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States; AI Fusion Technologies, Toronto, M5V 3Z5, ON, Canada; NEural TransmissionS Lab, Department of Mathematics and Systems Engineering, Florida Institute of Technology, Melbourne, 32901, FL, United States},
	abstract = {This research investigates the potential application of generative language models, especially ChatGPT, in aviation safety analysis as a means to enhance the efficiency of safety analyses and accelerate the time it takes to process incident reports. In particular, ChatGPT was leveraged to generate incident synopses from narratives, which were subsequently compared with ground-truth synopses from the Aviation Safety Reporting System (ASRS) dataset. The comparison was facilitated by using embeddings from Large Language Models (LLMs), with aeroBERT demonstrating the highest similarity due to its aerospace-specific fine-tuning. A positive correlation was observed between the synopsis length and its cosine similarity. In a subsequent phase, human factors issues involved in incidents, as identified by ChatGPT, were compared to human factors issues identified by safety analysts. The precision was found to be 0.61, with ChatGPT demonstrating a cautious approach toward attributing human factors issues. Finally, the model was utilized to execute an evaluation of accountability. As no dedicated ground-truth column existed for this task, a manual evaluation was conducted to compare the quality of outputs provided by ChatGPT to the ground truths provided by safety analysts. This study discusses the advantages and pitfalls of generative language models in the context of aviation safety analysis and proposes a human-in-the-loop system to ensure responsible and effective utilization of such models, leading to continuous improvement and fostering a collaborative approach in the aviation safety domain. © 2023 by the authors.},
	author_keywords = {aeroBERT; ASRS; aviation safety; Aviation Safety Reporting System; BERT; ChatGPT; generative language models; GPT-3.5; human factors; InstructGPT; large language models; LLM; NLP; prompt engineering},
	correspondence_address = {A. Tikayat Ray; Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, United States; email: archanatikayatray@gmail.com; O.J. Pinon Fischer; Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, United States; email: olivia.pinon@asdl.gatech.edu},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22264310},
	language = {English},
	abbrev_source_title = {Aerosp.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ishtiaq202455905,
	author = {Ishtiaq, Areeba and Munir, Kashif and Raza, Ali and Samee, Nagwan Abdel and Jamjoom, Mona M. and Ullah, Zahid},
	title = {Product Helpfulness Detection With Novel Transformer Based BERT Embedding and Class Probability Features},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {55905 – 55917},
	doi = {10.1109/ACCESS.2024.3390605},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190725156&doi=10.1109%2fACCESS.2024.3390605&partnerID=40&md5=48bc09f0cc85f53e5dae6bebb0c8f33b},
	affiliations = {Institute of Information Technology, Khwaja Fareed University of Engineering and Information Technology, Rahim Yar Khan, 64200, Pakistan; The University of Lahore, Department of Software Engineering, Lahore, 54000, Pakistan; Princess Nourah bint Abdulrahman University, College of Computer and Information Sciences, Department of Information Technology, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Princess Nourah bint Abdulrahman University, College of Computer and Information Sciences, Department of Computer Sciences, Riyadh, 11671, Saudi Arabia; King Abdulaziz University, Department of Information System, Jeddah, 21589, Saudi Arabia},
	abstract = {Nowadays global market products are readily accessible worldwide, and a vast array of reviews across numerous platforms are posted daily in several categories, making it challenging for customers to stay informed about their product interests. To make informed decisions regarding product quality, users require access to reviews and ratings. Owners and managers must analyze customer ratings and the underlying emotional content of reviews to enhance the product's quality, cost, customer service, and environmental impact. The primary aim of our proposed research is to accurately predict product helpfulness through customer reviews using the Large Language Model (LLM), thereby assisting customers in saving time and money. We employed a benchmark dataset, the Amazon Fine Food Reviews, to develop numerous advanced machine-learning techniques. We introduced a novel transformer approach BERF (BERT Random Forest) for feature engineering to enhance the value of user evaluations for Amazon's gourmet food products. The BERF method utilizes BERT embeddings and class probability features derived from product helpfulness online reviews textual data. We have balanced the dataset using the Synthetic Minority Over-sampling TEchnique (SMOTE) approach. Our comprehensive study results demonstrated that the Light Gradient Boosting Machine (LGBM) strategy outperformed existing state-of-the-art approaches, achieving an accuracy of 98%. The performance of each method is confirmed using a k-fold method and further improved through hyperparameter optimization. Our innovative study employing a transformer model has significantly enhanced the utility of customer reviews, substantially reducing online product scams and preventing wasted time and money.  © 2013 IEEE.},
	author_keywords = {BERT; deep learning; large language model (LLM); machine learning; Product helpfulness; text mining; transformer},
	keywords = {Data mining; Deep learning; Environmental impact; Feature extraction; Food products; International trade; Learning systems; Sales; Adaptation models; BERT; Deep learning; Features extraction; Language model; Large language model; Machine-learning; Product helpfulness; Sentiment analysis; Social networking (online); Text-mining; Transformer; Sentiment analysis},
	correspondence_address = {K. Munir; Institute of Information Technology, Khwaja Fareed University of Engineering and Information Technology, Rahim Yar Khan, 64200, Pakistan; email: kashif.munir@kfueit.edu.pk; N.A. Samee; Princess Nourah bint Abdulrahman University, College of Computer and Information Sciences, Department of Information Technology, Riyadh, P.O. Box 84428, 11671, Saudi Arabia; email: nmabdelsamee@pnu.edu.sa},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Firoz2024928,
	author = {Firoz, Neda and Berestneva, Olga and Aksyonov, Sergey V.},
	title = {Dual Layer Cogni - Insight Deep-Mood Encoder: A Two- Tiered Approach for Depression Detection},
	year = {2024},
	journal = {Proceedings - 2024 International Russian Smart Industry Conference, SmartIndustryCon 2024},
	pages = {928 – 937},
	doi = {10.1109/SmartIndustryCon61328.2024.10516113},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193237661&doi=10.1109%2fSmartIndustryCon61328.2024.10516113&partnerID=40&md5=43b42b6f08c99d64a0f3b59bddb3eb8f},
	affiliations = {Institute of Applied Mathematics and Computer Science, Tomsk State University, Tomsk, Russian Federation},
	abstract = {Depression (MDD) affects approximately 5% of adults globally, contributing to productivity loss and public health concerns. With 280 million people impacted, the risk of suicide and self-harm underscores its severity. Current treatments are inadequate, and the complex, heterogeneous nature of depression necessitates automated solutions for timely assessment and varied treatments. This study explores the transformative role of Artificial Intelligence in detecting depressive symptoms, leveraging NLP, and multimodal data analysis. The research introduces the 'Dual Layer Cogni-Insight Deep-Mood Encoder (DLCDME)' model, incorporating two-tiered feature encodings. Four pre-trained language models (BERT, MentalBERT, MentalRoBERTa, PsychBERT, and ClinicalBERT) are experimented and fused with linguistic features for comprehensive representation. A transformer encoder, multi-head attention, and LSTM fine-tuning enhances contextual text feature embeddings, demonstrating the efficacy of ClinicalBERT with transformer encoders for cost-effective large corpus handling. Contributions include a novel feature extraction approach, a thorough model analysis, and the superior performance of DLCDME over contemporary works, holding promise for clinical diagnosis. Our findings reveal that a) the application of ClinicalBERT over DLCDME significantly enhances the performance of depression detection, and b) employing dual feature encodings on text data with transformer attention for predicting depression yields an improved MAE of 3.40 and RMSE of 4.38. The model achieved a test accuracy of 95%, with F1 scores for precision, and recall recorded at 0.95, 0.96, 0.95 respectively. © 2024 IEEE.},
	author_keywords = {computational paralinguistics; depression; linguistic feature fusion; LLMs; LSTM; Transformer Encoders},
	keywords = {Cost effectiveness; Diagnosis; Electric transformer testing; Encoding (symbols); Linguistics; Long short-term memory; Signal encoding; Computational paralinguistic; Depression; Dual-layers; Features fusions; Linguistic feature fusion; Linguistic features; LLM; LSTM; Paralinguistic; Transformer encoder; Feature extraction},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039504-4},
	language = {English},
	abbrev_source_title = {Proc. - Int. Russian Smart Ind. Conf., SmartIndustryCon},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hung202411,
	author = {Hung, Shing-Li and Chen, Chung-Kuan and Furumoto, Keisuke and Takahashi, Takeshi and Sun, Hung-Min},
	title = {Dark Watchdog: A Novel RAG-Driven System for Real-Time Detection and Analysis of Data Leaks on Dark Web Forums},
	year = {2024},
	journal = {Proceeding - 2024 Annual Computer Security Applications Conference Workshops, ACSACW 2024},
	pages = {11 – 19},
	doi = {10.1109/ACSACW65225.2024.00010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001673159&doi=10.1109%2fACSACW65225.2024.00010&partnerID=40&md5=6afede71ea43fcd46bdee89f7c22fa30},
	affiliations = {National Tsing Hua University, Institue of Information Security, Hsinchu, Taiwan; CyCraft Technology CyCraft Technology, Taiwan; National Institute of Information and Communications Technology, Cybersecurity Research Institute, Tokyo, Japan; National Tsing Hua University, Departmant of Computer Science, Hsinchu, Taiwan},
	abstract = {Personal data breaches have become increasingly common, making the dark web a key marketplace for trading stolen information, often without the immediate awareness of affected organizations. To address this challenge, we introduce Dark Watchdog, a novel system that actively monitors dark web forums and employs a specially fine-Tuned BERT classification model to categorize transaction posts into five distinct types of breaches with high accuracy. Dark Watchdog uniquely integrates retrieval-Augmented generation (RAG) to efficiently vectorize and analyze dark web data, allowing cyber security analysts to access the latest intelligence on data leaks while preserving privacy by minimizing data exposure to large language models (LLMs). This approach not only improves detection precision but also optimizes computational resources by reducing token usage. Dark Watchdog offers an innovative and practical solution for real-Time dark web monitoring, enabling timely insights into ongoing data leak incidents and enhancing the overall effectiveness of cyber security efforts.  © 2024 IEEE.},
	author_keywords = {BERT; Classification; cyber security; Dark web; Large language model; LLM; Privacy; RAG; Retrieval-Augmented generation; Tor},
	keywords = {Cyber attacks; Data privacy; Differential privacy; Network security; BERT; Cyber security; Dark web; Language model; Large language model; Privacy; Retrieval-augmented generation; Tor; Information leakage},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833153281-9},
	language = {English},
	abbrev_source_title = {Proceeding - Annu. Comput. Secur. Appl. Conf. Workshops, ACSACW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hasan20242215,
	author = {Hasan, Md Rakibul and Hossain, Md Zakir and Gedeon, Tom and Rahman, Shafin},
	title = {LLM-GEm: Large Language Model-Guided Prediction of People’s Empathy Levels towards Newspaper Article},
	year = {2024},
	journal = {EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2024},
	pages = {2215 – 2231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188752149&partnerID=40&md5=a30bfec1c7637e9099f7a66a21880307},
	affiliations = {Curtin University, Perth, 6102, WA, Australia; North South University, Dhaka, 1229, Bangladesh},
	abstract = {Empathy – encompassing the understanding and supporting others’ emotions and perspectives – strengthens various social interactions, including written communication in healthcare, education and journalism. Detecting empathy using AI models by relying on self-assessed ground truth through crowdsourcing is challenging due to the inherent noise in such annotations. To this end, we propose a novel system, named Large Language Model-Guided Empathy (LLM-GEm) prediction system. It rectifies annotation errors based on our defined annotation selection threshold and makes the annotations reliable for conventional empathy prediction models, e.g., BERT-based pretrained language models (PLMs). Previously, demographic information was often integrated numerically into empathy detection models. In contrast, our LLM-GEm leverages GPT-3.5 LLM to convert numerical data into semantically meaningful textual sequences, enabling seamless integration into PLMs. We experiment with three NewsEmpathy datasets involving people’s empathy levels towards newspaper articles and achieve state-of-the-art test performance using a RoBERTa-based PLM. Code and evaluations are publicly available at https://github.com/hasan-rakibul/LLM-GEm. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Data handling; Newsprint; Annotation errors; Demographic information; Ground truth; Health care education; Inherent noise; Language model; Prediction modelling; Prediction systems; Social interactions; Written communications; Forecasting},
	editor = {Graham Y. and Purver M. and Purver M.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176093-6},
	language = {English},
	abbrev_source_title = {EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Find. EACL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Akomeah202426,
	author = {Akomeah, Kwabena Odame and Kruschwitz, Udo and Ludwig, Bernd},
	title = {Team Quabynar at the GermEval 2024 Shared Task 1 GerMS-Detect (Subtasks 1 and 2) on Sexism Detection},
	year = {2024},
	journal = {GerMS-Detect 2024 - Proceedings of the KONVENS 2024 - GermEval 2024 Task 1 GerMS-Detect Workshop on Sexism Detection in German Online News Fora},
	pages = {26 – 32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000825594&partnerID=40&md5=bb2cf217a7e75489473f14fd623ef71d},
	affiliations = {University of Regensburg, Germany},
	abstract = {While large language models such as Chat-GPT and GPT-3.5 Turbo offer impressive capabilities, their use can be costly and may not always be advisable, particularly for specific types of tasks. As part of our involvement in the GerMS-Detect challenge we observe that traditional, more cost-effective language models such as BERT are able to achieve better results than GPT-3.5 Turbo, a very robust LLM, when applied to sexist text classification. This suggests that for certain types of tasks and contexts, using BERT models may be a plausible alternative to state-of-the-art LLMs. This paper hightlights our approach to predicting annotator binary and soft labels using transformer models and an LLM in GermEval 2024 GerMS-Detect’s open and closed subtasks of sexism detection. © 2024 GermEval. All Rights Reserved.},
	keywords = {Binary labels; Cost effective; Language model; Soft labels; State of the art; Subtask; Text classification; Transformer modeling; Classification (of information)},
	editor = {Gross S. and Petrak J. and Venhoff L. and Krenn B.},
	publisher = {Association for Computational Linguistics (ACL)},
	language = {English},
	abbrev_source_title = {GerMS-Detect - Proc. KONVENS - GermEval Task 1 GerMS-Detect Workshop Sexism Detect. German Online News Fora},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Diaf20241239,
	author = {Diaf, Alaeddine and Korba, Abdelaziz Amara and Elislem Karabadji, Nour and Ghamri-Doudane, Yacine},
	title = {BARTPredict: Empowering IoT Security with LLM-Driven Cyber Threat Prediction},
	year = {2024},
	journal = {Proceedings - IEEE Global Communications Conference, GLOBECOM},
	pages = {1239 – 1244},
	doi = {10.1109/GLOBECOM52923.2024.10901770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000824021&doi=10.1109%2fGLOBECOM52923.2024.10901770&partnerID=40&md5=70408761f52afa12ae079dd65da6cab5},
	affiliations = {Badji Mokhtar-Annaba University, Laboratoire Reseaux et Systemes (LRS), Faculty of Technology, Algeria; University of La Rochelle, L3I, France; National Higher School of Technology and Engineering, Annaba, Algeria; Laboratoire De Technologies Des Systemes Energetiques (LTSE), E3360100, Annaba, Algeria},
	abstract = {The integration of Internet of Things (IoT) technology in various domains has led to operational advancements, but it has also introduced new vulnerabilities to cybersecurity threats, as evidenced by recent widespread cyberattacks on IoT devices. Intrusion detection systems are often reactive, triggered by specific patterns or anomalies observed within the network. To address this challenge, this work proposes a proactive approach to anticipate and preemptively mitigate malicious activities, aiming to prevent potential damage before it occurs. This paper proposes an innovative intrusion prediction framework empowered by Pre-trained Large Language Models (LLMs). The framework incorporates two LLMs: a fine-tuned Bidirectional and Auto-Regressive Transformers (BART) model for predicting network traffic and a fine-tuned Bidirectional Encoder Representations from Transformers (BERT) model for evaluating the predicted traffic. By harnessing the bidirectional capabilities of BART the framework then identifies malicious packets among these predictions. Evaluated using the CICIoT2023 IoT attack dataset, our framework showcases a notable enhancement in predictive performance, attaining an impressive 98% overall accuracy, providing a powerful response to the cybersecurity challenges that confront IoT networks. © 2024 IEEE.},
	author_keywords = {BART; BERT; Internet of Things (IoT); Intrusion Prediction; Large Language Models; Security; Transformers},
	keywords = {Cyber attacks; Distribution transformers; Intrusion detection; Modeling languages; Prediction models; Auto-regressive; Bidirectional and auto-regressive transformer; Bidirectional encoder representation from transformer; Cyber security; Internet of thing; Intrusion prediction; Language model; Large language model; Security; Transformer; Network intrusion},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {23340983},
	isbn = {979-835035125-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Glob. Commun. Conf., GLOBECOM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Sarkar2024,
	author = {Sarkar, Sneha and Kushwaha, Suresh Prasad and Sharma, Vandana and Mishra, Nilamadhab and Alkhayyat, Ahmed},
	title = {A Novel LLM enabled Code Snippet Generation Framework},
	year = {2024},
	journal = {International Conference on Intelligent and Innovative Practices in Engineering and Management 2024, IIPEM 2024},
	doi = {10.1109/IIPEM62726.2024.10925748},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001923777&doi=10.1109%2fIIPEM62726.2024.10925748&partnerID=40&md5=51a01eac874ed2ba9da5791502a644c4},
	affiliations = {Deemed to Be University, Kalinga Institute of Industrial Technology, Odisha, Bhuabneswar, India; CHRIST University, Computer Science Department, Bengaluru, India; VIT Bhopal University, Madhya Pradesh, Sehore, India; The Islamic University, College of Technical Engineering, Najaf, Iraq},
	abstract = {Large Language Models (LLMs) represent a breakthrough in natural language processing (NLP), leveraging deep learning techniques to achieve exceptional proficiency in code generation, analysis and modification of human languages. These models, characterized by their vast scale and parameter count, like Bidirectional Encoder Representations from Transformers (BERT by Google) and the Generative Pre-trained Transformer series (by OpenAI's GPT), have revolutionized various applications including text generation, translation, summarization, and question answering. In our paper we investigate the practicality,complications, and significance of using LLMs for code generation. We provide a review analysis of existing LLM models in use and compare their proficiency for code generation. This paper examines the underlying mechanisms of LLMs, specially their ability to grasp the code syntax, semantics, and programming logic from large-scale repositories and their documentations. The models' training techniques include fine-tuning programming-specific datasets and enhancing the models' competency to generate code snippets that are syntactically correct and contextually relevant. © 2024 IEEE.},
	author_keywords = {Code Generation; Code Quality; Large Language Models (LLMs); Natural Language Processing (NLP); Software Development},
	keywords = {Character sets; Computer aided language translation; Computer software selection and evaluation; Deep learning; Natural language processing systems; Program translators; Syntactics; Code modifications; Code quality; Codegeneration; Language model; Language processing; Large language model; Learning techniques; Natural language processing; Natural languages; Snippet generation; Semantics},
	correspondence_address = {S. Sarkar; Deemed to Be University, Kalinga Institute of Industrial Technology, Bhuabneswar, Odisha, India; email: 2206053@kiit.ac.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039004-9},
	language = {English},
	abbrev_source_title = {Int. Conf. Intell. Innov. Pract. Eng. Manag., IIPEM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {6th International Conference on Quantitative Ethnography, ICQE 2024},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2278 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002090811&partnerID=40&md5=187f87bbe0b90acb5b71b9788ae6a340},
	abstract = {The proceedings contain 41 papers. The special focus in this conference is on Quantitative Ethnography. The topics include: Bayesian Graph Neural Networks Modeling for Naturally Arisen Leadership; perfect Sampling; computer-Supported Code Discovery Utilizing Topic Modeling and Stepwise Coding; critical Reviews with Quantitative Ethnography: Theory Use in Literature on Quantified Group Work in Educational Settings; assessing the Potential and Limits of Large Language Models in Qualitative Coding; Closing the Interpretive Loop with BERT, Our Neural Topic Modeling Friend; making Sense of the Model: Interpreting Epistemic Networks and Their Projection Space; Using LLM-Based Filtering to Develop Reliable Coding Schemes for Rare Debugging Strategies; Development of ENA 3D: A Tool for Epistemic Network Analysis in Three-Dimensional Space; Exploring Variance: Seeking Nuanced Stories Within ENA; Shifting Paradigms: Trends in Quantitative Ethnography Research at ICQE; analyzing Nursing Assistant Attitudes Towards Geriatric Caregiving Using Epistemic Network Analysis; exploring Students’ Changing Conceptions About eLearning Leadership; learning from Student Mistakes: Using Epistemic Network Analysis of Students’ Knowledge of Fractions, Ratios and Percentages to Drive Middle School Instruction; studying the Interplay of Self-regulated Learning Cycles and Scaffolding Through Ordered Network Analysis Across Three Tutoring Systems; text-Based vs Audio-Based: What Differential Effects Do the Two Discussion Formats have on Scientific Reasoning?.},
	editor = {Kim Y.J. and Swiecki Z.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303176334-2},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Oh2024,
	author = {Oh, Sunggyeol and Cao, Yi and Katz, Andrew and Zhao, Jialu},
	title = {Explore Public's Perspectives on Generative AI in Computer Science (CS) Education: A Social Media Data Analysis},
	year = {2024},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	doi = {10.1109/FIE61694.2024.10893102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000783691&doi=10.1109%2fFIE61694.2024.10893102&partnerID=40&md5=9d83592b60a75fc2ccfebad37b9d4f6a},
	affiliations = {Virginia Tech, Department of Computer Science, Blacksburg, VA, United States; Virginia Tech, Department of Engineering Education, Blacksburg, VA, United States; Stanford Graduate School of Education, Stanford University, Stanford, CA, United States},
	abstract = {This research-to-practice full paper aims to analyze the public's comments on generative artificial intelligence (GAI) in computer science (CS) education, by the BERT-based model and Large Language Model (LLM) approaches to sentiment analysis and contextualize the results within broader educational and technological landscapes. Artificial intelligence (AI) has played a crucial role in advancing technical development throughout many areas. Evidence points toward the likelihood of major developmental breakthroughs unfolding soon in those sectors. Education is one such area. While there is certainly a possibility for hype and unfulfilled promises, the advent of available GAI platforms, such as ChatGPT, has caused a surge of scholarly interest in the impact of these technologies on CS education. Amid the growing debate, both the potential benefits and concerns of GAI in this sector are increasingly coming to the fore as people grapple with the tradeoffs associated with these technologies when applied in education settings. One can imagine the range of conversations around the topic, but that is difficult to use as input for policymakers and administrators without a more concrete understanding. To wit, there remain open questions about which benefits and concerns people tend to focus on when discussing GAI in education. This large-scale qualitative study addresses that gap by exploring the public's perspectives on GAI in CS education. We engage in this work by collecting and analyzing data from social media platforms, specifically Reddit comments. The social media dataset was analyzed using machine learning (ML) techniques to identify topics based on sentiment analysis. The study's objective was to document and characterize the public's perspectives concerning the general characteristics of GAI, its features related to learning, and its usability in educational settings. Through sentiment analysis using Large Language Models (LLM), the study revealed an overall positive public perception toward using generative AI in CS education, with over 57% of comments being favorable, while also identifying prominent topics of interest and concerns, such as the potential benefits of personalized learning support and automated grading, as well as issues like academic dishonesty, perpetuation of biases, over-reliance on AI hindering critical thinking, displacement of human instructors, and the need for updated curricula. The insights gleaned from the analysis will be instrumental in computing educators gaining a more profound comprehension of GAI 'srole in education and the subsequent development of GAI -enriched curricula. © 2024 IEEE.},
	author_keywords = {computer science education; Generative AI; sentiment analysis; social media dataset},
	keywords = {Adversarial machine learning; Contrastive Learning; Generative adversarial networks; Sentiment analysis; Computer Science Education; Contextualize; Generative artificial intelligence; Language model; Modeling approach; Potential benefits; Sentiment analysis; Social media; Social medium dataset; Technical development},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {979-835035150-7},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Qian2024164,
	author = {Qian, Cheng and Shi, Xianglong and Yao, Shanshan and Liu, Yichen and Zhou, Fengming and Zhang, Zishu and Akram, Junaid and Braytee, Ali and Anaissi, Ali},
	title = {Optimized Biomedical Question-Answering Services with LLM and Multi-BERT Integration},
	year = {2024},
	journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
	pages = {164 – 173},
	doi = {10.1109/ICDMW65004.2024.00028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001295070&doi=10.1109%2fICDMW65004.2024.00028&partnerID=40&md5=52e5defde7f9f6b0ce72d3abe2d6e2ec},
	affiliations = {University of Sydney, School of Computer Science, Australia; The University of Technology, TD School, Sydney, Australia},
	abstract = {We present a refined approach to biomedical question-answering (QA) services by integrating large language models (LLMs) with Multi-BERT configurations. By enhancing the ability to process and prioritize vast amounts of complex biomedical data, this system aims to support healthcare professionals in delivering better patient outcomes and informed decision-making. Through innovative use of BERT and BioBERT models, combined with a multi-layer perceptron (MLP) layer, we enable more specialized and efficient responses to the growing demands of the healthcare sector. Our approach not only addresses the challenge of overfitting by freezing one BERT model while training another but also improves the overall adaptability of QA services. The use of extensive datasets, such as BioASQ and BioMRC, demonstrates the system's ability to synthesize critical information. This work highlights how advanced language models can make a tangible difference in healthcare, providing reliable and responsive tools for professionals to manage complex information, ultimately serving the broader goal of social good through improved care and data-driven insights. © 2024 IEEE.},
	author_keywords = {BERT; biomedical question-answering; clinical decision support; large language models; multi-layer perceptron},
	keywords = {Modeling languages; BERT; Biomedical data; Biomedical question answering; Clinical decision support; Health care professionals; Informed decision; Language model; Large language model; Multilayers perceptrons; Question-answering services; Question answering},
	correspondence_address = {C. Qian; University of Sydney, School of Computer Science, Australia; email: cqia8658@uni.sydney.edu.au},
	editor = {He Y. and Hamidouche W. and Razzak I. and Hacid H. and Panov M.},
	publisher = {IEEE Computer Society},
	issn = {23759232},
	isbn = {979-833153063-1},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Data Mining Workshops, ICDMW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {1st International Artificial Intelligence Conference, IAIC 2023},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2059 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190705616&partnerID=40&md5=a2a28b1b0c128d55c5ad7c100475ef9f},
	abstract = {The proceedings contain 86 papers. The special focus in this conference is on Artificial Intelligence. The topics include: A Paper Citation Link Prediction Method Using Graph Attention Network; research on Emotional Analysis of Tibetan Short Text Based on Fusion Sentiment Lexicon; A Review of Solving Non-IID Data in Federated Learning: Current Status and Future Directions; a Review of Relationship Extraction Based on Deep Learning; BERT and LLM-Based Multivariate Hate Speech Detection on Twitter: Comparative Analysis and Superior Performance; Deep Learning for Protein-Protein Contact Prediction Using Evolutionary Scale Modeling (ESM) Feature; fedTag: Towards Automated Attack Investigation Using Federated Learning; Deep Learning Based SQL Injection Attack Detection; RSCC: Robust Semi-supervised Learning with Contrastive Learning and Augmentation Consistency Regularization; enhanced Prototypical Network for Few-Shot Named Entity Recognition; Regularized DNN Based Adaptive Compensation Algorithm for Gateway Power Meter in Ultra-High Voltage Substations; Dynamic Occlusion Expression Recognition Based on Improved GAN; Contrastive Learning Based on AMR Graph for Logic Reasoning; automated Detection and Recognition of Wild Dolphin Behaviors Using Deep Learning; M-GFCC: Audio Copy-Move Forgery Detection Algorithm Based on Fused Features of MFCC and GFCC; a Survey of Homogeneous and Heterogeneous Multi-source Information Fusion Based on Rough Set Theory; formula Maintenance of Single Material Tobacco Compatibility Based on Co-formulation Analysis Method; multi-physical Field Collaborative Simulation Optimization Technology and Reliability Analysis of Power Amplifiers; research and Design of Hydrological Data Visualization Based on Digital Twin; Design of Constraint FH-LFM DFRC Waveform; a Construction of IoT Malicious Traffic Dataset and Its Applications; meta-learning Based on Multi-objective Optimization; research and Implementation of Cooperative Utilization of Network Security Devices for Typical Security Events.},
	editor = {Jin H. and Pan Y. and Lu J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-981971279-3},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pratama2023388,
	author = {Pratama, Bacharuddin Adieb and Wiharja, Kemas Rahmat Saleh and Wulandari, Gia Septiana},
	title = {Knowledge Acquisition from Student Lecture Reflection Data: Leveraging Large Language Models and Tacit Knowledge},
	year = {2023},
	journal = {Proceeding - 2023 International Conference on Artificial Intelligence Robotics, Signal and Image Processing, AIRoSIP 2023},
	pages = {388 – 392},
	doi = {10.1109/AIRoSIP58759.2023.10873911},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000032338&doi=10.1109%2fAIRoSIP58759.2023.10873911&partnerID=40&md5=4127a9deb2a12e145d6b6e13f1441225},
	affiliations = {Telkom University, School of Computing, Bandung, Indonesia},
	abstract = {This research paper addresses a pertinent challenge encountered by lecturers in higher education institutions efficiently managing and analyzing the substantial volume of student lecture reflection data. To overcome this issue, we propose a novel knowledge acquisition system that amalgamates the capabilities of Large Language Models (LLM) with the invaluable tacit knowledge possessed by lecturers, enabling the inference of solutions. The process involves meticulously extracting textual information from student reflections and applying a multilingual BERT model for precise categorization. The acquired knowledge is subsequently stored within a sophisticated web-based platform, yielding an impressive acquisition rate of 73.85%, with 13.07% attributed to LLM and 60.78% emanating from lecturers' tacit knowledge. This study effectively showcases the potential of synergizing cutting-edge language models with human expertise, augmenting knowledge acquisition in educational environments. Furthermore, the proposed system furnishes a comprehensive and easily accessible resource, presenting insights into frequently encountered challenges and corresponding resolutions, benefiting students and lecturers. © 2023 IEEE.},
	author_keywords = {BERT; knowledge acquisition; Large Language Model; student lecture reflections; text extraction},
	keywords = {Economic and social effects; Knowledge acquisition; Knowledge representation; Teaching; BERT; Data leveraging; Language model; Large language model; Model knowledge; Reflection data; Research papers; Student lecture reflection; Tacit knowledge; Text extraction; Students},
	correspondence_address = {K.R.S. Wiharja; Telkom University, School of Computing, Bandung, Indonesia; email: bagindokemas@telkomuniversity.ac.id},
	editor = {Jusman Y.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032747-2},
	language = {English},
	abbrev_source_title = {Proceeding - Int. Conf. Artif. Intell. Robot., Signal Image Process., AIRoSIP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Anirudh2024387,
	author = {Anirudh, K. and Srikanth, Meghana and Shahina, A.},
	title = {Multilingual Fake News Detection in Low-Resource Languages: A Comparative Study Using BERT and GPT-3.5},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2046 CCIS},
	pages = {387 – 397},
	doi = {10.1007/978-3-031-58495-4_28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192391491&doi=10.1007%2f978-3-031-58495-4_28&partnerID=40&md5=cc1751301009878a92f66471323dc1a2},
	affiliations = {Department of Information Technology, Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, Chennai, 603110, India},
	abstract = {This paper presents a novel attempt at evaluating the authenticity of Tamil news headlines using large language models (LLMs) and evaluating it besides transformer models and existing machine learning results. To tackle this classification task, two potent models—the transformer-based BERT and the LLM, gpt-3.5-turbo—are deployed and fine-tuned to distinguish genuine from fabricated news headlines. Through careful fine-tuning and training of BERT, m-BERT, and GPT-3.5-Turbo, we assess their effectiveness, contrasting a bi-directional transformer with a generative transformer for fake news classification. Careful selection leads us to training based on three types of inputs: (1) Tamil news with English translations and author information; (2) Tamil news with author information only; and (3) English news with author information only. Our evaluation yields intriguing insights, showing that models trained on inputs with English versions consistently outperform those relying solely on Tamil text. Performance metrics, including accuracy, precision, recall, and F1-score, imply the superiority of the LLM -based gpt-3.5-turbo, achieving an accuracy of 0.92, precision of 0.902, recall of 0.949, and F1-score of 0.925. This highlights the effectiveness of LLMs in Tamil fake news classification. Moreover, these findings stress the significance of multilingual data processing for bolstering the accuracy of news headline classification systems. They also provide valuable insights for enhancing the reliability and precision of fake news detection systems in multilingual environments. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {BERT; Classification; Fake news detection; Fine-tuning; GPT-3.5; Low-resource languages; Multilingual},
	keywords = {Classification (of information); Fake detection; BERT; Comparatives studies; F1 scores; Fake news detection; Fine tuning; GPT-3.5; Language model; Low resource languages; Multilingual; Transformer modeling; Data handling},
	correspondence_address = {M. Srikanth; Department of Information Technology, Sri Sivasubramaniya Nadar College of Engineering, Chennai, Tamil Nadu, 603110, India; email: meghana2010694@ssn.edu.in},
	editor = {Chakravarthi B.R. and B B. and García Cumbreras M.A. and Jiménez Zafra S.M. and Subramanian M. and Shanmugavadivel K. and Nakov P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303158494-7},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Koru202414918,
	author = {Koru, Gulsum Kayabasi and Uluyol, Celebi},
	title = {Detection of Turkish Fake News from Tweets with BERT Models},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {14918 – 14931},
	doi = {10.1109/ACCESS.2024.3354165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182936157&doi=10.1109%2fACCESS.2024.3354165&partnerID=40&md5=aec5d9896d2a3ecd2d7699c53b404a3e},
	affiliations = {Gazi University, Computer Forensics Department, Ankara, 06640, Turkey},
	abstract = {As the number of people using social networks increases, more people are using social media platforms to meet their news needs. Users think that it is easier to follow the agenda by accessing news, especially on Twitter, rather than newspaper news pages. However, fake news is increasingly appearing on social media, and it is not always possible for people to obtain correct news from partial news pages or short Twitter posts. Understanding whether the news shared on Twitter is true or not is an important problem. Detecting fake tweets is of great importance in Turkish as well as in any language. In this study, fake news obtained from verification platforms on Twitter and real news obtained from the Twitter accounts of mainstream newspapers were labeled and, preprocessed using the Zemberek natural language processing tool developed for the Turkish language, and a dataset named TR_FaRe_News was created. Then, the TR_FaRe_News dataset was explored using ensemble methods and BoW, TF-IDF, and Word2Vec vectorization methods for fake news detection. Then a pre-trained BERT deep learning model was fine-tuned, and variations of the model extended with Bi-LSTM and Convolutional Neural Network (CNN) layers with the frozen and unfrozen parameters methods were explored. The performance evaluation was conducted using seven comparable datasets, namely BuzzFeedNews, GossipCop, ISOT, LIAR, Twitter15, and Twitter16, including an LLM-generated fake news dataset. Analyzing Turkish tweets and using fake news datasets generated by LLM is considered an important contribution. Accuracy values between 90 and 94% were obtained with the BERT and BERTurk + CNN models with 94% accuracy.  © 2013 IEEE.},
	author_keywords = {BERT; deep learning; ensemble learning; Fake news; generated news},
	keywords = {Convolution; Fake detection; Learning algorithms; Long short-term memory; Natural language processing systems; Newsprint; BERT; Convolutional neural network; Deep learning; Ensemble learning; Fake news; Generated news; Machine learning algorithms; Social networking (online); Social networking (online)},
	correspondence_address = {G.K. Koru; Gazi University, Computer Forensics Department, Ankara, 06640, Turkey; email: gulsum.kayabasikoru@gazi.edu.tr},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access}
}

@CONFERENCE{Konduru2024340,
	author = {Konduru, Kranthi Kumar and Natalia, Friska and Sudirman, Sud and Al-Jumeily, Dhiya},
	title = {Evaluating Few-Shot Prompting Approach Using GPT4 in Comparison to BERT-Variant Language Models in Biomedical Named Entity Recognition},
	year = {2024},
	journal = {Proceedings - International Conference on Developments in eSystems Engineering, DeSE},
	pages = {340 – 345},
	doi = {10.1109/DeSE63988.2024.10911889},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000521525&doi=10.1109%2fDeSE63988.2024.10911889&partnerID=40&md5=8f44372ff87398c5061ee9dea6ad1089},
	affiliations = {School of Computer Science and Mathematics, Liverpool John Moores University, Liverpool, United Kingdom; Information Systems Department, Universitas Multimedia Nusantara, Tangerang, Indonesia},
	abstract = {The wealth of information associated with the exponential increase in digital text, particularly within the biomedical field, has the potential to advance medical research, improve patient care, and enhance public health outcomes. However, the sheer volume and complexity of this data necessitate advanced computational tools for effective processing and analysis. We investigated the use of various pretrained transformer-based language models, particularly BERT, PubMedBERT, SciBERT, ClinicalBERT, DistilBERT, and the application of prompt engineering with GPT-4, within the context of biomedical Named Entity Recognition. Our approach incorporates a comprehensive performance evaluation analysis utilizing standard NLP evaluation metrics and computational resource usage metrics such as training time, memory usage, and inference time. Through this multifaceted approach, we sought to find out how the few-shot prompting approach using GPT4 performs in comparison to the BERT-variant language models while at the same time identifying models that not only excel in performance efficiency but also demonstrate computational affordability. Our experimental results show that even the most basic transformer-based language model outperforms the few-shot prompting approach of GPT-4, despite the popularity of the LLM in the more general Natural Language Processing tasks. © 2024 IEEE.},
	author_keywords = {Biomedical Texts; Large Language Model; Name Entity Recognition; Natural Language Processing; Transformer-based Language Model},
	keywords = {BASIC (programming language); Clinical research; Hospital data processing; Modeling languages; Biomedical named entity recognition; Biomedical text; Language model; Language processing; Large language model; Name entity recognition; Natural language processing; Natural languages; Transformer-based language model; Natural language processing systems},
	correspondence_address = {K.K. Konduru; School of Computer Science and Mathematics, Liverpool John Moores University, Liverpool, United Kingdom; email: k.k.konduru@2023.ljmu.ac.uk},
	editor = {Al-Jumeily D. and Assi S. and Jayabalan M. and Hind J. and Hussain A. and Tawfik H. and Rowe N. and Mustafina J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21611343},
	isbn = {979-835036869-7},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Dev. eSystems Eng., DeSE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Stearns2024199,
	author = {Stearns, Bernardo and Ballier, Nicolas and Gaillat, Thomas and Simpkin, Andrew and McCrae, John P.},
	title = {Evaluating the Generalisation of an Artificial Learner},
	year = {2024},
	journal = {Proceedings of the 13th Workshop on Natural Language Processing for Computer Assisted Language Learning, NLP4CALL 2024},
	pages = {199 – 208},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000132112&partnerID=40&md5=b058579202d61b292431d7bc6b7624c0},
	affiliations = {Insight Centre for Data Analytics, Data Science Institute, University of Galway, Ireland; LLF & CLILLAC-ARP, Université Paris Cité, rue Thomas Mann, PARIS, 75013, France; LIDILE, Université de Rennes 2, Rennes, 35000, France; School of Mathematical and Statistical Sciences, University of Galway, University Road, Galway, Ireland},
	abstract = {This paper focused on the creation of LLM-based artificial learners. Motivated by the capability of language models to encode language representation, we evaluated such models for predicting masked tokens in learner corpora. We domain-adapted the BERT model, pre-trained on native English, by further pretraining two learner models on learner corpora: a natural learner model on the EFCAMDAT dataset and a synthetic learner model on the C4200m dataset. We evaluated the two artificial learner models alongside the baseline native model using an external English-for-specific-purposes corpus from French undergraduates. We evaluated metrics related to accuracy, consistency, and divergence. While the native model performed reasonably well, the natural learner pre-trained model showed improvements in recall-at-k. We analysed error patterns, showing that the native model made “overconfident” errors by assigning high probabilities to incorrect predictions, while the artificial learners distributed probabilities more evenly when wrong. Finally, we showed that the general token choices from the native model diverged from the natural learner model and this divergence was higher at lower proficiency levels. © 2024 NLP4CALL. All Rights Reserved.},
	keywords = {Adversarial machine learning; Federated learning; Self-supervised learning; English for specific purpose; Error patterns; Generalisation; High probability; Language model; Learner corpora; Learner modeling; Pre-training; Proficiency level; Contrastive Learning},
	correspondence_address = {B. Stearns; Insight Centre for Data Analytics, Data Science Institute, University of Galway, Ireland; email: bernardo.stearns@insight-centre.org},
	editor = {Gaillat T. and Mallart C. and Moreau F. and Li J.-Y. and Drouet G. and Alfter D. and Volodina E. and Jonsson A.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {978-918075774-4},
	language = {English},
	abbrev_source_title = {Proc. Workshop Nat. Lang. Process. Comput. Assist. Lang. Learn., NLP4CALL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Silva2024325,
	author = {Silva, Kanishka and Frommholz, Ingo and Can, Burcu and Blain, Frédéric and Sarwar, Raheem and Ugolini, Laura},
	title = {Forged-GAN-BERT: Authorship Attribution for LLM-Generated Forged Novels},
	year = {2024},
	journal = {EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Student Research Workshop},
	pages = {325 – 337},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188724270&partnerID=40&md5=b656250a02398406c7da238cb2bcd42a},
	affiliations = {University of Wolverhampton, United Kingdom; University of Stirling, United Kingdom; Tilburg University, Netherlands; Manchester Metropolitan University, United Kingdom},
	abstract = {The advancement of generative Large Language Models (LLMs), capable of producing human-like texts, introduces challenges related to the authenticity of the text documents. This requires exploring potential forgery scenarios within the context of authorship attribution, especially in the literary domain. Particularly, two aspects of doubted authorship may arise in novels, as a novel may be imposed by a renowned author or include a copied writing style of a well-known novel. To address these concerns, we introduce Forged-GAN-BERT, a modified GAN-BERT-based model to improve the classification of forged novels in two data-augmentation aspects: via the Forged Novels Generator (i.e., ChatGPT) and the generator in GAN. Compared to other transformer-based models, the proposed Forged-GAN-BERT model demonstrates an improved performance with F1 scores of 0.97 and 0.71 for identifying forged novels in single-author and multi-author classification settings. Additionally, we explore different prompt categories for generating the forged novels to analyse the quality of the generated texts using different similarity distance measures, including ROUGE-1, Jaccard Similarity, Overlap Confident, and Cosine Similarity. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Authorship attribution; Data augmentation; Distance measure; F1 scores; Human like; Language model; Performance; Similarity distance; Text document; Writing style; Classification (of information)},
	editor = {Falk N. and Papi S. and Zhang M.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176090-5},
	language = {English},
	abbrev_source_title = {EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Proc. Stud. Res. Workshop},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Liu2024,
	author = {Liu, Kai and Fu, Zhihang and Chen, Chao and Zhang, Wei and Jiang, Rongxin and Zhou, Fan and Chen, Yaowu and Wu, Yue and Ye, Jieping},
	title = {Enhancing LLM's Cognition via Structurization},
	year = {2024},
	journal = {Advances in Neural Information Processing Systems},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000495166&partnerID=40&md5=b245f6c5c59c55b9c863208207977706},
	affiliations = {Zhejiang University, China; Alibaba Cloud, China},
	abstract = {When reading long-form text, human cognition is complex and structurized. While large language models (LLMs) process input contexts through a causal and sequential perspective, this approach can potentially limit their ability to handle intricate and complex inputs effectively. To enhance LLM's cognition capability, this paper presents a novel concept of context structurization. Specifically, we transform the plain, unordered contextual sentences into well-ordered and hierarchically structurized elements. By doing so, LLMs can better grasp intricate and extended contexts through precise attention and information-seeking along the organized structures. Extensive evaluations are conducted across various model architectures and sizes (including a series of auto-regressive LLMs as well as BERT-like masking models) on a diverse set of NLP tasks (e.g., context-based question-answering, exhaustive hallucination evaluation, and passage-level dense retrieval). Empirical results show consistent and significant performance gains afforded by a single-round structurization. In particular, we boost the open-sourced LLaMA2-70B model to achieve comparable performance against GPT-3.5-Turbo as the hallucination evaluator. Besides, we show the feasibility of distilling advanced LLMs' language processing abilities to a smaller yet effective StruXGPT-7B to execute structurization, addressing the practicality of our approach. Code is available at https://github.com/alibaba/struxgpt. © 2024 Neural information processing systems foundation. All rights reserved.},
	correspondence_address = {Z. Fu; Alibaba Cloud, China; email: zhihang.fzh@alibaba-inc.com; R. Jiang; Zhejiang University, China; email: rongxinj@zju.edu.cn},
	editor = {Globerson A. and Mackey L. and Belgrave D. and Fan A. and Paquet U. and Tomczak J. and Zhang C.},
	publisher = {Neural information processing systems foundation},
	issn = {10495258},
	language = {English},
	abbrev_source_title = {Adv. neural inf. proces. syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {6th International Conference on Quantitative Ethnography, ICQE 2024},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2279 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002089412&partnerID=40&md5=667b14ee5350c9efe2c07d584d786310},
	abstract = {The proceedings contain 41 papers. The special focus in this conference is on Quantitative Ethnography. The topics include: Bayesian Graph Neural Networks Modeling for Naturally Arisen Leadership; perfect Sampling; computer-Supported Code Discovery Utilizing Topic Modeling and Stepwise Coding; critical Reviews with Quantitative Ethnography: Theory Use in Literature on Quantified Group Work in Educational Settings; assessing the Potential and Limits of Large Language Models in Qualitative Coding; Closing the Interpretive Loop with BERT, Our Neural Topic Modeling Friend; making Sense of the Model: Interpreting Epistemic Networks and Their Projection Space; Using LLM-Based Filtering to Develop Reliable Coding Schemes for Rare Debugging Strategies; Development of ENA 3D: A Tool for Epistemic Network Analysis in Three-Dimensional Space; Exploring Variance: Seeking Nuanced Stories Within ENA; Shifting Paradigms: Trends in Quantitative Ethnography Research at ICQE; analyzing Nursing Assistant Attitudes Towards Geriatric Caregiving Using Epistemic Network Analysis; exploring Students’ Changing Conceptions About eLearning Leadership; learning from Student Mistakes: Using Epistemic Network Analysis of Students’ Knowledge of Fractions, Ratios and Percentages to Drive Middle School Instruction; studying the Interplay of Self-regulated Learning Cycles and Scaffolding Through Ordered Network Analysis Across Three Tutoring Systems; text-Based vs Audio-Based: What Differential Effects Do the Two Discussion Formats have on Scientific Reasoning?.},
	editor = {Kim Y.J. and Swiecki Z.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303176331-1},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{He2023414,
	author = {He, Meng and Bai, Yunli},
	title = {LAL-JER: Label-Aware Learning for Adaptive Joint Entity and Relation Extraction with LLM data augmentation},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {414 – 419},
	doi = {10.1145/3640912.3640993},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186957359&doi=10.1145%2f3640912.3640993&partnerID=40&md5=1cb3b848e14b5b8c1cc8e403db8c3ee8},
	affiliations = {College of Computer and Information Engineering, Inner Mongolia Agricultural University, Hohhot, 010018, China},
	abstract = {Joint entity and relation extraction has achieved great improvements in Natural Language Processing (NLP) and has been widely applied, such as constructing knowledge graph, query understanding and question answering. Existing methods usually spend long time on fitting the models on certain datasets with given label type, which greatly lacks the ability of generalization. The model cannot make prediction on label types that have not seen in the training set. To address this issue, we propose to use prompt to incorporate the semantic meaning of the label type description. Furthermore, we use large language model to perform data augmentation to improve the robustness of our model during training. Extensive experiments and ablation study on two joint entity and relation extraction validates the effectiveness of our work on that: 1. Our methods achieved states of art performance on joint entity and relation extraction benchmark based on pretrained language model bert. 2. Our methods can help the model make predictions on label type unseen before given prompts.  © 2023 ACM.},
	author_keywords = {Bert; data augmentation; Joint entity and relation extraction; large language model},
	keywords = {Benchmarking; Computational linguistics; Data mining; Extraction; Knowledge graph; Natural language processing systems; Query processing; Bert; Data augmentation; Entity extractions; Joint entity and relation extraction; Knowledge graphs; Language model; Language processing; Large language model; Natural languages; Relation extraction; Semantics},
	correspondence_address = {Y. Bai; College of Computer and Information Engineering, Inner Mongolia Agricultural University, Hohhot, 010018, China; email: baiyl@imau.edu.cn},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071668-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{García-Vázquez2024118,
	author = {García-Vázquez, Omar and Alcántara, Tania and Calvo, Hiram and Sidorov, Grigori},
	title = {LLM’s for Spanish Song Text Analysis and Classification Using Language Variants},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14392 LNAI},
	pages = {118 – 127},
	doi = {10.1007/978-3-031-47640-2_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177433894&doi=10.1007%2f978-3-031-47640-2_10&partnerID=40&md5=b8b902093951d29aa36f1daed159e8fb},
	affiliations = {Centro de Investigación en Computación, Instituto Politécnico Nacional, Mexico City, Mexico},
	abstract = {Feelings are the affective state of mind, which are produced in the brain and are caused by an emotion. This feelings have been transferred in multiple ways, such as texts, paintings music. Music transmits different emotions, which makes it even more important to know what kind of feelings are found within a song, which can be, among many others, positive, negative or neutral. Through this work, the texts of two different datasets of songs in the Spanish language were analyzed and classified, this through BERT, RoBERTa and DistilBERT. These experiments showed an improvement compared with previous works and improvement with the use of these methods. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {BERT; Classification; DistilBERT; LLM’s; Natural Language Processing; RoBERTa; Songs},
	keywords = {Natural language processing systems; Text processing; BERT; Distilbert; Language processing; LLM’s; Natural language processing; Natural languages; RoBERTa; Song; Text analysis; Text classification; Classification (of information)},
	correspondence_address = {T. Alcántara; Centro de Investigación en Computación, Instituto Politécnico Nacional, Mexico City, Mexico; email: talcantaram2020@cic.ipn.mx},
	editor = {Calvo H. and Martínez-Villaseñor L. and Ponce H.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303147639-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Patel2024,
	author = {Patel, Urjitkumar and Yeh, Fang-Chun and Gondhalekar, Chinmay},
	title = {CANAL - Cyber Activity News Alerting Language Model : Empirical Approach vs. Expensive LLMs},
	year = {2024},
	journal = {2024 IEEE 3rd International Conference on AI in Cybersecurity, ICAIC 2024},
	doi = {10.1109/ICAIC60265.2024.10433839},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186526416&doi=10.1109%2fICAIC60265.2024.10433839&partnerID=40&md5=828c549b33dd6b79986f0914a16ddaca},
	affiliations = {S&p Global, Ratings Data Science, New York, United States},
	abstract = {In today's digital landscape, where cyber attacks have become the norm, the detection of cyber attacks and threats is critically imperative across diverse domains. Our research presents a new empirical framework for cyber threat modeling, adept at parsing and categorizing cyber-related information from news articles, enhancing real-time vigilance for market stakeholders. At the core of this framework is a fine-tuned BERT model, which we call CANAL - Cyber Activity News Alerting Language Model, tailored for cyber categorization using a novel silver labeling approach powered by Random Forest. We benchmark CANAL against larger, costlier LLMs, including GPT-4, LLaMA, and Zephyr, highlighting their zero to few-shot learning in cyber news classification. CANAL demonstrates superior performance by outperforming all other LLM counterparts in both accuracy and cost-effectiveness. Furthermore, we introduce the Cyber Signal Discovery module, a strategic component designed to efficiently detect emerging cyber signals from news articles. Collectively, CANAL and Cyber Signal Discovery module equip our framework to provide a robust and cost-effective solution for businesses that require agile responses to cyber intelligence. © 2024 IEEE.},
	author_keywords = {BERT; Cyber News Alerts; Cyber Risk Modeling; Cyber Signal Discovery; Empirical Cost Analysis; Generative AI (Gen AI); Large Language Models (LLM); Machine Learning; Natural Language Processing (NLP)},
	keywords = {Computational linguistics; Computer crime; Cost benefit analysis; Crime; Learning algorithms; Learning systems; Natural language processing systems; Network security; Risk assessment; BERT; Cost analysis; Cybe news alert; Cybe risk modeling; Cybe signal discovery; Empirical cost analyse; Generative AI; Language model; Language processing; Large language model; Machine-learning; Natural language processing; Natural languages; News alerts; Risk modeling; Cost effectiveness},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038185-6},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. AI Cybersecur., ICAIC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Sattar2023,
	author = {Sattar, Husnain and Umar, Muhammad Shamil and Ijaz, Eeman and Arshad, Muhammad Umair},
	title = {Multi-Modal Architecture for Cricket Highlights Generation: Using Computer Vision and Large Language Model},
	year = {2023},
	journal = {2023 17th International Conference on Open Source Systems and Technologies, ICOSST 2023 - Proceedings},
	doi = {10.1109/ICOSST60641.2023.10414235},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185831018&doi=10.1109%2fICOSST60641.2023.10414235&partnerID=40&md5=d25b1d1aeace631915b7d54f1720d9e2},
	affiliations = {School of Computing, NUCES, Islamabad, Pakistan},
	abstract = {Generating highlights for cricket matches is a labour-intensive task that necessitates a high level of both cricket and video editing knowledge. Creating a coherent video with smooth transitions involves sorting through hours of video information, identifying key moments, and merging clips. Sports video summarization has gained a lot of traction in recent days. In this study, we provide a multi-modal framework designed for efficiently producing cricket highlights. We focus on identifying key events while utilizing information from commentary text and visual data. We make use of cues like replays, bowler and umpire positions, and commentary to do so. Starting by splitting the target video into its building blocks (non-replay deliveries), the commentary is transcribed using Automated Speech Recognition (ASR). The textual commentary is then preprocessed so as not to alter the context of the extracted speech. Based on the preprocessed text, a Large Language Model (LLM) is used to predict whether an event occurred after a particular delivery. Two computer vision models-one designed for bowler detection and the other focusing on replay identification-work at the heart of this architecture. These models perform admirably, as evidenced by their respective F1 scores of 0.97 and 0.99. Using BERT LLM exceptional F1 score of 0.96 is achieved. Notably, the architecture's large-scale training data (CricPulse) includes cricket matches from both the Indian Premier League (IPL) and Pakistan Super League (PSL), demonstrating its adaptability and robustness. In short, our study addresses the challenges of highlights generation by introducing a comprehensive framework for cricket match summarization. We help to accelerate this complex task by utilizing multi-modal inputs and cutting-edge transformer-based models, thereby improving viewing experiences for cricket lovers around the globe.  © 2023 IEEE.},
	author_keywords = {Automatic Speech Recognition; Large Language Models; Multi-modality; Transformers; Video-Summarization},
	keywords = {Computational linguistics; Computer architecture; High level languages; Speech recognition; Sports; Video recording; Video signal processing; Automatic speech recognition; F1 scores; Labour-intensive; Language model; Large language model; Multi-modal; Multi-modality; Transformer; Video editing; Video summarization; Computer vision},
	correspondence_address = {H. Sattar; School of Computing, NUCES, Islamabad, Pakistan; email: i211354@nu.edu.pk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038132-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Open Source Syst. Technol., ICOSST - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Wang2023296,
	author = {Wang, Zhiyuan and Zhou, Qiang and Junfeng, Zhao and Wang, Yasha and Ding, Hongxin and Song, Jiahe},
	title = {A Knowledge-Enhanced Medical Named Entity Recognition Method that Integrates Pre-Trained Language Models},
	year = {2023},
	journal = {Proceedings - 2023 1st IEEE International Conference on Medical Artificial Intelligence, MedAI 2023},
	pages = {296 – 301},
	doi = {10.1109/MedAI59581.2023.00046},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185217688&doi=10.1109%2fMedAI59581.2023.00046&partnerID=40&md5=da1f7cb03d4df335ecc56f413487e48f},
	affiliations = {Peking University, Key Lab of Hcst (PKU), Moe, Scs, Beijing, China; School of Software & Microelectronics, Peking University, Beijing, China; Shenzhen Emergency Medical Center, Shenzhen, China; Research Center of Big Data Technology, Nanhu Laboratory, Jiaxing, China; School of Computer Science, Peking University, Beijing, China},
	abstract = {Medical Named Entity Recognition (NER) is a critical task in medical text processing. But medical documents exhibit high variability in terms of language usage, abbreviations, synonyms, misspellings, and typographical errors, so the precise extraction of named entities is challenging. Although large language models (LLMs) have shown good performance in medical knowledge extraction tasks in few-shot settings, their performance is difficult to fully leverage in supervised medical named entity recognition (NER) tasks. This is because NER is a sequence labeling task, while LLMs are more suitable for tasks such as text generation. Furthermore, the structured output of NER tasks leads to a performance loss when LLMs convert it into generative text. Therefore, it is a challenging problem to utilize LLMs to improve the accuracy of medical named entity recognition tasks. On this paper, we propose a method that integrates LLM knowledge to enhance the performance of medical NER models. Firstly, we improve the structure of the LLM model to make it more adaptable to NER tasks. Secondly, we adopt the LoRA method and incorporate Chinese vocabulary information into the model training. Finally, to fully utilize the fine-tuned LLM to enhance the medical NER model, we convert the output of the LLM into a knowledge concentration matrix and inject it into the NER model. We have verify the effectiveness of our new method on the CMeEE dataset. The results demonstrate that our method can efficiently fine-tune the LLM and improve its performance. Moreover, our method can also leverage the prior knowledge of the fine-tuned LLM to enhance the BERT-based medical NER model. In addition, our method demonstrates good generalization and can tackle entity recognition tasks in other domains. We validated the superiority of our approach on the resume-zh dataset.  © 2023 IEEE.},
	author_keywords = {Knowledge Enhancement; Large Language Model; Large Model Finetuning; Named-entity Recognition},
	keywords = {Character recognition; Computational linguistics; Knowledge management; Natural language processing systems; Text processing; Critical tasks; Knowledge enhancement; Language model; Large language model; Large model finetuning; Large models; Named entity recognition; Performance; Recognition methods; Recognition models; Extraction},
	correspondence_address = {Q. Zhou; Shenzhen Emergency Medical Center, Shenzhen, China; email: zq_shenzhen2023@163.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035878-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Med. Artif. Intell., MedAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Raja2024,
	author = {Raja, Hina and Munawar, Asim and Mylonas, Nikolaos and Delsoz, Mohammad and Madadi, Yeganeh and Elahi, Muhammad and Hassan, Amr and Serhan, Hashem Abu and Inam, Onur and Hernandez, Luis and Chen, Hao and Tran, Sang and Munir, Wuqaas and Abd-Alrazaq, Alaa and Yousefi, Siamak},
	title = {Automated Category and Trend Analysis of Scientific Articles on Ophthalmology Using Large Language Models: Development and Usability Study},
	year = {2024},
	journal = {JMIR Formative Research},
	volume = {8},
	doi = {10.2196/52462},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191313841&doi=10.2196%2f52462&partnerID=40&md5=f8099496ebeae4182d682e7c311bfd8a},
	affiliations = {Department of Ophthalmology, University of Tennessee, Health Science Center, Memphis, TN, United States; Watson Research Center, IBM Research, New York, NY, United States; School of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; Quillen College of Medicine, East Tennessee State University, Johnson, TN, United States; Gavin Herbert Eye Institute, School of Medicine, University of California, Irvine, CA, United States; Department of Ophthalmology, Hamad Medical Corporation, Doha, Qatar; Edward S. Harkness Eye Institute, Vagelos College of Physicians and Surgeons, Columbia University, Irving Medical Center, New York, NY, United States; Department of Biophysics, Faculty of Medicine, Gazi University, Ankara, Turkey; Association to Prevent Blindness in Mexico, Ciudad, Mexico; Department of Pharmacology Addiction Science and Toxicology, University of Tennessee, Health Science Center, Memphis, TN, United States; Department of Ophthalmology and Visual Sciences, School of Medicine, University of Maryland, Baltimore, MD, United States; AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar},
	abstract = {Background: In this paper, we present an automated method for article classification, leveraging the power of large language models (LLMs). Objective: The aim of this study is to evaluate the applicability of various LLMs based on textual content of scientific ophthalmology papers. Methods: We developed a model based on natural language processing techniques, including advanced LLMs, to process and analyze the textual content of scientific papers. Specifically, we used zero-shot learning LLMs and compared Bidirectional and Auto-Regressive Transformers (BART) and its variants with Bidirectional Encoder Representations from Transformers (BERT) and its variants, such as distilBERT, SciBERT, PubmedBERT, and BioBERT. To evaluate the LLMs, we compiled a data set (retinal diseases [RenD] ) of 1000 ocular disease-related articles, which were expertly annotated by a panel of 6 specialists into 19 distinct categories. In addition to the classification of articles, we also performed analysis on different classified groups to find the patterns and trends in the field. Results: The classification results demonstrate the effectiveness of LLMs in categorizing a large number of ophthalmology papers without human intervention. The model achieved a mean accuracy of 0.86 and a mean F1-score of 0.85 based on the RenD data set. Conclusions: The proposed framework achieves notable improvements in both accuracy and efficiency. Its application in the domain of ophthalmology showcases its potential for knowledge organization and retrieval. We performed a trend analysis that enables researchers and clinicians to easily categorize and retrieve relevant papers, saving time and effort in literature review and information gathering as well as identification of emerging scientific trends within different disciplines. Moreover, the extendibility of the model to other scientific fields broadens its impact in facilitating research and trend analysis across diverse disciplines. © 2024 JMIR Publications Inc.. All rights reserved.},
	author_keywords = {BART; BERT; Bidirectional and Auto-Regressive Transformers; bidirectional encoder representations from transformers; large language model; LLM; ophthalmology; text classification; trend analysis},
	correspondence_address = {H. Raja; Department of Ophthalmology, University of Tennessee, Health Science Center, Memphis, 930 Madison Avenue, 38111, United States; email: hinaraja65@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {2561326X},
	language = {English},
	abbrev_source_title = {JMIR Form.  Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Mohammed2024,
	author = {Mohammed, Sabah and Fiaidhi, Jinan},
	title = {Harnessing Machine Learning in AIoT Environment to Support Evidence-Based Medicine Using Transformers},
	year = {2024},
	journal = {2024 International Conference on Computer and Applications, ICCA 2024},
	doi = {10.1109/ICCA62237.2024.10927828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002228468&doi=10.1109%2fICCA62237.2024.10927828&partnerID=40&md5=d9306af0c2460be60aeb1432e520426b},
	affiliations = {Lakehead University, Department of Computer Science, Thunder Bay, Canada},
	abstract = {In today's digital ecosystem, where we handle and share thousands of data in our daily lives, new technologies and analytical methods are emerging to help breaking the barrier for practicing evidence-based medicine. Such emerging technologies rely on effective methods for rapidly identifying relevant evidences from the body of biomedical literature as well as connecting to different sensors. An important challenge confronted by the medical practitioners is the long time needed to browse, monitor, filter, summarize and compile information from different medical resources. Deep learning can help in solving this based on the automatic question answering (Q&A) and transformers. However, Q&A and transformers technologies are not trained to answer clinical queries that can be used for evidence-based practice nor it can respond to structured clinical questioning protocol like PICO (Patient/Problem, Intervention, Comparison and Outcome). This article describes the use of deep learning techniques for Q&A that is based on transformer models like BERT and GPT to answer PICO clinical questions that can be used for evidence-based practice extracted from sound medical research resources like PubMed. We are reporting acceptable clinical answers that are supported by findings from PubMed. Our transformer methods are reaching an acceptable state of the art performance based on two staged bootstrapping process involving filtering relevant articles followed by identifying articles that support the requested outcome expressed by the PICO question. Moreover, we are also reporting experimentations to empower our bootstrapping techniques with patch attentions to the most important keywords in the clinical case and the PICO questions. Our bootstrapped patched with attention is showing relevancy of the evidences collected based on an entropy metrics.  © 2024 IEEE.},
	author_keywords = {Attention Entropy; Attention Patching; Automatic Question Answering; Bootstrapping; Evidence-Based Medicine; Generative Models; LLM Transformers; PICO questions},
	keywords = {Clinical research; Contrastive Learning; Deep learning; Attention entropy; Attention patching; Automatic question answering; Bootstrapping; Evidence-based medicine; Evidence-based practices; Generative model; LLM transformer; Patient/problem, intervention, comparison and outcome question; Question Answering; Distribution transformers},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036756-0},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Appl., ICCA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Udagawa202410176,
	author = {Udagawa, Takuma and Suzuki, Masayuki and Kurata, Gakuto and Muraoka, Masayasu and Saon, George},
	title = {MULTIPLE REPRESENTATION TRANSFER FROM LARGE LANGUAGE MODELS TO END-TO-END ASR SYSTEMS},
	year = {2024},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	pages = {10176 – 10180},
	doi = {10.1109/ICASSP48485.2024.10448022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001659341&doi=10.1109%2fICASSP48485.2024.10448022&partnerID=40&md5=0fe57ccbe8cf72d7dadbba708c08bece},
	affiliations = {IBM Research AI, United States},
	abstract = {Transferring the knowledge of large language models (LLMs) is a promising technique to incorporate linguistic knowledge into end-to-end automatic speech recognition (ASR) systems. However, existing works only transfer a single representation of LLM (e.g. the last layer of pretrained BERT), while the representation of a text is inherently non-unique and can be obtained variously from different layers, contexts and models. In this work, we explore a wide range of techniques to obtain and transfer multiple representations of LLMs into a transducer-based ASR system. While being conceptually simple, we show that transferring multiple representations of LLMs can be an effective alternative to transferring only a single LLM representation. © 2024 IEEE.},
	author_keywords = {Automatic speech recognition; BERT; knowledge distillation; large language models},
	keywords = {Knowledge representation; Linguistics; Modeling languages; Natural language processing systems; Automatic speech recognition; Automatic speech recognition system; BERT; Different layers; End to end; Knowledge distillation; Language model; Large language model; Linguistic knowledge; Multiple representation; Speech recognition},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15206149},
	coden = {IPROD},
	language = {English},
	abbrev_source_title = {ICASSP IEEE Int Conf Acoust Speech Signal Process Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Joy2024173,
	author = {Joy, Isaac and Wu, Jun and He, Jingrui},
	title = {GPT Attack for Adversarial Privacy Policies},
	year = {2024},
	journal = {Proceedings of the International Conference on Big Data Computing and Communications, BIGCOM},
	number = {2024},
	pages = {173 – 180},
	doi = {10.1109/BIGCOM65357.2024.00032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001664653&doi=10.1109%2fBIGCOM65357.2024.00032&partnerID=40&md5=b26d00b839f564d6c37f7caf3b7f0af3},
	affiliations = {UIUC, Informatics Program, Champaign, United States; UIUC, Department of Computer Science, Champaign, United States; School of Information Sciences, UIUC, Champaign, United States},
	abstract = {While Machine Learning (ML) is widely used in many industries, one sector that is just beginning to leverage this technology is the legal field. Efforts like the construction of the OPP-115 Privacy Policy corpus make it possible to train Natural Language Processing (NLP) and ML models for legal use, and tools such as Polisis, Claudette, etc., which utilize these models can now provide users with descriptive annotations of various types of contracts, including Privacy Policies. However, these tools remain vulnerable to adversarial attacks, specifically adversarial legal documents, which differ from typical text based adversarial attacks due to the necessity of preserving the continuity of a legal document. Therefore, focusing on the OPP-115 corpus and Polisis specifically, we propose a framework that consists of a Doc2Vec model and a variety of shallow and deep learning methods for classification, followed by adversarial attacks on Privacy Policy segments which utilize GPT 3.5, a state-of-the-art LLM, in order to create an adversarial Privacy Policy. We evaluate the effectiveness of our method by comparing attack results to those produced by current methods, including Bert Attack and Text Fooler. Our procedure reveals not just that an attack using GPT 3.5 is an effective means of producing an adversarial policy, but that it is surprisingly easy to prompt a widely used state-of-the-art LLM to perform such a task.  © 2024 IEEE.},
	author_keywords = {Adversarial Attacks; LLM; Privacy Policy},
	keywords = {Differential privacy; Generative adversarial networks; 'current; Language processing; Learning methods; Legal documents; LLM; Machine learning models; Machine-learning; Natural languages; Privacy policies; State of the art; Adversarial machine learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {27672182},
	isbn = {979-833150953-8},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Big Data Comput. Commun., BIGCOM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hadzic2024135,
	author = {Hadzic, Bakir and Mohammed, Parvez and Danner, Michael and Ohse, Julia and Zhang, Yihong and Shiban, Youssef and Rätsch, Matthias},
	title = {Enhancing early depression detection with AI: a comparative use of NLP models},
	year = {2024},
	journal = {SICE Journal of Control, Measurement, and System Integration},
	volume = {17},
	number = {1},
	pages = {135 – 143},
	doi = {10.1080/18824889.2024.2342624},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191192059&doi=10.1080%2f18824889.2024.2342624&partnerID=40&md5=92a25f711ca72eba8f9bcefd2e3d2c74},
	affiliations = {ViSiR, Reutlingen University, Reutlingen, Germany; CVSSP, University of Surrey, Guildford, United Kingdom; Private University of Applied Sciences, Göttingen, Germany; College of Information Science and Technology, Donghua University, Shanghai, China},
	abstract = {One of the most underdiagnosed medical conditions worldwide is depression. It has been demonstrated that the current classical procedures for early detection of depression are insufficient, which emphasizes the importance of seeking a more efficient approach to overcome this challenge. One of the most promising opportunities is arising in the field of Artificial Intelligence as AI-based models could have the capacity to offer a fast, widely accessible, unbiased and efficient method to address this problem. In this paper, we compared three natural language processing models, namely, BERT, GPT-3.5 and GPT-4 on three different datasets. Our findings show that different levels of efficacy are shown by fine-tuned BERT, GPT-3.5, and GPT-4 in identifying depression from textual data. By comparing the models on the metrics such as accuracy, precision, and recall, our results have shown that GPT-4 outperforms both BERT and GPT-3.5 models, even without previous fine-tuning, showcasing its enormous potential to be utilized for automated depression detection on textual data. In the paper, we present newly introduced datasets, fine-tuning and model testing processes, while also addressing limitations and discussing further considerations for future research. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {BERT; depression detection; GPT-4; LLM; Mental health},
	keywords = {Artificial intelligence; 'current; BERT; Depression detection; Fine tuning; GPT-4; LLM; Medical conditions; Mental health; Natural languages; Textual data; Natural language processing systems},
	correspondence_address = {M. Rätsch; ViSiR, Reutlingen University, Reutlingen, Germany; email: matthias.raetsch@reutlingen-university.de},
	publisher = {Taylor and Francis Ltd.},
	issn = {18849970},
	language = {English},
	abbrev_source_title = {SICE. J. Control. Meas.Syst. Integr.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gunawardena202369,
	author = {Gunawardena, Charlotte N. and Chen, Yan and Flor, Nick and Sánchez, Damien},
	title = {Deep Learning Models for Analyzing Social Construction of Knowledge Online},
	year = {2023},
	journal = {Online Learning Journal},
	volume = {27},
	number = {4},
	pages = {69 – 92},
	doi = {10.24059/olj.v27i4.4055},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178875529&doi=10.24059%2folj.v27i4.4055&partnerID=40&md5=20f76d4a6af7dd747ed25079b8c1c7cd},
	affiliations = {University of New Mexico, United States; University of Nevada Las Vegas, United States},
	abstract = {Gunawardena et al.’s (1997) Interaction Analysis Model (IAM) is one of the most frequently employed frameworks to guide the qualitative analysis of social construction of knowledge online. However, qualitative analysis is time consuming, and precludes immediate feedback to revise online courses while being delivered. To expedite analysis with a large dataset, this study explores how two neural network architectures—a feed-forward network (Doc2Vec) and a large language model transformer (BERT)—could automatically predict phases of knowledge construction using IAM. The methods interrogated the extent to which the artificial neural networks’ predictions of IAM Phases approximated a human coder’s qualitative analysis. Key results indicate an accuracy of 21.55% for Doc2Vec phases I-V, 43% for fine-tuning a pre-trained large language model (LLM), and 52.79% for prompt-engineering an LLM. Future studies for improving accuracy should consider either training the models with larger datasets or focusing on the design of prompts to improve classification accuracy. Grounded on social constructivism and IAM, this study has implications for designing and supporting online collaborative learning where the goal is social construction of knowledge. Moreover, it has teaching implications for guiding the design of AI tools that provide beneficial feedback for both students and course designers. © 2023, The Online Learning Consortium. All rights reserved.},
	author_keywords = {interaction analysis model; neural networks; social construction of knowledge online},
	publisher = {The Online Learning Consortium},
	issn = {24725749},
	language = {English},
	abbrev_source_title = {Online Learn. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Bariah20236542,
	author = {Bariah, Lina and Zou, Hang and Zhao, Qiyang and Mouhouche, Belkacem and Bader, Faouzi and Debbah, Merouane},
	title = {Understanding Telecom Language Through Large Language Models},
	year = {2023},
	journal = {Proceedings - IEEE Global Communications Conference, GLOBECOM},
	pages = {6542 – 6547},
	doi = {10.1109/GLOBECOM54140.2023.10437725},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187391044&doi=10.1109%2fGLOBECOM54140.2023.10437725&partnerID=40&md5=e79e60e115b7eceefaf3df30537b41e8},
	affiliations = {Technology Innovation Institute, Abu Dhabi, 9639, United Arab Emirates; Khalifa University, Abu Dhabi, 127788, United Arab Emirates},
	abstract = {The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the 3rd Generation Partnership Project (3GPP) standard working groups. We consider training the selected models on 3GPP technical documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP working groups. The distilled BERT model with around 50% less parameters achieves similar performance as others. This corroborates that fine-tuning pretrained LLM can effectively identify the categories of Telecom language. The developed framework shows a stepping stone towards realizing intent-driven and self-evolving wireless networks from Telecom languages, and paves the way for the implementation of generative AI in the Telecom domain. © 2023 IEEE.},
	author_keywords = {3GPP; Generative AI; Large Language Models; Pre-trained Transformer; Telecom Language},
	keywords = {Artificial intelligence; Mobile telecommunication systems; Tuning; 3rd generation; 3rd generation partnership project; Generative artificial intelligence; Language model; Large language model; Pre-trained transformer; Technical documents; Telecom; Telecom language; Working groups; Computational linguistics},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {23340983},
	isbn = {979-835031090-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Glob. Commun. Conf., GLOBECOM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@CONFERENCE{Khennouche2024,
	author = {Khennouche, Feriel and Elmir, Youssef and Djebari, Nabil and Boubchir, Larbi},
	title = {Improving User Experience for AI Chatbots through LLM Models},
	year = {2024},
	journal = {Proceedings of IEEE/ACS International Conference on Computer Systems and Applications, AICCSA},
	doi = {10.1109/AICCSA63423.2024.10912523},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000817548&doi=10.1109%2fAICCSA63423.2024.10912523&partnerID=40&md5=ef37853ea5dd99fba6712e170715cf86},
	affiliations = {École Supérieure en Sciences et Technologies de l'Informatique et du Numérique, Laboratoire LITAN, Amizour, Bejaia, 06300, Algeria; SGRE-lab, Bechar, Algeria; Université de Bejaia, Laboratoire d'Informatique Médical (LIMED), Targa Ouzemour, Bejaia, 06000, Algeria; University of Paris 8, LIASD Research Laboratory, Saint-Denis, 93526, France},
	abstract = {This paper introduces an innovative strategy for enhancing the user experience via an AI-powered FAQ chatbot for the Ecole Supérieure en Sciences et Technologies de l'Informatique et du Numérique (ESTIN). By combining multiple Large Language Models (LLMs) such as BART, GPT, and BERT, the standard static FAQ system is converted into a dynamic, interactive interface. Our hybrid approach aims to expose the unique strengths of each model through a multi-phase training process. Initial experimentations have revealed that BERT outperforms other models in handling ESTIN's FAQ dataset, providing better context comprehension and response relevance. We intend to additionally refine the chatbot by studying the effect of different model training sequences. The expected outcome is a scalable and adaptable chatbot that significantly improves user engagement.  © 2024 IEEE.},
	author_keywords = {AI-powered conversations; FAQ System; Generative AI; Large Language Model; User Experience},
	keywords = {Economic and social effects; Modeling languages; AI-powered conversation; Chatbots; Dynamic interactive; ET technology; FAQ system; Generative AI; Innovative strategies; Language model; Large language model; Users' experiences; Computer simulation languages},
	publisher = {IEEE Computer Society},
	issn = {21615322},
	isbn = {979-833151824-0},
	language = {English},
	abbrev_source_title = {Proc. IEEE/ACS Int. Conf. Comput. Syst. Appl., AICCSA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ayoobi2023,
	author = {Ayoobi, Navid and Shahriar, Sadat and Mukherjee, Arjun},
	title = {The Looming Threat of Fake and LLM-generated LinkedIn Profiles: Challenges and Opportunities for Detection and Prevention},
	year = {2023},
	journal = {HT 2023 - The 34th ACM Conference on Hypertext and Social Media},
	doi = {10.1145/3603163.3609064},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173668489&doi=10.1145%2f3603163.3609064&partnerID=40&md5=da06cfa80f5e90df47c40eede2d9f752},
	affiliations = {University of Houston, Houston, TX, United States},
	abstract = {In this paper, we present a novel method for detecting fake and Large Language Model (LLM)-generated profiles in the LinkedIn Online Social Network immediately upon registration and before establishing connections. Early fake profile identification is crucial to maintaining the platform's integrity since it prevents imposters from acquiring the private and sensitive information of legitimate users and from gaining an opportunity to increase their credibility for future phishing and scamming activities. This work uses textual information provided in LinkedIn profiles and introduces the Section and Subsection Tag Embedding (SSTE) method to enhance the discriminative characteristics of these data for distinguishing between legitimate profiles and those created by imposters manually or by using an LLM. Additionally, the dearth of a large publicly available LinkedIn dataset motivated us to collect 3600 LinkedIn profiles for our research. We release our dataset publicly for research purposes. This is, to the best of our knowledge, the first large publicly available LinkedIn dataset for fake LinkedIn account detection. Within our paradigm, we assess static and contextualized word embeddings, including GloVe, Flair, BERT, and RoBERTa. We show that the suggested method can distinguish between legitimate and fake profiles with an accuracy of about 95% across all word embeddings. In addition, we show that SSTE has a promising accuracy for identifying LLM-generated profiles, despite the fact that no LLM-generated profiles were employed during the training phase, and can achieve an accuracy of approximately 90% when only 20 LLM-generated profiles are added to the training set. It is a significant finding since the proliferation of several LLMs in the near future makes it extremely challenging to design a single system that can identify profiles created with various LLMs. © 2023 ACM.},
	author_keywords = {ChatGPT; Fake accounts; Large language models; LinkedIn; LinkedIn dataset},
	keywords = {Computational linguistics; Fake detection; Large dataset; Social networking (online); User profile; ChatGPT; Embeddings; Fake account; Language model; Large language model; LinkedIn; Linkedin dataset; Novel methods; Platform integrity; Embeddings},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070232-7},
	language = {English},
	abbrev_source_title = {HT - ACM Conf. Hypertext Soc. Media},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Green Open Access}
}

@ARTICLE{2024,
	title = {1st International Artificial Intelligence Conference, IAIC 2023},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2058 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190469519&partnerID=40&md5=8af14603f383455fe126b0c9349f9b05},
	abstract = {The proceedings contain 86 papers. The special focus in this conference is on Artificial Intelligence. The topics include: A Paper Citation Link Prediction Method Using Graph Attention Network; research on Emotional Analysis of Tibetan Short Text Based on Fusion Sentiment Lexicon; A Review of Solving Non-IID Data in Federated Learning: Current Status and Future Directions; a Review of Relationship Extraction Based on Deep Learning; BERT and LLM-Based Multivariate Hate Speech Detection on Twitter: Comparative Analysis and Superior Performance; Deep Learning for Protein-Protein Contact Prediction Using Evolutionary Scale Modeling (ESM) Feature; fedTag: Towards Automated Attack Investigation Using Federated Learning; Deep Learning Based SQL Injection Attack Detection; RSCC: Robust Semi-supervised Learning with Contrastive Learning and Augmentation Consistency Regularization; enhanced Prototypical Network for Few-Shot Named Entity Recognition; Regularized DNN Based Adaptive Compensation Algorithm for Gateway Power Meter in Ultra-High Voltage Substations; Dynamic Occlusion Expression Recognition Based on Improved GAN; Contrastive Learning Based on AMR Graph for Logic Reasoning; automated Detection and Recognition of Wild Dolphin Behaviors Using Deep Learning; M-GFCC: Audio Copy-Move Forgery Detection Algorithm Based on Fused Features of MFCC and GFCC; a Survey of Homogeneous and Heterogeneous Multi-source Information Fusion Based on Rough Set Theory; formula Maintenance of Single Material Tobacco Compatibility Based on Co-formulation Analysis Method; multi-physical Field Collaborative Simulation Optimization Technology and Reliability Analysis of Power Amplifiers; research and Design of Hydrological Data Visualization Based on Digital Twin; Design of Constraint FH-LFM DFRC Waveform; a Construction of IoT Malicious Traffic Dataset and Its Applications; meta-learning Based on Multi-objective Optimization; research and Implementation of Cooperative Utilization of Network Security Devices for Typical Security Events.},
	editor = {Jin H. and Pan Y. and Lu J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-981971276-2},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Singh20241,
	author = {Singh, Bhawna},
	title = {Building Applications with Large Language Models: Techniques, Implementation, and Applications},
	year = {2024},
	journal = {Building Applications with Large Language Models: Techniques, Implementation, and Applications},
	pages = {1 – 280},
	doi = {10.1007/979-8-8688-0569-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004114193&doi=10.1007%2f979-8-8688-0569-1&partnerID=40&md5=51fae1ffafa67312edfd2ea9ab9c5ee2},
	affiliations = {Dublin, Ireland},
	abstract = {This book delves into a broad spectrum of topics, covering the foundational aspects of Large Language Models (LLMs) such as PaLM, LLaMA, BERT, and GPT, among others. The book takes you through the complexities involved in creating and deploying applications based on LLMs, providing you with an in-depth understanding of the model architecture. You will explore techniques such as fine-tuning, prompt engineering, and retrieval augmented generation (RAG). The book also addresses different ways to evaluate LLM outputs and discusses the benefits and limitations of large models. The book focuses on the tools, techniques, and methods essential for developing Large Language Models. It includes hands-on examples and tips to guide you in building applications using the latest technology in Natural Language Processing (NLP). It presents a roadmap to assist you in navigating challenges related to constructing and deploying LLM-based applications. By the end of the book, you will understand LLMs and build applications with use cases that align with emerging business needs and address various problems in the realm of language processing. What You Will Learn Be able to answer the question: What are Large Language Models? Understand techniques such as prompt engineering, fine-tuning, RAG, and vector databases Know the best practices for effective implementation Know the metrics and frameworks essential for evaluating the performance of Large Language Models Who This Book Is For An essential resource for AI-ML developers and enthusiasts eager to acquire practical, hands-on experience in this domain; also applies to individuals seeking a technical understanding of Large Language Models (LLMs) and those aiming to build applications using LLMs. © 2024 by Bhawna Singh.},
	author_keywords = {Artificial Intelligence; Large Language Models; LoRA; Machine Learning; Natural Language Processing; Prompt Engineering; Python},
	keywords = {Computer aided instruction; Education computing; Python; Building applications; Fine tuning; Language model; Language processing; Large language model; LoRA; Machine-learning; Natural language processing; Natural languages; Prompt engineering; Engineering education},
	publisher = {Apress Media LLC},
	isbn = {979-886880569-1; 979-886880568-4},
	language = {English},
	abbrev_source_title = {Building Applications with Large Language Models: Techniques, Implement., and Applications},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Li2024841,
	author = {Li, Hongzheng and Wang, Ruojin and Feng, Chong and Liu, Fang},
	title = {Research on Construction of Corpus for Move Structures in Abstracts of English Scientific Research Articles; [英语科技论文摘要语步结构语料库构建研究]},
	year = {2024},
	journal = {CCL 2024 - 23rd Chinese National Conference on Computational Linguistics},
	volume = {1},
	pages = {841 – 852},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001922196&partnerID=40&md5=30924ff0ff538c0b598d1f7586ee6f9e},
	affiliations = {School of Foreign Languages, Key Laboratory of Language, Cognition and Computation Ministry of Industry and Information Technology, Beijing Institute of Technology, No.9, Liangxiang East Road, Fangshan District, Beijing, China; School of Computer Science, Beijing Institute of Technology, No.5, Zhongguancun South St., Haidian District, Beijing, China},
	abstract = {Move structures are discourse units in research articles (RA) and is of great value in move analysis, essay writing, etc. Although there is abundant research on move structures in academic articles, there are still relatively few move annotation data resources. This research developed and constructed a specific corpus for annotating move structures in English RA abstracts. Currently, nearly 34,000 Move structures have been annotated, covering the fields of Natural Language Processing (NLP), Computer Vision (CV), Communication Engineering and Mechanical Engineering. We also presented annotation statistics and analysis. The first stage of corpus construction relies on manual annotation to form high-quality corpus data. In the second and main stage, an automatic recognition and annotation model based on BERT is adopted, which can improve the annotation speed and expand the annotation scale while ensuring the annotation quality. We conducted move structure recognition experiments based on the constructed corpus, and compared the performance of our model with large language models(LLM) including ChatGPT and Claude3. The experimental results show that the F1 scores of move structure recognition achieved by our model outperformed those of LLM, indicating the effectiveness of the proposed model. This corpus is currently publicly available and can provide necessary data resources for NLP related tasks such as scientific paper information extraction and English writing intelligent assistance, it is also beneficial to foreign language teaching and research such as English for Academic Purposes, it can effectively promote the digital transformation of foreign language education. © 2024 China National Conference on Computational Linguistics.},
	author_keywords = {Abstract; Corpus; Move structure; Research article},
	keywords = {Data acquisition; Data mining; Data transfer; Information retrieval; Metadata; Modeling languages; Natural language processing systems; Abstract; Corpus; Data resources; Language model; Language processing; Move structure; Natural languages; Research article; Scientific researches; Structure recognition; Computational linguistics},
	correspondence_address = {C. Feng; School of Computer Science, Beijing Institute of Technology, Beijing, No.5, Zhongguancun South St., Haidian District, China; email: fengchong@bit.edu.cn},
	editor = {Sun M. and Liang J. and Han X. and Liu Z. and He Y.},
	publisher = {Chinese National Conference on Computational Linguistic (CCL)},
	isbn = {978-000000000-2},
	language = {Chinese},
	abbrev_source_title = {CCL - Chin. Natl. Conf. Comput. Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mannam2023,
	author = {Mannam, Praveen Kumar},
	title = {Optimizing Software Release Management with GPT-Enabled Log Anomaly Detection},
	year = {2023},
	journal = {2023 26th International Conference on Computer and Information Technology, ICCIT 2023},
	doi = {10.1109/ICCIT60459.2023.10441522},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187379675&doi=10.1109%2fICCIT60459.2023.10441522&partnerID=40&md5=04f5e1b66aa76cbdc94b1fffd3b2fa8f},
	affiliations = {Data and Analytics, Business Technology, Dallas, TX, United States},
	abstract = {As software systems become increasingly complex, detecting anomalies in log data is crucial to ensure high performance and stability. In this paper, we propose a novel approach to log anomaly detection using GPT-3 language models. We utilize the word embedding and tokenizer capabilities of GPT-3 to transform log data into a language model that can identify unusual patterns and anomalies. Our proposed method can be integrated with software release management processes to automatically detect anomalies and improve quality control. By leveraging GPT's ability to capture complex patterns and relationships within the data, our approach achieved an accuracy of 99.75%, 99.00%, 98.75%, and 99.33% on real-world datasets of Apache, BGL, HDFS, and Thunderbird respectively, outperforming traditional methods of anomaly detection. Our experimental results on real-world log data demonstrate the effectiveness of our proposed approach, making it a promising tool for software release management teams to streamline their processes and ensure the highest level of system performance and reliability.  © 2023 IEEE.},
	author_keywords = {anomaly detection; BERT; CatBoost; classification; GPT-3; LightGBM; LLM; release management; RF; word embeddings},
	keywords = {Computational linguistics; Embeddings; Human resource management; Information management; Quality control; Software reliability; Anomaly detection; BERT; Catboost; Embeddings; GPT-3; Lightgbm; LLM; Release management; RF; Word embedding; Anomaly detection},
	correspondence_address = {P.K. Mannam; Data and Analytics, Business Technology, Dallas, United States; email: praveenmannam2@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035901-5},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Inf. Technol., ICCIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yerramreddy2023,
	author = {Yerramreddy, Dhanvanth Reddy and Marasani, Jayasurya and Gowtham, Ponnuru Sathwik Venkata and Abhishek, S. and Anjali},
	title = {An Empirical Analysis of Topic Categorization using PaLM, GPT and BERT Models},
	year = {2023},
	journal = {2023 Innovations in Power and Advanced Computing Technologies, i-PACT 2023},
	doi = {10.1109/I-PACT58649.2023.10434768},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186985621&doi=10.1109%2fI-PACT58649.2023.10434768&partnerID=40&md5=2c399d2037cc2c4c0fee0fd75558f9ce},
	affiliations = {Dept. of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Amritapuri, India},
	abstract = {Topic Categorization is a crucial task for organizing and managing information. It is very useful for making it easier to find and retrieve relevant documents. In a mode of digital world filled with information, topic categorization plays pivotal role in many aspects. Numerous number of models were introduced in order to categorize the topics using various datasets whereas PaLM, BERT and GPT models are all large language models (LLM) that have been developed in the recent years. These models can learn the statistical relationships between words and phrases, which allows them to identify the topics that are discussed in a document with greater accuracy. They can also process large amounts of text data quickly, which is important for applications that require real-time topic categorization. Additionally, they are more robust to noise and errors than traditional methods. As these models continue to develop, they are likely to become even more effective at topic categorization. A comparative study has been made among PaLM, BERT and GPT language models for topic categorization using AG News Dataset in this paper. The results are promising and encouraging where the suggested models provides more precise categorization for text of the dataset. © 2023 IEEE.},
	author_keywords = {BERT; Embeddings; GPT; PaLM; Topic Categorization},
	keywords = {Computational linguistics; Embeddings; BERT; Digital world; Embeddings; Empirical analysis; GPT; Language model; Learn+; PaLM; Relevant documents; Topic categorization; Large datasets},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032518-8},
	language = {English},
	abbrev_source_title = {Innov. Power Adv. Comput. Technol., i-PACT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Lotfy2024411,
	author = {Lotfy, Abdelrahman and Saleh, Kirollos and Mohamed, Saher and Lorance, John and Yehia, Ehab and Mohammed, Khaled and AbdAlbaky, Ibrahim and Fathy, Mostafa and Yasser, Tawfik},
	title = {Sentiment Analysis for Arabic Product Reviews using LLMs and Knowledge Graphs},
	year = {2024},
	journal = {6th International Conference on Computing and Informatics, ICCI 2024},
	pages = {411 – 417},
	doi = {10.1109/ICCI61671.2024.10485037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190654881&doi=10.1109%2fICCI61671.2024.10485037&partnerID=40&md5=b8ad8aa0245a60b0f18ae8d33ddfd0f4},
	affiliations = {School of Information Technology and Computer Science (ITCS), Nile University, Giza, Egypt; Faculty of Computers and Artificial Intelligence, Benha University, Egypt; Faculty of Computer Science and Engineering, New Mansoura University, Egypt; Artificial Intelligence Department, Faculty of Computers and Artificial Intelligence, Benha University, Banha, 13518, Egypt},
	abstract = {The exploration of sentiment analysis in multilingual contexts, particularly through the integration of deep learning techniques and knowledge graphs, represents a significant advance in language processing research. This study specifically concentrates on the Arabic language, addressing the challenges presented by its morphological complexity. While the primary focus is Arabic, the research also includes a comprehensive review of related work in other languages such as Bangla and Chinese. This contextualizes the challenges and solutions found in Arabic sentiment analysis within a broader multilingual landscape. Utilizing pre-trained language models like BERT, the research has achieved noteworthy improvements in sentiment analysis accuracy and efficiency, particularly for the Arabic language. The integration of knowledge graphs stands out as a crucial innovation, offering essential contextual insights and mitigating the limitations posed by sparse labeled datasets in Arabic, a language less resourced compared to English. The findings of this study highlight the effectiveness of tailored BERT models for Arabic sentiment analysis, revealing the vast potential and inherent challenges of employing knowledge graphs and large language models for a deeper, more nuanced understanding. The future direction of this research includes enhancing these methods with cutting-edge machine learning techniques, aiming to further refine sentiment analysis processes and knowledge graph construction with a focus on Arabic within a multilingual framework. © 2024 IEEE.},
	author_keywords = {Arabic; Big Data; Knowledge Graph; LLMs; Sentiment Analysis},
	keywords = {Big data; Computational linguistics; Deep learning; Graphic methods; Knowledge graph; Learning algorithms; Learning systems; Arabic; Arabic languages; Knowledge graphs; Language model; Language processing; Learning techniques; LLM; Multilingual context; Product reviews; Sentiment analysis; Sentiment analysis},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037387-5},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Informatics, ICCI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Miyashita2024246,
	author = {Miyashita, Tensho and Shoji, Yoshiyuki and Fujita, Sumio and Durst, Martin J.},
	title = {BERT-Based Movie Keyword Search Leveraging User-Generated Movie Rankings and Reviews},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Big Data and Smart Computing, BigComp 2024},
	pages = {246 – 253},
	doi = {10.1109/BigComp60711.2024.00046},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191513587&doi=10.1109%2fBigComp60711.2024.00046&partnerID=40&md5=d13b289b5657af7db1d278edf52e7672},
	affiliations = {Graduate School of Science and Engineering, Aoyama Gakuin University, Kanagawa, Japan; Shizuoka University, Faculty of Informatics, Shizuoka, Japan; Ly Corporation, Tokyo, Japan; College of Science and Engineering, Aoyama Gakuin University, Kanagawa, Japan},
	abstract = {This paper introduces a novel method for movie keyword searches based on user-generated rankings and reviews. We utilize the capabilities of the BERT language model, which has been enriched with task-specific fine-tuning. The model is trained to understand the relationship between keywords and movies using paired user-generated ranking titles and movie reviews. We sourced our data from a renowned Japanese movie review platform. This dataset comprises 10,000 user rankings and 15,000 films. In a binary classification task, our model demonstrated superior performance compared to traditional similarity-based methods. While our approach outperforms traditional similarity methods, further improvements in pooling techniques are necessary.  © 2024 IEEE.},
	author_keywords = {LLM; Movie Search; Ranking; Review; User Generated Contents},
	keywords = {Motion pictures; Keyword search; Language model; LLM; Movie reviews; Movie search; Novel methods; Ranking; Search-based; User generated content; User-generated; Search engines},
	editor = {Unger H. and Chae J. and Lee Y.-K. and Wagner C. and Wang C. and Bennis M. and Ketcham M. and Suh Y.-K. and Kwon H.-Y.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835037002-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data Smart Comput., BigComp},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Patil2024262,
	author = {Patil, Avinash and Han, Kihwan and Jadon, Aryan},
	title = {A Comparative Analysis of Text Embedding Models for Bug Report Semantic Similarity},
	year = {2024},
	journal = {Proceedings - 11th International Conference on Signal Processing and Integrated Networks, SPIN 2024},
	pages = {262 – 267},
	doi = {10.1109/SPIN60856.2024.10512000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193785777&doi=10.1109%2fSPIN60856.2024.10512000&partnerID=40&md5=3dd9d685c851c8f85c0fe7b930188c87},
	affiliations = {Juniper Networks, Sunnyvale, United States},
	abstract = {Bug reports are an essential aspect of software development, and it is crucial to identify and resolve them quickly to ensure the consistent functioning of software systems. Retrieving similar bug reports from an existing database can help reduce the time and effort required to resolve bugs. In this paper, we compared the effectiveness of semantic textual similarity methods for retrieving similar bug reports based on a similarity score. We explored several embedding models such as TF-IDF (Baseline), FastText, Gensim, BERT, and ADA. We used the Software Defects Data containing bug reports for various software projects to evaluate the performance of these models. Our experimental results showed that BERT generally outperformed the rest of the models regarding recall, followed by ADA, Gensim, FastText, and TFIDF. Our study provides insights into the effectiveness of different embedding methods for retrieving similar bug reports and highlights the impact of selecting the appropriate one for this task. Our code is available on GitHub.  © 2024 IEEE.},
	author_keywords = {ADA; BERT; Bug Reports; Defect Reports; Duplicate Detection; Embeddings; FastText; Gensim; GPT3; GPT3.5; Information Retrieval; Large Language Models; LLM; Natural Language Processing; Sentence Textual Similarity; Similarity Search},
	keywords = {Ada (programming language); Defects; Embeddings; Natural language processing systems; Software design; ADA; BERT; Bug reports; Defect reports; Duplicate detection; Embeddings; Fasttext; Gensim; GPT3; Gpt3.5; Language model; Language processing; Large language model; LLM; Natural language processing; Natural languages; Sentence textual similarity; Similarity search; Textual similarities; Semantics},
	correspondence_address = {A. Patil; Juniper Networks, Sunnyvale, United States; email: patila@juniper.net},
	editor = {Shukla A.K.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030843-3},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Signal Process. Integr. Networks, SPIN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Scanlon2023,
	author = {Scanlon, Mark and Breitinger, Frank and Hargreaves, Christopher and Hilgert, Jan-Niclas and Sheppard, John},
	title = {ChatGPT for digital forensic investigation: The good, the bad, and the unknown},
	year = {2023},
	journal = {Forensic Science International: Digital Investigation},
	volume = {46},
	doi = {10.1016/j.fsidi.2023.301609},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175350369&doi=10.1016%2fj.fsidi.2023.301609&partnerID=40&md5=29d86465cb0df4623f2c0dde34d7cc76},
	affiliations = {Forensics and Security Research Group, School of Computer Science, University College Dublin, Ireland; School of Criminal Justice, University of Lausanne, Lausanne, Switzerland; Department of Computer Science, University of Oxford, United Kingdom; Fraunhofer FKIE, Bonn, Germany; Department of Computing and Mathematics, South East Technological University, Waterford, Ireland},
	abstract = {The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of domains has become a topic of much discussion in the scientific community and society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take instructions, or prompts, from users and generate answers and solutions based on very large volumes of text-based training data. This paper assesses the impact and potential impact of ChatGPT on the field of digital forensics, specifically looking at its latest pre-trained LLM, GPT-4. A series of experiments are conducted to assess its capability across several digital forensic use cases including artefact understanding, evidence searching, code generation, anomaly detection, incident response, and education. Across these topics, its strengths and risks are outlined and a number of general conclusions are drawn. Overall this paper concludes that while there are some potential low-risk applications of ChatGPT within digital forensics, many are either unsuitable at present, since the evidence would need to be uploaded to the service, or they require sufficient knowledge of the topic being asked of the tool to identify incorrect assumptions, inaccuracies, and mistakes. However, to an appropriately knowledgeable user, it could act as a useful supporting tool in some circumstances. © 2023 The Author(s)},
	author_keywords = {Artificial intelligence; ChatGPT; Digital forensics; Generative pre-trained transformers (GPT); Large language models (LLM)},
	keywords = {Anomaly detection; Computational linguistics; Computer crime; Electronic crime countermeasures; Risk perception; ChatGPT; Forensic investigation; Generative pre-trained transformer; Language model; Large language model; Large volumes; Potential impacts; Scientific community; Scientific society; Training data; Digital forensics},
	correspondence_address = {M. Scanlon; Forensics and Security Research Group, School of Computer Science, University College Dublin, Ireland; email: mark.scanlon@ucd.ie},
	publisher = {Elsevier Ltd},
	issn = {26662825},
	language = {English},
	abbrev_source_title = {For. Sci. Int: Dig. Investigation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 52; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Mehta2024,
	author = {Mehta, Harsh and Kumar Bharti, Santosh and Doshi, Nishant},
	title = {Comparative Analysis of Part of Speech(POS) Tagger for Gujarati Language using Deep Learning and Pre-Trained LLM},
	year = {2024},
	journal = {2024 3rd International Conference for Innovation in Technology, INOCON 2024},
	doi = {10.1109/INOCON60754.2024.10511678},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193627486&doi=10.1109%2fINOCON60754.2024.10511678&partnerID=40&md5=62da0f8bdeb53328b1dd2006a353881c},
	affiliations = {Pandit Deendayal Energy University, Computer Engineering, Gandhinagar, India},
	abstract = {Part of the Speech tagger takes the language word and tags it with grammar tags like nouns, verbs, and adjectives. Part of Speech Tagger(POS) is an important and useful aspect of Natural Language Processing(NLP).POS tagger is mature enough for the English language but much work needs to be done for the low-resource languages.POS tagging helps to understand the morphology of a particular language. We have applied the pre-trained LLM model BERT, RNN, LSTM, BiLSTM, and NLTK's prebuilt method on the Gujarati dataset for the comparative analysis. A major chunk of the Gujarati dataset was collected from the online source while some of the tagging tasks we have performed, totaling 29813 sentences and their tags were collected.RNN, LSTM surpasses the BERT and gives good accuracy because the BERT LLM is not trained on the Part of Speech Tagging task. Recurrent Neural Network(RNN) gives the highest accuracy which accounts for 98.02% as BERT gives 88% accuracy. © 2024 IEEE.},
	author_keywords = {BERT POS tagger; Gujarati POS tagger; NLTK; Part of Speech tagging; RNN POS tagger},
	keywords = {Long short-term memory; Natural language processing systems; Syntactics; BERT part of speech tag; Gujarati part of speech tag; NLTK; Part of speech tagging; Part-of-speech tagger; Part-of-speech tags; Parts-of-speech tagging; Recurrent neural network part of speech tag; Computational linguistics},
	correspondence_address = {H. Mehta; Pandit Deendayal Energy University, Computer Engineering, Gandhinagar, India; email: harshhp8@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038193-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Innov. Technol., INOCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{De Renzis202425,
	author = {De Renzis, Simone and Dosso, Dennis and Testolin, Alberto},
	title = {Exploiting Large Language Models to Train Automatic Detectors of Sensitive Data},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3643},
	pages = {25 – 33},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186145176&partnerID=40&md5=65180f473767e150704feae6341f76f3},
	affiliations = {Department of Mathematics, University of Padova, Italy; Siav S.p.A., Italy; Department of General Psychology, University of Padova, Italy},
	abstract = {This paper describes a machine learning system designed to identify sensitive data within Italian text documents, aligning with the definitions and regulations outlined in the General Data Protection Regulation (GDPR). To overcome the lack of suitable training datasets, which would require the disclosure of sensitive data from real users, the proposed system exploits a Large Language Model (LLM) to generate synthetic documents that can be used to train supervised classifiers to detect the target sensitive data. We show that “artificial” sensitive data can be generated using both proprietary or open source LLMs, demonstrating that the proposed approach can be implemented either using external services or by relying on locally runnable models. We focus on the detection of six key domains of sensitive data, by training supervised classifiers based on the BERT Transformer architecture adapted to carry out text classification and Named-Entity Recognition (NER) tasks. We evaluate the performance of the system using fine-grained metrics, and show that the NER model can achieve a remarkable detection performance (over 90% F1 score), thus confirming the quality of the synthetic datasets generated with both proprietary and open source LLMs. The dataset we generated using the open source model is made publicly available for download. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT; Generative Artificial Intelligence; LLM; NER; Sensitive data detection},
	keywords = {Artificial intelligence; Character recognition; Classification (of information); Computational linguistics; Large datasets; Learning systems; Natural language processing systems; Text processing; BERT; Data-detection; Generative artificial intelligence; Language model; Large language model; Named entity recognition; Open-source; Sensitive data detection; Sensitive datas; Supervised classifiers; Sensitive data},
	editor = {Bernasconi E. and Mannocci A. and Poggi A. and Salatino A. and Silvello G.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gao2024,
	author = {Gao, Zhenyu and Ni, Qin and Liu, Wen and Zhang, Lei},
	title = {A LLMs-Assisted Framework for Parkinson's Disease Assessment Based on PPMI Dataset},
	year = {2024},
	journal = {ACAI 2024 - 2024 7th International Conference on Algorithms, Computing and Artificial Intelligence},
	doi = {10.1109/ACAI63924.2024.10899636},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000751322&doi=10.1109%2fACAI63924.2024.10899636&partnerID=40&md5=d452c1b5770633dd8ed4d6c2016fe8cb},
	affiliations = {College of Information Science and Technology, Donghua University, Shanghai, China; Shanghai International Studies University, The Key Laboratory of Multilingual Education with AI, Shanghai, China},
	abstract = {The assessment of diseases such as Parkinson's disease, which are chronic neurodegenerative conditions, is an extremely complex and time-consuming process. Self-assessment scales or interviews in the outpatient often lead to the loss of key information. Large Language Models (LLMs) show abilities in capturing subtle linguistic differences and handling long texts, enabling the extraction of a significant amount of key information while ensuring data integrity and user privacy. We focus attention on people with Parkinson's disease (PwP). In response to these issues, we propose a framework in this paper. Firstly, we use large language model (LLM) with chain-of-thought (CoT) prompt to rephrase patient self-report texts from real-outpatient structured data as a supervised fine-tuning (SFT) corpus. Secondly, we fine-tune bidirectional encoder representation from transformers (BERT) with Low-Rank Adaptation (LoRA) to enable it to under-stand and extract the semanteme of self-report, thus predicting each MDS-UPDRS item. Finally, we designed experiments on a large amount of test data to evaluate the effectiveness of the framework. The results indicate that the accuracy on this task has been improved to 95.36%, which is a 6.7% increase compared to the best-performing model.  © 2024 IEEE.},
	author_keywords = {BERT; Healthcare; Large language models; Parkinson's disease; Supervised Fine-Tuning},
	keywords = {Data privacy; Hospital data processing; Network security; Bidirectional encoder representation from transformer; Condition; Fine tuning; Healthcare; Language model; Large language model; Neurodegenerative; Parkinson's disease; Self-assessment; Supervised fine-tuning; Neurodegenerative diseases},
	editor = {Wang Z.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833152931-4},
	language = {English},
	abbrev_source_title = {ACAI - Int. Conf. Algorithms, Comput. Artif. Intell.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Joint Workshop on Multiword Expressions and Universal Dependencies, MWE-UD 2024 at LREC-COLING 2024 - Workshop Proceedings},
	year = {2024},
	journal = {Joint Workshop on Multiword Expressions and Universal Dependencies, MWE-UD 2024 at LREC-COLING 2024 - Workshop Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195169397&partnerID=40&md5=ee3deb9ad6356e04d21f9fb119e542ec},
	abstract = {The proceedings contain 25 papers. The topics discussed include: every time we hire an LLM, the reasoning performance of the linguists goes up; using universal dependencies for testing hypotheses about communicative efficiency; automatic manipulation of training corpora to make parsers accept real-world text; assessing BERT’s sensitivity to idiomaticity; identification and annotation of body part multiword expressions in old Egyptian; synthetic-error augmented parsing of Swedish as a second language: experiments with word order; the Vedic compound dataset; overcoming early saturation on low-resource languages in multilingual dependency parsing; diachronic analysis of multi-word expression functional categories in scientific English; and towards the semantic annotation of SR-ELEXIS corpus: insights into multiword expressions and named entities.},
	editor = {Bhatia A. and Bouma G. and Dogruoz A.S. and Evang K. and Garcia M. and Giouli V. and Han L. and Nivre J. and Rademacher A.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381420-3},
	language = {English},
	abbrev_source_title = {Jt. Workshop Multiword Expressions Univers. Depend., MWE-UD LREC-COLING - Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Insuasti2023,
	author = {Insuasti, Jesus and Roa, Felipe and Zapata-Jaramillo, Carlos Mario},
	title = {Computers’ Interpretations of Knowledge Representation Using Pre-Conceptual Schemas: An Approach Based on the BERT and Llama 2-Chat Models},
	year = {2023},
	journal = {Big Data and Cognitive Computing},
	volume = {7},
	number = {4},
	doi = {10.3390/bdcc7040182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180700331&doi=10.3390%2fbdcc7040182&partnerID=40&md5=080cbde132b1783b7bf6bcb375a73c3e},
	affiliations = {Systems Engineering Department, University of Nariño, Pasto, 520001, Colombia; Computer and Decision Science Department, Universidad Nacional de Colombia, Medellín, 050034, Colombia},
	abstract = {Pre-conceptual schemas are a straightforward way to represent knowledge using controlled language regardless of context. Despite the benefits of using pre-conceptual schemas by humans, they present challenges when interpreted by computers. We propose an approach to making computers able to interpret the basic pre-conceptual schemas made by humans. To do that, the construction of a linguistic corpus is required to work with large language models—LLM. The linguistic corpus was mainly fed using Master’s and doctoral theses from the digital repository of the University of Nariño to produce a training dataset for re-training the BERT model; in addition, we complement this by explaining the elicited sentences in triads from the pre-conceptual schemas using one of the cutting-edge large language models in natural language processing: Llama 2-Chat by Meta AI. The diverse topics covered in these theses allowed us to expand the spectrum of linguistic use in the BERT model and empower the generative capabilities using the fine-tuned Llama 2-Chat model and the proposed solution. As a result, the first version of a computational solution was built to consume the language models based on BERT and Llama 2-Chat and thus automatically interpret pre-conceptual schemas by computers via natural language processing, adding, at the same time, generative capabilities. The validation of the computational solution was performed in two phases: the first one for detecting sentences and interacting with pre-conceptual schemas with students in the Formal Languages and Automata Theory course—the seventh semester of the systems engineering undergraduate program at the University of Nariño’s Tumaco campus. The second phase was for exploring the generative capabilities based on pre-conceptual schemas; this second phase was performed with students in the Object-oriented Design course—the second semester of the systems engineering undergraduate program at the University of Nariño’s Tumaco campus. This validation yielded favorable results in implementing natural language processing using the BERT and Llama 2-Chat models. In this way, some bases were laid for future developments related to this research topic. © 2023 by the authors.},
	author_keywords = {computational linguistics; language models; linguistic corpus; pre-conceptual schema},
	keywords = {Computational linguistics; Curricula; Formal languages; Large dataset; Modeling languages; Natural language processing systems; Students; Computational solutions; Conceptual schemas; Engineering undergraduates; Language model; Language processing; Linguistic corpus; Natural languages; Pre-conceptual schema; Second phase; Undergraduate projects; Knowledge representation},
	correspondence_address = {J. Insuasti; Systems Engineering Department, University of Nariño, Pasto, 520001, Colombia; email: insuasti@udenar.edu.co},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {25042289},
	language = {English},
	abbrev_source_title = {Big Data Cogn. Computing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Tamekuri2024466,
	author = {Tamekuri, Atsuki and Yamaguchi, Saneyasu},
	title = {Provide Interpretability of Document Classification by Large Language Models Based on Word Masking},
	year = {2024},
	journal = {Journal of Information Processing},
	volume = {32},
	pages = {466 – 470},
	doi = {10.2197/ipsjjip.32.466},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195573334&doi=10.2197%2fipsjjip.32.466&partnerID=40&md5=c6a99829098bb858b4ff786f98ac7458},
	affiliations = {Kogakuin University, Shinjuku, Tokyo, 163–8677, Japan},
	abstract = {Deep neural networks have greatly improved natural language processing and text analysis technologies. In particular, pre-trained large language models have achieved significant improvement. However, it has been argued that they are black boxes and that it is important to provide interpretability. In our previous work, we focused on self-attention and proposed methods for providing and evaluating interpretability. However, the work did not use large language models, and the evaluation method used unusual sentences by deleting words. In this paper, we focus on BERT, which is a popular large language model, and its masking function instead of deleting words. We then show a problem of using this masking function to provide interpretability, which is that the mask token is not neutral for decision. We then propose an evaluation method based on this masking function with training to learn that the mask token is neutral. © 2024 Information Processing Society of Japan.},
	author_keywords = {Attention; BERT; deep learning; LLM; news documents classification; word masking},
	correspondence_address = {A. Tamekuri; Kogakuin University, Tokyo, Shinjuku, 163–8677, Japan; email: cm22031@g.kogakuin.jp},
	publisher = {Information Processing Society of Japan},
	issn = {18826652},
	language = {English},
	abbrev_source_title = {J. Info. Process.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kosonocky2023,
	author = {Kosonocky, Clayton W. and Feller, Aaron L. and Wilke, Claus O. and Ellington, Andrew D.},
	title = {Using alternative SMILES representations to identify novel functional analogues in chemical similarity vector searches},
	year = {2023},
	journal = {Patterns},
	volume = {4},
	number = {12},
	doi = {10.1016/j.patter.2023.100865},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176934724&doi=10.1016%2fj.patter.2023.100865&partnerID=40&md5=760f94a3a4a1c1851a506ee88d34e001},
	affiliations = {Department of Molecular Biosciences, University of Texas at Austin, Austin, 78705, TX, United States; Department of Integrative Biology, University of Texas at Austin, Austin, 78705, TX, United States; Center for Systems and Synthetic Biology, University of Texas at Austin, Austin, 78705, TX, United States},
	abstract = {Chemical similarity searches are a widely used family of in silico methods for identifying pharmaceutical leads. These methods historically relied on structure-based comparisons to compute similarity. Here, we use a chemical language model to create a vector-based chemical search. We extend previous implementations by creating a prompt engineering strategy that utilizes two different chemical string representation algorithms: one for the query and the other for the database. We explore this method by reviewing search results from nine queries with diverse targets. We find that the method identifies molecules with similar patent-derived functionality to the query, as determined by our validated LLM-assisted patent summarization pipeline. Further, many of these functionally similar molecules have different structures and scaffolds from the query, making them unlikely to be found with traditional chemical similarity searches. This method may serve as a new tool for the discovery of novel molecular structural classes that achieve target functionality. © 2023 The Authors},
	author_keywords = {BERT; canonicalization; chemical similarity search; drug discovery; DSML 2: Proof-of-concept: Data science output has been formulated, implemented, and tested for one domain/problem; machine learning; prompt engineering; SMILES; transformer; vector search},
	keywords = {Machine learning; Patents and inventions; Query processing; Scaffolds; BERT; Canonicalization; Chemical similarity; Chemical similarity search; Domain problems; Drug discovery; DSML 2: proof-of-concept: data science output have been formulated, implemented, and tested for one domain/problem; Machine-learning; Prompt engineering; Proof of concept; Similarity search; SMILES; Transformer; Vector search; Molecules},
	correspondence_address = {C.O. Wilke; Department of Integrative Biology, University of Texas at Austin, Austin, 78705, United States; email: wilke@austin.utexas.edu},
	publisher = {Cell Press},
	issn = {26663899},
	language = {English},
	abbrev_source_title = {Patterns},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Chinnalagu2024255,
	author = {Chinnalagu, Anandan},
	title = {Comparative Analysis of Fine-Tuned LLM, BERT and DL Models for Customer Sentiment Analysis},
	year = {2024},
	journal = {Proceedings of the 2024 13th International Conference on System Modeling and Advancement in Research Trends, SMART 2024},
	pages = {255 – 259},
	doi = {10.1109/SMART63812.2024.10882546},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000009858&doi=10.1109%2fSMART63812.2024.10882546&partnerID=40&md5=6bb2fe448752a1e80c1df8132506d2af},
	affiliations = {CanString Ai, AI 3120 De La Cruz Blvd, Suite 106, Santa Clara, CA, United States},
	abstract = {The fine-tuned Large Language Models such as Generative Pre-Trained Transformers (GPT), Google's and BERT models are leveraged for NLP tasks. The online businesses are relying on customers' online review posting and positive feedback to improve the products sales and services. To predict the accurate emotion and sentiment of the customers remains challenging. There are literatures and sentiment models' research studies show that the traditional models are having performance and accuracy issues. To overcome the sentiment prediction accuracy and model performance issues, author propose the fine-tuned Mistral LLM and BERT models. These models' experimental study results show that fine-tuned LLM outperforms traditional models, and it predicts more accurate sentiments of the customers.  © 2024 IEEE.},
	author_keywords = {Generative PreTrained Transformers; GPT; Large Language Model; LLM; Long Short-Term Memory; LSTM; Sentiment Analysis (SA)},
	keywords = {Distribution transformers; Prediction models; Problem oriented languages; Generative pre-trained transformer; Generative pretrained transformer; Language model; Large language model; LLM; LSTM; Sentiment analysis; Sentiment analyze; Short term memory; Traditional models; Sales},
	correspondence_address = {A. Chinnalagu; CanString Ai, Santa Clara, AI 3120 De La Cruz Blvd, Suite 106, United States; email: anandanc@hotmail.com},
	editor = {Dwivedi R.K. and Saxena A.Kr. and Sharma R. and Bhardwaj S. and Gupta R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038058-3},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Syst. Model. Adv. Res. Trends, SMART},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cartier202412,
	author = {Cartier, Emmanuel and Tanev, Hristo},
	title = {Event Detection in the Socio Political Domain},
	year = {2024},
	journal = {2nd Workshop on Natural Language Processing for Political Sciences, PoliticalNLP 2024 at LREC-COLING 2024- Proceedings},
	pages = {12 – 21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195120638&partnerID=40&md5=e519ddcee6078f7fd49f259413349466},
	affiliations = {European Commission, Joint Research Center, Via Enrico Fermi, 2749, VA, Ispra, 21027, Italy},
	abstract = {In this paper we present two approaches for detection of socio political events: the first is based on manually crafted keyword combinations, and is implemented inside the NEXUS event extraction system, and the second one is based on a BERT classifier. We compare the performance of the two systems on a dataset of socio-political events. We also evaluated only NEXUS on the ACLED event dataset, in order to show the effects of taxonomy mapping and the performance of rule based approaches. Interestingly, both systems demonstrate complementary performance. Both showing their best performance on different event type sets. Nevertheless, an LLM data augmented dataset shows that in this case the transformer-based system improves considerably. We also review in the related work section the most important resources and approaches for event extraction in the recent years. © 2024 ELRA Language Resource Association.},
	keywords = {Event Types; Events detection; Events extractions; Extraction systems; Performance; Political events; Related works; Rule-based approach; Taxonomy mappings; Extraction},
	editor = {Afli H. and Bouamor H. and Casagran C.B. and Ghannay S.},
	publisher = {European Language Resources Association (ELRA)},
	isbn = {978-249381426-5},
	language = {English},
	abbrev_source_title = {Workshop Nat. Lang. Process. Political Sci., PoliticalNLP at LREC-COLING - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sharma2024970,
	author = {Sharma, Simple and Panda, Supriya P.},
	title = {Performance Metrics Analysis for Deep Learning Models},
	year = {2024},
	journal = {2024 2nd International Conference on Advances in Computation, Communication and Information Technology, ICAICCIT 2024},
	pages = {970 – 976},
	doi = {10.1109/ICAICCIT64383.2024.10912181},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001342750&doi=10.1109%2fICAICCIT64383.2024.10912181&partnerID=40&md5=d71a42b215cd4fb86ed6b0529db36248},
	affiliations = {School of Engineering and Technology (SET), Manav Rachna International Institute of Research and Studies (MRIIRS), Department of Computer Science and Engineering, Faridabad, India},
	abstract = {Evaluating an Information Retrieval (IR) model is a multi-faceted process that requires selecting the right quantitative metrics to assess performance. The selection of evaluation metrics in IR depends on specific tasks, relevant standards, and desired characteristics. To thoroughly assess an IR system's performance, a combination of metrics is necessary. This study explores the effectiveness of deep learning (DL) models in semantic and personalized information retrieval (SIR), focusing on BERT and other large language models (LLMs) that provide context-sensitive embeddings and advanced language comprehension capabilities. Through a detailed analysis, this paper demonstrates how DL models can significantly enhance accuracy and relevance in IR, using evaluation metrics critical for assessing model performance. Metrics like recall, precision, and F1-score are key in capturing model accuracy and coverage; for example, a recall of 1.0 indicates complete retrieval of relevant instances, while a precision of 0.6 reflects a 60% accuracy in positive predictions, balancing these measures at an F1-score of 46.15%. Ranking and prioritization metrics, such as Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (NDCG), evaluated at 91.67% and 95.1%, respectively highlight the models' capabilities in prioritizing relevant results effectively. In personalized and semantic search, selecting the right evaluation metrics is essential to maximize DL model potential and improve the user experience. Recent LLM advancements, like GPT-4, are instrumental in capturing nuanced meanings and understanding complex user queries, which enhances the accuracy of search engines. Continuous optimization of these models through tailored metrics can improve IR systems' contextual relevance and accuracy, fostering greater user satisfaction. © 2024 IEEE.},
	author_keywords = {BERT; Deep Learning Models; Evaluation; Metrics; Ontology; Personalized IR; Semantic IR; Transformer Models; User Profiling},
	keywords = {Adversarial machine learning; Data accuracy; Deep learning; Deep reinforcement learning; Federated learning; Information retrieval; Semantics; BERT; Deep learning model; Evaluation; Learning models; Metric; Ontology's; Personalized information retrieval; Semantic information retrieval; Transformer modeling; User's profiling; Contrastive Learning},
	correspondence_address = {S. Sharma; School of Engineering and Technology (SET), Manav Rachna International Institute of Research and Studies (MRIIRS), Department of Computer Science and Engineering, Faridabad, India; email: simple.fet@mriu.edu.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-833154121-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Adv. Comput., Commun. Inf. Technol., ICAICCIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jeong2024280,
	author = {Jeong, Jaehan and Jin, Dongsup},
	title = {Automatic Classification of Scientific and Technical Papers Using Large Language Models and Retrieval-Augmented Generation},
	year = {2024},
	journal = {Journal of Information and Communication Convergence Engineering},
	volume = {22},
	number = {4},
	pages = {280 – 287},
	doi = {10.56977/jicce.2024.22.4.280},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001363553&doi=10.56977%2fjicce.2024.22.4.280&partnerID=40&md5=0a54bcaef2901a9c819643483892384e},
	affiliations = {Department of IT Convergence, University of Ulsan, 44610, South Korea},
	abstract = {This study proposes artificial intelligence (AI) technology for the automatic classification of Korean scientific and technical papers, aiming to achieve high accuracy even with a small amount of labeled data. Unlike existing BERT-based Korean document classification models that perform supervised learning based on a large amount of accurately labeled data, this study proposes a structure that utilize large language models (LLMs) and retrieval-augmented generation (RAG) technology. The proposed method experimentally demonstrates that it can achieve higher accuracy than existing technologies across all cases using various amounts of labeled data. Furthermore, a qualitative comparison between manually-generated labels, and recognized as correct answers and those produced by LLM responses confirmed that the LLM responses were more accurate. The findings of this study, while limited to Korean scientific documents, provide evidence that a system utilizing LLM and RAG for document classification can easily be extended to other domains with diverse document datasets, owing to its effectiveness even with limited labels. © The Korea Institute of Information and Communication Engineering},
	author_keywords = {BERT; Document classification; Large language model (LLM); Retrieval-augmented generation (RAG); Vector database (DB)},
	correspondence_address = {D. Jin; Department of IT Convergence, University of Ulsan, 44610, South Korea; email: dsjin@ulsan.ac.kr},
	publisher = {Korea Institute of Information and Communication Engineering},
	issn = {22348255},
	language = {English},
	abbrev_source_title = {J. Inf. Commun. Converg. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@ARTICLE{2023,
	title = {12th National CCF Conference on Natural Language Processing and Chinese Computing, NLPCC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14303 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174742706&partnerID=40&md5=33efe130cb973fd16f291329b3c1a9b8},
	abstract = {The proceedings contain 169 papers. The special focus in this conference is on National CCF Conference on Natural Language Processing and Chinese Computing. The topics include: Improving Few-Shot and Zero-Shot Entity Linking with Coarse-to-Fine Lexicon-Based Retriever; GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning; A Study on the Classification of Chinese Medicine Records Using BERT, Chest Impediment as an Example; A Two-Stage Chinese Medical Video Retrieval Framework with LLM; conversational Aspect-Based Sentiment Quadruple Analysis with Consecutive Multi-view Interaction; solving Math Word Problem with Problem Type Classification; preface; fantastic Gradients and Where to Find Them: Improving Multi-attribute Text Style Transfer by Quadratic Program; a Numeracy-Enhanced Decoding for Solving Math Word Problem; consistent Solutions for Optimizing Search Space of Beam Search; improving Conversational Aspect-Based Sentiment Quadruple Analysis with Overall Modeling; a Model Ensemble Approach for Conversational Quadruple Extraction; enhancing Conversational Aspect-Based Sentiment Quadruple Analysis with Context Fusion Encoding Method; a Unified Framework for Optimizing Video Corpus Retrieval and Temporal Answer Grounding: Fine-Grained Modality Alignment and Local-Global Optimization; TiBERT: A Non-autoregressive Pre-trained Model for Text Editing; improving Cross-Modal Visual Answer Localization in Chinese Medical Instructional Video Using Language Prompts; two-Stage Topic Sentence Extraction for Chinese Student Essays; multi-angle Prediction Based on Prompt Learning for Text Classification; task-Related Pretraining with Whole Word Masking for Chinese Coherence Evaluation; towards Robust Chinese Spelling Check Systems: Multi-round Error Correction with Ensemble Enhancement; Overview of the NLPCC 2023 Shared Task: Chinese Spelling Check; user Preference Prediction for Online Dialogue Systems Based on Pre-trained Large Model; auto-scaling Distribution Fitting Network for User Feedback Prediction; adversarial Training and Model Ensemble for User Feedback Prediciton in Conversation System; generating Better Responses from User Feedback via Reinforcement Learning and Commonsense Inference; semantic Candidate Retrieval for Few-Shot Entity Linking.},
	editor = {Liu F. and Duan N. and Xu Q. and Hong Y.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303144695-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gunasekaran2023449,
	author = {Gunasekaran, Karthick Prasad and Chase, Babrich and Shirodkar, Saurabh and Hwang, Hee},
	title = {Text2Time: Transformer-based Article Time Period Prediction},
	year = {2023},
	journal = {2023 IEEE 6th International Conference on Pattern Recognition and Artificial Intelligence, PRAI 2023},
	pages = {449 – 455},
	doi = {10.1109/PRAI59366.2023.10331985},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180531871&doi=10.1109%2fPRAI59366.2023.10331985&partnerID=40&md5=16afcb073c6d430be6a58d1db536c0b4},
	affiliations = {University of Massachusetts, Amherst, United States},
	abstract = {The prediction of the publication period of textual documents, such as news articles, represents a significant and relatively understudied problem within the realm of natural language processing. Determining the year in which a news article was published holds relevance in various domains, including historical research, sentiment analysis, and media monitoring. In this research, our focus is on investigating the prediction of publication periods specifically for news articles, leveraging their textual content. To tackle this challenge, we curated an extensive labeled dataset consisting of over 350,000 news articles published by The New York Times over a span of six decades. This dataset forms the foundation of our investigation. Our approach involves utilizing a pretrained BERT model that has been fine-Tuned for the task of text classification, specifically tailored for time period prediction. The performance of our model surpasses our initial expectations, demonstrating impressive results in accurately classifying news articles into their respective publication decades. Through rigorous evaluation, our model outperforms the baseline model for this relatively unexplored task of predicting time periods based on textual content. This research sheds light on the potential for effectively predicting the publication periods of news articles and presents promising outcomes achieved by leveraging a pretrained BERT model fine-Tuned for time period classification. The results obtained contribute to the advancement of this underexplored task, demonstrating the viability and accuracy of time prediction from textual data.  © 2023 IEEE.},
	author_keywords = {article time; Bert; LLM; NLP; NYTimes},
	keywords = {Classification (of information); Publishing; Sentiment analysis; Article time; Bert; Language processing; LLM; Natural languages; News articles; Nytime; Textual content; Textual documents; Time-periods; Forecasting},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032548-5},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Pattern Recognit. Artif. Intell., PRAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Yuan20231256,
	author = {Yuan, Shuzhou and Färber, Michael},
	title = {Evaluating Generative Models for Graph-to-Text Generation},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {1256 – 1264},
	doi = {10.26615/978-954-452-092-2_133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172438721&doi=10.26615%2f978-954-452-092-2_133&partnerID=40&md5=635ba4a8fe579664b6721be5ea897219},
	affiliations = {Karlsruhe Institute of Technology (KIT), Germany},
	abstract = {Large language models (LLMs) have been widely employed for graph-to-text generation tasks. However, the process of finetuning LLMs requires significant training resources and annotation work. In this paper, we explore the capability of generative models to generate descriptive text from graph data in a zeroshot setting. Specifically, we evaluate GPT-3 and ChatGPT on two graph-to-text datasets and compare their performance with that of finetuned LLM models such as T5 and BART. Our results demonstrate that generative models are capable of generating fluent and coherent text, achieving BLEU scores of 10.57 and 11.08 for the AGENDA and WebNLG datasets, respectively. However, our error analysis reveals that generative models still struggle with understanding the semantic relations between entities, and they also tend to generate text with hallucinations or irrelevant information. As a part of error analysis, we utilize BERT to detect machine-generated text and achieve high macro-F1 scores. We have made the text generated by generative models publicly available. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {Semantics; Annotation work; Fluents; Generative model; Graph data; Language model; Machine-generated texts; Performance; Semantic relations; Text generations; Two-graphs; Error analysis},
	editor = {Angelova G. and Kunilovskaya M. and Mitkov R.},
	publisher = {Incoma Ltd},
	issn = {13138502},
	isbn = {978-954452092-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Recent Adv. Nat. Lang. Proces., RANLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Amalvy202310372,
	author = {Amalvy, Arthur and Labatut, Vincent and Dufour, Richard},
	title = {Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {10372 – 10382},
	doi = {10.18653/v1/2023.emnlp-main.642},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182863509&doi=10.18653%2fv1%2f2023.emnlp-main.642&partnerID=40&md5=dcc9d687e20c3155205a3210b984ac7c},
	affiliations = {Laboratoire Informatique d'Avignon, France; Laboratoire des Sciences du Numérique de Nantes, France},
	abstract = {While recent pre-trained transformer-based models can perform named entity recognition (NER) with great accuracy, their limited range remains an issue when applied to long documents such as whole novels. To alleviate this issue, a solution is to retrieve relevant context at the document level. Unfortunately, the lack of supervision for such a task means one may have to settle for unsupervised approaches. Instead, we propose to generate a synthetic context retrieval training dataset using Alpaca, an instruction-tuned large language model (LLM). Using this dataset, we train a neural context retriever based on a BERT model that is able to find relevant context for NER. We show that our method outperforms several unsupervised retrieval baselines for the NER task on an English literary dataset composed of the first chapter of 40 books, and that it performs on par with re-rankers trained on manually annotated data, or even better. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Context retrieval; Language model; Named entity recognition; Synthetic datasets; Training dataset; Unsupervised approaches; Large datasets},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Chumakov2023284,
	author = {Chumakov, Stanislav and Kovantsev, Anton and Surikov, Anatoliy},
	title = {Generative approach to Aspect Based Sentiment Analysis with GPT Language Models},
	year = {2023},
	journal = {Procedia Computer Science},
	volume = {229},
	pages = {284 – 293},
	doi = {10.1016/j.procs.2023.12.030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184097714&doi=10.1016%2fj.procs.2023.12.030&partnerID=40&md5=ca9bfa6fd45bb93dfcd33c56eca1521d},
	affiliations = {National Center for Cognitive Research, ITMO University, St. Petersburg, 197101, Russian Federation},
	abstract = {Aspect Sentiment Triplet Extraction (ASTE) is a modern and effective form of sentiment analysis that enables the extraction of highly representative features of source textual data. Recent solutions rely on models built upon Bidirectional Encoder Representations from Transformers (BERT) embeddings and large manually-tagged datasets. This implies that usage of such methods requires large amounts of gold-tagged domain-specific data and is vulnerable to data drifts, while not being able to recognize segmented and summarize more complex terms. We propose an open-domain generative method for ASTE based on Generative pre-trained transformer (GPT) with few-shot and fine-tuning strategies. This method has shown to be applicable for the task, with the models being capable of consistent structuring of the output triplet, simplification of the terms without losing meaningful information, as well as successful analysis of data from unknown domains. Resulting models was tested on mixed domain Russian-language automatically tagged data with thorough manual editing by means of a large language model (LLM) with a few-shot approach and English data, which was only automatically tagged. The developed models have shown to take advantage of the ability to perform learning in a few-shot way, allowing knowledge distillation from larger to cardinally smaller ones. Models have also been tested on summarizing of large amounts of reviews and have shown results comparable to enterprise grade solutions. © 2023 The Authors. Published by Elsevier B.V.},
	author_keywords = {Data Tagging; Natural Language Processing; Russian; Sentiment Analysis},
	keywords = {Computational linguistics; Distillation; Extraction; Large datasets; Data tagging; Embeddings; Language model; Language processing; Large amounts; Natural language processing; Natural languages; Russian; Sentiment analysis; Textual data; Sentiment analysis},
	editor = {Krzhizhanovskaya V. and Daud A. and Klimova A. and LaTorre D. and Boukhanovsky A.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access}
}

@ARTICLE{Datta2023751,
	author = {Datta, Pratim Milton and Zahn, Brian J. and Attias, Luca and Salierno, Giulio and Bertè, Rosamaria and Battisti, Daniela and Acton, Thomas},
	title = {GiusBERTo: Italy’s AI-Based Judicial Transformation: A Teaching Case},
	year = {2023},
	journal = {Communications of the Association for Information Systems},
	volume = {53},
	pages = {751 – 766},
	doi = {10.17705/1CAIS.05331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177455712&doi=10.17705%2f1CAIS.05331&partnerID=40&md5=a17806abed11db4ac81bea25ef727083},
	affiliations = {ISBA, Ambassador Crawford College of Business Kent State University, United States; University of Johannesburg, Auckland Park, Gauteng, South Africa; Ambassador Crawford College of Business Kent State University, United States; Department of Political Science University of Roma Tre, Italy; Department for Digital Transformation Presidency of the Council of Ministers Government of Italy, Rome, Italy; Business Information Systems J. E. Cairnes School of Business & Economics University of Galway, Ireland},
	abstract = {In an age when open access to law enforcement files and judicial documents can erode individual privacy and confidentiality, miscreants can abuse this open access to personal information for blackmail, misinformation, and even social engineering. Yet, limiting access to law enforcement and court cases is a freedom-of-information violation. To address this tension, this collaborative action-research-based teaching case exemplifies how Italy’s Corte dei Conti (Court of Auditors) used artificial intelligence in the automated deidentification and anonymization of court documents in Italy’s public sector. This teaching case is aimed at undergraduate and graduate students learning about Artificial Intelligence (AI), Large Language Model (LLM) (e.g., ChatGPT) evolution, development, and operations. The case will help students learn the origin and evolution of AI transformer models and architectures, and discusses the GiusBERTo operation and process, highlighting opportunities and challenges. GiusBERTo, Italy’s custom-AI model, offers an innovative approach that walks a tightrope between anonymizing Italy’s judicial court documents without sacrificing context or information loss. The case ends with a series of questions, challenges, and potential for LLMs in data anonymization. © 2023 by the Association for Information Systems.},
	author_keywords = {AI; BERT; Digital Transformation; eGovernment; GPT; Italy; Public Administration; Transformer Models},
	keywords = {Artificial intelligence; Law enforcement; Students; BERT; Digital transformation; e-Government; GPT; Individual privacy; Italy; OpenAccess; Personal information; Social engineering; Transformer modeling; Public administration},
	publisher = {Association for Information Systems},
	issn = {15293181},
	language = {English},
	abbrev_source_title = {Commun. Assoc. Info. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@CONFERENCE{Muñoz-Ortiz2023,
	author = {Muñoz-Ortiz, Alberto and Vilares, David},
	title = {LyS A Coruña at GUA-SPA@IberLEF2023: Multi-Task Learning with Large Language Model Encoders for Guarani-Spanish Code Switching Analysis},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175314184&partnerID=40&md5=5f1a4722199b1bd95850c0f1a7842e22},
	affiliations = {Universidade da Coruña, CITIC, Departamento de Ciencias de la Computación y Tecnologías de la Información, Campus de Elviña s/n, A Coruña, 15071, Spain},
	abstract = {This paper introduces the LyS A Coruña proposal for the Guarani-Spanish Code Switching Analysis task at IberLEF2023. The shared task proposes to analyze Guarani-Spanish code-switched texts, focusing on language identification, named entity recognition (NER), and a novel classification task for Spanish spans in a code-switched Guarani-Spanish context. We propose three multi-task learning systems that have common encoders based on two language models and different decoders in a multi-task learning setup. The encoders use the contextual embeddings by: (i) a large language model (LLM) pretrained on bidirectional machine translation on 200 languages (including Spanish and Guarani) from the No Language Left Behind project, and (ii) a BERT-based model pretrained in Spanish and finetuned in around 800k Guarani tokens. The decoders are: (i) a softmax output layer for Task 1, and (ii) conditional random fields (CRF) output layers for Tasks 2 and 3. According to official results, we ranked third in the three tasks. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Code Classification; Code-switching; Guarani; Language identification; Multi-Task Learning; Named Entity Recognition; Spanish},
	keywords = {Computational linguistics; Decoding; Learning systems; Natural language processing systems; Signal encoding; Classification tasks; Code classification; Code-switching; Guarani; Language identification; Language model; Multitask learning; Named entity recognition; Output layer; Spanish; Random processes},
	editor = {Montes-y-Gomez M. and Rangel F. and Jimenez-Zafra S.M. and Casavantes M. and Altuna B. and Alvarez-Carmona M.A. and Bel-Enguix G. and Chiruzzo L. and de la Iglesia I. and Escalante H.J. and Garcia-Cumbreras M.A. and Garcia-Diaz J.A. and Barba J.A.G. and Tamayo R.L. and Lima S. and Moral P. and del Arco F.M.P. and Valencia-Garcia R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chang2023251,
	author = {Chang, Wei-Shan and Chen, Mingchih and Shia, Ben-Chang},
	title = {Recommendation System Based on LLM and Collaborative Filtering},
	year = {2023},
	journal = {28th ISSAT International Conference on Reliability and Quality in Design, RQD 2023},
	pages = {251 – 254},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174235167&partnerID=40&md5=cbe02a0813f8ccb402cfcc2e058a49ea},
	affiliations = {Graduate Institute of Business Administration, College of Management, Fu Jen Catholic University, No. 510, Zhongzheng Rd., Xinzhuang Dist., New Taipei City, 242062, Taiwan; Artificial Intelligence Development Center, Fu Jen Catholic University, No. 510, Zhongzheng Rd., Xin-Zhuang Dist., New Taipei City, 242062, Taiwan},
	abstract = {In today's era of information overload, recommendation systems have become ubiquitous in online shopping and streaming platforms. These systems are designed to quickly match users with items or content, increasing user engagement and loyalty. Typically, recommendation systems use similarity measures to suggest items that match a user's preferences. This paper aims to optimize recommendation systems in text processing by combining them with large language models to improve performance and quality. This study consists of three main processes. First, a recommendation system is established using collaborative filtering. Second, large language models are used for downstream task training. Third, large language models with Adapter technology are employed to enhance performance and reduce training time and costs. Finally, the study evaluates the recommendation system's performance using metrics such as cosine similarity and top-5 accuracy under different algorithms. By combining recommendation system technology with large language models and using reliable evaluation metrics, this study recommends more suitable journals to researchers as an example of a journal recommendation system. The study aims to explore further optimization of large language models' applications in recommendation systems and expand their scope to cover additional domains in the future. © RQD 2023. All rights reserved.All right reserved.},
	author_keywords = {Adapter; BERT; Collaborative Filtering; Journal Recommendation System; Large Language Model},
	keywords = {Collaborative filtering; Computational linguistics; Online systems; Text processing; Adapter; BERT; Information overloads; Journal recommendation system; Language model; Large language model; Online shopping; Similarity measure; System use; User engagement; Recommender systems},
	publisher = {International Society of Science and Applied Technologies},
	isbn = {979-898657612-1},
	language = {English},
	abbrev_source_title = {ISSAT Int. Conf. Reliab. Qual. Des., RQD},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ali202312,
	author = {Ali, Abbas Raza and Siddiqui, Muhammad Ajmal and Algunaibet, Rema and Ali, Hasan Raza},
	title = {A Large and Diverse Arabic Corpus for Language Modeling},
	year = {2023},
	journal = {Procedia Computer Science},
	volume = {225},
	pages = {12 – 21},
	doi = {10.1016/j.procs.2023.09.086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183535747&doi=10.1016%2fj.procs.2023.09.086&partnerID=40&md5=6dfa8a9ca4f73f9a5d743e81f4a17407},
	affiliations = {Data Science and AI Lab, New York University, Abu Dhabi, United Arab Emirates; Smart Nations, Inception Institute of AI, Abu Dhabi, United Arab Emirates; Digital Transformation, Saudi Aramco, Al Khobar, Saudi Arabia; CTO Office, Kyndryl, Dubai, United Arab Emirates},
	abstract = {Large Language Models (LLMs) have ushered in a major paradigm shift in Natural Language Processing (NLP), where large pre-trained Language models (LMs) have become a fundamental component of most NLP tasks. These models are intelligent enough to find relevant and meaningful representations of a language without any supervision. They are used to fine-tune typical NLP tasks with substantially higher precision than conventional shallow learning techniques. However, training these models requires a massively large corpus that adequately represents a language. Due to the availability of enormous corpora, English LLMs typically perform better than their counterparts. This effort focuses on the design and development of a large Arabic corpus. The corpus comprises over 500 GB of Arabic cleaned text, intended to improve cross-domain knowledge and downstream generalization capability of LLMs. The corpus was employed in the training of a large Arabic LLM. In order to assess the efficacy of the LLM, a variety of typical NLP tasks were fine-tuned. The fine-tuned tasks exhibited a significant boost in accuracy ranging between 4.5 and 8.5%, when compared to those downstreamed from multi-lingual BERT (mBERT). To the best of our knowledge, this is currently the largest clean and diverse Arabic corpus ever assembled. © 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)},
	author_keywords = {Arabic Corpus; GPT-3; Language Model; NLP; Transformers},
	keywords = {Computational linguistics; Learning systems; Modeling languages; Natural language processing systems; Arabic corpus; Fundamental component; GPT-3; High-precision; Language model; Language processing; Natural language processing; Natural languages; Paradigm shifts; Transformer; Domain Knowledge},
	correspondence_address = {A.R. Ali; Data Science and AI Lab, New York University, Abu Dhabi, United Arab Emirates; email: abbas.raza.ali@gmail.com},
	editor = {Howlett R. and Tsihrintzis G.A. and Toro C. and Rios S.A. and Jain L.C.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Li2023230,
	author = {Li, Can and Pang, Bin and Wang, Wenbo and Hu, Lingshu and Gordon, Matthew and Marinova, Detelina and Balducci, Bitty and Shang, Yi},
	title = {How Well Can Language Models Understand Politeness?},
	year = {2023},
	journal = {Proceedings - 2023 IEEE Conference on Artificial Intelligence, CAI 2023},
	pages = {230 – 231},
	doi = {10.1109/CAI54212.2023.00106},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168710833&doi=10.1109%2fCAI54212.2023.00106&partnerID=40&md5=8e1cc2ba825a59cf1880af2efa8afdc2},
	affiliations = {University of Missouri, Department of Electrical Engr. & Comp. Science, Columbia, MO, United States; Washington and Lee University, Department of Business Administration, Lexington, VA, United States; University of Missouri, Department of English, Columbia, MO, United States; University of Missouri, Robert J. Trulaske, Sr. College of Business, Columbia, MO, United States; Washington State University, Carson College of Business, Pullman, WA, United States},
	abstract = {Politeness plays a key role in social communications. Previous work proposed an SVM-based computational method for predicting politeness using linguistic features on a corpus that contains Wikipedia and Stack Exchange requests data. To extend this prior work, we focus on evaluating the performance of state-of-the-art language models on politeness prediction using the same dataset. Two models are applied in this study. First, we fine-tune BERT on politeness data and then use the fine-tuned model for politeness prediction. Second, we use ChatGPT to predict politeness. The results show that both fine-tuned BERT and ChatGPT achieved better results than the state-of-the-art results on both Wikipedia and Stack Exchange data. Fine-tuned BERT outperforms zero shot ChatGPT, but ChatGPT can provide explanations for its prediction. Moreover, fine-tuned BERT outperforms human-level performance by 2.28% on Wikipedia corpus.  © 2023 IEEE.},
	author_keywords = {BERT; ChatGPT; Large Language Model (LLM); Politeness Prediction},
	keywords = {Computational linguistics; Support vector machines; Zero-shot learning; BERT; ChatGPT; Language model; Large language model; Linguistic features; Performance; Politeness prediction; Social communications; State of the art; Wikipedia; Forecasting},
	correspondence_address = {C. Li; University of Missouri, Department of Electrical Engr. & Comp. Science, Columbia, United States; email: lican@mail.missouri.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835033984-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Conf. Artif. Intell., CAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Thant2023261,
	author = {Thant, Shin and Racharak, Teeradaj and Andres, Frederic},
	title = {BERT Fine-Tuning the Covid-19 Open Research Dataset for Named Entity Recognition},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1942 CCIS},
	pages = {261 – 275},
	doi = {10.1007/978-981-99-7969-1_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177820256&doi=10.1007%2f978-981-99-7969-1_19&partnerID=40&md5=daa58d05bc892480a069118e90d8af96},
	affiliations = {Asian Institute of Technology, Khlong Nueng, Thailand; School of Information Science, Japan Advanced Institute of Science and Technology, Nomi, Japan; National Institute of Informatics, Tokyo, Japan},
	abstract = {This study employs the widely used Large Language Model (LLM), BERT, to implement Named Entity Recognition (NER) on the CORD-19 biomedical literature corpus. By fine-tuning the pre-trained BERT on the CORD-NER dataset, the model gains the ability to comprehend the context and semantics of biomedical named entities. The refined model is then utilized on the CORD-19 to extract more contextually relevant and updated named entities. However, fine-tuning large datasets with LLMs poses a challenge. To counter this, two distinct sampling methodologies are proposed to apply on each dataset. First, for the NER task on the CORD-19, a Latent Dirichlet Allocation (LDA) topic modeling technique is employed. This maintains the sentence structure while concentrating on related content. Second, a straightforward greedy method is deployed to gather the most informative data of 25 entity types from the CORD-NER dataset. The study realizes its goals by demonstrating the content comprehension capability of BERT-based models without the necessity of supercomputers, and converting the document-level corpus into a source for NER data, enhancing data accessibility. The outcomes of this research can shed light on the potential progression of more sophisticated NLP applications across various sectors, including knowledge graph creation, ontology learning, and conversational AI. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.},
	author_keywords = {BERT; CORD-19; CORD-NER; Dataset sampling; Document level entity extraction; Large language models; NER},
	keywords = {Computational linguistics; Large dataset; Natural language processing systems; Semantics; Statistics; BERT; CORD-19; CORD-named entity recognition; Dataset sampling; Document level entity extraction; Entity extractions; Language model; Large language model; Named entity recognition; Supercomputers},
	correspondence_address = {S. Thant; Asian Institute of Technology, Khlong Nueng, Thailand; email: shinthant@alumini.ait.asia},
	editor = {Anutariya C. and Bonsangue M.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-981997968-4},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {12th National CCF Conference on Natural Language Processing and Chinese Computing, NLPCC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14302 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174698816&partnerID=40&md5=6fd9681ead9b896d9cbc783e02257fe3},
	abstract = {The proceedings contain 169 papers. The special focus in this conference is on National CCF Conference on Natural Language Processing and Chinese Computing. The topics include: Improving Few-Shot and Zero-Shot Entity Linking with Coarse-to-Fine Lexicon-Based Retriever; GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning; A Study on the Classification of Chinese Medicine Records Using BERT, Chest Impediment as an Example; A Two-Stage Chinese Medical Video Retrieval Framework with LLM; conversational Aspect-Based Sentiment Quadruple Analysis with Consecutive Multi-view Interaction; solving Math Word Problem with Problem Type Classification; preface; fantastic Gradients and Where to Find Them: Improving Multi-attribute Text Style Transfer by Quadratic Program; a Numeracy-Enhanced Decoding for Solving Math Word Problem; consistent Solutions for Optimizing Search Space of Beam Search; improving Conversational Aspect-Based Sentiment Quadruple Analysis with Overall Modeling; a Model Ensemble Approach for Conversational Quadruple Extraction; enhancing Conversational Aspect-Based Sentiment Quadruple Analysis with Context Fusion Encoding Method; a Unified Framework for Optimizing Video Corpus Retrieval and Temporal Answer Grounding: Fine-Grained Modality Alignment and Local-Global Optimization; TiBERT: A Non-autoregressive Pre-trained Model for Text Editing; improving Cross-Modal Visual Answer Localization in Chinese Medical Instructional Video Using Language Prompts; two-Stage Topic Sentence Extraction for Chinese Student Essays; multi-angle Prediction Based on Prompt Learning for Text Classification; task-Related Pretraining with Whole Word Masking for Chinese Coherence Evaluation; towards Robust Chinese Spelling Check Systems: Multi-round Error Correction with Ensemble Enhancement; Overview of the NLPCC 2023 Shared Task: Chinese Spelling Check; user Preference Prediction for Online Dialogue Systems Based on Pre-trained Large Model; auto-scaling Distribution Fitting Network for User Feedback Prediction; adversarial Training and Model Ensemble for User Feedback Prediciton in Conversation System; generating Better Responses from User Feedback via Reinforcement Learning and Commonsense Inference; semantic Candidate Retrieval for Few-Shot Entity Linking.},
	editor = {Liu F. and Duan N. and Xu Q. and Hong Y.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303144692-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Agarwal2023659,
	author = {Agarwal, Udit Kumar and Chan, Abraham and Pattabiraman, Karthik},
	title = {Resilience Assessment of Large Language Models under Transient Hardware Faults},
	year = {2023},
	journal = {Proceedings - International Symposium on Software Reliability Engineering, ISSRE},
	pages = {659 – 670},
	doi = {10.1109/ISSRE59848.2023.00052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178048368&doi=10.1109%2fISSRE59848.2023.00052&partnerID=40&md5=498e99484b581e3548b4d78aeaf70f99},
	affiliations = {The University of British Columbia, Canada},
	abstract = {Large Language Models (LLMs) are transforming the field of natural language processing and revolutionizing the way machines interact with humans. LLMs like ChatGPT and Google's Bard have already made significant strides in conversational AI, enabling machines to understand natural language and respond in a more human-like manner. In addition to typical applications like sentiment analysis and text generation, LLMs are also used in safety-critical applications such as code generation and speech comprehension in autonomous driving vehicles, where reliability is important.In this work, we investigate the resilience of LLMs under transient hardware faults. Specifically, we used IR-level fault injection (FI) to assess the reliability of five popular LLMs, including Bert, GPT2, and T5, under transient hardware faults. Moreover, we also investigate how the resilience of LLMs varies with different pre-training, fine-tuning objectives, and the number of encoder and decoder blocks. We find that LLMs are quite resilient to transient faults overall. We also find that the behavior of the LLM under transient faults varies significantly with the input, LLM's architecture, and the type of task (e.g., translation vs. fill-in-the-blank). Finally, we find that the Silent Data Corruption (SDC) rate varies with different fine-tuning objectives, and for the fill-mask fine-tuning objective, the SDC rate also increases with the model size. Overall, our findings indicate that the use of LLMs in safety-critical applications needs further investigation.  © 2023 IEEE.},
	author_keywords = {Error resilience; LLMS; Soft Errors},
	keywords = {Computational linguistics; Radiation hardening; Reliability analysis; Error resilience; Fine tuning; Hardware faults; Language model; LLMS; Natural languages; Safety critical applications; Silent data corruptions; Soft error; Transient faults; Sentiment analysis},
	correspondence_address = {U.K. Agarwal; The University of British Columbia, Canada; email: uditag97@student.ubc.ca},
	publisher = {IEEE Computer Society},
	issn = {10719458},
	isbn = {979-835031594-3},
	coden = {PSSRF},
	language = {English},
	abbrev_source_title = {Proc. Int. Symp. Softw. Reliab. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Abijith2023,
	author = {Abijith, P.Y. and Patidar, Piyush and Nair, Gaurav and Pandya, Rohan},
	title = {Large Language Models Trained on Equipment Maintenance Text},
	year = {2023},
	journal = {Society of Petroleum Engineers - ADIPEC, ADIP 2023},
	doi = {10.2118/216336-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176739602&doi=10.2118%2f216336-MS&partnerID=40&md5=71bb2bfa71d50a2c69b4b773e403f09f},
	affiliations = {ExxonMobil Services and Technology Private Ltd., Karnataka, Bengaluru, India},
	abstract = {Work orders, equipment information, technical records and best practices documents contain within them a wealth of insights related to Equipment Maintenance which can be unlocked with Natural Language Processing tasks like classification, clustering, named entity recognition or part of speech tagging. But obtaining large enough labelled data sets in Equipment Maintenance domain manually is prohibitive and very expensive. This lack of labeled Equipment Maintenance data can be overcome with Large Language Models (LLMs) such as GPT-3, BERT that are pretrained transformer networks, considered state-of-the-art when it comes to Natural Language Processing (NLP) tasks. However, the vocabulary understood by these LLMs are mostly from English Language and need to be fine-tuned to understand industry and organization specific vocabulary and acronyms. This paper explores the potential of a domain specific LLM model for oil and gas industries. Data that are of good quality and that provide a comprehensive overview of industry are collected. This corpus of text contains documents like work orders, equipment data and technical documents. A custom tokenizer is trained on this data to identify domain specific terminology. A comparative study is done with other off-the-shelf tokenizers: BERT and RoBERTa, to compare the effectiveness of the tokenization. With millions of work orders and equipment documents, training pipelines had to parallelized so that training can occur on multiple GPUs. A comprehensive study of multiple training methods is done in this paper. Model and tokenizer developed were packaged and archived to be consumed in machine learning pipelines to specific use-cases across the organization. For an organization adopting digital transformation, the availability of an organization specific LLM is an enabler to extract insights from millions of documents containing free text. The applicability of such models spans across multiple disciplines like Maintenance, Reliability, Safety etc. and streamlines the development of highly accurate and robust text analytics. © 2023, Society of Petroleum Engineers.},
	author_keywords = {Data Parallel; Distributed Data Parallel; Large Language Model; Masked Language Model; Natural Language Processing; RoBERTa; tokenization},
	keywords = {Classification (of information); Computational linguistics; Information retrieval systems; Maintenance; Natural language processing systems; Program processors; Speech recognition; Data parallel; Distributed data; Distributed data parallel; Language model; Language processing; Large language model; Masked language model; Natural language processing; Natural languages; RoBERTa; Tokenization; Pipelines},
	publisher = {Society of Petroleum Engineers},
	isbn = {978-195902507-8},
	language = {English},
	abbrev_source_title = {Soc. Pet. Eng. - ADIPEC, ADIP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Barreto2023545,
	author = {Barreto, Fabian and Moharkar, Lalita and Shirodkar, Madhura and Sarode, Vidya and Gonsalves, Saniya and Johns, Aaron},
	title = {Generative Artificial Intelligence: Opportunities and Challenges of Large Language Models},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {699 LNNS},
	pages = {545 – 553},
	doi = {10.1007/978-981-99-3177-4_41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172001965&doi=10.1007%2f978-981-99-3177-4_41&partnerID=40&md5=c94228721a37ef873d9f9dfcc34282b1},
	affiliations = {Department of Electronics and Telecommunication, Xavier Institute of Engineering, Mumbai, India; Department of Applied Sciences and Humanities, Xavier Institute of Engineering, Mumbai, India; Department of Information Technology, St. Xavier’s College, Mumbai, India},
	abstract = {Artificial Intelligence (AI) research in the past decade has led to the development of Generative AI, where AI systems create new information from almost nothing after learning from trained models. Generative AI can create original work, like an article, a code, a painting, a poem, or a song. Google Brain initially used Large Language Models (LLM) for context-aware text translation, and Google went on to develop Bidirectional Encoder Representations from Transformers (BERT) and Language Model for Dialogue Applications (LaMDA). Facebook created OPT-175B and BlenderBot, while OpenAI innovated GPT-3 for text, DALL-E2 for images, and Whisper for speech. GPT-3 was trained on around 45 terabytes of text data at an estimated cost of several million dollars. Generative models have also been developed from online communities like Midjourney and open-source ones like HuggingFace. On November 30, 2022, OpenAI launched ChatGPT, which used natural language processing (NLP) techniques and was trained on LLM. There was excitement and caution as OpenAI’s ChatGPT reached one million users in just five days, and in January 2023 reached 100 million users. Many marveled at its eloquence and the limited supervision with which it generated code and answered questions. More deployments followed; Microsoft’s OpenAI-powered Bing on February 7, 2023, followed by Google’s Bard on February 8, 2023. We describe the working of LLM and their opportunities and challenges for our modern world. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Bing; chatGPT; Generative artificial intelligence; Large language models},
	keywords = {Artificial intelligence; Codes (symbols); Computational linguistics; Natural language processing systems; Artificial intelligence research; Artificial intelligence systems; Bing; Chatgpt; Context-Aware; Generative artificial intelligence; Google+; Language model; Large language model; Transformer modeling; Social networking (online)},
	correspondence_address = {F. Barreto; Department of Electronics and Telecommunication, Xavier Institute of Engineering, Mumbai, India; email: frfabiansj@xavier.ac.in},
	editor = {Balas V.E. and Semwal V.B. and Khandare A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-981993176-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{Danner20231290,
	author = {Danner, Michael and Hadzic, Bakir and Gerhardt, Sophie and Ludwig, Simon and Uslu, Irem and Shao, Peng and Weber, Thomas and Shiban, Youssef and Rätsch, Matthias},
	title = {Advancing Mental Health Diagnostics: GPT-Based Method for Depression Detection},
	year = {2023},
	journal = {2023 62nd Annual Conference of the Society of Instrument and Control Engineers, SICE 2023},
	pages = {1290 – 1296},
	doi = {10.23919/SICE59929.2023.10354236},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182597815&doi=10.23919%2fSICE59929.2023.10354236&partnerID=40&md5=3d8e22d3916aaa431580499da6b1fede},
	affiliations = {University of Surrey, Guildford, United Kingdom; Reutlingen University, ViSiR, Reutlingen, Germany; Xi'an Polytechnic University, School of Management, Xi'an, China; Private University of Applied Sciences, Göttingen, Germany},
	abstract = {In this paper, we present a novel artificial intelligence (AI) application for depression detection, using advanced transformer networks to analyse clinical interviews. By incorporating simulated data to enhance traditional datasets, we overcome limitations in data protection and privacy, consequently improving the model's performance. Our methodology employs BERT-based models, GPT-3.5, and ChatGPT-4, demonstrating state-of-the-art results in detecting depression from linguistic patterns and contextual information that significantly outperform previous approaches. Utilising the DAIC-WOZ and Extended-DAIC datasets, our study showcases the potential of the proposed application in revolutionising mental health care through early depression detection and intervention. Empirical results from various experiments highlight the efficacy of our approach and its suitability for real-world implementation. Furthermore, we acknowledge the ethical, legal, and social implications of AI in mental health diagnostics. Ultimately, our study underscores the transformative potential of AI in mental health diagnostics, paving the way for innovative solutions that can facilitate early intervention and improve patient outcomes.  © 2023 Society of Instrument and Control Engineers - SICE.},
	author_keywords = {ChatGPT-4; Deep Learning; Depression Detection; GPT-3.5; Mental Health; NLP Transformer LLM},
	keywords = {Patient treatment; Transformer protection; ChatGPT-4; Clinical interview; Deep learning; Depression detection; GPT-3.5; Linguistic patterns; Mental health; Modeling performance; NLP transformer LLM; State of the art; Deep learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-490776480-7},
	language = {English},
	abbrev_source_title = {Annu. Conf. Soc. Instrum. Control Eng., SICE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{Qi202353,
	author = {Qi, Hao and Dai, Liuyao and Chen, Weicong and Jia, Zhen and Lu, Xiaoyi},
	title = {Performance Characterization of Large Language Models on High-Speed Interconnects},
	year = {2023},
	journal = {Proceedings - Symposium on the High Performance Interconnects, Hot Interconnects},
	volume = {2023-August},
	pages = {53 – 60},
	doi = {10.1109/HOTI59126.2023.00022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176949643&doi=10.1109%2fHOTI59126.2023.00022&partnerID=40&md5=2a0a057da17a3ea240f0f7e2282b76f9},
	affiliations = {University of California Merced, Merced, CA, United States; AmazonWeb Service, Santa Clara, CA, United States},
	abstract = {Large Language Models (LLMs) have recently gained significant popularity due to their ability to generate human-like text and perform a wide range of natural language processing tasks. Training these models usually requires a large amount of computational resources and is often done in a distributed manner. The use of high-speed interconnects can significantly influence the efficiency of distributed training. Therefore, there poses a need for systematic studies to explore the distributed training characteristics of these models on high-speed interconnects. This paper presents a comprehensive performance characterization of representative large language models: GPT, BERT, and T5. We evaluate their training performance in terms of iteration time, interconnect utilization, and scalability, over different high-speed interconnects and communication protocols, including TCP/IP, IPoIB, and RDMA. We observe that interconnects play a vital role in LLM training. Specifically, RDMA-100 Gbps outperforms IPoIB-100 Gbps and TCP/IP-10 Gbps by an average of 2.51x and 4.79x regarding training iteration time, and scores the highest interconnect utilization (up to 60 Gbps) in both strong and weak scaling, compared to IPoIB with up to 20 Gbps and TCP/IP with up to 9 Gbps, leading to the shortest training time. We also observe that larger models tend to have higher requirements for communication bandwidth, especially for AllReduce during backward propagation, which can take up to 91.12% of training time. Through our evaluation, we envision opportunities to improve the communication time for better training performance of LLMs. We extensively explore and summarize the role communication plays in distributed LLM training.  © 2023 IEEE.},
	author_keywords = {BERT; Characterization; GPT; Large language models; T5; Transformer},
	keywords = {Computational linguistics; Convolutional codes; Transmission control protocol; BERT; Characterization; GPT; High-speed interconnects; Language model; Large language model; Performance; Performance characterization; T5; Transformer; Natural language processing systems},
	correspondence_address = {X. Lu; University of California Merced, Merced, United States; email: xiaoyi.lu@ucmerced.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15504794},
	isbn = {979-835030475-6},
	language = {English},
	abbrev_source_title = {Proc. Symp. High Perform. Interconnects Hot Interconnects},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Stewart2023164,
	author = {Stewart, Jake and Lyubashenko, Nikita and Stefanek, George},
	title = {The efficacy of detecting AI-generated fake news using transfer learning},
	year = {2023},
	journal = {Issues in Information Systems},
	volume = {24},
	number = {2},
	pages = {164 – 177},
	doi = {10.48009/2_iis_2023_114},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174260113&doi=10.48009%2f2_iis_2023_114&partnerID=40&md5=80aec32cf44a02050f59243f04cb7ff8},
	affiliations = {Purdue University Northwest, United States},
	abstract = {This research investigates the detectability of AI-generated fake news by a fine-tuned BERT transformer that does text classification. The performance of the model is evaluated by testing it on GPT-generated (Generative Pre-trained Transformer) news articles as well as real-world news articles from a Kaggle dataset. The study focuses on how fake news articles can be created by AI tools and how effective a fine-tuned, open-source large language model is at detecting the GPT-generated fake news. The model was fine-tuned with Kaggle real-world articles and GPT-generated articles from OpenAI ChatGPT and Davinci. The use of state-of-the-art tools like the BERT pre-trained, large language model transformer were found to effectively classify GPT-generated articles but were less effective at classifying fake news articles that were not GPT generated. Copyright © 2023 the Author(s).},
	author_keywords = {AI; BERT; fake news; GPT; LLM; machine learning; transfer learning},
	publisher = {International Association for Computer Information Systems},
	issn = {15297314},
	language = {English},
	abbrev_source_title = {Issue. Inf. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Balasubramanian20233590,
	author = {Balasubramanian, Prasasthy and Seby, Justin and Kostakos, Panos},
	title = {Transformer-based LLMs in Cybersecurity: An in-depth Study on Log Anomaly Detection and Conversational Defense Mechanisms},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {3590 – 3599},
	doi = {10.1109/BigData59044.2023.10386976},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184979836&doi=10.1109%2fBigData59044.2023.10386976&partnerID=40&md5=111e93b666fa21fdd4a98b1d23d1aefb},
	affiliations = {University of Oulu, Center for Ubiquitous Computing, Finland; University of Oulu, Biomimetics and Intelligent Systems Group, Finland},
	abstract = {With the advancement of conversational AI and Large Language Models (LLMs), interactive chatbots are emerging as pivotal assets for connecting with users across various sectors, enabling various capabilities and functions. However, their potential in the cybersecurity domain remains largely untapped. This article introduces a novel method to enhance chatbot performance by incorporating anomaly detection features. Our chatbot uses advanced GPT-3 models and rule-based logic to identify and extract unusual patterns and deviations within logs, making it more proficient in detecting anomalies. We present the architecture and methodology behind our anomaly detection system, showcasing its effectiveness in real-world scenarios. Combining machine learning and domain expertise, our chatbot sets a new standard in interactive, anomaly-aware conversational agents. Our anomaly detection classifier was able to achieve more than 99% of accuracy by illustrating its robust performance in accurately identifying and flagging outliers or unusual patterns in log file data. We also compared the performance of GPT-3 models with other LLMs: BERT, DistilBERT, and ALBERT. Our findings concluded that GPT-3 models consistently outperform all the other LLM models and exhibit significantly higher performance.  © 2023 IEEE.},
	author_keywords = {AI chatbot; Anomaly Detection; Conversational AI; Cybersecurity; GPT-3; Interactive Chatbot; Log Analysis},
	keywords = {Classification (of information); AI chatbot; Anomaly detection; Chatbots; Conversational AI; Cyber security; GPT-3; Interactive chatbot; Language model; Log analysis; Anomaly detection},
	correspondence_address = {P. Balasubramanian; University of Oulu, Center for Ubiquitous Computing, Finland; email: prasasthy.balasubramanian@oulu.fi},
	editor = {He J. and Palpanas T. and Hu X. and Cuzzocrea A. and Dou D. and Slezak D. and Wang W. and Gruca A. and Lin J.C.-W. and Agrawal R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032445-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{2023,
	title = {22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14265 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177195187&partnerID=40&md5=8b40c4b8d53d8783594689275fc7e0ed},
	abstract = {The proceedings contain 58 papers. The special focus in this conference is on Semantic Web. The topics include: How is Your Knowledge Graph Used: Content-Centric Analysis of SPARQL Query Logs; iterative Geographic Entity Alignment with Cross-Attention; entity-Relation Distribution-Aware Negative Sampling for Knowledge Graph Embedding; negative Sampling with Adaptive Denoising Mixup for Knowledge Graph Embedding; comparison of Knowledge Graph Representations for Consumer Scenarios; a Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning; Compact Encoding of Reified Triples Using HDTr; causal Inference-Based Debiasing Framework for Knowledge Graph Completion; Can ChatGPT Replace Traditional KBQA Models? An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family; Dense Re-Ranking with Weak Supervision for RDF Dataset Search; mapping and Cleaning Open Commonsense Knowledge Bases with Generative Translation; integrating Knowledge Graph Embeddings and Pre-trained Language Models in Hypercomplex Spaces; LLMs4OL: Large Language Models for Ontology Learning; biomedical Knowledge Graph Embeddings with Negative Statements; knowledge Graph Enhanced Language Models for Sentiment Analysis; TemporalFC: A Temporal Fact Checking Approach over Knowledge Graphs; Assessing the Generalization Capabilities of Neural Machine Translation Models for SPARQL Query Generation; linking Tabular Columns to Unseen Ontologies; neural Multi-hop Logical Query Answering with Concept-Level Answers; ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs; Optimizing SPARQL Queries with SHACL; SORBET: A Siamese Network for Ontology Embeddings Using a Distance-Based Regression Loss and BERT; visualizing Mappings Between Pairwise Ontologies - An Empirical Study of Matrix and Linked Indented List in Their User Support During Class Mapping Creation and Evaluation; FeaBI: A Feature Selection-Based Framework for Interpreting KG Embeddings; CapsKG: Enabling Continual Knowledge Integration in Language Models for Automatic Knowledge Graph Completion; HAEE: Low-Resource Event Detection with Hierarchy-Aware Event Graph Embeddings; textual Entailment for Effective Triple Validation in Object Prediction.},
	editor = {Payne T.R. and Presutti V. and Qi G. and Poveda-Villalón M. and Stoilos G. and Hollink L. and Kaoudi Z. and Cheng G. and Li J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303147239-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mukherjee2023382,
	author = {Mukherjee, Prasenjit and Gokul, R.S. and Sadhukhan, Sourav and Godse, Manish and Chakraborty, Baisakhi},
	title = {Detection of Autism Spectrum Disorder (ASD) from Natural Language Text using BERT and ChatGPT Models},
	year = {2023},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {14},
	number = {10},
	pages = {382 – 396},
	doi = {10.14569/IJACSA.2023.0141041},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175352568&doi=10.14569%2fIJACSA.2023.0141041&partnerID=40&md5=a73709f4e2898d46b82caf0bccaf393d},
	affiliations = {Dept. of Technology, Vodafone Intelligent Solutions, Pune, India; Dept. of Computer Science, Manipur International University, Manipur, India; Dept. of Finance, Pune Institute of Business Management, Pune, India; Dept. of IT, BizAmica Software, Pune, India; Dept. of Computer Science and Engg, National Institute of Technology, Durgapur, India},
	abstract = {ASD may be caused by a combination of genetic and environmental factors, including gene mutations and exposure to toxins. People with ASD may also have trouble forming social relationships, have difficulty with communication and language, and struggle with sensory sensitivity. These difficulties can range from mild to severe and can affect a person’s ability to interact with the world around them. Autism spectrum disorder (ASD) is a developmental disorder that affects people in different ways. But early detection of ASD in a child is a good option for parents to start corrective therapies and treatment. They can take action to reduce the ASD symptoms in their child. The proposed work is the detection of ASD in a child using a parent’s dialog. The most popular Bert model and recent ChatGPT have been utilized to analyze the sentiment of each statement from parents for the detection of symptoms of ASD. The Bert model has been developed by the transformers which are the most popular in the natural language processing field whereas the ChatGPT model is a large language model (LLM). It is based on Reinforcement learning from human feedback (RLHF) that can able to generate the sentiment of the sentence, computer language codes, text paragraphs, etc. The sentiment analysis has been done on parents’ dialog using the Bert model and ChatGPT model. The data has been prepared from various Autism groups on social sites and other resources on the internet. The data has been cleaned and prepared to train the Bert model and ChatGPT model. The Bert model is able to detect the sentiment of each sentence from parents. Any positive sentiment detection means parents should be aware of their children. The proposed model has given 83 percent accuracy according to the prepared data. © (2023) All Rights Reserved.},
	author_keywords = {autism; autism detection; BERT model; ChatGPT model; generative AI; machine learning},
	keywords = {Diseases; Reinforcement learning; Autism; Autism detection; Autism spectrum disorders; BERT model; ChatGPT model; Environmental factors; Generative AI; Genetic factors; Machine-learning; Natural languages texts; Sentiment analysis},
	publisher = {Science and Information Organization},
	issn = {2158107X},
	language = {English},
	abbrev_source_title = {Intl. J. Adv.  Comput. Sci. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access}
}

@CONFERENCE{Le202393,
	author = {Le, Ngoc Tran Khanh and Hadiprodjo, Nadia and El-Alfy, Hazem and Kerimzhanov, Aziz and Teshebaev, Avtandil},
	title = {The Recent Large Language Models in NLP},
	year = {2023},
	journal = {22nd International Symposium on Communications and Information Technologies, ISCIT 2023},
	pages = {93 – 98},
	doi = {10.1109/ISCIT57293.2023.10376050},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183465368&doi=10.1109%2fISCIT57293.2023.10376050&partnerID=40&md5=62036597ba21bc4216d5eda208141b91},
	affiliations = {S P Jain School of Global Management, Sydney, Australia; Alexandria University, Faculty of Engineering, Alexandria, Egypt},
	abstract = {Over the past few years, Natural Language Processing (NLP) has evolved significantly thanks to the development of large Language Models (LMs). In this paper, we present a survey of four recent language models that we believe have had a significant importance in the NLP field lately: BERT (Google), ELMo (Allen Institute), GPT-3 (OpenAI), and LLaMA (Meta AI). For each model, we analyse its architecture, the dataset on which it was trained, its performance evaluation, as well as the strengths and challenges faced by each. Our paper compares the recent Language Models and their contributions to the field of NLP, and discusses future extensions.  © 2023 IEEE.},
	author_keywords = {application.; architecture; BERT; data; ELMo; GPT-3; LLaMA; LLM(s); model; NLP; performance; pre-trained; state-of-art},
	keywords = {Computational linguistics; Natural language processing systems; Application.; BERT; Data; ELMo; GPT-3; Language processing; LLaMA; LLM(s); Natural language processing; Natural languages; Performance; Pre-trained; State-of-art; Petroleum reservoir evaluation},
	correspondence_address = {N.T.K. Le; S P Jain School of Global Management, Sydney, Australia; email: tran.aj23syd008@spjain.org},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166545731-6},
	language = {English},
	abbrev_source_title = {Int. Symp. Commun. Inf. Technol., ISCIT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Newman2022,
	author = {Newman, Benjamin and Choubey, Prafulla Kumar and Rajani, Nazneen},
	title = {P-ADAPTERS: ROBUSTLY EXTRACTING FACTUAL INFORMATION FROM LANGUAGE MODELS WITH DIVERSE PROMPTS},
	year = {2022},
	journal = {ICLR 2022 - 10th International Conference on Learning Representations},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141560710&partnerID=40&md5=80e6ed4df955671bfffd51f46886718e},
	affiliations = {Stanford University, United States; Salesforce Research},
	abstract = {Recent work (e.g. LAMA (Petroni et al., 2019)) has found that the quality of the factual information extracted from Large Language Models (LLMs) depends on the prompts used to query them. This inconsistency is problematic because different users will query LLMs for the same information using different wording, but should receive the same, accurate responses regardless. In this work we aim to address this shortcoming by introducing P-Adapters: lightweight models that sit between the embedding layer and first attention layer of LLMs. They take LLM embeddings as input and output continuous prompts that are used to query the LLM. Additionally, we investigate Mixture of Experts (MoE) models that learn a set of continuous prompts (“experts”) and select one to query the LLM. They require a separate classifier trained on human-annotated data to map natural language prompts to the continuous ones. P-Adapters perform comparably to the more complex MoE models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations. P-Adapters show between 12-26% absolute improvement in precision and 36-50% absolute improvement in consistency over a baseline of only using natural language queries. Finally, we investigate what makes P-Adapters successful and conclude that a significant factor is access to the LLM's embeddings of the original natural language prompt, particularly the subject of the entity pair being queried. © 2022 ICLR 2022 - 10th International Conference on Learning Representationss. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Accurate response; Complex mixture; Embeddings; Factual information; Input and outputs; Language model; Learn+; Mixture-of-experts model; Model embedding; Natural languages; Embeddings},
	correspondence_address = {B. Newman; Stanford University, United States; email: blnewman@cs.stanford.edu},
	publisher = {International Conference on Learning Representations, ICLR},
	language = {English},
	abbrev_source_title = {ICLR - Int. Conf. Learn. Represent.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Lu202322812,
	author = {Lu, Yucheng and Agrawal, Shivani and Subramanian, Suvinay and Rybakov, Oleg and De Sa, Christopher and Yazdanbakhsh, Amir},
	title = {STEP: Learning N:M Structured Sparsity Masks from Scratch with Precondition},
	year = {2023},
	journal = {Proceedings of Machine Learning Research},
	volume = {202},
	pages = {22812 – 22824},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172282238&partnerID=40&md5=d88dcae1e592f12df6837d47b0790edb},
	affiliations = {Department of Computer Science, Cornell University, United States; Google, United States; Google DeepMind, United Kingdom},
	abstract = {Recent innovations on hardware (e.g. Nvidia A100) have motivated learning N:M structured sparsity masks from scratch for fast model inference. However, state-of-the-art learning recipes in this regime (e.g. SR-STE) are proposed for non-adaptive optimizers like momentum SGD, while incurring non-trivial accuracy drop for Adam-trained models like attention-based LLMs. In this paper, we first demonstrate such gap origins from poorly estimated second moment (i.e. variance) in Adam states given by the masked weights. We conjecture that learning N:M masks with Adam should take the critical regime of variance estimation into account. In light of this, we propose STEP, an Adam-aware recipe that learns N:M masks with two phases: first, STEP calculates a reliable variance estimate (precondition phase) and subsequently, the variance remains fixed and is used as a precondition to learn N:M masks (mask-learning phase). STEP automatically identifies the switching point of two phases by dynamically sampling variance changes over the training trajectory and testing the sample concentration. Empirically, we evaluate STEP and other baselines such as ASP and SR-STE on multiple tasks including CIFAR classification, machine translation and LLM fine-tuning (BERT-Base, GPT-2). We show STEP mitigates the accuracy drop of baseline recipes and is robust to aggressive structured sparsity ratios. © 2023 Proceedings of Machine Learning Research. All rights reserved.},
	keywords = {Machine learning; Critical regimes; FAST model; Learn+; Model inference; Non-trivial; Optimizers; Second moments; State of the art; Structured sparsities; Two phase; Drops},
	correspondence_address = {Y. Lu; Department of Computer Science, Cornell University, United States; email: yl2967@cornell.edu},
	editor = {Krause A. and Brunskill E. and Cho K. and Engelhardt B. and Sabato S. and Scarlett J.},
	publisher = {ML Research Press},
	issn = {26403498},
	language = {English},
	abbrev_source_title = {Proc. Mach. Learn. Res.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Taffa2023,
	author = {Taffa, Tilahun Abedissa and Usbeck, Ricardo},
	title = {Leveraging LLMs in Scholarly Knowledge Graph Question Answering},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180546080&partnerID=40&md5=ccf7f534c71dcf553c48378d6818a7ee},
	affiliations = {Semantic Systems, Universität Hamburg, Vogt-Kölln-Straße 30, Hamburg, 22527, Germany; Leuphana Universität Lüneburg, Universitätsallee 1, C 4.314, Lüneburg, 21335, Germany},
	abstract = {This paper presents a scholarly Knowledge Graph Question Answering (KGQA) that answers bibliographic natural language questions by leveraging a large language model (LLM) in a few-shot manner. The model initially identifies the top-n similar training questions related to a given test question via a BERT-based sentence encoder and retrieves their corresponding SPARQL. Using the top-n similar question-SPARQL pairs as an example and the test question creates a prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runs the SPARQL against the underlying KG - ORKG (Open Research KG) endpoint and returns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one of the Scholarly-QALD-23 challenge benchmarks. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Knowledge Graph Question Answering (KGQA); Large Language Model; Open Research Knowledge Graph; ORKG; Scholarly KGQA; Scholarly-QALD; SciQA},
	keywords = {Computational linguistics; Knowledge management; Natural language processing systems; Knowledge graph question answering; Knowledge graphs; Language model; Large language model; Open research KG; Open research knowledge graph; Question Answering; Scholarly knowledge graph question answering; Scholarly-QALD; SciQA; Knowledge graph},
	correspondence_address = {T.A. Taffa; Semantic Systems, Universität Hamburg, Hamburg, Vogt-Kölln-Straße 30, 22527, Germany; email: tilahun.taffa@uni-hamburg.de},
	editor = {Banerjee D. and Usbeck R. and Mihindukulasooriya N. and Jaradeh M.Y. and Auer S. and Singh G. and Mutharaju R. and Kapanipathi P.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Aguilar-Canto2023,
	author = {Aguilar-Canto, Fernando and Cardoso-Moreno, Marco and Jiménez, Diana and Calvo, Hiram},
	title = {GPT-2 versus GPT-3 and Bloom: LLMs for LLMs Generative Text Detection},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175314590&partnerID=40&md5=fa09987f5bf95ddddd1a8f24dd4f13c0},
	affiliations = {Computational Cognitive Sciences Laboratory, Center for Computing Research, Instituto Politécnico Nacional, Mexico City, 07700, Mexico},
	abstract = {With the advent and proliferation of advanced Large Language Models (LLMs) such as BLOOM, GPT series, and ChatGPT, there is a growing concern regarding the potential misuse of this technology. Consequently, it has become imperative to develop machine learning techniques that can discern whether a given text has been generated by an LLM or authored by a human. In this paper, we present our approach in the AuTexTification shared task, where we fine-tuned BERT-based models and GPT-2 Small. Remarkably, GPT-2 Small achieved the highest F1-macro score in the validation set, prompting us to evaluate its performance on the testing set. We achieved an F1-macro score of 0.74134, securing the third position in the benchmark. Furthermore, we extended our fine-tuning efforts to the model attribution subtask, yielding a F1-macro score of 0.52282. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {AuTexTification; Generative Text Detection; Large Language Models (LLMs); Model Attibution},
	keywords = {Blooms (metal); Learning systems; Autextification; Generative text detection; Language model; Large language model; Machine learning techniques; Model attibution; Performance; Testing sets; Text detection; Validation sets; Computational linguistics},
	correspondence_address = {M. Cardoso-Moreno; Computational Cognitive Sciences Laboratory, Center for Computing Research, Instituto Politécnico Nacional, Mexico City, 07700, Mexico; email: mcardosom2021@cic.ipn.mx},
	editor = {Montes-y-Gomez M. and Rangel F. and Jimenez-Zafra S.M. and Casavantes M. and Altuna B. and Alvarez-Carmona M.A. and Bel-Enguix G. and Chiruzzo L. and de la Iglesia I. and Escalante H.J. and Garcia-Cumbreras M.A. and Garcia-Diaz J.A. and Barba J.A.G. and Tamayo R.L. and Lima S. and Moral P. and del Arco F.M.P. and Valencia-Garcia R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gupta2023155,
	author = {Gupta, Pranjal and Kumar, Harshit and Kar, Debanjana and Bhukar, Karan and Aggarwal, Pooja and Mohapatra, Prateeti},
	title = {Learning Representations on Logs for AIOps},
	year = {2023},
	journal = {IEEE International Conference on Cloud Computing, CLOUD},
	volume = {2023-July},
	pages = {155 – 166},
	doi = {10.1109/CLOUD60044.2023.00026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174307322&doi=10.1109%2fCLOUD60044.2023.00026&partnerID=40&md5=71db74663b7e3b816fe65bea857751d3},
	affiliations = {IBM Research, India},
	abstract = {AI for IT Operations (AIOps) is a powerful platform that Site Reliability Engineers (SREs) use to automate and streamline operational workflows with minimal human intervention. Automated log analysis is a critical task in AIOps as it provides key insights for SREs to identify and address ongoing faults. Tasks such as log format detection, log classification, and log parsing are key components of automated log analysis. Most of these tasks require supervised learning; however, there are multiple challenges due to limited labeled log data and the diverse nature of log data. Large Language Models (LLMs) such as BERT and GPT3 are trained using self-supervision on a vast amount of unlabeled data. These models provide generalized representations that can be effectively used for various downstream tasks with limited labeled data. Motivated by the success of LLMs in specific domains like science and biology, this paper introduces a LLM for log data which is trained on public and proprietary log data. Results of our experiments demonstrate that the proposed LLM outperforms existing models on multiple downstream tasks. In summary, AIOps powered by LLMs offers an efficient and effective solution for automating log analysis tasks and enabling SREs to focus on higher-level tasks. Our proposed LLM, trained on public and proprietary log data, offers superior performance on multiple downstream tasks, making it a valuable addition to the AIOps platform. © 2023 IEEE.},
	author_keywords = {AIOps; Large Language Model; Log Analysis},
	keywords = {Learning systems; Well logging; AI for IT operation; Critical tasks; Down-stream; Human intervention; Language model; Large language model; Log analysis; Log data; Reliability engineers; Work-flows; Computational linguistics},
	editor = {Ardagna C. and Atukorala N. and Beckman P. and Chang C.K. and Chang R.N. and Evangelinos C. and Fan J. and Fox G.C. and Fox J. and Hagleitner C. and Jin Z. and Kosar T. and Parashar M.},
	publisher = {IEEE Computer Society},
	issn = {21596182},
	isbn = {979-835030481-7},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Cloud Comput., CLOUD},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{VAN OSTAEYEN2023540,
	author = {VAN OSTAEYEN, Sofie and DE LANGHE, Loic and DE CLERCQ, Orphée and Embo, Mieke and Schellens, Tammy and Valcke, Martin},
	title = {Automating the Identification of Feedback Quality Criteria and the CanMEDS Roles in Written Feedback Comments Using Natural Language Processing},
	year = {2023},
	journal = {Perspectives on Medical Education},
	volume = {12},
	number = {1},
	pages = {540 – 549},
	doi = {10.5334/pme.1056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180491120&doi=10.5334%2fpme.1056&partnerID=40&md5=8d5995be50ceab90fbe31941f781d424},
	affiliations = {Department of Educational Sciences, Ghent University, Belgium; Language and Translation Technology Team, Ghent University, Belgium; Department of Educational Sciences, Ghent University and in the Expertise Network Health and Care at the Artevelde University of Applied Sciences, Belgium},
	abstract = {Introduction: Manually analysing the quality of large amounts of written feedback comments is time-consuming and demands extensive resources and human effort. Therefore, this study aimed to explore whether a state-of-the-art large language model (LLM) could be fine-tuned to identify the presence of four literature-derived feedback quality criteria (performance, judgment, elaboration and improvement) and the seven CanMEDS roles (Medical Expert, Communicator, Collaborator, Leader, Health Advocate, Scholar and Professional) in written feedback comments. Methods: A set of 2,349 labelled feedback comments of five healthcare educational programs in Flanders (Belgium) (specialistic medicine, general practice, midwifery, speech therapy and occupational therapy) was split into 12,452 sentences to create two datasets for the machine learning analysis. The Dutch BERT models BERTje and RobBERT were used to train four multiclass-multilabel classification models: two to identify the four feedback quality criteria and two to identify the seven CanMEDS roles. Results: The classification models trained with BERTje and RobBERT to predict the presence of the four feedback quality criteria attained macro average F1-scores of 0.73 and 0.76, respectively. The F1-score of the model predicting the presence of the CanMEDS roles trained with BERTje was 0.71 and 0.72 with RobBERT. Discussion: The results showed that a state-of-the-art LLM is able to identify the presence of the four feedback quality criteria and the CanMEDS roles in written feedback comments. This implies that the quality analysis of written feedback comments can be automated using an LLM, leading to savings of time and resources. © 2023 The Author(s).},
	keywords = {Clinical Competence; Family Practice; Feedback; Humans; Natural Language Processing; Physicians; clinical competence; feedback system; general practice; human; natural language processing; physician},
	correspondence_address = {S. VAN OSTAEYEN; Department of Educational Studies, Faculty of Psychology and Educational Sciences, Ghent University, Ghent, Henri Dunantlaan 2, 9000, Belgium; email: Sofie.VanOstaeyen@UGent.be},
	publisher = {Ubiquity Press},
	issn = {22122761},
	pmid = {38144670},
	language = {English},
	abbrev_source_title = {Perspect. Med. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sawiński2023453,
	author = {Sawiński, Marcin and Węcel, Krzysztof and Księżniak, Ewelina and Stróżyna, Milena and Lewoniewski, Włodzimierz and Stolarski, Piotr and Abramowicz, Witold},
	title = {OpenFact at CheckThat! 2023: Head-to-Head GPT vs. BERT - A Comparative Study of Transformers Language Models for the Detection of Check-worthy Claims},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3497},
	pages = {453 – 472},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175618550&partnerID=40&md5=9699c4484061c08acb916be246713fb0},
	affiliations = {Department of Information Systems, Poznań University of Economics and Business, Al. Niepodległości 10, Poznań, 61-875, Poland},
	abstract = {This paper presents the research findings resulting from experiments conducted as part of the CheckThat! Lab Task 1B-English submission at CLEF 2023. The aim of the research was to evaluate the check-worthiness of short texts in English. Various methodologies were employed, including zero-shot, few-shot, and fine-tuning techniques, and different GPT and BERT models were assessed. Given the significant increase in the use of GPT models in recent times, we posed a research question to investigate whether GPT models exhibit notable superiority over BERT models in detecting check-worthy claims. Our findings indicate that fine-tuned BERT models can perform comparably to large language models such as GPT-3 in identifying check-worthy claims for this particular task. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT; check-worthiness; fact-checking; fake news detection; GPT; language models; LLM},
	keywords = {Fake detection; Zero-shot learning; BERT; Check-worthiness; Comparatives studies; Fact-checking; Fake news detection; Fine tuning; GPT; Language model; LLM; Short texts; Computational linguistics},
	correspondence_address = {M. Sawiński; Department of Information Systems, Poznań University of Economics and Business, Poznań, Al. Niepodległości 10, 61-875, Poland; email: marcin.sawinski@ue.poznan.pl},
	editor = {Aliannejadi M. and Faggioli G. and Ferro N. and Vlachos M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Udagawa20223919,
	author = {Udagawa, Takuma and Suzuki, Masayuki and Kurata, Gakuto and Itoh, Nobuyasu and Saon, George},
	title = {Effect and Analysis of Large-scale Language Model Rescoring on Competitive ASR Systems},
	year = {2022},
	journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	volume = {2022-September},
	pages = {3919 – 3923},
	doi = {10.21437/Interspeech.2022-11123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140053991&doi=10.21437%2fInterspeech.2022-11123&partnerID=40&md5=f6f4cf8db75c89ad61b77f403b520a91},
	affiliations = {IBM Research, Tokyo, Japan; IBM T. J. Watson Research Center, Yorktown Heights, United States},
	abstract = {Large-scale language models (LLMs) such as GPT-2, BERT and RoBERTa have been successfully applied to ASR N-best rescoring. However, whether or how they can benefit competitive, near state-of-the-art ASR systems remains unexplored. In this study, we incorporate LLM rescoring into one of the most competitive ASR baselines: the Conformer-Transducer model. We demonstrate that consistent improvement is achieved by the LLM's bidirectionality, pretraining, in-domain finetuning and context augmentation. Furthermore, our lexical analysis sheds light on how each of these components may be contributing to the ASR performance. Copyright © 2022 ISCA.},
	author_keywords = {large-scale language models; N-best rescoring; speech recognition},
	keywords = {Computational linguistics; Speech communication; Bidirectionality; Language model; Large-scale language model; Large-scales; Lexical analysis; N-best rescoring; Performance; Pre-training; State of the art; Transducer modeling; Speech recognition},
	publisher = {International Speech Communication Association},
	issn = {2308457X},
	language = {English},
	abbrev_source_title = {Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access}
}

@CONFERENCE{Dipongkor20231012,
	author = {Dipongkor, Atish Kumar and Moran, Kevin},
	title = {A Comparative Study of Transformer-Based Neural Text Representation Techniques on Bug Triaging},
	year = {2023},
	journal = {Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023},
	pages = {1012 – 1023},
	doi = {10.1109/ASE56229.2023.00217},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178995352&doi=10.1109%2fASE56229.2023.00217&partnerID=40&md5=3da055af4729db11de2317b1f2502917},
	affiliations = {University of Central Florida, Dept. of Computer Science, Orlando, United States},
	abstract = {Bug report management has been shown to be an important and time consuming software maintenance task. Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process - to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-tained neural text representation techniques (i.e., large language models or LLMs) such as BERT and CodeBERT have achieved greater performance with simplified training procedures in several natural language processing tasks, including text classification. However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood. Therefore, in this paper we offer one of the first investigations that fine-tunes transformer-based language models for the task of bug triaging on four open source datasets, spanning a collective 53 years of development history with over 400 developers and over 150 software project components. Our study includes both a quantitative and qualitative analysis of effectiveness. Our findings illustrate that DeBERTa is the most effective technique across the triaging tasks of developer and component assignment, and the measured performance delta is statistically significant compared to other techniques. However, through our qualitative analysis, we also observe that each technique possesses unique abilities best suited to certain types of bug reports.  © 2023 IEEE.},
	author_keywords = {Bug Triaging; DL4SE; LLMs; Text-Embedding; Transformer},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; Open systems; Text processing; Bug reports; Bug triaging; DL4SE; Embeddings; LLM; Representation techniques; Software project; Text representation; Text-embedding; Transformer; Open source software},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032996-4},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/ACM Int. Conf. Autom. Softw. Eng., ASE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Liu2023592,
	author = {Liu, Shih-Yang and Liu, Zechun and Huang, Xijie and Dong, Pingcheng and Cheng, Kwang-Ting},
	title = {LLM-FP4: 4-Bit Floating-Point Quantized Transformers},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {592 – 605},
	doi = {10.18653/v1/2023.emnlp-main.39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184830587&doi=10.18653%2fv1%2f2023.emnlp-main.39&partnerID=40&md5=5b37fa50b882ae5ddc8dbbdd37b354bb},
	affiliations = {Hong Kong University of Science and Technology, Hong Kong; Meta Reality Labs, United States},
	abstract = {We propose LLM-FP4 for quantizing both weights and activations in large language models (LLMs) down to 4-bit floating-point values, in a post-training manner. Existing post-training quantization (PTQ) solutions are primarily integer-based and struggle with bit widths below 8 bits. Compared to integer quantization, floating-point (FP) quantization is more flexible and can better handle long-tail or bell-shaped distributions, and it has emerged as a default choice in many hardware platforms. One characteristic of FP quantization is that its performance largely depends on the choice of exponent bits and clipping range. In this regard, we construct a strong FP-PTQ baseline by searching for the optimal quantization parameters. Furthermore, we observe a high inter-channel variance and low intra-channel variance pattern in activation distributions, which adds activation quantization difficulty. We recognize this pattern to be consistent across a spectrum of transformer models designed for diverse tasks, such as LLMs, BERT, and Vision Transformer models. To tackle this, we propose per-channel activation quantization and show that these additional scaling factors can be reparameterized as exponential biases of weights, incurring a negligible cost. Our method, for the first time, can quantize both weights and activations in the LLaMA-13B to only 4-bit and achieves an average score of 63.1 on the common sense zero-shot reasoning tasks, which is only 5.8 lower than the full-precision model, significantly outperforming the previous state-of-the-art by 12.7 points. Code is available at: https://github.com/nbasyl/LLM-FP4. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Digital arithmetic; Zero-shot learning; Bit-Width; Floating points; Hardware platform; Integer quantization; Language model; Long tail; Performance; Point value; Quantisation; Transformer modeling; Chemical activation},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{2023,
	title = {12th National CCF Conference on Natural Language Processing and Chinese Computing, NLPCC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14304 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174539973&partnerID=40&md5=8ba47a7e17e653a440b4e4bbf5c53ffa},
	abstract = {The proceedings contain 169 papers. The special focus in this conference is on National CCF Conference on Natural Language Processing and Chinese Computing. The topics include: Improving Few-Shot and Zero-Shot Entity Linking with Coarse-to-Fine Lexicon-Based Retriever; GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning; A Study on the Classification of Chinese Medicine Records Using BERT, Chest Impediment as an Example; A Two-Stage Chinese Medical Video Retrieval Framework with LLM; conversational Aspect-Based Sentiment Quadruple Analysis with Consecutive Multi-view Interaction; solving Math Word Problem with Problem Type Classification; preface; fantastic Gradients and Where to Find Them: Improving Multi-attribute Text Style Transfer by Quadratic Program; a Numeracy-Enhanced Decoding for Solving Math Word Problem; consistent Solutions for Optimizing Search Space of Beam Search; improving Conversational Aspect-Based Sentiment Quadruple Analysis with Overall Modeling; a Model Ensemble Approach for Conversational Quadruple Extraction; enhancing Conversational Aspect-Based Sentiment Quadruple Analysis with Context Fusion Encoding Method; a Unified Framework for Optimizing Video Corpus Retrieval and Temporal Answer Grounding: Fine-Grained Modality Alignment and Local-Global Optimization; TiBERT: A Non-autoregressive Pre-trained Model for Text Editing; improving Cross-Modal Visual Answer Localization in Chinese Medical Instructional Video Using Language Prompts; two-Stage Topic Sentence Extraction for Chinese Student Essays; multi-angle Prediction Based on Prompt Learning for Text Classification; task-Related Pretraining with Whole Word Masking for Chinese Coherence Evaluation; towards Robust Chinese Spelling Check Systems: Multi-round Error Correction with Ensemble Enhancement; Overview of the NLPCC 2023 Shared Task: Chinese Spelling Check; user Preference Prediction for Online Dialogue Systems Based on Pre-trained Large Model; auto-scaling Distribution Fitting Network for User Feedback Prediction; adversarial Training and Model Ensemble for User Feedback Prediciton in Conversation System; generating Better Responses from User Feedback via Reinforcement Learning and Commonsense Inference; semantic Candidate Retrieval for Few-Shot Entity Linking.},
	editor = {Liu F. and Duan N. and Xu Q. and Hong Y.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303144698-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ahmed2023235,
	author = {Ahmed, Umair},
	title = {Reimagining open data ecosystems: a practical approach using AI, CI, and Knowledge Graphs},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3514},
	pages = {235 – 249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176118205&partnerID=40&md5=3aa98b44917bcdc9c7a8b2629ebf5cea},
	affiliations = {University of Camerino (UNICAM), 9 Via Madonna delle Carceri, Camerino, Italy},
	abstract = {Open data promotes transparency, facilitates innovation, and enables informed decision-making. In the information age, despite the abundance of data, issues related to findability, accessibility, usability, and value creation continue to be significant challenges. This study focuses on ways to tackle those challenges within the realm of open data ecosystem. It particularly investigates the utilization of AI (Artificial Intelligence) and CI (Collective Intelligence) to enhance the open data ecosystem in the aforementioned aspects. It also navigates through fitting knowledge representation methodologies for open data, which promote semantic reasoning and make it conducive for AI and CI to work more effectively. Given the main objectives of this study, in the preliminary stage, apart from the literature review, we surveyed multiple open data portals to find the state of functional traits currently. We found the state to be significantly lacking in terms of the aforementioned objectives. Initially, we focused on the problem of missing metadata. We explored state-of-the-art AI methodologies such as BERT, YAKE, RAKE, TextRank, ChatGPT and proposed BRYT (a hybrid methodology) for automated metadata extraction. We proposed to extract keywords, themes/categories, and descriptions of data sets using AI to fill in the missing metadata and recommend them to publishers while uploading new data sets. Following metadata extraction, we proposed to explore the idea of constructing a representative knowledge graph from open data sets and investigate how it aids with the objectives of this study. To address this, we chose Open Street Maps as our source of geographical open data and GTFS as a layer of mobility data on top of it. Following it, we propose to employ intuitive search algorithms and recommender systems on top of it to enhance the open data ecosystem. In association with OSM and GTFS, we also plan to focus on the problem of optimal route recommendation, improved navigation, and emergency response planning. The objectives of this study mainly focus on enhancing the open data ecosystem, and by employing the previously stated methods, we intend to advance it and evaluate the impact. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Artificial Intelligence; Collective Intelligence; Knowledge Graphs; LLM; Metadata Extraction; Open Data; Open Street Map; Search Engine},
	keywords = {Data mining; Decision making; Decision support systems; Ecosystems; Extraction; Metadata; Open Data; Search engines; Semantics; Collective intelligences; Data set; Decisions makings; Informed decision; Knowledge graphs; LLM; Meta-data extractions; Open datum; Open street map; Street maps; Knowledge graph},
	correspondence_address = {U. Ahmed; University of Camerino (UNICAM), Camerino, 9 Via Madonna delle Carceri, Italy; email: umairahmedq@gmail.com},
	editor = {Morichetta A. and University of Camerino, Via Madonna Delle Carceri 7, Camerino and Buchmann R.A. and University Babes-Bolyai, Sstr. T. Mihali 58-60, Cluj Napoca and Sandkuhl K. and Rostock University, Institute of Computer Science, Albert-Einstein Str. 22, Rostock and Sandkuhl K. and Jonkoping University, School of Engineering, Gjuterigatan 5, Jonkoping and Seigerroth U. and Jonkoping University, School of Engineering, Gjuterigatan 5, Jonkoping and Kirikova M. and Riga Technical University, Department of Artificial Intelligence and Systems Engineering, 6A Kipsalas Street, Riga and Moller C. and Aalborg University, Center for Industrial Production, Fibigerstraede 16, Aalborg and Forbrig P. and University of Rostock, Albert-Einstein-Str. 22, Rostock and Gutschmidt A. and University of Rostock, Albert-Einstein-Str. 22, Rostock and Ghiran A.-M. and Babes-Bolyai University, Strada Teodor Mihali, Nr. 58-60, Cluj-Napoca and Marcelletti A. and University of Camerino, Via Madonna delle Carceri 7, Camerino and Harer F. and University of Fribourg, Bd de Perolles 90, Fribourg and Re B. and University of Camerino, Via Madonna delle Carceri 7, Camerino and Johansson B.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Ehrhart2023,
	author = {Ehrhart, Thibault and Troncy, Raphaël and Shapira, David and Limoges, Bertrand},
	title = {Predicting Business Events from News Articles},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184379083&partnerID=40&md5=dcf23e7632470b9eeb02ab68aa0c0b08},
	affiliations = {EURECOM, Campus SophiaTech, France; Pairing Technology Capital, France},
	abstract = {This paper presents a comparative study of different approaches for predicting business events from news articles. We evaluate the effectiveness of zero-shot classification models that use Large Language Models (LLM), methods relying on NLI, and a supervised approach using a fine-tuned BERT-based classifier. We also propose a novel ensemble method that combines spaCy, CamemBERT, and FlairNLP models to semantically annotate the news articles in terms of named entities. We discuss the strengths and limitations of each family of approaches that contribute to the development of tools for accurate event prediction from news articles. The public demonstration available at https://jde-predict.tools.eurecom.fr/ enables the user to submit news articles and to visualize the extracted and predicted semantic annotations. In addition, a SPARQL interface is exposed enabling to search through annotations of news articles. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Business events prediction; Claude); LLM (GPT-4; NLI models; Zero-shot classification methods; ZeSTE},
	keywords = {Forecasting; HTTP; Natural language processing systems; Zero-shot learning; Business event prediction; Classification methods; Claude); Event prediction; Language model; Large language model (GPT-4; NLI model; Shot classification; Zero-shot classification method; ZeSTE; Semantics},
	correspondence_address = {T. Ehrhart; EURECOM, Campus SophiaTech, France; email: thibault.ehrhart@eurecom.fr},
	editor = {Fundulaki I. and Kozaki K. and Garijo D. and Gomez-Perez J.M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Diamantini2023,
	author = {Diamantini, Claudia and Mircoli, Alex and Potena, Domenico and Vagnoni, Simone},
	title = {An Experimental Comparison of Large Language Models for Emotion Recognition in Italian Tweets},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3606},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182938263&partnerID=40&md5=9adce81cc38e1d7e07116cdb5aa4e2ac},
	affiliations = {Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy},
	abstract = {In recent years, the advent of Large Language Models (LLMs), which are task-agnostic models trained on huge amounts of textual data, has given momentum to a wide variety of NLP applications, ranging from chatbots to sentiment classifiers. Currently, many LLMs are publicly available, each with different features and performance, and the selection of the best LLM for a specific task may be challenging. In this work, we focus on the task of emotion recognition in Italian social media content and we present an experimental comparison among three of the most popular LLMs: Google Bidirectional Encoder Representations from Transformers (BERT), OpenAI Generative Pre-trained Transformer 3 (GPT-3) and GPT-3.5. Model specialization in emotion recognition has been achieved by using two different approaches, namely fine-tuning and prompt engineering with few-shot task transfer. The experimentation has been performed on TwIT, a corpus of about 3100 Italian tweets annotated with respect to six emotions. The results show that fine-tuning GPT-3 leads to the best performance on the considered dataset, achieving a remarkable F1=0.90. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT; emotion recognition; emotion recognition in Italian; emotion recognition of tweets; few-shot learning; fine tuning; GPT-3; large language model; sentiment analysis},
	keywords = {Computational linguistics; Speech recognition; Bidirectional encoder representation from transformer; Emotion recognition; Emotion recognition in italian; Emotion recognition of tweet; Few-shot learning; Fine tuning; Generative pre-trained transformer 3; Language model; Large language model; Sentiment analysis; Emotion Recognition},
	correspondence_address = {A. Mircoli; Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy; email: a.mircoli@univpm.it},
	editor = {Bena N. and Di Martino B. and Maratea A. and Sperduti A. and Di Nardo E. and Ciaramella A. and Montella R. and Ardagna C.A.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14266 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177448280&partnerID=40&md5=5a6a808bf67cfb68607e7e3cb9533d1f},
	abstract = {The proceedings contain 58 papers. The special focus in this conference is on Semantic Web. The topics include: How is Your Knowledge Graph Used: Content-Centric Analysis of SPARQL Query Logs; iterative Geographic Entity Alignment with Cross-Attention; entity-Relation Distribution-Aware Negative Sampling for Knowledge Graph Embedding; negative Sampling with Adaptive Denoising Mixup for Knowledge Graph Embedding; comparison of Knowledge Graph Representations for Consumer Scenarios; a Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning; Compact Encoding of Reified Triples Using HDTr; causal Inference-Based Debiasing Framework for Knowledge Graph Completion; Can ChatGPT Replace Traditional KBQA Models? An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family; Dense Re-Ranking with Weak Supervision for RDF Dataset Search; mapping and Cleaning Open Commonsense Knowledge Bases with Generative Translation; integrating Knowledge Graph Embeddings and Pre-trained Language Models in Hypercomplex Spaces; LLMs4OL: Large Language Models for Ontology Learning; biomedical Knowledge Graph Embeddings with Negative Statements; knowledge Graph Enhanced Language Models for Sentiment Analysis; TemporalFC: A Temporal Fact Checking Approach over Knowledge Graphs; Assessing the Generalization Capabilities of Neural Machine Translation Models for SPARQL Query Generation; linking Tabular Columns to Unseen Ontologies; neural Multi-hop Logical Query Answering with Concept-Level Answers; ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs; Optimizing SPARQL Queries with SHACL; SORBET: A Siamese Network for Ontology Embeddings Using a Distance-Based Regression Loss and BERT; visualizing Mappings Between Pairwise Ontologies - An Empirical Study of Matrix and Linked Indented List in Their User Support During Class Mapping Creation and Evaluation; FeaBI: A Feature Selection-Based Framework for Interpreting KG Embeddings; CapsKG: Enabling Continual Knowledge Integration in Language Models for Automatic Knowledge Graph Completion; HAEE: Low-Resource Event Detection with Hierarchy-Aware Event Graph Embeddings; textual Entailment for Effective Triple Validation in Object Prediction.},
	editor = {Payne T.R. and Presutti V. and Qi G. and Poveda-Villalón M. and Stoilos G. and Hollink L. and Kaoudi Z. and Cheng G. and Li J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303147242-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Urrutia20233736,
	author = {Urrutia, Felipe and Buc, Cristian and Barriere, Valentin},
	title = {Deep Natural Language Feature Learning for Interpretable Prediction},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {3736 – 3763},
	doi = {10.18653/v1/2023.emnlp-main.229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184795426&doi=10.18653%2fv1%2f2023.emnlp-main.229&partnerID=40&md5=954aaefe45a62a5275a3a27b3d436e07},
	affiliations = {Centro Nacional de Inteligencia Artificial, Macul, Chile; Department of Computer Science, Universidad de Chile, Santiago, Chile},
	abstract = {We propose a general method to break down a main complex task into a set of intermediary easier sub-tasks, which are formulated in natural language as binary questions related to the final target task. Our method allows for representing each example by a vector consisting of the answers to these questions. We call this representation Natural Language Learned Features (NLLF). NLLF is generated by a small transformer language model (e.g., BERT) that has been trained in a Natural Language Inference (NLI) fashion, using weak labels automatically obtained from a Large Language Model (LLM). We show that the LLM normally struggles for the main task using in-context learning, but can handle these easiest subtasks and produce useful weak labels to train a BERT. The NLI-like training of the BERT allows for tackling zero-shot inference with any binary question, and not necessarily the ones seen during the training. We show that this NLLF vector not only helps to reach better performances by enhancing any classifier, but that it can be used as input of an easy-to-interpret machine learning model like a decision tree. This decision tree is interpretable but also reaches high performances, surpassing those of a pre-trained transformer in some cases. We have successfully applied this method to two completely different tasks: detecting incoherence in students' answers to open-ended mathematics exam questions, and screening abstracts for a systematic literature review of scientific papers on climate change and agroecology. ©2023 Association for Computational Linguistics.},
	keywords = {Climate change; Computational linguistics; Deep learning; Zero-shot learning; Break down; Feature learning; General method; Language features; Language inference; Language model; Natural languages; Performance; Subtask; Weak labels; Decision trees},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Haq20231,
	author = {Haq, Ijazul and Qiu, Weidong and Guo, Jie and Tang, Peng},
	title = {Pashto offensive language detection: a benchmark dataset and monolingual Pashto BERT},
	year = {2023},
	journal = {PeerJ Computer Science},
	volume = {9},
	pages = {1 – 26},
	doi = {10.7717/PEERJ-CS.1617},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175080058&doi=10.7717%2fPEERJ-CS.1617&partnerID=40&md5=5d59196a36fa17241d5216860a68eee2},
	affiliations = {School of Cyber Science and Engineering, Shanghai Jiao Tong University, Minhang, Shanghai, China},
	abstract = {Social media platforms have become inundated with offensive language. This issue must be addressed for the growth of online social networks (OSNs) and a healthy online environment. While significant research has been devoted to identifying toxic content in major languages like English, this remains an open area of research in the low-resource Pashto language. This study aims to develop an AI model for the automatic detection of offensive textual content in Pashto. To achieve this goal, we have developed a benchmark dataset called the Pashto Offensive Language Dataset (POLD), which comprises tweets collected from Twitter and manually classified into two categories: ‘‘offensive’’ and ‘‘not offensive’’. To discriminate these two categories, we investigated the classic deep learning classifiers based on neural networks, including CNNs and RNNs, using static word embeddings: Word2Vec, fastText, and GloVe as features. Furthermore, we examined two transfer learning approaches. In the first approach, we fine-tuned the pre-trained multilingual language model, XLM-R, using the POLD dataset, whereas, in the second approach, we trained a monolingual BERT model for Pashto from scratch using a custom-developed text corpus. Pashto BERT was then fine-tuned similarly to XLM-R. The performance of all the deep learning and transformer learning models was evaluated using the POLD dataset. The experimental results demonstrate that our pre-trained Pashto BERT model outperforms the other models, achieving an F1-score of 94.34% and an accuracy of 94.77%. © 2023 Haq et al.},
	author_keywords = {BERT; Large language models; LLMs; Low-resource languages; NLP; Offensive language detection; Osn; Pashto; Social media; Text processing},
	keywords = {Computational linguistics; Deep learning; Large dataset; Learning systems; Natural language processing systems; Social networking (online); Transfer learning; BERT; Language detection; Language model; Large language model; LLM; Low resource languages; Offensive language detection; Offensive languages; Osn; Pashto; Social media; Text-processing; Text processing},
	correspondence_address = {I. Haq; School of Cyber Science and Engineering, Shanghai Jiao Tong University, Shanghai, Minhang, China; email: hanjie@sjtu.edu.cn},
	publisher = {PeerJ Inc.},
	issn = {23765992},
	language = {English},
	abbrev_source_title = {PeerJ Comput. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@CONFERENCE{2023,
	title = {EEKE-AII 2023 - Proceedings of Joint Workshop of the 4th Extraction and Evaluation of Knowledge Entities from Scientific Documents and the 3rd AI + Informetrics, co-located with the JCDL 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3451},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169431194&partnerID=40&md5=f8a16832d2a6cc1d12adfd68f26952e5},
	abstract = {The proceedings contain 14 papers. The topics discussed include: an approach for identifying complementary patents based on deep learning; functional structure recognition of scientific documents in information science; linkages among science, technology, and industry; the impact of interdisciplinarity and entity characteristics on the clinical translation intensity of COVID-19 papers; LLM-based entity extraction is not for cybersecurity; characterizing emerging technologies of global digital humanities using scientific method entities; identifying potential sleeping beauties based on dynamic time warping algorithm; scientific knowledge combination in networks: new perspectives on analyzing knowledge absorption and integration; and sentiment classification of scientific citation based on modified BERT attention by sentiment dictionary.},
	editor = {Zhang C. and Nanjing University of Science and Technology, No. 200, Xiaolinvgwei, Nanjing and Zhang Y. and University of Technology Sydney, Australian Artificial Intelligence Institute, 15 Broadway, Ultimo, NSW and Mayr P. and GESIS - Leibniz-Institute for the Social Sciences, Unter Sachsenhausen 6-8, Cologne and Lu W. and Suominen A. and Chen H. and Ding Y.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Haq20231344,
	author = {Haq, Ijazul and Qiu, Weidong and Guo, Jie and Tang, Peng},
	title = {NLPashto: NLP Toolkit for Low-resource Pashto Language},
	year = {2023},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {14},
	number = {6},
	pages = {1344 – 1352},
	doi = {10.14569/IJACSA.2023.01406142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168805516&doi=10.14569%2fIJACSA.2023.01406142&partnerID=40&md5=ff2bfef5f9bc8652639cd8283ecdcd54},
	affiliations = {School of Cyber Science and Engineering, Shanghai Jiao Tong University, China},
	abstract = {In recent years, natural language processing (NLP) has transformed numerous domains, becoming a vital area of research. However, the focus of NLP studies has predomi-nantly centered on major languages like English, inadvertently neglecting low-resource languages like Pashto. Pashto, spoken by a population of over 50 million worldwide, remains largely unexplored in NLP research, lacking off-the-shelf resources and tools even for fundamental text-processing tasks. To bridge this gap, this study presents NLPashto, an open-source and publicly accessible NLP toolkit specifically designed for Pashto. The initial version of NLPashto introduces four state-of-the-art models for Spelling Correction, Word Segmentation, Part-of-Speech (POS) Tagging, and Offensive Language Detection. The toolkit also includes essential NLP resources like pre-trained static word embeddings, Word2Vec, fastText, and GloVe. Furthermore, we have pre-trained a monolingual language model for Pashto from scratch, using the Bidirectional Encoder Representations from Transformers (BERT) architecture. For the training and evaluation of all the models, we have developed several benchmark datasets and also included them in the toolkit. Experimental results demonstrate that the models exhibit satisfactory perfor-mance in their respective tasks. This study can be a significant milestone and will hopefully support and speed-up future research in the field of Pashto NLP. © (2023), All Rights Reserved.},
	author_keywords = {BERT; CNNs; CRF; LLMs; low-resource languages; NLP; Pashto; POS tagging; RNNs; text processing; word segmentation},
	keywords = {Bridges; Computational linguistics; Natural language processing systems; Syntactics; Bidirectional encoder representation from transformer; CRF; Language processing; LLM; Low resource languages; Natural language processing; Natural languages; Part of speech tagging; Parts-of-speech tagging; Pashto; RNN; Text-processing; Word segmentation; Text processing},
	publisher = {Science and Information Organization},
	issn = {2158107X},
	language = {English},
	abbrev_source_title = {Intl. J. Adv.  Comput. Sci. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}
